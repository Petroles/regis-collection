<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.22086</field>
		<field name="filename">5996_MenezesJunior_LuizFerreira_D.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">
UNIVERSIDADE ESTADUAL DE CAMPINAS

FACULDADE DE ENGENHARIA MECÂNICA

COMISSÃO DE PÓS-GRADUAÇÃO EM ENGENHARIA MECÂNICA

Processamento de Imagens na Análise 
Dinâmica de Risers de Produção de Petróleo 

com Modelo de Escala Reduzida 
em Ambiente de Laboratório

Autor: Luiz Ferreira Menezes Junior

Orientador: Paulo Roberto Gardel Kurka

09/2009



UNIVERSIDADE ESTADUAL DE CAMPINAS

FACULDADE DE ENGENHARIA MECÂNICA

COMISSÃO DE PÓS-GRADUAÇÃO EM ENGENHARIA MECÂNICA

DEPARTAMENTO DE PROJETO MECÂNICO

Processamento de Imagens na Análise 
Dinâmica de Risers de Produção de Petróleo 

com Modelo de Escala Reduzida 
em Ambiente de Laboratório

Autor: Luiz Ferreira Menezes Junior

Orientador: Paulo Roberto Gardel Kurka

Curso: Engenharia Mecânica 

Área de Concentração: Mecânica dos Sólidos e Projeto Mecânico

Tese de doutorado apresentada à comissão de Pós Graduação da Faculdade de Engenharia 

Mecânica, como requisito para a obtenção do título de Doutor em Engenharia Mecânica.

Campinas,  2008
SP – Brasil

i



FICHA  CATALOGRÁFICA  ELABORADA  PELA 

  BIBLIOTECA  DA  ÁREA  DE  ENGENHARIA  E  ARQUITETURA  -  BAE  -  UNICAMP

    M524p
Menezes Junior, Luiz Ferreira
     Processamento de imagens na análise dinâmica de 
risers de produção de petróleo com modelo de escala 
reduzida em ambiente de laboratório / Luiz Ferreira 
Menezes Junior. --Campinas, SP: [s.n.], 2008.

     Orientador: Paulo Roberto Gardel Kurka.
     Tese de Doutorado - Universidade Estadual de 
Campinas, Faculdade de Engenharia Mecânica.

     1. Processamento de Imagens.  2. Processamento de 
Sinais.  3. Visão por computador.  4. Engenharia de 
petróleo.  I. Kurka, Paulo Roberto Gardel.  II. 
Universidade Estadual de Campinas. Faculdade de 
Engenharia Mecânica.  III. Título.

Título em Inglês: Image processing in dynamic analysis of risers of petroleum 
production with reduced-scale model in a laboratory 
environment

Palavras-chave em Inglês: Image processing, Signal processing, Computer 
Vision, Petroleum engineering

Área de concentração: Mecânica dos Sólidos e Projeto Mecânico

Titulação: Doutor em Engenharia Mecânica

Banca examinadora: Sérgio Nascimento Bordalo, Niederauer Mastelari, João 
Antônio Pereira, Renê Pegoraro

Data da defesa: 31/07/2008

Programa de Pós Graduação: Engenharia Mecânica

ii



UNIVERSIDADE ESTADUAL DE CAMPINAS

FACULDADE DE ENGENHARIA MECÂNICA

COMISSÃO DE PÓS-GRADUAÇÃO EM ENGENHARIA MECÂNICA

DEPARTAMENTO DE PROJETO MECÂNICO

TESE DE DOUTORADO

Processamento de Imagens na Análise Dinâmica de Risers de Produção de 
Petróleo com Modelo de Escala Reduzida em Ambiente de Laboratório

Autor: Luiz Ferreira Menezes Junior

Orientador: Paulo Roberto Gardel Kurka

A Banca Examinadora composta pelos membros abaixo aprovou esta Tese:

Campinas, 31 de Julho de 2008.

iii



DEDICATÓRIA:

Dedico este trabalho à minha esposa Bianka e meus filhos Luigi e Pietro.

iv



AGRADECIMENTOS

Este  trabalho não poderia ser terminado  sem a ajuda de diversas  pessoas  e entidades  às 

quais presto meus agradecimentos: 

 
– Prof.  Dr.  Paulo  Roberto  Gardel  Kurka,  pelo  trabalho  de  orientação  e  complementação  de 

meus conhecimentos, sem o qual não seria possível a conclusão deste trabalho.

– Prof. Dr. Sérgio  Bordalo, pelo  acompanhamento e dedicação ao trabalho desenvolvido em 
laboratório;

– CAPES, pela bolsa de doutorado durante a vigência do desenvolvimento do projeto;

– PETROBRAS,  pela  disponibilização  dos  conhecimentos  e  recursos  para  a  construção  e 
montagem dos equipamentos em laboratório;

– Minha família, pela paciência e apoio moral nos momentos mais difíceis;

– Ms. Carlos Roberto Mingoto Junior pela ajuda na busca dos procedimentos 3D;

– César  Calvante  e  Paulo  Guilger  Valdivia  pela  ajuda  na  captura  dos  dados,  montagem  e 
utilização do laboratório;

 
– Departamento  de  Projeto  Mecânico/FEM,  pela  disponibilização  do  laboratório  e 

dependências para a captura de dados simulados do modelo utilizado;

v



“As Conquistas não são tão prazerosas quanto

os caminhos que levam até ela.”

vi



RESUMO

Menezes  Jr.,  Luiz  Ferreira, “Processamento  de  imagens  na  análise  dinâmica  de  risers  de  

produção  de  petróleo  com  modelo  de  escala  reduzida  em  ambiente  de  laboratório”, 

Campinas: Faculdade de Engenharia Mecânica, Universidade Estadual de Campinas, 2008. 

127p. Tese (Doutorado)

Este trabalho apresenta o desenvolvimento de uma técnica para  o registro e processamento 

dos  sinais  de  movimento  de  um  modelo  reduzido  de  riser de  produção  de  petróleo,  com  a 

utilização de câmeras. O processo se baseia na utilização de alvos fixados no modelo do riser e a 

detecção de sua posição no espaço. A aplicação da técnica proposta é baseada em uma seqüência 

de  imagens  capturadas  do  alvo,  que  informa  a  sua  localização  e  padrão  de  movimento.  É 

construído um software de processamento de imagens para a aplicação em laboratório. Este tem 

sua robustez verificada através de imagens geradas em software de simulação de ambiente 2D/3D 

virtual e de uma aplicação prática. A técnica utiliza conceitos de análise de imagens 2D e 3D, 

morfologia, visão computacional e processamento de sinais.

Palavras Chave

Processamento  de  imagens  2D,  processamento  de  imagens  3D,  visão  computacional, 

morfologia, processamento de sinais, Riser de produção de petróleo.

vii



ABSTRACT

Menezes Jr., Luiz Ferreira, “Image processing in dynamic analysis of petroleum riser production  

with  a  reduced  scale  model  on  laboratory  environment”,  Campinas:  Mechanical 

Engineering Faculty at State University of Campinas, 2008. 1257. Thesis (doctor degree)

This  work  develops  a  technique  for  recording  and  processing  the  signals  of 

movement of a reduced oil producing riser, with the use of optical cameras. It is based on the use 

of targets attached to the riser model, and the detection of its position in space. The application of 

the proposed technique is based on the sequence of images captured from the target, which are 

indicators of its position and pattern of movement. An image processing software is built with the 

purpose  of  laboratory  usage.  The  validation  of  the  software  with  the  proposed  technique  is 

verified through 2D/3D virtual simulations as well as a practical application. The technique uses 

2D/3D image analysis concepts, morphology, computer vision and signal processing.

Key Words

Image processing 2D, image  processing  3D,  signal  processing,  computer  vision, 

morphology, Fourier transform, petroleum riser production.

viii



ÍNDICE

Lista de Figuras .................................................................................................................... xii
Lista de Tabelas .................................................................................................................... xvii
Nomenclatura ....................................................................................................................... xviii

Capítulo 1 – Introdução ....................................................................................................... 1
1.1. Objetivos propostos no projeto ........................................................................... 5
1.2. Contexto da Pesquisa .......................................................................................... 5
1.3. Descrição da estrutura do presente trabalho ....................................................... 6

Capítulo 2 – Processamento de Sinais ................................................................................. 7
2.1. O princípio da amostragem de Nyquist ............................................................... 8
2.2. Freqüência máxima de um sinal .......................................................................... 9
2.3. Janelas Espectrais …............................................................................................ 10
2.4. A Transformada de Fourier .................................................................................. 10
2.5. A Transformada Fourier de um sinal periódico ................................................... 11
2.6. Correção de atraso de ?t com Interpolação Spline ............................................. 12

Capítulo 3 – Processamento de Imagens ............................................................................. 16
3.1. Formação da Imagem .......................................................................................... 16
3.2. Modelo de Cores ................................................................................................. 18

3.2.1. RGB ........................................................................................................ 18
3.2.2. YUV e Tons de Cinza .............................................................................. 19
3.2.3. CMYK ..................................................................................................... 20

ix



3.2.4. HSV ......................................................................................................... 21
3.2.5. HSL ......................................................................................................... 22

3.3. Correção da distorção da lente ............................................................................ 23
3.4. Remoção de Ruídos ............................................................................................. 25
3.5. Corte – Thresholding ........................................................................................... 25
3.6. Equalização de Histogramas ............................................................................... 27
3.7. Remoção de objetos pequenos e Fechamento ..................................................... 29

3.7.1. Elemento de estrutura ............................................................................. 30
3.7.2. Erosão e Remoção de objetos Pequenos ................................................. 30
3.7.3. Dilatação e Fechamento .......................................................................... 31

Capítulo 4 – Extração de parâmetros da imagem ................................................................ 34
4.1. Caixa de contorno ................................................................................................ 34
4.2. Cálculo do centro de objetos ............................................................................... 36
4.3. Cálculo do Ângulo entre dois pontos .................................................................. 38
4.4. Cálculo do Ponto Médio ...................................................................................... 39
4.5. Cálculo da distância em metros do ponto médio em relação a origem ............... 39
4.6. Cálculo do deslocamento médio ......................................................................... 41
4.7. Correlação de imagens estéreo (3D) ................................................................... 42

Capítulo 5 - Riser de Petróleo e Modelo em escala ............................................................. 47
5.1. Construção do modelo em escala ........................................................................ 48
5.2. Hardware de Captura ........................................................................................... 55

Capítulo 6 – Sistema de Captura e Processamento de Imagens ........................................... 57
6.1. Aplicativo de Captura .......................................................................................... 57
6.2. Aplicativo de Processamento de Imagens ........................................................... 59
6.3. NI-Vision Assistant .............................................................................................. 61

Capítulo 7 – Simulação e Aplicação das Técnicas de Processamento ................................. 69
7.1. Simulação através do software 3D Studio Max .................................................. 69
7.2. Simulação do Riser em movimento 2D ............................................................... 71

x



7.2.1. Simulação do Riser em movimento a 1Hz .............................................. 72
7.2.2. Simulação do Riser em movimento a 2Hz .............................................. 73
7.2.3. Simulação do Riser em movimento com 1 Hz e 2 Hz ............................ 75

7.3. Comparação de dados entre acelerômetro e câmera ........................................... 77
7.3.1. Caso 01 .................................................................................................... 79
7.3.2. Caso 02 .................................................................................................... 81
7.3.3. Caso 03 .................................................................................................... 83
7.3.4. Caso 04 .................................................................................................... 86
7.3.5. Caso 05 .................................................................................................... 88
7.3.6. Caso 06 .................................................................................................... 90
7.3.7. Comparação de erro do ?t ....................................................................... 92

7.4. Simulação do Riser em movimento 3D ............................................................... 93

Capítulo 8 – Conclusão ........................................................................................................ 99
8.1. Sugestões para desenvolvimento futuro .............................................................. 100

Referências bibliográficas .................................................................................................... 101

Anexo I ................................................................................................................................ 107

xi



LISTA DE FIGURAS

2.1 – O efeito de aliasing na amostragem incorreta de um sinal ........................................................ 9

2.2 – Janelamento de um sinal …........................................................................................................ 10

2.3 – Transformada de Fourier da função x(t) com janela Hanning …............................................... 11

2.4 – Diagrama demonstrativo de Nyquist a esquerda e Bode a direita ............................................. 13

2.5 – Sinal amostrado com ?t variante ............................................................................................... 15

2.6 – Sinal amostrado com ?t variante e sua interpolação Spline ...................................................... 15

3.1 – Formação de uma imagem em um CCD .................................................................................... 17

3.2 – Exemplo de uma imagem digital ............................................................................................... 17

3.3 – Adição dos componentes RGB, distribuídos em 2D a esquerda e em 3D a direita ................... 18

3.4 – Decomposição de uma imagem em seus componentes RGB .................................................... 19

3.5 – Decomposição de uma imagem RGB no componente Y ........................................................... 20

3.6 – Subtração dos componentes CMY ............................................................................................. 20

3.7 – Componentes CMY .................................................................................................................... 21

3.8 – Componentes CMYK ................................................................................................................. 21

3.9 – Distribuição das cores no modelo HSV ..................................................................................... 21

3.10 – Aumento da saturação para três níveis de brilho ...................................................................... 22

3.11 – Aumento do brilho para três níveis de saturação ..................................................................... 22

3.12 – Esfera de componentes HSL .................................................................................................... 22

3.13 – À esquerda distorção côncava e a direita distorção convexa ................................................... 23

3.14 – A esquerda matriz de círculos, ao centro imagem sem correção, a direita imagem corrigida.. 24

3.15 – A esquerda matriz sem correção, a direita matriz corrigida ..................................................... 24

3.16 – A esquerda imagem sem correção, a direita imagem corrigida ................................................ 24

3.17 – A esquerda imagem com ruído, a direita imagem após remoção de ruídos, em tons de cinza. 25

3.18 – A esquerda imagem original, a direita imagem após Thresholding no nível 127 .................... 26

xii



3.19 – Thresholding RGB com três faixas de corte ............................................................................ 26

3.20 – A esquerda imagem original, a direita imagem após Thresholding ......................................... 26

3.21 – Imagem com baixo contraste ................................................................................................... 27

3.22 – Histograma e Gráfico das freqüências acumuladas ................................................................. 28

3.23 – Imagem com histograma equalizado ........................................................................................ 28

3.24 – Histograma equalizado e o novo gráfico de freqüências acumuladas ..................................... 29

3.25 – A esquerda imagem original, a direita imagem com histograma equalizado ........................... 29

3.26 – Elementos de estruturação em Cruz, Quadrado e Hexágono ................................................... 30

3.27 – Efeito da erosão em uma imagem binária ................................................................................ 31

3.28 – Efeito da erosão em uma imagem colorida .............................................................................. 31

3.29 – A esquerda sem erosão, a direita efeito da erosão no alvo com estrutura 5x5 (em detalhe) .... 31

3.30 – Efeito da dilatação em uma imagem binária ............................................................................ 32

3.31 – Efeito da dilatação em uma imagem colorida .......................................................................... 32

3.32 – Efeito do fechamento de uma imagem binária com elemento de estrutura quadrado 7x7 ...... 33

3.33 – A esquerda imagem original, a direita imagem fechada (em detalhe) ..................................... 33

4.1 – Detecção de bordas para determinação da caixa de contorno .................................................... 35

4.2 – Pixels (em vermelho) com valores máximos e mínimos para cada objeto ................................ 35

4.3 – Caixa de contorno 2D definida por objeto e o método aplicado na imagem alvo ..................... 36

4.4 – Centro do objeto definido pelo cruz. das retas formada pelos pontos da caixa de contorno ..... 37

4.5 – Centro do objeto definido pela média dos valores de X e Y e aplicado no alvo ........................ 38

4.6 – Ângulo definido pelos pontos A e B e aplicado no alvo ............................................................ 38

4.7 – Ponto médio definido pela média dos valores de X e Y e aplicado no alvo .............................. 39

4.8 – Distância calculada através dos pontos A e B e aplicado no alvo .............................................. 40

4.9 – Distância em pixels do ponto médio em relação à origem ........................................................ 40

4.10 – Imagem seqüencial ................................................................................................................... 41

4.11 – Deslocamento do ponto médio em metros a esquerda e com interpolação spline a direita ..... 41

4.12 – Deslocamento do ponto médio com interp. spline a esquerda e subtraído da média à direita.. 42

4.13 – Câmera com resolução MxN e seu foco .................................................................................. 43

4.14 – Projeção de um ponto P em uma câmera ................................................................................. 43

4.15 – Projeção de um ponto P em uma câmera ................................................................................. 44

4.16 – Triângulos diretamente proporcionais ...................................................................................... 44

4.17 – Projeção do ponto P em duas câmeras deslocadas em Tx ........................................................ 45

4.18 – Visão topo à esquerda, lateral ao centro e frontal à direita ...................................................... 45

5.1 – Esquema de um Riser de produção de petróleo ......................................................................... 47

xiii



5.2 – Imagens do LabPetro ................................................................................................................. 48

5.3 – Disposição do laboratório LabPetro ........................................................................................... 49

5.4 – Foto da mangueira utilizada para simulação de um riser .......................................................... 50

5.5 – Representação esquemática do sistema experimental ............................................................... 51

5.6 – Tubulação de ar-água e seus manômetros digitais ..................................................................... 51

5.7 – Desenho esquemático do injetor ................................................................................................ 52

5.8 – Imagens do injetor ..................................................................................................................... 52

5.9 – Imagens do duto flexível em catenária ...................................................................................... 53

5.10 – Imagens da célula de carga ...................................................................................................... 53

5.11 – Câmeras fixadas paralelas ao modelo ...................................................................................... 54

5.12 – Duto flexível com alvos laranja ............................................................................................... 55

5.13 – Câmeras USB utilizadas na captura de imagens ...................................................................... 56

6.1 – Aplicativo de captura de câmeras ............................................................................................... 58

6.2 – Fluxograma simplificado de execução do aplicativo de captura ............................................... 59

6.3 – Tela do aplicativo de processamento de imagens ...................................................................... 60

6.4 – Tela de configuração de Thresholding ....................................................................................... 61

6.5 – Tela inicial do NI-Vision Assistant ............................................................................................ 62

6.6 – Imagem aberta para processamento ........................................................................................... 62

6.7 – Processamento de Thresholding ................................................................................................. 63

6.8 – Seleção da área de interesse de Thresholding ............................................................................ 63

6.9 – Seleção da faixa de corte de Thresholding ................................................................................. 64

6.10 – Thresholding aplicado .............................................................................................................. 64

6.11 – Erosão 5x5 dos objetos para remoção de objetos pequenos .................................................... 65

6.12 – Dilatação 5x5 dos objetos para fechamento ............................................................................. 65

6.13 – Identificação de objetos ........................................................................................................... 66

6.14 –Análise de objetos ..................................................................................................................... 66

6.15 – Análise de objetos com resultados de Distância, Ângulo e Ponto Médio ................................ 67

6.16 – Processo finalizado .................................................................................................................. 67

6.17 – Seqüência executada ................................................................................................................ 68

7.1 – Interface gráfica do aplicativo de computação gráfica 3D Studio Max .................................... 70

7.2 – Curva de deslocamento do sistema em detalhe (cm) ................................................................. 71

7.3 – Curva contínua do deslocamento em Z do sistema (cm) ........................................................... 71

7.4 – Quadros seqüenciais da simulação ............................................................................................ 72

7.5 – Freqüência de 1Hz, com deslocamento em Z de +/- 15cm ........................................................ 72

xiv



7.6 – Sinal de 1 Hz recuperado através do aplicativo de processamento de imagens ........................ 73

7.7 – Freqüência de 1 Hz encontrada através da Transformada de Fourier ........................................ 73

7.8 – Freqüência de 2 Hz, com deslocamento em Z de +/- 15cm ....................................................... 74

7.9 – Sinal de 2 Hz recuperado através do aplicativo de processamento de imagens ........................ 74

7.10 – Freqüência de 1 Hz encontrada através da Transformada de Fourier ...................................... 75

7.11 – Freqüência de 1Hz combinada com 2 Hz, com deslocamento em Z de +/- 26,2cm ................ 76

7.12 – Sinal de 1Hz combinada a 2 Hz recuperado através do aplicativo de proc. de imagens ......... 76

7.13 – Freqüência de 1 Hz combinada a 2Hz encontradas através da Transformada de Fourier ....... 76

7.14 – Deslocamento obtido através do processamento de 5 (cinco) alvos ........................................ 77

7.15 – Freqüências obtidas através do processamento de 5 (cinco) alvos .......................................... 77

7.16 – Modelo em escala com alvos e acelerômetro fixado próximo ao centro ................................. 78

7.17 – Quadros seqüenciais da captura ............................................................................................... 78

7.18 – Amostragem do sinal com acelerômetro .................................................................................. 79

7.19 – Amostragem do sinal com câmera ........................................................................................... 79

7.20 – Transformada de Fourier do sinal do acelerômetro ................................................................. 80

7.21 – Transformada de Fourier do sinal da câmera ........................................................................... 80

7.22 – Variação do ?t de captura da câmera ....................................................................................... 81

7.23 – Amostragem do sinal com acelerômetro .................................................................................. 81

7.24 – Amostragem do sinal com câmera ........................................................................................... 82

7.25 – Transformada de Fourier do sinal do acelerômetro ................................................................. 82

7.26 – Transformada de Fourier do sinal da câmera ........................................................................... 82

7.27 – Variação do ?t de captura da câmera ....................................................................................... 83

7.28 – Amostragem do sinal com acelerômetro .................................................................................. 84

7.29 – Amostragem do sinal com câmera ........................................................................................... 84

7.30 – Transformada de Fourier do sinal do acelerômetro ................................................................. 84

7.31 – Transformada de Fourier do sinal da câmera ........................................................................... 85

7.32 – Variação do ?t de captura da câmera ....................................................................................... 85

7.33 – Amostragem do sinal com acelerômetro .................................................................................. 86

7.34 – Amostragem do sinal com câmera ........................................................................................... 86

7.35 – Transformada de Fourier do sinal do acelerômetro ................................................................. 87

7.36 – Transformada de Fourier do sinal da câmera ........................................................................... 87

7.37 – Variação do ?t de captura da câmera ....................................................................................... 88

7.38 – Amostragem do sinal com acelerômetro .................................................................................. 88

7.39 – Amostragem do sinal com câmera ........................................................................................... 89

xv



7.40 – Transformada de Fourier do sinal do acelerômetro ................................................................. 89

7.41 – Transformada de Fourier do sinal da câmera ........................................................................... 89

7.42 – Variação do ?t de captura da câmera ....................................................................................... 90

7.43 – Amostragem do sinal com acelerômetro .................................................................................. 91

7.44 – Amostragem do sinal com câmera ........................................................................................... 91

7.45 – Transformada de Fourier do sinal do acelerômetro ................................................................. 91

7.46 – Transformada de Fourier do sinal da câmera ........................................................................... 92

7.47 – Variação do ?t de captura da câmera ....................................................................................... 92

7.48 – Erro médio x Freqüência à esquerda e Erro médio x Resolução à direita ............................... 93

7.49 – Interface gráfica do aplicativo de computação gráfica 3D Studio Max para duas câmeras .... 94

7.50 – Alvos após Thresholding vistos pela Câmera 01 à esquerda e pela Câmera 02 à direita ........ 95

7.51 – Alvos conhecidos utilizados para calibração da câmera .......................................................... 95

10.1 – Acelerômetro PCB 320C33 ..................................................................................................... 108

xvi



LISTA DE TABELAS

5.1 – Tabela de dados técnicos das câmeras utilizadas ...................................................................... 54

6.1 – Arquivo de configuração da captura .......................................................................................... 56

7.1 – Posição dos objetos no simulador ............................................................................................. 69

7.2 – Pontos de configuração de deslocamento .................................................................................. 70

7.3 – Pontos de configuração de deslocamento .................................................................................. 72

7.4 – Pontos de configuração de deslocamento .................................................................................. 73

7.5 – Planilha de trabalho ................................................................................................................... 76

7.6 – Tabela de configuração e cálculo do ?t para o caso 01 ............................................................. 77

7.7 – Tabela de configuração e cálculo do ?t para o caso 02 ............................................................. 79

7.8 – Tabela de configuração e cálculo do ?t para o caso 03 ............................................................. 81

7.9 – Tabela de configuração e cálculo do ?t para o caso 04 ............................................................. 84

7.10 – Tabela de configuração e cálculo do ?t para o caso 05 ........................................................... 86

7.11 – Tabela de configuração e cálculo do ?t para o caso 06 ........................................................... 88

7.12 – Compilação das tabelas de configuração e cálculo do ?t para todas as capturas .................... 91

7.13 – Posição dos objetos com duas câmeras no simulador ............................................................. 92

7.14 – Posição conhecida dos alvos utilizado para calibração da câmera .......................................... 93

7.15 – Comparação dos valores gerados no 3D Studio com os valores recuperados do Alvo 01 ...... 95

7.16 – Comparação dos valores gerados no 3D Studio com os valores recuperados do Alvo 02 ...... 96

7.17 – Comparação dos valores de erro de posicionamento dos alvos .............................................. 96

xvii



NOMENCLATURA

Siglas

CCD – Charged Couple Device

CEPETRO – Centro de Estudos do Petróleo

CMYK – Cyan, Magenta, Yellow, Key

DPM – Departamento de Projeto Mecânico

JPEG – Joint Picture Experts Group

HSL – Hue, Saturation, Luminosity

HSV – Hue, Saturation, Value

LABPETRO – Laboratório de Petróleo

PETROBRAS – Petróleo Brasileiro S/A

RGB – Red, Green, Blue

xviii



Capítulo 1

Introdução

Muitas  das  tarefas  executadas  pelo  homem  são  baseadas  principalmente  no  sentido  da 

visão. Através da visão é possível identificar, classificar e compreender as coisas que o cercam. A 

interpretação  visual  do  mundo  é  algo  natural  ao  ser  humano,  mas  é  de  difícil  representação 

computacional.  A  tecnologia  atualmente  disponível  tem  colaborado  significativamente  na 

ampliação da capacidade da visão humana, bem como vem produzindo ferramentas que servem 

de apoio à tomadas  de decisão, ou mesmo,  na  substituição da intervenção humana em algum 

processo. 

Quando se tenta dar a uma máquina o sentido da visão, se está preocupado em como uma 

cena deve ser interpretada. Assim, a visão computacional trata de um conjunto de eventos que 

operam em seqüência desde a captura da imagem de uma cena, passando pela sua decodificação 

através de um processamento da imagem, de onde são extraídas as informações importantes para 

a interpretação de algum evento, até a execução de alguma ação de interação com o evento. 

As ferramentas computacionais que operam com imagens digitais são usadas em função de 

duas necessidades fundamentais. Primeiro, na melhoria da imagem para interpretação humana, no 

que  diz  respeito  a  correção  de  iluminação  e  distorções,  suavização  de  regiões,  detecção  de 

contornos, entre outros. Segundo, o processamento das imagens para interpretação computacional 

que trata do processo de aquisição e formação da imagem para guiar um processo automatizado. 

1



Muitas  tecnologias  relacionadas  aos  sistemas  de  visão  computacional  e  processamento  de 

imagens  têm  sido  utilizadas  com  sucesso  em  aplicações  relevantes  na  análise  dinâmica  de 

estruturas,  manufatura  assistida,  robótica  de  manipuladores,  robótica  móvel  e  em  sistemas 

produtivos.  Estas  aplicações  utilizam  diversas  ferramentas  computacionais  para  o  pré-

processamento, segmentação de imagens e identificação de objetos. Dentre as diversas aplicações 

da visão computacional, a análise dinâmica de estruturas aparece como um campo de pesquisa de 

grande interesse. 

Como  a  indústria  em  geral  tem  interesse  em  ter  seus  processos  automatizados,  muitas 

ferramentas matemáticas e computacionais vem sendo propostas. O processamento e a análise de 

imagens criam uma ciência que permite manipular, analisar e modificar imagens digitais, a partir 

de procedimentos que envolvem, morfologia matemática [Facon, 1996] e [Hasan, 2000]; técnicas 

para  o  processamento  de  informação  geométrica  e  estatística  [Shen,  2000];  análise  de 

componentes principais [Zhang, 2001]; algoritmos de processamento de imagens implementados 

em  hardware  [Spitz,  2000]  e  [Gasteratos,  2000];  transformada  rápida  de  Fourier  [Oppenheim, 

1989];  extração  de  características  (features)  [Gordon,  1984];  wavelets em  [Quak,  1994],  e 

paradigmas  da  inteligência  computacional,  tais  como  redes  neurais  [Augusteijn,  1996], 

algoritmos genéticos [Wang, 2001], e sistemas nebulosos [Cheng, 2000], entre outros. Assim, os 

sistemas de visão artificial contemplam um conjunto de técnicas e metodologias que dão suporte 

ao desenvolvimento de produtos confiáveis ou processos suficientemente eficientes, que possam 

ser empregados em situações práticas de um ambiente de laboratório ou industrial. 

Os sistemas de visão podem operar com uma ou mais câmeras, e que podem ser móveis ou 

fixas  [Motta,  2002].  Embora  seja  possível  se  ter  uma  idéia  do  mundo  3D  usando  uma  única 

imagem,  por  um  processo  direcionado  de  segmentação  [Ryoo,  2004],  procedimentos  mais 

consistentes podem ser obtidos a partir de duas imagens. Este trabalho é baseado num sistema de 

visão 2D usando apenas uma câmera, e 3D usando pares de imagens, obtidas a partir de duas 

câmeras.

Devido  às  particularidades  e ao conjunto de restrições  de cada aplicação, as  tecnologias 

2



usadas em visão computacional são direcionadas a solução de um problema específico, adaptando 

o conjunto de ferramentas matemáticas e os sistemas computacionais para a resolução de cada 

tipo de problema. Não é possível ter um sistema de visão genérico que possa ser usado em vários 

propósitos,  mas  a  aplicação  de  várias  técnicas  de  modo  escalonado  permite  dar  solução  aos 

problemas  mais  complexos.  Um  desses  problemas  é  relativo  à  recuperação  da  informação  da 

posição  tridimensional  de  objetos  a  partir  de  imagens.  A  determinação  de  dados  em  três 

dimensões (3D) a partir de imagens em duas dimensões (2D) é uma área atual e importante em 

visão computacional e  sujeito  de um grande  número de estudos  atuais.  Um sistema  de visão 

computacional recupera informações sobre uma cena a partir de suas projeções bidimensionais. 

Como  as  imagens  são  projeções  bidimensionais  do  mundo  real  tridimensional,  qualquer 

informação sobre a cena não é obtida diretamente, mas, através de uma estimação [Jain, 1995].

  Existem problemas bem definidos relacionado com a obtenção da informação 3D de uma 

cena. O primeiro problema é chamado localização de correspondência (stereo matching), que é a 

forma de estabelecer uma correlação entre duas  imagens do mesmo objeto obtidas a partir de 

pontos  de  vista  diferentes.  Um  ponto  projetado  na  primeira  imagem  deve  corresponder  a  um 

ponto na segunda imagem, que é a projeção do mesmo ponto da cena real. Inúmeros métodos 

para  determinação  automática  desta  correspondência  têm  sido propostos. Para  o caso  de  duas 

câmeras,  a  teoria  é  exposta  de  forma  bastante  completa  [Faugeras,  1995],  apresentando  os 

procedimentos algébricos e geométricos relacionados. Erros de correspondência podem ocorrer 

quando  os  eixos  óticos  das  câmera  não  são  paralelos  entre  si  e  a  correspondência  entre  um 

modelo  e  o  conjunto  de  pontos  tridimensional  do  objeto  são  restritos  pelo  número  de 

correspondências falsas [Galo, 1999]. Técnicas mais recentes de correspondência de imagens são 

baseadas na forma do objeto e na deteção de bordas, cantos e regiões [Xie, 2004]. Encontra-se 

ainda na literatura técnicas baseadas em gradientes [Twardowski, 2004]. 

O  segundo  problema,  relacionado  com  a  reconstrução  tridimensional,  é  chamado  de 

calibração  de  câmeras.  A calibração  é  necessária  em  qualquer  inspeção  visual  onde  se  busca 

determinar  a  posição  de  objetos,  ou  a  localização  da  câmera  no  ambiente  [Salvi,  2002]. 

Normalmente, a única informação que se dispõe são as imagens dos objetos.  A idéia básica da 

3



calibração é estabelecer uma relação entre os pontos da imagem e as coordenadas espaciais em 

unidade  métricas  (para  este  trabalho).  Esta  relação  depende  da  configuração  dos  parâmetros 

óticos da câmera, bem como da estimação da posição relativa entre câmeras [Trucco, 1998] e 

[Forsyth, 2003]. A posição relativa é dada por uma matriz de rotação e um vetor de translação, 

que  formam  uma  expressão  matricial  chamada  de  matriz  essencial.  A  estimativa  da  matriz 

essencial é um passo preliminar na obtenção do modelo tridimensional. A maneira de estimar a 

matriz  essencial  é  através  de  sua  decomposição  em  valores  singulares  (SVD –  singular  value  

decomposition),  o  que  permite  encontrar  os  parâmetros  de  rotação  e  translação  [Tsai,  1984], 

[Fiori,  2000],  [Oisel,  2003]  e  [Ma,  2004].  Procedimentos  para  estimativa  da  matriz  essencial 

estão presentes nas aplicações de reconstrução 3D, onde a precisão de medidas são necessárias. 

Diferentes  formas  de  estimativa  desta  matriz  são  apresentadas  no  contexto  de  calibração  de 

câmeras [Salvi, 2002].  Para este trabalho a posição relativa entre as câmeras é dada apenas por 

um deslocamento no eixo X, eliminando-se a matriz de rotação e o cálculo da matriz essencial, 

tornando o método simplificado e eficiente em temos computacionais.

A junção das técnicas de processamento de imagens e visão computacional com a análise 

dinâmica  de  estruturas  permite  propor  uma  solução  para  o  monitoramento  da  vibração  de 

estruturas  mecânicas.  Tal  é  o  caso  da  aplicação  investigada  no  presente  trabalho,  de 

monitoramento  do movimento  de  risers [Sparks, 2007] de  produção de petróleo  causado pelo 

deslocamento  de  óleo  e  gás  em  seu interior.  Risers são essencialmente  dutos  de  condução  do 

petróleo extraído em águas profundas, que fazem a conexão entre a cabeça do poço perfurado no 

leito do mar e a o navio ou plataforma de produção. Os  risers são estruturas cujo comprimento 

atinge a ordem de alguns milhares de metros, o que torna muito difícil a tarefa de medição do seu 

movimento nas condições naturais de operação. Por esse motivo, a monitoração de movimento de 

vibração dessa estrutura é feita em laboratório através de um modelo em escala reduzida, que tem 

seus parâmetros proporcionais ao de um riser real.  A utilização de câmeras para a captura de seu 

movimento é um processo de baixo custo e bastante conveniente, pois nesse caso o sistema de 

monitoramento não interfere na dinâmica estrutural do modelo em estudo. 

É  proposto  aqui  um  método  de  captura  e  processamento  de  imagens  para  o  estudo  do 

4



movimento  do  modelo  de  riser de  petróleo  com  as  propostas  e  objetivos  são  apresentados  a 

seguir.

1.1. Objetivos propostos no projeto

Este trabalho tem os seguintes objetivos:

– Criação  de  um  método  para  identificação  do  deslocamento,  freqüências  e  ângulos 

existentes na oscilação do modelo reduzido de riser de produção de petróleo;

– Verificação do método desenvolvido através da simulação das capturas por um software 

de computação gráfica;

– Construção  de  um  software  de  captura  de  imagens  para  uma  ou  mais  câmeras 

simultaneamente, utilizando um ou mais computadores;

– Análise dos dados capturados em duas e três dimensões através de simulação 3D.

A técnica proposta tem aplicação na área de processamento de imagens e sinais utilizando 

sistemas de baixo custo,  em particular no estudo e análise de movimento de um riser de petróleo. 

Apresenta-se também a comparação dos resultados obtidos empregando a técnica proposta com o 

uso de acelerômetros.

1.2. Contexto da Pesquisa

O  presente trabalho é desenvolvido junto ao grupo de Processamento de Imagens, Sinais e 

Análise de Sistemas Dinâmicos do Departamento de Projeto Mecânico (DPM) da Faculdade de 

Engenharia Mecânica da UNICAMP em parceria com o Departamento de Engenharia de Petróleo 

(DEP)  da  Faculdade  de  Engenharia  de  Petróleo  desta  mesma  Universidade.  Encontra-se  no 

contexto de pesquisa, aplicação e desenvolvimento de técnicas de processamento de imagens e 

visão computacional na análise dinâmica de estruturas, que o grupo vêm desenvolvendo durante 

os  últimos  anos.  Alguns  resultados  recentes  do  grupo  podem  ser  encontrados  nos  trabalhos 

[KURKA, 2007], [RUDEK, 2005], [KURKA, 2004] e [MENEZES, 2004].

5



A aplicação das técnicas de visão computacional ao monitoramento do riser de produção de 

petróleo  em  escala  reduzida,  constitui  uma  solução  para  a  identificação  das  freqüências, 

deslocamento  e  ângulos  do  riser sem  a  fixação  de  equipamentos  de  medição  que  possam 

interferir em seu movimento. Tal tema é também fruto de pesquisa dos fenômenos  que atuam 

sobre o riser dentro d'água, que vem sendo realizado pelo grupo do DEP através dos trabalhos 

[Bordalo, 2007], [Cavalcante, 2007], [Morooka, 2007] e [Valdivia, 2007].

1.3. Descrição da estrutura do presente trabalho

O capítulo 2 apresenta uma  revisão da teoria de processamento de sinais, janelamento e 

interpolação  spline,  que  são  usadas  na  análise  dos  resultados  de  captura  de  movimento.  O 

capítulo  3  apresenta  os  conceitos  de  processamento  de  imagens  que  embasam  os  resultados 

práticos  do  uso  de  imagens  das  câmeras.  O  capítulo  4  apresenta  técnicas  de  extração  de 

parâmetros da imagem. O capítulo 5 descreve a importância do estudo do  riser de petróleo e a 

construção  do  modelo  em  escala  reduzida  em  laboratório.  O  capítulo  6  apresenta  o  sistema 

desenvolvido para captura e processamento de imagens. O capítulo 7 verifica a robustez e explora 

demais potencialidades da técnica de monitoramento desenvolvida, através do processamento de 

dados  provenientes  de  imagens  numericamente  simuladas.  As  conclusões  deste  trabalho,  bem 

como  as  propostas  de  futuros  desenvolvimentos  são  apresentas  no  capítulo  8,  seguido  das 

referências bibliográficas.

6



Capítulo 2

Processamento de Sinais

Sinais  dinâmicos  são  grandezas  físicas  que  variam  continuamente  com  o  tempo  e  estão 

disponíveis  para  fins  de  visualização  ou  monitoramento.  Estes  podem  ser  considerados 

tipicamente  como  as  saídas  condicionadas  de  diferentes  sensores  e  transdutores,  quando 

utilizados  para  o  acompanhamento  do  movimento  de  máquinas  e  estruturas.  Uma  maneira 

conveniente  de  se  trabalhar  com  os  sinais  dinâmicos  é  através  de  sua  representação  por  um 

número  limitado de amostras  adquiridas  em instantes  progressivos  e  igualmente espaçados  de 

tempo. 

O processo de amostragem de sinais dinâmicos deve obedecer a determinadas leis que são 

apresentadas  no  item  2.1.  A  utilização  de  amostras  do  sinal  dinâmico  é  um  procedimento 

econômico  e conveniente  quando se tem em  vista  o trabalho  em um ambiente  computacional 

onde a disponibilidade de registros de memória é sempre um fator limitante da informação.

A  representação  de  sinais   em  ambiente  computacional  requer  ainda  uma  importante 

simplificação. Os transdutores utilizados em laboratório possuem como saída um sinal cujo nível 

varia continuamente com a variação do nível da grandeza observada. Este de variação contínua 

(ou  analógica)  pode  ser  mapeado  por  um  número  inteiro  de  níveis  discretos.  Os  níveis  de 

mapeamento  do  sinal  analógico  podem  ser  convenientemente  representados  por  um  número 

binário com uma quantidade fixa de dígitos. A execução desse mapeamento ou a inter-relação 

entre  o  sinal  analógico  e  um  valor  binário  correspondente  é  chamada  de  procedimento  de 

7



conversão  analógico-digital.  Conversores  analógico  digitais  (A/D)  são  equipamentos  que 

realizam tal mapeamento.

2.1. O princípio da amostragem de Nyquist

Para que se explique de forma conveniente a amostragem de sinais dinâmicos é necessário 

que se estabeleçam as características mais importantes dos sinais e do processo de amostragem. 

Assim define-se:

• fx ou fmax – Freqüência de um sinal harmônico simples ou freqüência máxima de 
um sinal qualquer.

• Tx ou Tmin – Período do sinal harmônico simples ou período mínimo de um sinal 

qualquer (
min

max
1

e
1

T
f

T
f

x
x == ).

• fs – Freqüência ou taxa de amostragem de um sinal.

• t?  – Intervalo de amostragem de um sinal (
t

f s ?
=

1
).

• fc – Freqüência de corte da amostragem (
2

s
c

f
f = ).

Um sinal que varia continuamente no tempo, a uma taxa máxima de fmax ciclos por segundo, 

só pode ser convenientemente amostrado com uma freqüência mínima  fs, superior a  2 fmax. A 

“Freqüência de  Nyquist” [Oppenheim, 1989] de um sinal é definida como a mínima freqüência 

com a qual o mesmo pode ser amostrado. 

Quando se pretende amostrar um sinal dinâmico com uma freqüência  fs, deve-se garantir 

que a freqüência máxima do mesmo seja inferior à freqüência de corte da amostragem, ou seja, 

2
ou maxmax

s
c

f
fff&amp;lt;&amp;lt;. 

Um sinal discretizado por uma freqüência menor do que o dobro de sua freqüência  máxima 

terá a sua representação alterada (devido ao fenômeno de “aliasing”) para a de um sinal com 

8



menor conteúdo de freqüência. Uma apresentação gráfica de tal problema é mostrada à  Figura

2.1.

Figura 2.1 - O efeito de aliasing na amostragem incorreta de um sinal

2.2. Freqüência máxima de um sinal

O  exemplo  apresentado  pela  Figura  2.1  considera  o  efeito  de  aliasing quando  o  sinal 

amostrado é do tipo harmônico, com freqüência bem definida.  A freqüência máxima  de um sinal 

genérico no entanto não é algo de fácil ou imediata compreensão. Diz respeito à máxima taxa 

instantânea de variação do sinal no tempo.

Em aplicações típicas de engenharia, não se conhece a priori qual é a maior freqüência de 

um determinado sinal a ser amostrado. O que se conhece entretanto é a freqüência fs com a  qual 

o sinal será amostrado. Nesse caso, o procedimento adotado previamente à amostragem é o de 

filtragem do sinal numa freqüência inferior a fs/2, o que garante que as amostras do sinal estarão 

livres  do erro de alias. A filtragem é realizada  de forma  elétrica ou eletrônica e o filtro,  com 

características do tipo “passa baixa” é denominado “filtro anti-alias”. 

9



2.3. Janelamento de Hanning

O fato das amplitudes espectrais da FFT de um sinal periódico não coincidirem com os 

valores dos coeficientes de expansão do sinal em série de Fourier é conhecido como “leakage”. 

Isso ocorre, conforme visto, quando o tempo T de amostragem do sinal não é múltiplo inteiro de 

seu período TP e os zeros da função lóbulo não coincidem com as freqüências de ocorrência dos 

impulsos  da  função  “pente”.  Para  minimizar  tal  efeito,  aplica-se  uma  função  lóbulo  cuja 

amplitude dos lóbulos laterais seja significativamente menor do que aqueles da transformada da 

função  janela  de  observação   apresentada  anteriormente.  A  Figura  2.2 (a)  apresenta  uma 

ilustração  de  tal  função  lóbulo.  Lembrando  ainda  que  a  função  lóbulo  é  a  representação  do 

espectro  de  ( )t? ,  pode-se  chegar  a  forma  original  de  uma  função  janela  de  observação, 
representada à Figura 2.4 (b), cuja transformada de Fourier leva à função lóbulo apresentada. 

Figura 2.2 - Janelamento de um sinal

A função janela de observação apresentada à Figura 2.2 é conhecida como janela Hanning 

[Oppenheim, 1989], e possui a expressão analítica dada pela equação 2.1:

( ) ?
?
?

?
?
??= t

T
t

?
?

2
cos1 [eq. 2.1]

A aplicação de uma janela espectral no sinal  ( )txP  equivale a multiplicá-lo pela função 
( )t? , antes de realizar a transformada de Fourier do sinal resultante ( )tx  dado pela equação 2.2:

10

?
? ?6

?
? ?4

?
? ?2

?
?6

?
?4

?
?2

|W(?)|

1

...

( )t?

2

(a) (b)

T
t



p

k
?

?2
?

p

k
?

?? 2

p?
?? 6

p?
?? 4

p?
?? 2

p?
?6

p?
?4

p?
?2

|X
0
|

|X
3
|

|X
1
|

|X
2
|

|X
1
|

|X
2
|

|X
3
|

( ) ( ) ( )ttxtx P ?.=  , Tt ??0 [eq. 2.2]

A Figura  2.3 apresenta  o  resultado  da  transformada  de  Fourier  do  sinal  ( )txP ,  com 
aplicação da janela de Hanning. Observa-se da figura que o espectro resultante possui amplitudes 

máximas que aproximam de forma satisfatória as amplitudes dos componentes da expansão de 

Fourier do sinal ( )txP .

|X(w)|

Figura 2.3 -  Transformada de Fourier da função x(t) com janela Hanning

Diferentes janelas espectrais podem ser usadas para a transformada de Fourier de funções 

periódicas. A janela de Hanning apresentada, entretanto, é de grande aplicação prática na análise 

espectral  de  sinais  periódicos  ou  permanentes.  Para  sinais  transientes  pode-se  também  definir 

janelas  do  tipo  exponencial  quando  o  tempo  de  duração  do  sinal  extrapola  a  sua  janela  de 

medição.  Nesses  casos  porém,  sempre  que  possível,  é  preferível  se  trabalhar  com  um  tempo 

maior de medição, de forma a que não se precise utilizar janelas espectrais

2.4. A Transformada de Fourier

A Transformada de Fourier [Oppenheim, 1989], é uma  integral que expressa um sinal em 

termos de  somas  de funções senoidais multiplicadas por coeficientes ("amplitudes"). Tem como 

objetivo obter, em forma de distribuição de espectro, o conteúdo de freqüências  presentes no 

sinal.

11



A Transformada de Fourier de um sinal genérico x(t) é dada pela equação 2.3:

( ) ( )1
2

j tX x t e dt??
?

? ?

? ?
= ?

[eq. 2.3]

A existência da Transformada (ou Integral) de Fourier de um sinal é garantida quando o 

mesmo obedece à seguinte condição:

( )x t dt
?

? ?
&amp;lt;?? [eq. 2.4]

A condição da equação 2.4 equivale a dizer que o sinal x(t) é não permanente em relação 

aos limites de integração, ou de energia finita.

Note-se que a Integral de Fourier é uma transformação que leva a função x(t) a um domínio 

complexo  através  da  sua  multiplicação  pela  função  exponencial  complexa.  Assim,  a 

representação  gráfica  adequada  da  transformação  de  x(t)  se  dá  num  espaço  vetorial  de  três 

dimensões, em função de sua parte real, imaginária e da variável independente . Outras maneiras 

de representação gráfica da Transformada de Fourier são os diagramas de Bode e Nyquist.

O diagrama de Bode e Nyquist composto pelos gráficos de amplitude e fase, ambos função 

da variável independente  w são apresentados na  Figura 2.4. O gráfico de amplitudes de  X(w), 

também chamado de “espectro” ou “distribuição espectral” de  x(t), fornece informação sobre a 

influência ou “ponderação” de um sinal harmônico de freqüência w rd/s, na formação de x(t). O 

gráfico de fases de X(w) fornece informação sobre a ponderação relativa do sinal harmônico seno 

ou co-seno, na amplitude do sinal harmônico de freqüência  w rd/s. Uma outra representação da 

Transformada de Fourier é através do diagrama de  Nyquist, onde os gráficos das partes real e 

imaginária de X(w) são apresentados como eixos de abscissa e ordenadas, tendo como parâmetro 

implícito  o  valor  da  freqüência  w.  A  Figura  2.4 ilustra  a  representação  da  Transformada  de 

Fourier em termos do diagrama de Nyquist. 

12



As representações de Bode [Oppenheim, 1989] ou Nyquist são convenientes, especialmente 

ao  processo  de  análise  e  identificação  onde  se  utiliza  a  transformada  de  Fourier  de  sinais  de 

vibração de sistemas dinâmicos.

 

5 10 15 20 25 30 35 
-15 

-10 

-5 

0 

5 

10 

15 

parte real de X(?) 

p
ar

te
 i

m
ag

in
ár

ia
 d

e
 X

(?
) 

     

 

0 2 4 
-4 

-2 

0 

2 

4 

t 

x(t) 

0 10 20 30 
0 

10 

20 

30 

40 

w 

|X(w)| 

0 10 20 30 
-1 

-0.5 

0 

0.5 

1 

w 

fase de X(w) 

Figura 2.4 - Diagrama demonstrativo de Nyquist a esquerda e Bode a direita

2.5. Transformada de Fourier de um sinal periódico

A seção anterior apresentou a estimativa da transformada de Fourier de um sinal transiente. 

Um sinal periódico de período Tp, amostrado no intervalo de tempo T, será considerado transiente 

para  qualquer  efeito  prático  e  equivale  a  transformada  de  seu  produto  por  uma  janela  de 

observação w(t):

( ) =tx p sinal periódico com período Tp

( ) ( ) ( )twtxtx p .=  com ( )
?
?
? ??

=
acima intervalo do fora  para0

0  para1
t

Tt
tw

A transformada de Fourier avaliada nos pontos múltiplos inteiros da freqüência 2kw /T pode 

ser descrita pela equação 2.5:

13



?
?

=

?
=?

?
?

?
?
?

?
=?

1

0

212 M

r

M
kr

j

rk exM
kXX

??
? [eq. 2.5]

A expressão acima é conhecida como “transformada discreta de Fourier” (ou FFT, de sua 

sigla no idioma inglês). A utilização da FFT, devido a sua simplicidade, é largamente empregada 

na estimativa da transformada de Fourier de sinais periódicos, mesmo não havendo relação de 

multiplicidade inteira entre os tempos de amostragem e período do sinal.

2.6. Correção de ?t irregular com Interpolação Spline

O tempo de captura de imagem de uma câmera, para efeito de medidas de deslocamento em 

sistemas dinâmicos, pode conter erros aleatórios no tempo de aquisição ?t. Este erro ocorre por 

diversos  motivos: baixa velocidade  de transferência  de dados  entre  a câmera e o computador, 

processador ocupado, pouca memória RAM disponível, baixa velocidade de gravação de dados 

do disco rígido e principalmente alto tempo de exposição do CCD para que a imagem se forme.

Um sinal capturado com ?t variável, não permite o processamento direto da Transformada 

de  Fourier.  Uma  forma  de  se  minimizar  esse  problema  é  a  utilização  de  uma  interpolação 

numérica. A técnica Spline [Kreyszig, 2005], é usada para interpolação polinomial da função do 

sinal medido e reamostragem em instantes igualmente espaçados do tempo f(x) para os pontos 

x[i], com i = [0,1,...,n-1].

A Figura 2.5 e  Figura 2.6 ilustram um sinal amostrado com  ?t variante, e a aplicação de 

uma Spline sobre o mesmo.

14



Figura 2.5 - Sinal amostrado com ?t variante

Figura 2.6 - Sinal amostrado com ?t variante e sua interpolação Spline

O processo de interpolação por  Spline garante a continuidade entre a primeira e segunda 

derivada do sinal em cada ponto amostrado, regularizando o processo de obtenção de amostras 

igualmente espaçadas no tempo.

15



 

Capítulo 3 

Processamento de Imagens

Este  capítulo  apresenta  o  conceito  de  formação  da  imagem  digital  e  técnicas  de 

processamento aplicadas à identificação do movimento de pontos da imagem. Tais conceitos são 

introduzidos  na  obtenção  de  medidas  de  movimento  do  modelo  de  laboratório  do  riser de 

petróleo.

3.1. Formação da Imagem

A imagem nas câmeras digitais, é capturada pelo dispositivo eletrônico chamado de CCD 

(Charged  Coupled  Device)  [Holst,  2007].  Tal  dispositivo  consiste  em  uma  uma  matriz  de 

sensores de luz,  que recebe a informação luminosa através das lentes e a converte em uma matriz 

de valores digitais com M linhas e N colunas. Cada posição (x,y) dessa matriz contém um valor 

discreto  proporcional  a  intensidade  luminosa  medida  naquela  posição.  Este  valor  representa  a 

informação  mais  básica  da  composição  da  imagem,  chamada  de  pixel,  uma  abreviação  da 

expressão picture element, conforme ilustra a Figura 3.1:

16



Figura 3.1 – Formação de uma imagem em um CCD

A Figura 3.2 apresenta o exemplo de uma imagem de tamanho MxN. A coordenada  (0,0) 

representa a origem da imagem no canto superior esquerdo, e as posições dos pixels aumentam da 

esquerda para direita, na direção do eixo X e de cima para baixo na direção do eixo Y.

Figura 3.2 – Exemplo de uma imagem digital .

17

x

y

Um pixel

N-1

M-1

Origem
(0,0)



Os  valores  armazenados  pelo  CCD  são  transferidos  ao  computador  pelo  modelo  de  cor 

conhecido como Vermelho, Verde e Azul (RGB), porém outros formatos são aplicados para o 

processamento de imagens, conforme é descrito nas seções seguintes.

3.2. Modelo de Cores

A digitalização  dos  valores  de  intensidade  de  cores  e  luz  recebidos  em  um  CCD  são 

transmitidos ao computador através de números e armazenados em formatos como RGB, YUV, 

CMYK,  HSV  e  HSL.  A  escolha  do  formato  correto  depende  da  aplicação  para  a  qual  o 

processamento de imagens se destina.

3.2.1. RGB

Criado em 1953 como um padrão para a telas e  displays a cores, o modelo de cor RGB 

[Gonzalez,  2002] é um modelo aditivo no qual  as  cores  vermelho (red), verde  (green) e  azul 

(blue)  são  combinadas  para  reproduzir  outras  cores  e  não  devem  ser  confundidas  com  os 

pigmentos  conhecidos  como  cores  primárias.  É  conveniente  para  softwares  de  computação 

gráfica devido a forma como o sistema de visão humano reconhece as cores.

A adição dos componentes RGB geram outras cores, conforme demonstra Figura 3.3:

      
Figura 3.3 – Adição dos componentes RGB, distribuídos em 2D a esquerda e em 3D a direita.

18



Uma imagem qualquer pode ser decomposta em seus três componentes conforme Figura 3.4:

Figura 3.4 – Decomposição de uma imagem em seus componentes RGB.

O  modelo  RGB  tem  grande  aplicação  em  telas  de  televisão  (tubos  de  raios  catódicos), 

cristal  líquido  e telas  de plasma, onde cada pixel da tela é  representado  por uma interface  de 

hardware com valores em RGB convertidos em intensidades elétricas.

Tipicamente os hardwares gráficos utilizam oito  bits para mapear cada componente, onde 

suas intensidades podem variar de zero (escuro) a 255 (claro) gerando um total de 16.777.216 

tons de cores, ou seja, 28x3 bits.

3.2.2. YUV e Tons de Cinza

O modelo de cor YUV [Gonzalez, 2002] é definido por um componente de brilho (Y) e 

dois de cor (UV), e é utilizado pelo sistema PAL para processar vídeo analógico. A utilização de 

imagens  em  tons  de  cinza  com  8  (oito)  bits,  onde  zero  equivale  ao  preto  e  255  ao  branco  é 

importante para aplicações de visão computacional devido a baixa quantidade de dados a serem 

processados e pode ser conseguido através do seu componente Y, definido pela equação 3.1 e 

demonstrado na Figura 3.5

Y =?0,299×R???0,587×G???0,114×B?  [eq 3.1]

19



Figura 3.5 – Decomposição de uma imagem RGB no componente Y

Outros padrões de cores são derivados do YUV como YPbPr, YCbCr e YIQ utilizado no 

padrão mais complexo NTSC, e vêm sendo aplicados em televisões de nova geração devido a 

baixa quantidade de dados necessária para a formação da cor na tela [Gonzalez, 2002].

3.2.3. CMYK

O modelo de cor CMYK [Gonzalez, 2002] é composto por ciano (cyan), roxo (magenta), 

amarelo (yellow) e preto (key). A mistura das cores CMYK é subtrativa pois parte do branco do 

papel, conforme demonstra a Figura 3.6:

Figura 3.6 – Subtração dos componentes CMY

O modelo de cores CMYK é utilizado principalmente em impressoras, pois o modelo CMY 

utilizaria mais tinta colorida do que o necessário e normalmente textos são impressos em preto, 

20



conforme demonstra as figuras 3.7 e 3.8:

Figura 3.7 – Componentes CMY

Figura 3.8 – Componentes CMYK

3.2.4. HSV

O modelo de cor HSV [Gonzalez, 2002] , também conhecido como HSB, foi criado em 

1978 como uma transformação não linear do RGB sendo composto por tom (hue), saturação e 

valor (brilho) e pode ser representado através de um cone de cores conforme Figura 3.9:

Figura 3.9 – Distribuição das cores no modelo HSV

A representação em cone define o tom sendo formado por um círculo de cores, a saturação 

é representada pela distância do centro à borda deste círculo e o brilho representado pela distância 

21



entre a base e o topo do cone.

A Figura 3.10 apresenta uma tabela de cores com aumento do componente saturação para 

três  valores  de  brilho,  e  Figura  3.11 o  aumento  do  componente  brilho  para  três  valores  de 

saturação.

Figura 3.10 – Aumento da saturação 

para três níveis de brilho

Figura 3.11 – Aumento do brilho para 

três níveis de saturação

3.2.5. HSL

O modelo de cor HSL [Gonzalez, 2002], também conhecido como HSI, é composto por 

tom  (hue),  saturação  e  luminosidade  e  pode  se  representado  por  uma  esfera  conforme  Figura

3.12.

Figura 3.12 – Esfera de componentes HSL

22



O modelo HSL é similar ao modelo HSV, porém o modelo HSL reflete melhor a notação 

intuitiva  de  saturação  e  luminosidade  como  dois  parâmetros  independentes, exceto  para  cores 

pastéis que podem ser percebidas como muito saturadas no modelo HSL.

No  modelo  HSL a  saturação  vai  de  muito  saturado  ao  cinza  equivalente  daquela  cor, 

enquanto  no  HSV o  componente  V varia  da  cor  atual  até  branco,  o  que  pode  não  ser  muito 

intuitivo. A luminosidade do modelo HSL sempre cobre a faixa que vai das cores preto a branco 

passando  pelo  tom  (hue)  escolhido,  enquanto  no  HSV  o  componente  V  cobre  apenas  meio 

caminho da cor até o preto, não alcançando o branco.

3.3. Correção da distorção da lente

As  lentes  das  câmeras,  principalmente  as  de  baixo  custo,  contêm  imperfeições  em  sua 

fabricação  que  levam  a  distorções  não-lineares  do  tipo  barril,  que  podem  ser  côncavas  ou 

convexas conforme Figura 3.13.

      
Figura 3.13 – À esquerda distorção côncava e a direita distorção convexa.

Essa distorção pode levar a um erro no cálculo da posição do alvo, já que objetos próximos 

à borda da imagem tendem a conter um erro maior em relação a posições centrais.

Para corrigir a imagem utiliza-se o método de calibração espacial [Chu, 2001], que utiliza 

uma  matriz  de  círculos,  com  espaçamentos  iguais  e  conhecidos,  impresso  e  fotografado  pela 

23



câmera. A partir desta matriz é possível calcular a distorção da lente e corrigir qualquer imagem 

proveniente desta câmera, conforme Figuras 3.14 a 3.16.

            
Figura 3.14 – A esquerda matriz de círculos, ao centro imagem sem correção, a direita imagem corrigida.

      
Figura 3.15 – A esquerda matriz sem correção, a direita matriz corrigida.

      
Figura 3.16 – A esquerda imagem sem correção, a direita imagem corrigida.

24



3.4. Remoção de Ruídos

Devido a baixa luminosidade do ambiente de captura das imagens e a saturação do sensor 

CCD, um ruído aleatório pode ser inserido na imagem, caracterizado por uma grande flutuação 

de  intensidade  e  cor  em relação  a  imagem  real,  tornando-se  necessário  um processamento  de 

remoção de ruídos.

As técnicas existentes [Gonzalez, 2002] assemelham-se aos filtros de passa-baixa e cálculo 

de mediana de processamento de sinais, porém o resultado final também filtra texturas e perde a 

definição de bordas, conforme Figura 3.17:

      
Figura 3.17 – A esquerda imagem com ruído, a direita imagem após remoção de ruídos, em tons de cinza.

3.5. Corte – Thresholding

Um  forma  eficiente  e  simples  de  separar  o  alvo  dos  outros  componentes  da  imagem  é 

remover  cores  que  não  são  de  interesse.  Este  processo  é  chamado  de  thresholding [Florczyk, 

2005] e em imagens em tons de cinza é feito definindo-se um valor de intensidade de luz que 

deverá  permanecer  na  imagem.  Valores  abaixo  do  estipulado  para  o  corte  serão  considerados 

pretos e o restante branco conforme Figura 3.18:

25



      
Figura 3.18 – A esquerda imagem original, a direita imagem após Thresholding no nível 127.

Outra forma de Thresholding é a definição de uma faixa de valores de corte, um mínimo e 

um máximo, conforme  Figura 3.19, determinando quais intensidades deverão permanecer. Este 

método é aplicado na Figura 3.20, definindo-se três faixas de corte, uma para cada canal de cor 

da imagem:

Figura 3.19 – Thresholding RGB com três faixas de corte

      
Figura 3.20 – A esquerda imagem original, a direita imagem após Thresholding.

26



Observa-se que o  Thresholding apenas elimina parte do problema, porém resíduos devem 

ser eliminados até que reste apenas o alvo escolhido. Variações na luz ambiente também podem 

trazer resultados inválidos, tornando-se necessário modificar o valor do corte para cada imagem 

capturado.  Utiliza-se  o  método  de  equalização  de  histogramas  para  reduzir  variações  de 

iluminação.

3.6. Equalização de Histogramas

Este método [Gonzalez, 2002] realça a imagem através  de uma melhor distribuição da 

quantidade de  pixels em cada tom de cinza e obtém bons resultados  em imagens com poucas 

cores ou com baixo contraste. Para este procedimento é necessário o cálculo do histograma, que é 

a  distribuição  da  quantidade  de  pixels de  cada  intensidade  em  um  gráfico.  A  Figura  3.21 

(640x480 pixels) será utilizada para demonstrar a técnica:

      
Figura 3.21 – Imagem com baixo contraste

O  histograma  desta  imagem  possui  pixels com  intensidades  medianas  (de  120  a  200), 

tornando a imagem acinzentada. O objetivo é expandir as intensidades de forma que preencha 

todo o espectro, sendo necessário o cálculo das freqüências acumuladas da imagem, onde dado 

um nível de cinza L, a freqüência acumulada para este nível é a soma do histograma de 0 (zero) 

até L. A Figura 3.22 mostra as freqüências acumuladas para cada nível de cinza da Figura 3.21:

27



      
Figura 3.22 – Histograma e Gráfico das freqüências acumuladas

O gráfico de freqüências acumuladas tem um valor máximo igual ao número de  pixels da 

imagem (640x480 = 307.200 neste caso). Desta forma pode-se redistribuir as intensidades através 

do espectro percorrendo cada ponto da imagem e aplicando-se a equação 3.2:

) y)L(x, Acumulada(Frequencia
255

),`( ×=
numPixels

yxL  [eq. 3.2]

Onde, L(x,y) é o nível de intensidade do ponto (x,y). 

A Figura 3.23 demonstra o resultado da aplicação desta técnica.

Figura 3.23 – Imagem com histograma equalizado

Após a equalização, a imagem torna-se mais clara e detalhes podem ser identificados. A 

Figura 3.24 exibe o histograma e o gráfico de freqüências acumuladas da Figura 3.23 equalizada:

28



      
Figura 3.24 – Histograma equalizado e o novo gráfico de freqüências acumuladas.

O  histograma  equalizado  foi  “esticado”  através  do  espectro,  e  o  gráfico  de  freqüências 

acumuladas  demonstra  praticamente  uma  reta  de  distribuição  de cada  intensidade  dos  tons  de 

cinza.

Para  imagens  coloridas,  a  equalização  pode  ser  aplicada  separadamente  nos  canais 

Vermelho, Verde e Azul (RGB), conforme resultado da Figura 3.25:

      
Figura 3.25 – A esquerda imagem original, a direita imagem com histograma equalizado.

3.7. Remoção de objetos pequenos e Fechamento

O último passo do processamento da imagem com alteração do seu conteúdo é feito com a 

remoção dos resíduos (objetos pequenos), através do processo de Erosão, seguido do processo de 

29



Dilatação para que ocorra o fechamento da figura do alvo (esferas laranjas)

3.7.1. Elemento de estrutura

O  elemento  de  estrutura  [Florczyk,  2005]  é  um  conjunto  de  pixels que  será  aplicado  à 

imagem a ser processada para a execução do algoritmo escolhido. A Figura 3.26 mostra alguns 

tipos de elementos de estruturação:

Figura 3.26 – Elementos de estruturação em Cruz, Quadrado e Hexágono

A escolha da forma e tamanho do elemento de estrutura depende da aplicação e dos objetos 

que estão na imagem e deve ser ajustado para obter o resultado esperado.

3.7.2. Erosão e Remoção de objetos Pequenos

O  método  de erosão [Florczyk,  2005] verifica se os  elementos  da  estrutura encaixam-se 

completamente  em  um  conjunto  de  pixels.  Em  caso  verdadeiro,  todo  o  conjunto  de  pixels é 

trocado pelo valor mínimo do elemento de estrutura que está em volta do pixel, provocando uma 

redução das bordas da imagem. Em imagens binárias, o elemento de estruturação é 1 ou 0. 

A Figura 3.27 e 3.29 demonstra a aplicação da erosão utilizando um elemento de estrutura 

quadrado de 3x3 pixels em uma imagem binária e outra colorida na Figura 3.28.

30



      
Figura 3.27 – Efeito da erosão em uma imagem binária

      
Figura 3.28 – Efeito da erosão em uma imagem colorida

      
Figura 3.29 – A esquerda sem erosão, a direita efeito da erosão no alvo com estrutura 5x5 (em detalhe)

3.7.3. Dilatação e Fechamento

O processo de dilatação [Florczyk, 2005] produz o efeito inverso da erosão, produzindo 

um aumento das bordas através da troca do valor do  pixel de referência pelo valor máximo do 

31



elemento de estrutura que está em volta dele.

A Figura 3.30 demonstra a aplicação do efeito de dilatação para uma imagem binária e 

outra colorida na Figura 3.31 com elemento de estrutura quadrado de 3x3 pixels:

      
Figura 3.30 – Efeito da dilatação em uma imagem binária

      
Figura 3.31 – Efeito da dilatação em uma imagem colorida

Por último, o processo de fechamento é feito através de uma dilatação seguido por uma 

erosão, utilizado para remover pequenos buracos conforme ilustra a Figura 3.32 e 3.33:

32



        
Figura 3.32 – Efeito do fechamento de uma imagem binária com elemento de estrutura quadrado 7x7

      
Figura 3.33 – A esquerda imagem original, a direita imagem fechada (em detalhe)

Com os  alvos  devidamente  isolados  e com a imagem sem ruídos, é possível  separar  e 

calcular a posição de cada objeto conforme é apresentado no capítulo a seguir.

33



Capítulo 4

Extração de parâmetros da imagem

Neste capítulo são apresentados os métodos para a separação dos alvos (círculos) e suas 

posições, ângulo e ponto médio na imagem.

4.1. Caixa de contorno

Para  separar  e  identificar  cada  objeto  é  necessário  conhecer  sua  posição  que  pode  ser 

definida através de sua caixa de contorno 2D [Chan, 2001], demarcando sua borda com quatro 

pontos  permitindo,  assim,  permitindo  o  cálculo  e conhecimento  de  seu  tamanho  e  posição  no 

espaço.

Um método para criar caixas de contorno é a varredura de toda a imagem, da esquerda para 

a direita e de cima para baixo, procurando por pixels com valores 1 (em uma imagem binária)

Quando uma borda 1 é encontrada, marca-se como início do objeto e armazena-se a posição 

(X,Y) deste pixel. O mesmo é feito ao encontrar uma borda 0, armazenando-se o pixel como final 

do objeto. Caso seja encontrada outra borda antes do final da linha, determina-se um começo de 

um novo objeto, conforme Figura 4.1.

34



N-1

(0
,0) x

y

M-1

Figura 4.1 – Detecção de bordas para determinação da caixa de contorno

Após a detecção de todas as bordas é possível conhecer os objetos alvos separadamente. De 

todos os pixels encontrados apenas os valores máximos e mínimos de X e Y de cada objeto são 

importantes, conforme Figura 4.2.

N-1

(0
,0) x

y

M-1

A
B

Figura 4.2 – Pixels (em vermelho) com valores máximos e mínimos para cada objeto

A definição da caixa de contorno 2D de cada objeto é dada por: P1(Xmin,Ymin)i, P2(Xmax,Ymin)i, 

P3(Xmax,Ymax)i e P4(Xmin,Ymax)i, onde P é um ponto de definição da caixa, X e Y são as coordenadas 

do ponto P e i é o nome da caixa de contorno, conforme Figura 4.3.

35



N-1

(0
,0) x

y

M-1

A
B

21

34

21

34

      
Figura 4.3 – Caixa de contorno 2D definida por objeto e o método aplicado na imagem alvo

4.2. Cálculo do centro de objetos

O  cálculo  do  centro  de  objetos  utilizando  caixas  de  contorno  pode  ser  feito  através  da 

obtenção do ponto de cruzamento formado pelas Retas dos Pontos 1 e 3 com os Pontos 2 e 4 

[Iezzi,  1985],  resolvendo  a  equação  4.1 e  4.2,  onde  Xc e  Yc  são  as  coordenadas  do  ponto  de 

intersecção.

[ X c Y c 1X 1 Y 1 1X 3 Y 3 1]=0 [eq. 4.1]
[ X c Y c 1X 2 Y 2 1X 4 Y 4 1]=0 [eq. 4.2]

Define-se o coeficiente angular conforme equação 4.3.

K =? X 1? X 3?×?Y 2?Y 4???Y 1?Y 3?×? X 2?X 4? [eq. 4.3]

Com K ?0 para garantir que existe intersecção, tem-se a equação 4.4 e 4.5.

36



X c=
1
K [[

X 1 Y 1
X 3 Y 3]? X 1? X 3?
[ X 2 Y 2X 4 Y 4]? X 2? X 4?] [eq. 4.4]

Y c=
1
K [[

X 1 Y 1
X 3 Y 3]?Y 1?Y 3?
[ X 2 Y 2X 4 Y 4]?Y 2?Y 4?] [eq. 4.5]

Resolve-se as matrizes da equação 4.5 para as equações 4.6 e 4.7.

X c=
? X 2?X 4?×? X 1×Y 3?Y 1× X 3??? X 1? X 3?×? X 2×Y 4?Y 2× X 4?

K
[eq. 4.6]

Y c=
?Y 2?Y 4?×? X 1×Y 3?Y 1× X 3???Y 1?Y 3?×? X 2×Y 4?Y 2× X 4?

K
[eq. 4.7]

A Figura 4.4 demonstra a aplicação deste método.

N-1

(0
,0) x

y

M-1

A

B

21

34

21

34

B
P

A
P

Figura 4.4 – Centro do objeto definido pelo cruzamento das retas formada pelos pontos da caixa de contorno.

Para caixas de contorno quadradas ou retangulares, o cálculo do centro dos objetos é feito 

pela média dos valores de X e Y, conforme equação 4.8.

P c ?
X max? X min

2
,
Y max?Y min

2
? [eq. 4.8]

37



A  Figura  4.5 demonstra  a  aplicação  deste  método,  simples  e  eficiente  em  temos 

computacionais em comparação ao método do cruzamento de retas.

N-1

(0
,0) x

y

M-1

21

34

21

34

Ymin

Ymax

XmaxXmin

Ymin

Ymax

XmaxXmin

A

B
B
P

A
P

      
Figura 4.5 – Centro do objeto definido pela média dos valores de X e Y e aplicado no alvo

4.3. Cálculo do Ângulo entre dois pontos

O ângulo existente entre as retas formadas pelos pontos Pa - Pb e o eixo X pode ser utilizado 

para cálculos de força e tração do riser e é encontrado através da equação 4.9

?=arctg ?
Y P A?Y P B
X P A? X P B

? [eq. 4.9]

A Figura 4.6 demonstra a aplicação deste método.

N-1

(0
,0)

y

M-1

B
P

A
P

x

      
Figura 4.6 – Ângulo definido pelos pontos A e B e aplicado no alvo

38



4.4. Cálculo do Ponto Médio

O ponto médio entre os dois objetos é quem define a posição atual do riser, e é calculado 

através da média dos valores de X e Y dos centros dos objetos, conforme equação 4.10.

P m?
X max? X min

2
,
Y max?Y min

2
? [eq. 4.10]

A Figura 4.7 demonstra a aplicação deste método.

N-1

(0
,0)

y

M-1

B
P

M
P

A
P

Ymin

Ymax

XmaxXminx

     
Figura 4.7 – Ponto médio definido pela média dos valores de X e Y e aplicado no alvo.

4.5. Cálculo da distância em metros do ponto médio em relação à origem

Para o cálculo da distância em metros do ponto médio em relação à origem, é necessário 

obter uma relação de escala através  de uma medida em metros  e a mesma medida em  pixels. 

Neste modelo é calculado através da distância em metros entre os alvos com a distância em pixels 

dos mesmos na imagem, conforme pela equação 4.11.

d alvos pixels=?? X B? X A?
2??Y B?Y A?

2 [eq. 4.11]

A Figura 4.8 apresenta a aplicação deste método.

39



N-1

(0
,0)

y

M-1

B
P

A
P

d

x

      

Figura 4.8 – Distância calculada através dos pontos A e B e aplicado no alvo

O valor de  dalvospixels é diretamente relacionado com o valor em metros dos alvos medidos 

em  laboratório.  Para  calcular  a  distância  do  Ponto  médio  à  origem  em  metros,  deve-se  antes 

calcular a distância em pixels, conforme equação 4.12.

d Pm pixels=?? X P m?2??Y Pm?2 [eq. 4.12]

A Figura 4.9 apresenta a aplicação deste método.

N-1

(0
,0)

y

M-1

M
P

d

xxxx

Figura 4.9 – Distância em pixels do ponto médio em relação à origem.

Com as distâncias entre os alvos e do ponto médio à origem calculadas, a conversão para 

metros é feita através de uma regra de três, conforme equação 4.13.

40



d Pmmetros=
d Pm pixels × d alvosmetros

d alvos pixels
[eq. 4.13]

4.6. Cálculo do deslocamento médio

Para encontrar as freqüências do sistema, deve-se gerar uma seqüência de deslocamentos 

extraindo a distância em metros do ponto médio à origem de cada imagem seqüencial capturada, 

conforme Figura 4.10.

     
Figura 4.10 – Imagem seqüencial

A  Figura  4.11 demonstra  o  deslocamento  do  ponto  médio  no  tempo,  e  sua  interpolação 

Spline.

0 1 2 3 4 5
0

0,5

1

1,5

2

2,5

3

 
0 1 2 3 4 5

0,0

0,5

1,0

1,5

2,0

2,5

3,0
Distância

Figura 4.11 – Deslocamento do ponto médio em metros a esquerda e com interpolação spline a direita.

Os  valores  de  deslocamento  encontrados  estão  afastados  do  eixo  X  por  um  offset  

determinado pela posição dos alvos na câmera. Para processar a Transformada de Fourier neste 

sinal deve-se subtraí-lo da média, conforme equação 4.14.

41



d medio=d spline?
?

0

x

d spline

x ?1
[eq. 4.14]

A  Figura  4.12 demonstra  a  aplicação  desta  técnica  para  o  deslocamento  apresentado  na 

Figura 4.11.

0 1 2 3 4 5
0,0

0,5

1,0

1,5

2,0

2,5

3,0
Distância

 
0 1 2 3 4 5

-1,5

-1,0

-0,5

0,0

0,5

1,0

1,5
Distância

Figura 4.12 – Deslocamento do ponto médio com interpolação spline a esquerda e subtraído da média à direita.

4.7. Correlação de imagens estéreo (3D)

O cálculo do deslocamento médio feito através da captura da imagem de uma única câmera 

leva  em consideração apenas  deslocamentos  nos  eixos  X e Y, mas  perde as  informações  para 

deslocamentos em profundidade (eixo Z).

Utilizando-se  um  par  de  câmeras,  é  possível  correlacionar  um  ponto  na  câmera  A e  o 

mesmo ponto na câmera B, obtendo-se as suas coordenadas XYZ no mundo real [Oisel, 2003].

A Figura 4.13 apresenta uma câmera e a imagem projetada de tamanho m x n.

42



     

Figura 4.13 – Câmera com resolução MxN e seu foco.

Dado um ponto P(x,y,z) qualquer no espaço, ele tem sua projeção na tela da câmera através 

de um ponto P1(x,y), com deslocamento dx e dy em relação ao foco (f).

     

Figura 4.14 – Projeção de um ponto P em uma câmera

O ponto P1 e o foco define dois triângulos com arestas f-x e f-y conforme Figura 4.15.

43



     

Figura 4.15 – Projeção de um ponto P em uma câmera

O triângulos A e B são diretamente proporcionais aos triângulos C e D conforme  Figura

4.16.

     

Figura 4.16 – Triângulos diretamente proporcionais

Com duas câmeras deslocadas em Tx, tem-se a relação conforme demonstra Figura 4.17.

44



     

Figura 4.17 – Projeção do ponto P em duas câmeras deslocadas em Tx

A Figura 4.18 mostra a visão em topo, lateral e frontal do sistema.

      

Figura 4.18 – Visão topo à esquerda, lateral ao centro e frontal à direita.

Definindo-se a Câmera 01 na Origem (0,0,0), as equações 4.15 e 4.16 definem os pontos P1 
e P2.

P 1=[ X 1Y 1f ] [eq. 4.15]
P 2=[ X 2Y 2f ] [eq. 4.16]

45



Relacionando-se os triângulos, tem-se as equações 4.17 e 4.18.

Z
f
×P 1=T x?

Z
f
×P 2 [eq. 4.17]

Z =T x×?
P 1
f
?

P 2
f
? [eq. 4.18]

Expandindo-se a equação 4.18 obtêm-se 4.19.

Z =[ 0T x0 ]?[
Y 2
f
?

Y 1
f

X 2
f
?

X 1
f

0
] [eq. 4.19]

Através equação 4.19, obtém-se as coordenadas P(X,Y,Z) através das equações 4.20 a 4.22

Z =
T x× f

? X 1? X 2?
[eq. 4.20]

X =
X 1×Z

f
[eq. 4.21]

Y =
Y 1×Z

f
[eq. 4.22]

46



Capítulo 5

Riser de Produção de Petróleo e Modelo em escala

Os  risers são dutos  suspensos  utilizados  para movimentar os fluidos petrolíferos  entre o 

fundo do mar e a plataforma de extração de petróleo. Durante a produção de petróleo em águas 

profundas e ultraprofundas, os  risers são considerados equipamentos críticos ao processo, uma 

vez  que  estão  submetidos  a  grandes  carregamentos  estáticos  e  dinâmicos.  Estes  esforços  são 

oriundos da ação das correntezas, das ondas, da plataforma de produção e do escoamento interno 

dos fluidos produzidos. 

O  conhecimento  da  contribuição  de  cada  um  desses  efeitos  sobre  o  carregamento  total 

atuante em um duto suspenso é fundamental para o correto dimensionamento do mesmo, portanto 

o  estudo  focalizou-se  na  influência  do  escoamento  interno  dos  fluidos  produzidos  sobre  a 

estrutura de risers dispostos em forma de catenária.

Figura 5.1 - Esquema de um Riser de produção de petróleo

47



5.1. Construção do modelo em escala

É  proposta  a  montagem  de  um  aparato  experimental  com  a  finalidade  de  prover  o 

entendimento do fenômeno físico envolvido. O espaço do Laboratório de Petróleo – LabPetro do 

Centro  de  Estudos  de  Petróleo  –  CEPETRO,  na  Universidade  Estadual  de  Campinas  – 

UNICAMP, é utilizado para a montagem do equipamento experimental. Este laboratório possui 

área construída de aproximadamente 350 m², dispondo de um pé-direito principal de 12,5 m de 

altura localizado no salão dos  fundos do prédio. Neste espaço estão dispostos  dois  mezaninos 

com  escadas  de  acesso  ao  teto,  também  habitável,  e  com  capacidade  de  suportar  até  1.000 

kgf/m2, conforme Figura 5.2 e 5.3.

  

  
Figura 5.2 - Imagens do LabPetro

48



12,
48 

m

38 
m

1
2
,4

8
 m

3,9 m

3,9
 m

Protótipo Modelo
Projeção Horizontal   1600 m 22,2 m

Projeção Vertical   900 m escala 12,5 m
Touch Down Point   830 m 72 11,5 m

Comprimento Total do Riser   2066 m 28,7 m

12,
48 

m

38 
m

1
2
,4

8
 m

3,9 m

3,9
 m

Protótipo Modelo
Projeção Horizontal   1600 m 22,2 m

Projeção Vertical   900 m escala 12,5 m
Touch Down Point   830 m 72 11,5 m

Comprimento Total do Riser   2066 m 28,7 m

Figura 5.3 - Disposição do laboratório LabPetro

O aparato experimental desenvolvido tem o objetivo de simular o escoamento bifásico de 

óleo e gás no interior de uma linha de riser. Para esse fim é construído um modelo de riser em 

escala reduzida utilizando-se os dados fornecidos pela Petróleo Brasileiro S.A. - PETROBRAS. 

A metodologia  utilizada  para  o  estudo  do  efeito  de  chicoteamento  do  riser devido  ao 

escoamento  interno  baseou-se  na  construção  de  um  modelo  experimental  em  escala  reduzida. 

Portanto, objetivando a reprodutibilidade do fenômeno, correlacionou-se os principais parâmetros 

geométricos, estruturais e do escoamento no riser real com os do modelo através do teorema Pi 

de Buckingham [Hart, 1995].

Este  método  consiste  na  seleção  das  variáveis  relevantes  e  suas  combinações,  visando 

fornecer números adimensionais que possibilitem a redução de escala apropriada entre modelo e 

protótipo. Resultados significativos podem ser obtidos a partir da análise dimensional, reduzindo-

se os custos e os esforços empregados nesse processo.

O cálculo das vazões de ar e água utilizadas para realização dos experimentos no modelo 

baseou-se em dados das vazões de produção de óleo no riser real, da fração de gás (ou fração de 

49



vazio) e nos diâmetros do protótipo e do modelo. Valores de vazões dos fluidos também foram 

extrapolados visando abranger uma faixa maior de estudo. Nesse procedimento igualaram-se os 

números de Froude [White, 1999] para ambos os casos.

O material empregado para a confecção do modelo de riser é silicone, formando um duto 

flexível  de  35  m  de  comprimento  e  diâmetros  interno  e  externo  de  19  mm  e  25  mm 

respectivamente . A escolha deste material é feita baseada na necessidade de manter a relação de 

escala entre os módulos de rigidez à flexão do riser real e do modelo em estudo, conforme Figura

5.4.  Para os testes empíricos, foram instalados medidores de vazão de fluidos (água) no duto e 

medidores  de  força  de  sustentação  de  topo.  Um sistema  de  captura  de  imagens,  formado  por 

câmeras e equipamento para aquisição de dados foi posicionado paralelo ao plano de movimento.

Figura 5.4 - Foto da mangueira utilizada para simulação de um riser

No sistema, a circulação de água é feita em circuito fechado. Entretanto, a circulação da 

fase gasosa é feita de forma aberta, uma vez que o ar é liberado na atmosfera após fluir através do 

sistema.

O abastecimento de água é feito por meio de um tanque d’água com capacidade para 1000L 

(mil litros) instalado no terraço do prédio do LabPetro. A água escoa através de uma tubulação até 

atingir  o  ponto  mais  baixo  do  circuito  (térreo  do  prédio)  onde  está  posicionado  o  sistema  de 

bombeamento. Ao passar por uma bomba, a água é pressurizada e segue através da tubulação 

para o sistema de medição de vazão. Neste ponto estão instalados dois medidores de vazão de 

50



água: um com faixa de aplicação para baixas vazões e outro para altas vazões. O escoamento é 

direcionado somente através de um destes medidores, e segue através da tubulação até a entrada 

do injetor, conforme Figura 5.5 e 5.6.

6,2
3,925 4,15

4,15

4,2

23,68

50,48
12,48

11,5010,70

Linha de 
ar

Linha 
de 

água

Linha 
de 

retorno

Tanque de 
Água (volume 

= 1000 L)

Tanque 
separador 
Água-Ar

Sistema de 
fixação e 
agitador

TDP
6,2

3,925 4,15

4,15

4,2

23,68

50,48
12,48

11,5010,70

Linha de 
ar

Linha 
de 

água

Linha 
de 

retorno

Linha 
de 

retorno

Tanque de 
Água (volume 

= 1000 L)

Tanque 
separador 
Água-Ar

Sistema de 
fixação e 
agitador

TDPTDPTDP

Figura 5.5 - Representação esquemática do sistema experimental

  
Figura 5.6 - Tubulação de ar-água e seus manômetros digitais

O abastecimento de ar comprimido é realizado através do acionamento de um compressor, 

onde o ar pressurizado é introduzido no sistema através da abertura de uma válvula de restrição 

51



de fluxo acoplada a um manômetro. O ar flui através de uma tubulação passando pelo medição de 

vazão de gás, chegando posteriormente a um injetor/misturador ar-água.

O sistema de injeção de fluidos consiste de um injetor de nylon e de uma janela de acrílico 

para visualização do escoamento. O sistema de injeção foi projetado para propiciar a mistura do 

gás e do líquido conforme Figura 5.7 e 5.8.

Figura 5.7 - Desenho esquemático do injetor

  
Figura 5.8 - Imagens do injetor

No injetor os fluxos monofásicos de água e ar são misturados e o escoamento deste ponto 

em  diante  passa  a  ser  bifásico.  Na  saída  do  injetor  existe  um  tubo  de  acrílico  que  permite  a 

visualização do padrão de escoamento do fluxo bifásico. 

52



Após  passar pelo sistema  de injeção,  o escoamento  através  do modelo  de  riser varia da 

inclinação horizontal até a vertical. Há uma longa seção horizontal que eleva-se após o “ponto de 

contato  com  o  solo”  (touchdown  point  -  tdp)  em  forma  de  catenária  até  a  conexão  de  topo 

conforme Figura 5.9.

  
Figura 5.9 - Imagens do duto flexível em catenária

No topo do modelo de  riser, está posicionado um dinamômetro (célula de carga), o qual 

permite  a  medição  dos  valores  da  força  de  topo.  Este  dinamômetro  foi  especificado  para 

acompanhar as variações do ângulo de topo do modelo de acordo com a variação de carga.

  
Figura 5.10 - Imagens da célula de carga

53



Após chegar ao topo do modelo de riser (no terraço do LabPetro) o escoamento bifásico é 

direcionado  através  de  uma  tubulação  retornando  para  o  tanque  d’água.  Neste  ponto, o  gás  é 

liberado para a atmosfera e o líquido é reaproveitado pelo sistema. 

Todos  os  sinais  captados  pelos  instrumentos  são  transmitidos  através  de  cabos  para  o 

sistema de aquisição de dados. Neste sistema os sinais recebidos são condicionados, tratados e 

armazenados em arquivos de texto para posterior análise.

As câmeras de captura de imagem são fixadas  paralelas ao modelo ao longo do laboratório, 

no total de 6 (seis) câmeras (Figura 5.11), a fim de se conhecer as freqüências das oscilações e 

suas  amplitudes  existentes  durante todo o processo de  escoamento  dos  fluidos.  Para marcar  e 

facilitar a detecção com as câmeras, duas esferas de isopor em cor laranja são fixadas no duto 

flexível.  (Figura 5.12).

  
Figura 5.11 - Câmeras fixadas paralelas ao modelo

54



  
Figura 5.12 - Duto flexível com alvos laranja

5.2. Hardware de Captura de Imagens

Para  a análise  do modelo  de  riser define-se alguns  requisitos  mínimos  para  captura  das 

imagens do modelo: baixo custo de implementação, capaz de gerar imagens a uma freqüência 

mínima  de  5Hz,  resolução  mínima  de  320  por  240  pixels  e  um computador  com  porta  USB 

versão 1.1 ou superior.

As câmeras utilizadas possuem dois encapsulamentos. Uma versão para computadores de 

mesa (desktop)  e outra com haste flexível  para computadores  portáteis  (notebooks), conforme 

ilustrado na Figura 5.13, com as especificações da Tabela 5.1:

55



Sensor: CMOS colorido
Resolução: 640 x 480 (350K pixels) VGA

352 x 288 (100K pixels) CIF
Alimentação: 5Vdc (Porta USB)

Interface: Porta USB ver. 1.1
Lentes: F2.2 / F6.85

Atualização de vídeo: 20 - 30 q/s (CIF) / 10 - 15 q/s (VGA)
Distância de foco: 30mm ao infinito

Formato da imagem: RGB24 (True Color: 24 bit)
Ângulo de rotação: 360° horizontal

Ângulo da inclinação: 55° vertical
Comprimento do cabo: 1,30m +/- 5%

Custo (Junho/2008): R$55,00
Tabela 5.1 - Tabela de dados técnicos das câmeras utilizadas

            

Figura 5.13 - Câmeras USB utilizadas na captura de imagens

56



Capítulo 6

Sistema de Captura e Processamento de Imagens

A  automação  da  captura  e  processamento  das  imagens  é  realizada  através  do 

desenvolvimento  de  um  aplicativo  de  captura  e  geração  de  imagens  no  formato  “Joint  

Photographic  Experts  Group”  [JPEG,  2000]  ,  que  se  conecta  diretamente  ao  equipamento 

instalado  em  laboratório.  Outro  aplicativo  é  utilizado  para  o  posterior  processamento  destas 

imagens.

6.1. Aplicativo de Captura

Devido ao comprimento extenso do duto flexível utilizado como modelo de riser, torna-se 

necessário  a  utilização  de  6  (seis)  câmeras  para  a  captura  do  movimento  de  grande  parte  da 

extensão do sistema. Portanto, é desenvolvido um aplicativo de captura de imagens, que supre a 

necessidade de captura de uma ou mais câmeras simultâneas utilizando um mesmo computador, 

sendo capaz de capturar e gravar, em disco rígido, imagens seqüenciais em formato JPEG para 

processamento posterior, conforme Figura 6.1.

57



Figura 6.1 - Aplicativo de captura de câmeras

Um arquivo de configuração chamado “setup.ini”, localizado junto ao aplicativo de captura, 

define os parâmetros da aquisição e amostragem, conforme  Tabela 6.1. O fluxograma da Figura

6.2 apresenta a seqüência lógica simplificada da rotina de captura.

[SETUP]
;Quantidade de câmeras neste computador
Cameras = 2
;Tempo total de captura (em segundos)
Tempo   = 5
;Tamanho da imagem a ser capturada (em pixels)
Largura = 640
Altura  = 320
;Tempo entre cada amostragem (em milissegundos)
DeltaT = 50

Tabela 6.1 - Arquivo de configuração da captura

58



Figura 6.2 - Fluxograma simplificado de execução do aplicativo de captura

6.2. Aplicativo de Processamento de Imagens

Após  o  término  da  captura  das  imagens,  é  possível  processar  o  resultado  utilizando  o 

aplicativo de processamento de imagens desenvolvido, que utiliza as técnicas de processamento 

de sinais, imagens e extração de dados apresentadas nos capítulos 2 ao 4 deste trabalho.

É  utilizado  o  aplicativo  Labview  8.5,  juntamente  com  o  pacote  de  visão  computacional 

IMAQ  Vision da  empresa  National  Instruments  para  desenvolver  o  aplicativo  de  extração  de 

59

Inicializa em modo
de espera

Recebeu aviso
para começar 

a captura?

não

Captura uma
imagem

Salva a
imagem
em disco

Acabou o tempo 
total de captura?

Verifica quantos
segundos

se passaram
desde o início

finaliza

não

sim

sim



dados da imagem [National, 2008].

A configuração  do  aplicativo  de  processamento  dá-se  através  da  seleção  do  Ponto  de 

trabalho (Caso de Captura), Pasta (para armazenar os arquivos de imagem) e  Thresholding. A 

Figura 6.3 exibe a tela principal do aplicativo com um resultado exemplo processado para duas 

câmeras,  e  a  Figura  6.4 exibe  a  tela  de  configuração  de  Thresholding,  com  parâmetros 

independentes para 6 (seis) câmeras.

Figura 6.3 - Tela do aplicativo de processamento de imagens

60



Figura 6.4 - Tela de configuração de Thresholding

A seleção dos parâmetros de thresholding, erosão e dilatação são demonstrados no tópico a 

seguir.

6.3. NI-Vision Assistant

O  pacote  “NI-IMAQ  Vision”  contém  um  aplicativo  chamado  “NI-Vision  Assistant”, 

necessário para a  seleção visual dos parâmetros dos algoritmos de processamento de imagens, 

conforme é apresentado na Figura 6.5.

61



Figura 6.5 - Tela inicial do NI-Vision Assistant

Após a inicialização do programa, deve-se abrir uma imagem capturada através do menu 

FILE &gt; OPEN IMAGE, conforme Figuras 6.5 e 6.6.

Figura 6.6 - Imagem aberta para processamento

Após a seleção do processo de  Thresholding  (no painel esquerdo), são exibidos os  pixels  

que serão definidos como 1 (um) através da cor escolhida em “Preview Color”. Na cor vermelha 

62



para o exemplo da Figura 6.7.

Figura 6.7 - Processamento de Thresholding

Utiliza-se  a  ferramenta  de  seleção  de  área  circular  para  encontrar  a  faixa  de  espectro 

existente em cada canal RGB nos  pixels que estão dentro da região selecionada. O espectro é 

mostrado em um gráfico na esquerda, parte inferior da tela do aplicativo, conforme Figura 6.8.

Figura 6.8 - Seleção da área de interesse de Thresholding

63



Utiliza-se os valores de Min/Max para escolher uma faixa de Thresholding que cubra todo o 

gráfico de cada canal. Para as cores laranja da Figura 6.9, a faixa definida é: Vermelho (R) 110 a 

255, Verde (G) de 0 a 145 e Azul (B) de 0 a 60. 

Figura 6.9 - Seleção da faixa de corte de Thresholding

A Figura 6.10 apresenta o resultado da técnica de Thresholding, com os resíduos que devem 

ser eliminados.

Figura 6.10 - Thresholding aplicado

64



A  Figura 6.11 demonstra a aplicação da técnica de Erosão, e a  Figura 6.12 demonstra a 

Dilatação. Para imagens de 640x480 pixels utiliza-se o elemento de estrutura 5x5 e para imagens 

de 320x240 pixels utiliza-se o elemento de 3x3.

Figura 6.11 - Erosão 5x5 dos objetos para remoção de objetos pequenos

Figura 6.12 - Dilatação 5x5 dos objetos para fechamento

65



A Figura 6.13 apresenta a aplicação do algoritmo de identificação de objetos, utilizada pelo 

algoritmo  de  Calibração  do  aplicativo  NI-Vision  Assistant (Figura  6.14)  para  calcular  os 

parâmetros de distância, ângulo e ponto médio dos objetos conforme Figura 6.15 e Figura 6.16.

Figura 6.13 - Identificação de objetos

Figura 6.14 - Análise de objetos

66



 

Figura 6.15 - Análise de objetos com resultados de Distância, Ângulo e Ponto Médio

Figura 6.16 - Processo finalizado

67



A Figura 6.17 apresenta a seqüência final dos algoritmos aplicados para a identificação dos 

parâmetros da imagem escolhida na Figura 6.6.

Figura 6.17 - Seqüência executada

68



Capítulo 7

Simulação e Aplicação das Técnicas de Processamento

Neste  capítulo  são  apresentados  os  resultados  das  medidas  de  vibração  utilizando-se 

imagens de câmera. Faz-se inicialmente uma validação da técnica proposta, através do uso de um 

modelo virtual com  imagens geradas em software de simulação gráfica. Apresenta-se a seguir os 

resultados das medidas de vibração no riser, comparando-os com as medidas de um acelerômetro. 

O movimento predominante do riser é em um plano  perpendicular ao eixo óptico das câmeras, o 

que não permitiu a validação da técnica proposta para a medida de movimentos espaciais. Assim, 

ao final do capítulo é apresentada uma nova simulação do movimento espacial geral de um alvo, 

e a sua reconstrução após captura de imagens por câmeras.

7.1. Simulação através do aplicativo 3D Studio Max

Os algoritmos de processamento de imagens e extração de dados apresentados no capítulo 3 

e  4  são  aplicados  às  imagens  geradas  por  computador  através  do  aplicativo  de  computação 

gráfica  3D  Studio  Max  [Autodesk,  2008],  no  qual  é  possível  determinar  a  posição  e  o 

deslocamento periódico dos alvos (duas esferas laranjas fixadas ao duto flexível).

A  Figura 7.1 ilustra a tela de desenvolvimento da simulação e dos objetos em 3D. Uma 

câmera é colocada em frente aos alvos, simulando as situação encontrada no laboratório, e dois 

alvos são de igual forma fixados a um duto flexível.

69



As  Figura 7.2 e 7.3 exibem os gráficos das curvas deslocamento, utilizados para criar um 

movimento  periódico  do  sistema.  O  eixo  X  determina  em  qual  quadro  (frame)  é  aplicado  o 

deslocamento e o eixo Y define a amplitude do deslocamento em centímetros. 

Figura 7.1 - Interface gráfica do aplicativo de computação gráfica 3D Studio Max

70



Figura 7.2 - Curva de deslocamento do sistema em detalhe (cm)

Figura 7.3 - Curva contínua do deslocamento em Z do sistema (cm)

Na  simulação  são  utilizados  os  seguintes  parâmetros  de  posição  dos  alvos  e  da  câmera 

conforme Tabela 7.1:

X (cm) Y (cm) Z (cm) Diâmetro (cm)
Alvo esquerdo -15 0 0 15
Alvo direito 15 0 0 15
Câmera 0 -150 0 -

Tabela 7.1 - Posição dos objetos no simulador

7.2. Simulação do Riser em movimento 2D

A Figura 7.4 ilustra alguns quadros seqüenciais gerados, com rotação de -30o  em torno do 

eixo Y com centro no ponto médio dos alvos.

71



    
Figura 7.4 - Quadros seqüenciais da simulação

Nas próximas seções serão apresentados três casos de simulações, com sinais de freqüência 

e deslocamento conhecidos.

7.2.1. Simulação do Riser em movimento a 1Hz

É definido uma taxa de geração de imagem a 24Hz, com tempo total de 10 segundos.  A 

Figura 7.5 exibe o gráfico da curva deslocamento contínuo no sentido do eixo Z com os valores 

da Tabela 7.2:

Quadro Deslocamento Z (cm)
0 0
6 15
12 0
24 -15

Tabela 7.2 - Pontos de configuração de deslocamento

Figura 7.5 - Freqüência de 1Hz, com deslocamento em Z de +/- 15cm

72



Após  a geração  das  240 imagens,  é utilizado  o aplicativo  de processamento de imagens 

para extrair os valores de deslocamento encontrados na simulação. A Figura 7.6 exibe o gráfico 

de deslocamento gerado após o processamento de imagens e a  Figura 7.7 exibe as freqüências 

encontradas.

Figura 7.6 - Sinal de 1 Hz recuperado através do aplicativo de processamento de imagens

Figura 7.7 - Freqüência de 1 Hz encontrada através da Transformada de Fourier

Observa-se que a amplitude encontrada de +/- 15 cm é a mesma gerada pelo aplicativo 3D, 

assim como a freqüência de 1Hz mostrada pela Figura 7.7. Esta mesma verificação deve ser feita 

para os casos simulados a seguir.

7.2.2. Simulação do Riser em movimento a 2Hz

Para a segunda simulação é utilizado um sinal de deslocamento com freqüência de 2Hz. A 

73



Figura 7.8 exibe o gráfico da curva deslocamento contínuo no sentido do eixo Z com os valores 

da Tabela 7.3:

Quadro Deslocamento Z (cm)
0 0
3 10
6 0
12 -10

Tabela 7.3 - Pontos de configuração de deslocamento

É definida uma taxa de geração de imagem a 24Hz, com tempo total de 10 segundos.

Figura 7.8 - Freqüência de 2 Hz, com deslocamento em Z de +/- 10cm

A Figura 7.9 exibe o gráfico de deslocamento gerado após o processamento de imagens e a 

Figura 7.10 exibe as freqüências encontradas.

Figura 7.9 - Sinal de 2 Hz recuperado através do aplicativo de processamento de imagens

74



Figura 7.10 - Freqüência de 2 Hz encontrada através da Transformada de Fourier

Novamente observa-se que a amplitude encontrada de +/- 10 cm é a mesma gerada pelo 

aplicativo 3D, assim como a freqüência de 2Hz mostrada pela Figura 7.10.

7.2.3. Simulação do Riser em movimento com freqüência combinada de 1 Hz e 2 Hz

Para a segunda simulação é utilizado um sinal de deslocamento com freqüência de 1Hz 

combinada a 2Hz. A  Figura 7.13 exibe o gráfico da curva deslocamento contínuo no sentido do 

eixo Z com os valores da Tabela 7.4:

Quadro Deslocamento Z (cm)
0 0
5 26,2
10 -5,5
15 5,5
20 -26,2
25 0

Tabela 7.4 - Pontos de configuração de deslocamento

É definido uma taxa de geração de imagem a 25Hz, com tempo total de 10 segundos.

75



Figura 7.11 - Freqüência de 1Hz combinada com 2 Hz, com deslocamento em Z de +/- 26,2cm

A Figura 7.12 exibe o gráfico de deslocamento gerado após o processamento de imagens e 

a Figura 7.13 exibe as freqüências encontradas.

Figura 7.12 - Sinal de 1Hz combinada a 2 Hz recuperado através do aplicativo de processamento de imagens

Figura 7.13 - Freqüência de 1 Hz combinada a 2Hz encontradas através da Transformada de Fourier

76



A  Figura  7.14 exibe  o  gráfico  de  deslocamento  e  a  Figura  7.15 exibe  um  exemplo  de 

gráfico resultado das freqüências encontradas após o processamento de uma captura de imagens 

em laboratório, a partir de 5 (cinco) alvos diferentes fixados no duto flexível.

Figura 7.14 - Deslocamento obtido através do processamento de 5 (cinco) alvos

Figura 7.15 - Freqüências obtidas através do processamento de 5 (cinco) alvos

7.3. Comparação de dados entre acelerômetro e câmera

Após a validação do procedimento  de medidas dinâmicas a partir de imagens procede-se a 

realização  da  medida  e  análise  de  vibração  do  modelo  de  riser em  laboratório.  Os  sinais  de 

movimento do riser são capturados também através de  um acelerômetro, para comparar e validar 

os resultados obtidos por uma câmera. A Figura 7.16 apresenta o modelo com dois alvos de 15cm 

de diâmetro fixados a 25cm de distância e o acelerômetro fixado próximo ao ponto médio. A 

Figura  7.17 exibe  uma  seqüência  de  quadros  capturados  pela  câmera.  As  especificações  do 

77



acelerômetro encontram-se no Anexo I.

Figura 7.16 - Modelo em escala com alvos e acelerômetro fixado próximo ao centro.

    
Figura 7.17 - Quadros seqüenciais da captura

É  definido  também  um  planejamento  de  testes,  adotando-se  diferentes  velocidades  de 

captura  e diferentes resoluções da imagem, conforme mostrado na Tabela 7.5.

Caso 01 02 03 04 05 06
Freqüência de Amostragem 5 Hz 5 Hz 10 Hz 10 Hz 25 Hz 25 Hz
Resolução da Câmera

200 ms 200 ms 100 ms 100 ms 40 ms 40 ms
640 x 480 pixels 320 x 240 pixels 640 x 480 pixels 320 x 240 pixels 640 x 480 pixels 320 x 240 pixels

DeltaT desejado

Tabela 7.5 - Planilha de trabalho

A seguir são apresentados os resultados  de cada experimento, na forma  de gráficos  com 

as medidas de acelerômetro e da câmera. É apresentado também a variação do tempo de captura 

de  cada  amostra  de  imagem,  antes  da  regularização  das  amostras  via  Spline.  Isso  porque, 

conforme explicado anteriormente, o valor nominal da freqüência de captura das  câmeras  não 

corresponde ao que se obtém de maneira prática .

78



7.3.1. Caso 01

Parâmetros de aquisição:

Freqüência de Amostragem 5 Hz
Resolução da Câmera 640 x 480 pixels
?t desejado 200 ms
?t Médio obtido 264,26 ms
?t Mínimo obtido 125 ms
?t Máximo obtido 688 ms

Tabela 7.6 - Tabela de configuração e cálculo do ?t para o caso 01

Resultados das medidas de aceleração:

Figura 7.18 - Amostragem do sinal com acelerômetro

Resultados das medidas de deslocamento via câmera:

Figura 7.19 - Amostragem do sinal com câmera

79



Resultados do especto de acelerações:

Figura 7.20 - Transformada de Fourier do sinal do acelerômetro

Resultados do espectro de deslocamento via câmera:

Figura 7.21 - Transformada de Fourier do sinal da câmera

Observa-se  nos  dois  gráficos  acima  que  as  medidas  espectrais  apresentam  a  mesma 

característica  de distribuição das freqüências, com picos em 0,98Hz e 1,13Hz.

A Figura 7.22 apresenta a variação do tempo de captura das imagens da câmera. Observa-se 

que  as  variações  possuem  características  aleatórias,  mantendo  constante  o  tempo  médio  de 

aquisição.

80



Figura 7.22 - Variação do ?t de captura da câmera

7.3.2. Caso 02

Parâmetros de aquisição:

Freqüência de Amostragem 5 Hz
Resolução da Câmera 320 x 240 pixels
?t desejado 200 ms
?t Médio obtido 203,16 ms
?t Mínimo obtido 141 ms
?t Máximo obtido 266 ms

Tabela 7.7 - Tabela de configuração e cálculo do ?t para o caso 02

Resultados das medidas de aceleração:

Figura 7.23 - Amostragem do sinal com acelerômetro

81



Resultados das medidas de deslocamento via câmera:

Figura 7.24 - Amostragem do sinal com câmera

Resultados do especto de acelerações:

Figura 7.25 - Transformada de Fourier do sinal do acelerômetro

Resultados do espectro de deslocamento via câmera:

Figura 7.26 - Transformada de Fourier do sinal da câmera

82



Observa-se nos dois gráficos acima que as medidas espectrais apresentam a mesma 

característica  de distribuição das freqüências, com picos em 0,95Hz e 1,06Hz.

A Figura 7.27 apresenta a variação do tempo de captura das imagens da câmera. Observa-se 

que  as  variações  possuem  características  aleatórias,  mantendo  constante  o  tempo  médio  de 

aquisição.

Figura 7.27 - Variação do ?t de captura da câmera

7.3.1. Caso 03

Parâmetros de aquisição:

Freqüência de Amostragem 10 Hz
Resolução da Câmera 640 x 480 pixels
?t desejado 100 ms
?t Médio obtido 231,10 ms
?t Mínimo obtido 140 ms
?t Máximo obtido 359 ms

Tabela 7.8 - Tabela de configuração e cálculo do ?t para o caso 03

83



Resultados das medidas de aceleração:

Figura 7.28 - Amostragem do sinal com acelerômetro

Resultados das medidas de deslocamento via câmera:

Figura 7.29 - Amostragem do sinal com câmera

Resultados do especto de acelerações:

Figura 7.30 - Transformada de Fourier do sinal do acelerômetro

84



Resultados do espectro de deslocamento via câmera:

Figura 7.31 - Transformada de Fourier do sinal da câmera

Observa-se  nos  dois  gráficos  acima  que  as  medidas  espectrais  apresentam  a  mesma 

característica  de distribuição das freqüências, com picos em 1,02Hz e 1,15Hz.

A Figura 7.32 apresenta a variação do tempo de captura das imagens da câmera. Observa-se 

que  as  variações  possuem  características  aleatórias,  mantendo  constante  o  tempo  médio  de 

aquisição.

Figura 7.32 - Variação do ?t de captura da câmera

85



7.3.4. Caso 04

Parâmetros de aquisição:

Freqüência de Amostragem 10 Hz
Resolução da Câmera 320 x 240 pixels
?t desejado 100 ms
?t Médio obtido 120,99 ms
?t Mínimo obtido 62 ms
?t Máximo obtido 469 ms

Tabela 7.9 - Tabela de configuração e cálculo do ?t para o caso 04

Resultados das medidas de aceleração:

Figura 7.33 - Amostragem do sinal com acelerômetro

Resultados das medidas de deslocamento via câmera:

Figura 7.34 - Amostragem do sinal com câmera

86



Resultados do especto de acelerações:

Figura 7.35 - Transformada de Fourier do sinal do acelerômetro

Resultados do espectro de deslocamento via câmera:

Figura 7.36 - Transformada de Fourier do sinal da câmera

Observa-se  nos  dois  gráficos  acima  que  as  medidas  espectrais  apresentam  a  mesma 

característica  de distribuição das freqüências, com picos em 0,87Hz e 1,0Hz.

A Figura 7.37 apresenta a variação do tempo de captura das imagens da câmera. Observa-se 

que  as  variações  possuem  características  aleatórias,  mantendo  constante  o  tempo  médio  de 

aquisição

87



Figura 7.37 - Variação do ?t de captura da câmera

7.3.5. Caso 05

Parâmetros de aquisição:

Freqüência de Amostragem 25 Hz
Resolução da Câmera 640 x 480 pixels
?t desejado 40 ms
?t Médio obtido 195,75 ms
?t Mínimo obtido 125 ms
?t Máximo obtido 500 ms

Tabela 7.10 - Tabela de configuração e cálculo do ?t para o caso 05

Resultados das medidas de aceleração:

Figura 7.38 - Amostragem do sinal com acelerômetro

88



Resultados das medidas de deslocamento via câmera:

Figura 7.39 - Amostragem do sinal com câmera

Resultados do especto de acelerações:

Figura 7.40 - Transformada de Fourier do sinal do acelerômetro

Resultados do espectro de deslocamento via câmera:

Figura 7.41 - Transformada de Fourier do sinal da câmera

89



Observa-se  nos  dois  gráficos  acima  que  as  medidas  espectrais  apresentam  a  mesma 

característica  de distribuição das freqüências, com picos em 0,875Hz e 1,115Hz.

A Figura 7.42 apresenta a variação do tempo de captura das imagens da câmera. Observa-se 

que  as  variações  possuem  características  aleatórias,  mantendo  constante  o  tempo  médio  de 

aquisição.

Figura 7.42 - Variação do ?t de captura da câmera

7.3.7. Caso 06

Parâmetros de aquisição:

Freqüência de Amostragem 25 Hz
Resolução da Câmera 320 x 240 pixels
?t desejado 40 ms
?t Médio obtido 93,40 ms
?t Mínimo obtido 62 ms
?t Máximo obtido 141 ms

Tabela 7.11 - Tabela de configuração e cálculo do ?t para o caso 06

90



Resultados das medidas de aceleração:

Figura 7.43 - Amostragem do sinal com acelerômetro

Resultados das medidas de deslocamento via câmera:

Figura 7.44 - Amostragem do sinal com câmera

Resultados do especto de acelerações:

Figura 7.45 - Transformada de Fourier do sinal do acelerômetro

91



Resultados do espectro de deslocamento via câmera:

Figura 7.46 - Transformada de Fourier do sinal da câmera

Observa-se nos dois gráficos acima que as medidas espectrais apresentam a mesma 

característica  de distribuição das freqüências, com picos em 0,795Hz, 1,12Hz e 1,225Hz.

A Figura 7.47 apresenta a variação do tempo de captura das imagens da câmera. Observa-se 

que  as  variações  possuem  características  aleatórias,  mantendo  constante  o  tempo  médio  de 

aquisição.

Figura 7.47 - Variação do ?t de captura da câmera

7.3.7. Comparação de erro do ?t de captura

Efetua-se em seguida a comparação dos dados da variação do tempo de captura  dentre os 

casos medidos. Observa-se que o erro médio encontrado em cada processamento tem seu valor 

92



diretamente relacionado com a resolução da câmera e a freqüência de amostragem. No caso de 

baixa resolução de captura e de freqüência de amostragem, o ?t médio fica próximo ao desejado, 

ocorrendo o inverso para resoluções e freqüências mais altas, conforme mostrado na Tabela 7.12 

e na Figura 7.48:

Caso 01 02 03 04 05 06
Freqüência de Amostragem 5 Hz 5 Hz 10 Hz 10 Hz 25 Hz 25 Hz
Resolução da Câmera

200 ms 200 ms 100 ms 100 ms 40 ms 40 ms
264,26 ms 203,16 ms 231,10 ms 120,99 ms 195,75 ms 93,40 ms

125 ms 141 ms 140 ms 62 ms 125 ms 62 ms
688 ms 266 ms 359 ms 469 ms 500 ms 141 ms

640 x 480 pixels 320 x 240 pixels 640 x 480 pixels 320 x 240 pixels 640 x 480 pixels 320 x 240 pixels
?t desejado
?t Médio obtido
?t Mínimo obtido
?t Máximo obtido

Tabela 7.12 - Compilação das tabelas de configuração e cálculo do ?t para todas as capturas

Figura 7.48 - Erro médio x Freqüência à esquerda e Erro médio x Resolução à direita.

7.4. Simulação do Riser em 3D

Os  dados  experimentais  de  captura  de  imagem  foram  feitos  com  o  uso  de  apenas  uma 

câmera, já que o movimento do riser ocorre predominantemente na direção paralela ao eixo das 

imagens. A aplicação da técnica para medidas de movimento no espaço 3D, com o uso de duas 

câmeras  paralelas,  conforme  descrito  no  capítulo  4,  seção  7,  é  aqui  verificada  por  meio  de 

simulação virtual. 

A Figura 7.49 ilustra a configuração geral do ambiente de simulação através de computação 

gráfica. A Figura 7.50 apresenta duas imagens virtualmente projetadas em cada câmera. O eixo X 

93



mede o deslocamento horizontal, o eixo Y mede o deslocamento em vertical e o eixo Z é o eixo 

de medidas de profundidades. A tabela 7.13 apresenta os dados de posição do centro das imagens-

alvo em relação aos referencias das duas câmeras projetivas.

Figura 7.49 - Interface gráfica do aplicativo de computação gráfica 3D Studio Max para duas câmeras

X (mm) Y (mm) Z (mm) Diâmetro (mm)
Alvo 01 esquerdo -1,915 -50 892,642 150
Alvo 02 direito 161,915 -50 1007,358 150
Câmera 01 35mm 0 0 0 -
Câmera 02 35mm 200 0 0 -

Tabela 7.13 - Posição dos objetos com duas câmeras no simulador

94



        
Figura 7.50 - Alvos após Thresholding vistos pela Câmera 01 à esquerda e pela Câmera 02 à direita.

Para  a  utilização  do método  apresentado  no  capítulo  4, seção  7 aplicado  a  Figura  7.50, 

torna-se necessário a calibração da imagem para a descoberta do valor de escala que corresponde 

a  medida  da  relação  mm  por  pixel  da  imagem  projetada  na  câmera.  Este  valor  é  calculado 

através da equação 7.1, conhecendo-se a distância real e a distância em pixels (Figura 7.51) entre 

os alvos conforme Tabela 7.14.

X (mm) Y (mm) Z (mm) Diâmetro (mm)
Alvo 01 esquerdo -20 -50 950 150
Alvo 02 direito 180 -50 950 150
Câmera 01 35mm 0 0 0 -
Câmera 02 35mm 200 0 0 -

Tabela 7.14 - Posição conhecida dos alvos utilizado para calibração da câmera

Figura 7.51 - Alvos conhecidos utilizados para calibração da câmera

95



S x=S y=

f ×T x
mmreal

pixel imagem
[eq. 7.1]

S x=S y=

f ×T x
mmreal

pixel imagem
? S x=S y=

35×200
950

164,723
?

S x=S y=0,0447321
mm
pixel

Observa-se também que o cálculo dos valores das coordenadas  X e Y utiliza a posição do 

pixel deslocado a partir do Foco, que está localizado no centro da imagem. Utiliza-se portanto as 

coordenadas (x1,y1) e (x2,y2) a partir do centro da imagem. Define-se a largura da imagem pela 

variável  W  (800  pixels),  a  altura   pela  variável  H  (600  pixels)  e  o  deslocamento  X  entre  as 

câmeras por Tx., Tem-se portanto:

X 1c=? x1?
W
2
??S x [eq. 7.2]

Y 1c=? y1?
H
2
??S y [eq. 7.3]

X 2c=? x2?
W
2
??S x [eq. 7.4]

Y 2c=? y2?
H
2
??S y [eq. 7.5]

Para o cálculo do posicionamento do Alvo 01 utiliza-se as equações 7.2 a 7.5:

X 1c=? x1?
W
2
??S x ? X 1c=?397,862?

800
2

??0,0447321 ? X 1c=?0,09564 mm

Y 1c=? y1?
H
2
??S y ? Y 1c=?343,398?

600
2

??0,0447321 ? Y 1c=?1,94127 mm

X 2c=? x2?
W
2
??S x ? X 2c=? 222,271?

800
2

??0,0447321 ? X 2c=?7,95021 mm

Y 2c=? y2?
H
2
??S y ? Y 2c=?343,395?

600
2

??0,0447321 ? Y 2c=?1,94114 mm

96



Z 1=
T x× f

? X 1c? X 2c?
? Z 1=

200×35
?0,09564???1,94127? ? 

Z 1=891,201 mm?892,642 mm

X 1=
X 1c×Z

f
? X 1=

?0,09564×891,201
35

?  X 1=?2,4354 mm??1,915 mm

Y 1=
Y 1c×Z

f
? Y 1=

?1,94127×1007,73
35

? Y 1=?49,4305 mm??50 mm

Para o cálculo do posicionamento do Alvo 02 utiliza-se as equações 7.2 a 7.5:

X 1c=? x1?
W
2
??S x ? X 1c=?525,274?

800
2

??0,0447321 ? X 1c=5,60379 mm

Y 1c=? y1?
H
2
??S y ? Y 1c=?338,258?

600
2

??0,0447321 ? Y 1c=?1,71138 mm

X 2c=? x2?
W
2
??S x ? X 2c=?369,987?

800
2

??0,0447321 ? X 2c=?1,34253 mm

Y 2c=? y2?
H
2
??S y ? Y 2c=?338,245?

600
2

??0,0447321 ? Y 2c=?1,7108 mm

Z 1=
T x× f

? X 1c? X 2c?
? Z 1=

200×35
5,60379???1,34253? ? 

Z 1=1007,73 mm?1007,358 mm

X 1=
X 1c×Z

f
? X 1=

5,60379×1007,73
35

?  X 1=161,346 mm?161,915 mm

Y 1=
Y 1c×Z

f
? Y 1=

?1,71138×1007,73
35

? Y 1=?49,2745 mm??50 mm

A  Tabela  7.15 e  7.16 compara  os  valores  das  posições  obtidas  através  dos  cálculos 

apresentados e os valores gerados através do aplicativo 3D Studio.

Alvo 01 Obtido Alvo 01 3D Studio Erro
X (mm) -2,4354 -1,915 0,52
Y (mm) -49,4305 -50 0,57
Z (mm) 891,201 892,642 1,44

Tabela 7.15 - Comparação dos valores gerados no 3D Studio com os valores recuperados do Alvo 01

97



Alvo 02 Obtido Alvo 02 3D Studio Erro
X (mm) 161,346 161,915 0,57
Y (mm) -49,2745 -50 0,73
Z (mm) 1007,73 1007,358 0,37

Tabela 7.16 - Comparação dos valores gerados no 3D Studio com os valores recuperados do Alvo 02

Analisando-se a média dos valores dos erros para o Alvos tem-se a Tabela 7.17.

Alvo 01 Alvo 02
X (mm) 0,52 0,57
Y (mm) 0,57 0,73
Z (mm) 1,44 0,37

média (mm) 0,84 0,56
Tabela 7.17 - Comparação dos valores de erro de posicionamento dos alvos

Para  os  alvos  processados,  o  erro  de  cálculo  do  posicionamento  em  média  é 

aproximadamente 0,7mm calculado por Erro médio=
?0,84?0,56?

2
=0,7 mm .

98



Capítulo 8

Conclusão

O texto, em seus capítulos iniciais, fornece o embasamento teórico sobre processamento de 

sinais, processamentos de imagem, morfologia através da extração dos parâmetros de interesse da 

imagem, informações sobre  risers de produção de petróleo e o modelo em escala reduzida para 

pesquisas em laboratório.

A importância do conhecimento da dinâmica existente em um riser de produção de petróleo 

e a medição do movimento de um modelo reduzido, levou ao desenvolvimento de um método 

para  a  captura   de  sinais  com  a  utilização  de  câmeras  digitais,  utilizando  algoritmos  de 

processamento de imagem. .

Uma simulação gráfica do modelo de  riser é feita inicialmente para validar o método de 

captura de sinais de movimento proposto. Simula-se o movimento do riser, com um padrão pré-

estabelecido  e  utilizam-se  as  imagens  de  tal  movimento  para  recuperar  através  das  medidas 

realizadas, de forma satisfatória,  o mesmo padrão gerado.

Medições práticas foram também executadas com a utilização de acelerômetros juntamente 

com  as  câmeras.  Uma  comparação  do  movimento  capturado,  bem  como  o  resultado  de  sua 

análise espectral indica uma correlação entre os diferentes meios de medida. 

99



Uma  simulação  da  medida  de  movimento  de  corpos  3-D  no  espaço  através  da  mesma 

técnica  de  processamento  de  imagens  é  indicativa  do  potencial  de  emprego  do  atual 

desenvolvimento.

A técnica de processamento de imagens proposto, associado ao equipamento de medição 

utilizado – câmeras de baixo custo – representa uma  alternativa ao uso de sensores mais caros e 

de uso mais restrito como os acelerômetros. 

8.1. Sugestões para trabalhos futuros

O  desenvolvimento  deste  trabalho  possibilita  novas  aplicações  e  melhorias,  conforme 

descritas abaixo:

– Discretização completa do modelo reduzido do riser de petróleo. A técnica desenvolvida foi 

empregada  para  a  medida  de  movimento  de  apenas  alguns  pontos  do  modelo  de  riser.  O 

potencial da técnica entretanto permite que mais pontos ou mesmo a totalidade do movimento 

da estrutura do riser seja medida por meio de sua imagem de câmeras.

– Desenvolvimento de um software para processamento 3D  do modelo do  riser, tornando-se 

possível identificar movimentos em profundidade, mesmo que sejam pequenos;

– Estudo  aprofundado  das  variações  de  iluminação  e  a  resolução  da  imagem  na  captura  do 

movimento dinâmico do duto flexível os parâmetros que influenciam no sinal de movimento 

recuperado.

– O método desenvolvido e implementado serve também como plataforma de uso de imagens 

de câmeras, aplicado à medição da posição de objetos em um espaço 3-D. Tal aplicação é de 

uso direto na área de interesse do grupo de pesquisa em navegação robótica com o uso de 

câmeras,  do  laboratório  de  Processamento  de  Sinais  e  Análise  de  Sistemas  Dinâmicos  da 

FEM/UNICAMP.

100



Referências Bibliográficas

Augusteijn,  M.  F.,  Clemens,  L.  E.,  “A neural-network  approach  to  the  detection  of  texture  

boundaries”, Engineering Applications of Artificial Intelligence, vol. 9, no. 1, pp. 75-81,  

1996.

Autodesk, “3D Studio Max”, http://www.autodesk.com, acesso em 10 de julho de 2008.

Bordalo, S. N., Morooka, C. K., Cavalcante, C. C. P., Valdivia, P. G., Frizzone, C. M. R., Matt, C. 

G. C., Franciss, R., "Experimental verification of the whipping phenomenon on offshore  

catenary  risers caused  by  the  internal  flow  momentum",  In:  International  Congress  of  

Mechanical Engineering (COBEM), 19, 2007, Brasília, Brasil. Proceedings. COBEM2007-

2027.

Brigham, E. Oren, “The fast Fourier Transform and its applications”, Englewood Cliffs,  

Prentice-Hall, Inc., 448 pp, 1988.=

Cavalcante, César C. P., Bordalo, Sérgio N. , Morooka, Celso K. (Unicamp), Matt, Cyntia G. C., 

Franciss, Ricardo, “Influência do escoamento interno no movimento de oscilação de um  

riser rígido em catenária”, ABPG-PDPETRO, 2007.

 

Chan, C.K., Tan, S.T., “Determination of the minimum bounding box of an arbitrary solid: an  

iteractive approach”, Computer and Structures, n.79, pp.1433-1449, 2001.

101

http://www.autodesk.com/


Cheng,  H.  D.,  Xu,  H.  X.,  “A novel  fuzzy  logic  approach  to  contrast  enhancement”,  Pattern  

Recognittion, vol.33, pp. 809-819, 2000.

Chu, C. W., Hwang, S., Jung, S. K., “Calibration-free approach to 3D reconstruction using light 

stripe projections on a cube frame”, IEEE, pp.13-19, 2001.

Facon, Jacques,  “Morfologia Matemática: Teoria e Exemplos”, Curitiba, 1996.

Faugeras,  O.,  Quan,  L.,  Strum,  P.,  "Self-Calibration  of  a  1-D  projective  camera  and  Its  

application  to  the  self-calibration  of  a  2-D  projective  camera".  IEEE,  Transactions  on  

Pattern Analysis and Machine Intelligence, vol 22, n.10, 2000.

Florczyk, Stefan, "Robot Vision: Video-based Indoor Exploration with Autonomous and Mobile 

Robots", 216pp, Wiley-VCH, 2005

Forsyth, D. A, Ponce, J., “Computer vision. A modern approach”, Prentice Hall, 2003.

Galo, Mauricio, Tozzi, Clésio L., “The concept of matching parallelepiped and its  use in the  

correspondence Problem”, IEEE, pp.410-414, 1999.

Gasteratos, A., Andredis, I., “Non-linear image processing in hardware”, Pattern Recognition,  

vol. 33, pp. 1013-1021, 2001.

Gonzalez, Rafael C., Woods, Richard E., “Digital image processing”, 2nd Ed, Prentice Hall, 2002.

Gordon,  R.,  Ranganyyan,  R.  M., “Feature  enhancement  of film mamograms  using  fixed  and  

adaptive neighborhoods”, Appl.  Optics, vol. 23, no. 4, pp. 560-564, 1984. 

Hart,  G. W., “Multidimensional  analysis:  algebras  and  systems  for science  and  engineering”,  

Springer-Verlag, 1995, ISBN 0387944176

102



Hasan, Y. N. Y., Karam, L. J., “Morphological reversible contour representation, IEEE. Trans. on 

Pattern Analysis and Machine Intelligence”, vol. 22, no. 3, pp. 227-240, 2000.

Holst,  G.,  Lomheim,  T.S.,  "CMOS/CCD  Sensors  and  camera  systems",  SPIE-International  

Society for Optical Engine, pp. 355, 2007.

Iezzi, G., "Fundamentos de matemática elementar", Ed. Atual, São Paulo, 3a. ed., Vol.7, 1985.

Jain,  R.,  Kasturi,  R.,  Schunck,  B.G.,  “Machine  vision”,   McGraw-Hill  Series  in  Computer  

Science, 1995.

Joint  Photographic  Experts  Group  Committee,  “The  JPEG  Standard”,  http://www.jpeg.org,  

acesso em 10 de julho de 2008.

Kreyszig, E., "Advanced engineering mathematics", Wiley, 9th Ed., pp 1248, 2005. 

Kurka, P.R.G., 2004, “Aplicações de visão computacional e controle robótico autônomo”, Pós  

Doutorado”, Proj. CAPES BEX1394/03-7, Faculdade de Engenharia da Universidade do  

Porto. 

Kurka,  P.  R.  G.  ,  Rudek,  M.,  “Three-Dimensional  volume  and  position  recovering  using  a  

virtual reference box”, IEEE Transactions on Image Processing, Estados Unidos, v. 16, n. 

2, p. 573-576, 2007.

Ma, Y. S. Soatto, J. Kosecká, S. S. Sastry, “An invitation to 3-D vision from images to geometric 

models”, Series: Interdisciplinary Applied Mathematics, Vol. 26, Springer. 526 p., 2004.

Menezes,  L.F.M.,  “Controle  automatizado  para  scanners  de  luz”,  Faculdade  de  Engenharia  

Mecânica, Universidade de Campinas – UNICAMP, Mestrado, p.70, 2004.

103

http://www.jpeg.org/


Morooka, Celso K.; Valdivia, Paulo G.; Bordalo, Sérgio N.; Matt, Cyntia G. C.;Franciss, Ricardo, 

“Resposta dinâmica de um riser rígido em catenária devido à excitação do fluxo interno”, 

ABPG-PDPETRO, 2007.

Motta, J.M.S.T., Mc Master, R. S., “Experimental validation of a 3-D vision-based measurement 

system applied to robot calibration”, Journal of the Braz. Soc. Mechanical Sciences, vol.  

XXIV, p. 234-238, July 2002.

National  Instruments,  “Labview  and  IMAQ  Vision”,  http://www.ni.com,  acesso  em  10  de  

agosto de 2008.

Oisel, L., “One dimensional dense disparity estimation for three-dimensional reconstruction”,  

IEEE Transactions on Image Processing, vol 12, no.9,2003.

Oppenheim,  A.  V.,  Shafer,  R.  W.,  “Discrete-time  signal  processing”,  Englewood  Cliffs,  NJ:  

Prentice Hall, 1989.

Proakis,  J.G.,  Manolakis,  D.K,  "Digital  signal  processing",  Prentice-Hall,  4th  Ed.,  pp.  1004,  

2006.

Quak, E., Weyrich, N., “Decomposition and reconstruction algorithms for spline wavelets on a  

bounded  interval”,  Applied  and  Computational  Harmonic  Analysis,  vol.  1,  no.  3,  pp.  

217-231, 1994.

Rudek, M., Kurka, P. R. G., “3-D image signal processing for automates operations using range 

cube”, XI dyname, 2005.

Ryoo,  Seung  Taek,  “Segmentation  Based  Environment  Modeling  Using  a  Single  Image”,  

International Conference, ICIAR, Proceedings, Part I, p.98-105, 2004.

Salvi, J., Armangué, X., Battle, J., “A comparative review of camera calibrating methods with  

104

http://www.ni.com/


accuracy evaluation”, Pattern Recognition, 35, 1617-1635, 2002.

Shen, D., Davatzikos, C., “An adaptive-focus deformable model using statistical and geometric 

information, IEEE Trans. on Pattern Analysis and Machine Intelligence”, vol. 22, no. 8, pp. 

906-912, 2000.

Sparks,  C.P.,  "Fundamentals  of  marine  riser mechanics:  basic  principles  and  simplified  

analysis", PennWell Corp., pp.300, 2007.

Spitz, S. N., Rechicha, A. A. G., “Accessibility analysis  using computer graphics  hardware”,  

IEEE Trans. on Visualization and Computer Graphics, vol. 6, no. 3, pp. 208-219, 2000.

Trucco, E, Verri, A., “Introductory techniques for 3-D computer vision”, Prentice Hall, 1998.

Tsai, R., Huang, T., “Uniqueness and estimation of three dimensional motion parameters of rigid 

objects with curved surface”, IEEE Trans. Pattern Anal. Machine Intell., vol 6, pp.13-26,  

1984.

Twardowski, Tomasz, Cyganek, B., Borgoz, J., “Gradient based dense stereo matching”, ICIAR 

2004, pp.721-728, 2004.

Valdivia, P. G., Morooka, C, K., Bordalo, S. N., Matt, C. G. C., Franciss, R., "Resposta dinâmica 

de um riser rígido em catenária devido à excitação induzida pelo escoamento Interno". In: 

Congresso Brasileiro de Pesquisa e Desenvolvimento em Petróleo e Gás (PDPETRO), 4,  

2007, Campinas, Brasil. Proceedings... ABPG 2.4.0265-1.

Wang,  R.Z.,  Lin,  C.F.,  Lin,  J.C.,  “Image  hiding  by  optimal  LSB  substitution  and  genetic  

algorithm”, Pattern Recognition, vol. 34, pp. 671-683, 2001.

105



White, F. M, “Fluid Mechanics”, 4th edition, McGraw-Hill, 1999.

Xie, J., Tat T., Hung, “Wide baseline stereo matching by corner-edge-regions”, ICIAR 2004, pp. 

713-720, 2004. 

Zhang, B., Fu, M., Yan, H., ”A nonlinear neural network model of mixture of local principal  

component analysis: application to handwritten digits  recognition”, Pattern Recognition,  

vol. 34, pp. 203-214, 2001.

106



Anexo I

Especificações técnicas do acelerômetro utilizado

Modelo -  PCB 320C33 

Tipo -  Acelerômetro, Sensor de vibração

PERFORMANCE

Sensitividade  (± 10 %) - 10,2 mV/(m/s²) 

Alcance de medida - ± 490 m/s² pk 

Alcance de freqüência  (± 5 %) - 1 a 4000 Hz 

Alcance de freqüência  (± 10 %) - 0,7 a 6000 Hz 

Alcance de freqüência (± 3 dB) - 0,35 a 10.000 Hz 

Freqüência  de ressonância - ? 22 kHz 

Faixa de resolução  (1 to 10.000 Hz) - 0,003 m/s² rms  [1] 

Não-linearidade  - ? 1 %  [2] 

Sensibilidade transversal - ? 5 %  [3] 

AMBIENTE

Limite de Carga - ± 19,620 m/s² pk 

Faixa de temperatura  (em operação)  -73 a +163 °C 

Sensitividade da base  - ? 0,002 (m/s²)/µ? [1] 

107



ELÉTRICA

Voltagem de Excitação - 18 a 30 VDC 

Voltagem de excitação constante - 2 a 20 mA 

Impedância de saída - ? 100 ohm 

Voltagem de saída - 8 a 12 VDC 

Tempo constante de descarga – 0,5 a 1,5 segundos 

Ruído espectral (10 Hz) - 294 (µm/s²)/?Hz [1] 

Ruído espectral (100 Hz) - 78 (µm/s²)/?Hz [1] 

Ruído espectral (1 kHz) - 20 (µm/s²)/?Hz [1] 

FÍSICO

Elemento sensor  - Quartzo

Material  - Titanium 

Selagem - Hermética 

Tamanho (Largura x Altura) - 19,1 mm x 21,6 mm 

Peso - 20 gm  [1] 

Conector elétrico - 10-32 Coaxial

Torque de montagem - 113 a 225 N-cm 

Todas a especificações são em temperatura ambiente.

NOTAS: [1] Padrão. [2]  Base-zero [3]  Sensitividade transversal é tipicamente ? 3%. 

Figura 10.1 – Acelerômetro PCB 320C33

108


</field>
	</doc>
</add>