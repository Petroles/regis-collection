<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.06340</field>
		<field name="filename">10868_Bertolini_AndreCarlos_D.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">UNICAMP
ANDRÉ CARLOS BERTOLINI
PROBABILISTIC HISTORY MATCHING METHODOLOGY
FOR REAL-TIME RESERVOIR SURVEILLANCE
METODOLOGIA DE AJUSTE DE HISTÓRICO
PROBABILÍSTICO PARA MONITORAMENTO CONTÍNUO DE
RESERVATÓRIOS
CAMPINAS
2015
ii

UNICAMP	UNIVERSIDADE ESTADUAL DE CAMPINAS FACULDADE DE ENGENHARIA MECÂNICA E INSTITUTO DE GEOCIÊNCIAS ANDRÉ CARLOS BERTOLINI
PROBABILISTIC HISTORY MATCHING METHODOLOGY FOR
REAL-TIME RESERVOIR SURVEILLANCE
METODOLOGIA DE AJUSTE DE HISTÓRICO PROBABILÍSTICO PARA MONITORAMENTO CONTÍNUO DE RESERVATÓRIOS
Thesis presented to the Mechanical Engineering Faculty and Geosciences Institute of the University of Campinas in partial fulfillment of the requirements for the degree of Doctor in Petroleum Sciences and Engineering in the area of Reservoirs and Management.
Tese apresentada à Faculdade de Engenharia Mecânica e Instituto de Geociências da Universidade Estadual de Campinas como parte dos requisitos exigidos para a obtenção do título de Doutor em Ciências e Engenharia de Petróleo na área de Reservatórios e Gestão.
Orientador: Prof. Dr. Denis José Schiozer
Este exemplar corresponde à versão final da tese defendida pelo aluno André Carlos
Ficha catalográfica Universidade Estadual de Campinas Biblioteca da Área de Engenharia e Arquitetura Elizangela Aparecida dos Santos Souza - CRB 8/8098
Bertolini, André Carlos, 1980-
B462p Probabilistic history matching methodology for real-time reservoir surveillance / André Carlos Bertolini. - Campinas, SP : [s.n ], 2015.
Orientador: Denis José Schiozer.
Tese (doutorado) - Universidade Estadual de Campinas, Faculdade de Engenharia Mecânica e Instituto de Geociências.
1. Reservatórios - Simulação. 2. Incerteza. 3. Probabilística. 4. Controle em tempo real. 5. Avaliação. I. Schiozer, Denis José,1963-, II. Universidade Estadual de Campinas. Faculdade de Engenharia Mecânica. III. Título.
Informações para Biblioteca Digital
Título em outro idioma: Metodologia de ajuste de histórico probabilístico para monitoramento contínuo de reservatórios
Palavras-chave em inglês:
Reservoirs - Simulation
Uncertainty
Probabilistic
Real-time control
Evaluation
Área de concentração: Reservatórios e Gestão
Titulação: Doutorem Ciências e Engenharia de Petróleo
Banca examinadora:
Osvair Vidal Trevisan
Rosângela Barros Zanoni Lopes Moreno
Régis Kruel Romeu
Daniel Nunes de Miranda Filho
Data de defesa: 15-05-2015
Programa de Pós-Graduação: Ciências e Engenharia de Petróleo
UIMICAMP
UNIVERSIDADE ESTADUAL DE CAMPINAS
FACULDADE DE ENGENHARIA MECÂNICA
E INSTITUTO DE GEOCIÊNCIAS
TESE DE DOUTORADO
PROBABILISTIC HISTORY MATCHING METHODOLOGY FOR
REAL-TIME RESERVOIR SURVEILLANCE
Autor: André Carlos Bertolini
Orientador: Prof. Dr. Denis José Schiozer
A banca examihadora cqmposta pelos membros abaixo aprovou esta tese:
V.

Prof. Dr. Denis Jpsé^Sçhiozer, Presidente FEM/UNICAM
Prof. Dr. Osvair Vidal Trevisan
FEM/UNICAMP „


Prof.3 Dra. Rosângela Barros Zanoni Lopes Moreno FEM/UNICAMP
Dr. Régis Kruel Ropie PETROBRAS
Dr. Daniel .Nunes de Miranda Filho'
PETROBRAS
I
Campinas, 15 de maio de 2015.
vi
DEDICATION
This thesis is dedicated to my immediate family members: my mother, father, grandmother, brother, sister and especially my spouse for her patience. Thank you for all of your endless support, sacrifice, patience and love.
viii
ACKNOWLEDGEMENTS
I would like to express my deep gratitude and appreciation to Denis José Schiozer for his guidance, support and encouragement throughout my Master and PhD programs.
I also wish to thank my colleagues and staff of the Petroleum Engineering Department (DEP), CEPETRO, UNISIM and all co-workers from Schlumberger.
Finally, I would like to thank my family members, especially my parents José Eduardo and Luzia, my grandmother Rosina for the impressive and wise lessons, my brother Alexandre, and my sister Sandra. Without them, I would not have made it this far in life. They have been there for me every step of the way, loving me unconditionally, and supporting me through all tough decisions.
I dedicate this work to my wife Fernanda, for without her full love, support, and sacrifice I would never would have achieved my full potential.
X
“If you can’t explain it simply, you don’t understand it well enough. ”
Albert Einstein
xii
ABSTRACT
This work focuses on probabilistic real-time history matching to improve reservoir forecast over time. The proposed methodology uses a rigorous model evaluation, which is synchronized with history data acquisition frequency. A continuous model evaluation allows a quick model deficiency identification and reaction to start a model reparametrization process as needed. In addition, the methodology includes an uncertainty quantification technique, which uses the dynamic data to reduce reservoir uncertainties, and a step to include measurement errors and observed data tolerance margin. The real-time history matching workflow is composed of nine steps. It starts with a set of representative models selected through a probabilistic approach, the uncertainties of the reservoir and an acceptance history data range. The models are run and the results compared with the history data. The following steps are uncertainty reduction and a second model evaluation to guarantee an improved history matching. The models are then filtered to discard any model outside the acceptance range, and then used to make reservoir forecast. In the final step, the workflow searches for new data observed. The methodology also presents a novel and efficient way to support reservoir surveillance through graphical indicators of matching quality. To better control the results of all the methods, which supports the proposed methodology, a synthetic reservoir model was used in the entire work. In addition, the proposed methodology was applied in the UNISIM-I-H model, which is based on the Namorado field, located in the Campos Basin, Brazil. The performed study cases were shown that the proposed history matching procedure assimilates continuously the observed reservoir data, evaluates the model performances through quality indicators and maintains a set of calibrated reservoir models in real-time.
Keywords: History matching, reservoir simulation, uncertainty, probabilistic approach, real-time and reservoir evaluation.
xiv
RESUMO
Este trabalho propõe uma metodologia de ajuste de histórico probabilístico em tempo real a fim de melhorar a previsão do reservatório ao longo do tempo. A metodologia proposta utiliza uma avaliação rigorosa nos modelos sincronizada com a frequência de aquisição de dados históricos. Esta avaliação contínua permite uma rápida identificação de deficiência do modelo e reação para iniciar um processo de recaracterização conforme necessário. Além disso, a metodologia inclui uma técnica de quantificação de incertezas utilizando os dados dinâmicos para reduzir as incertezas do reservatório, e um passo para incluir erros de medição e margens de tolerância para os dados históricos. O fluxo de trabalho da metodologia é composto por nove etapas. O fluxo começa com um conjunto de modelos representativos selecionados através de uma abordagem probabilística, as incertezas do reservatório, e um intervalo de aceitação dos dados históricos. Os modelos são simulados e os resultados comparados com os dados históricos. Os passos seguintes são a redução da incerteza e uma segunda avaliação do modelo para garantir um melhor ajuste de histórico. Depois, os modelos são filtrados para descartar aqueles que estejam fora da faixa de aceitação e, em seguida, usados para fazer previsões do reservatório. O último passo é a verificação de novos dados observados, que é sincronizada com a aquisição de dados. O método também apresenta uma maneira inovadora e eficiente para apoiar o monitoramento do reservatório através de indicadores gráficos da qualidade do ajuste. Um modelo de reservatório sintético foi usado em todo o trabalho a fim de controlar os resultados de todos os métodos que apoiam a metodologia proposta. Além disso, a metodologia foi aplicada no modelo UNISIM-IH, baseado no campo de Namorado, localizado na Bacia de Campos, Brasil. Os estudos de caso realizados mostraram que a metodologia proposta assimila continuamente os dados observados do reservatório, avalia o desempenho do modelo, e mantém um conjunto de modelos de reservatórios calibrados em tempo real.
Palavras Chave: Ajuste de histórico, simulação de reservatórios, incertezas, abordagem probabilística, tempo real e avaliação de reservatórios.
xvi
TABLE OF CONTENT
1.	INTRODUCTION..................................................................1
1.1.	Objective...............................................................4
1.2.	Reservoir simulation models.............................................4
1.3.	Description of the work.................................................5
2.	ARTICLE 1: Influence of the Objective Function in the History Matching Process.11
3.	ARTICLE 2: A Methodology to Evaluate and Reduce Reservoir Uncertainties using
Multivariate Distribution....................................................23
4.	ARTICLE 3: Principal Component Analysis for Reservoir Uncertainty Reduction..39
5.	ARTICLE 4: Use of a Probabilistic Approach to Perform History Matching Tracking over
Simulation Time..............................................................53
6.	CONCLUSIONS..................................................................93
7.	FUTURE WORK..................................................................97
REFERENCE........................................................................99
xviii
1.	INTRODUCTION
Reservoir management practice relies on use of financial, technological and human resources, while minimizing capital investment and operating expense to maximize economic recovery of oil and gas from a reservoir (Thakur, 1996). It is based on a series of decisions that enables oil and gas companies to meet their technical and business objectives. The initial concept considers reservoir engineering the major technical subject of reservoir management. Over the years, other factors were included: automation with computers, synergy between geoscientists and reservoir engineers, detailed reservoir description with geological and geophysical data (Craig et al., 1977). Management, economics, legal and environmental considerations are included in modern reservoir management.
Reservoir surveillance requires a model of the reservoir system and the ability to predict the consequences of implementing possible and alternative strategies. The reliability of reservoir forecast is closely related to the amount of reservoir information and the understanding of its behavior. Reservoir characterization, a vital part of the model creation process, involves generating an editable mathematical subsurface model. It is a continuous process that must be updated as new information is gathered from the asset. The details and type of mathematical reservoir modeling depends on data gathering. The traditional sequence, while working with reservoir characterization, is first the acquisition and interpretation of data from different disciplines. Secondly, data integration, which is used to build the initial reservoir model. Finally, the calibration of the model is the last step.
Numerical reservoir simulation is widely used in the industry for reservoir forecast. It is a more sophisticated method, compared with decline curve and material balance methods. It can represent the physics of fluid flow in porous media. In general, the model is calibrated to reproduce the past observed dynamic performance of the reservoir and is expected to reliably predict future performance. This method allows integration of the full data set, which might include logging and core well data, seismic survey, well testing data, geological and fluid properties. Numerical solutions handle the highest level of complexity, but require more information from the reservoir. The acquisition and interpretation of new information commonly
require time and expertise for model preparation and simulation execution. These challenging characteristics remain similar over the entire simulation period. The common reasons for model updating are the availability of new observed data, or more frequently, irreconcilable conflicts between the model simulation and the measurement data.
One of the biggest challenges in building a simulation model is the history matching (HM) process, which is the last stage in the reservoir characterization sequence. It is an inverse problem, which adjusts reservoir attributes by history matching production data. The desired output are known and the inputs are unknown. The solutions are not unique, or exact solutions do not exist for real cases (Oliver et al., 2008) because the models are approximations of the real reservoir. The history data used as the observed reservoir response to some stimulus are subject to noise and error, which also may prohibit an exact solution.
Traditionally, the model properties modifications are manually performed through a try and error approach or through computed assisted process. Assisted HM normally uses mathematical functions to describe how close the model is to the history data. They are normally faster than the manual method, since they tend to search the solution space effectively, respecting the geologic model.
An inefficient HM evaluation criteria can also contribute to poor reservoir forecast over time. Often, a rigorous method does not exist to regularly validate the HM. For instance, when the calibrated model cannot capture the water breakthrough or the bottom-hole pressure (BHP) trend, a reservoir evaluation tool must identify such model deficiencies early on. If the model deficiencies is not identified by the model evaluation, the initial calibrated models will continue providing production forecasts over the years without any update, probably leading to erroneous forecasts. Faced with this risk, the desired approach is a rigorous model evaluation, combined with model assessment and updating as needed.
Apart from the HM challenges, the quality of the observed data and of the reservoir characterization must be considered in every reservoir simulation study. Tolerance margins and measurement errors from the observed data leads to the concept of an acceptance range (AR). The range varies according to (1) the quality of the measurements, which is related to sensor specifications, flow conditions in the well and measurement conditions, and (2) the field characterization quality and the desired HM quality. Considering the ranges during the HM evaluation, they avoid restricted model filtering based only on a fixed dataset (conventional HM).
In the literature, most history matching articles and applications focus on the initial field development phase and they are performed once, at a specific period. The majority of the published methods do not continuously evaluate the mismatch over time, and they either do not account for the possibility of assimilation of future information or consider uncertainty to be resolved before any HM process. They neglects the potentially significant value imparted by that information.
The proposed HM approach works in synchrony with the data acquisition frequency and with a quality evaluation tool. Each new information is added into the HM evaluation while still incorporating the reduction of reservoir uncertainty through the information over time.
HM methods and uncertainty quantification tools keep evolving as more and new reservoir measurement become available and computer power increases. Manual and assisted HM approaches have been published over the years, using different mathematical tools and focusing on different reservoir applications. The ultimate goal of HM is to enhance the confidence in predictions. This work was developed to support a real-time HM process, focusing on model evaluation and updating, and uncertainty analysis over time. The proposed method integrates a probabilistic reservoir model building and a rigorous model assessment to filter and modify them as needed. The method is synchronized with the history data acquisition allowing a real-time HM process.
The thesis is structured with four articles. The first three articles were developed based on the needs to support the real-time history matching. The first article shows that more attention must be given to the objective function used in the history matching process due to its influence on the performance of the optimization method. The work provided a performance comparison between different objective functions, which are frequently used in assisted history matching processes. The selected function is then used in the second article to evaluate the mismatch. Article 2 proposes a new process to evaluate and reduce reservoir uncertainties using multivariate analysis incorporating the interaction between reservoir properties. The method uses a Latin Hypercube (LHC) to sample the reservoir attribute range and a smoothed mismatch data set. The attribute interval, which minimizes the mismatch, is identified through polynomial fitting. Evaluation and an uncertainty reduction tools were also the subject of article 3. The third article uses Principal Component Analysis (PCA) to reduce the interpretable dataset dimension. Using smoothed mismatch from the principal component and polynomial fitting, the method was able to
reduce the reservoir uncertainties and improves HM. The fourth article is the core of the thesis. It uses all the findings and methods developed in the previous articles and proposes the real-time HM procedure. The novel method works continuously with nine steps to incorporate the new information, evaluate the HM and manage the uncertainty quantification using the acceptance range concept.
1.1.	Objective
The objective of this thesis is to develop a methodology to provide reliable reservoir simulation models for a better reservoir forecast at each time period by incorporating new observed data into the real-time history matching. The methodology must achieve the following:
1.	Include measurement errors and a tolerance margin into the history data before the HM evaluation. Reservoir measurements and reservoir characterization are subject to errors, and the desired HM quality must be accounted while evaluating a reservoir model;
2.	Synchronize the history data sampling frequency with the HM workflow, capturing the reservoir trends along the production period in the model. New observed dynamic data provide additional reservoir information and helps the reduction of reservoir uncertainties. Every new important data must be assimilated and incorporated, while history matching the model;
3.	Provide quality indicator and an efficient way to evaluate the reservoir model performance over time. Nowadays, reservoir surveillance is performed by evaluating several data and quality indicators, so the real-time HM method must allow a practical and efficient way to assess the reservoir response.
1.2.	Reservoir simulation models
The methods and analysis described in the articles are applied to two reservoir simulation models, which are available at the UNISIM website (www.unisim.cepetro.unicamp.br). The first reservoir is an upscaled model (validation model) from a synthetic refined reservoir (Bertolini and Schiozer, 2011 and Bertolini et al., 2015). The history data used in the objective function
calculations were obtained from the refined model. Although it is a synthetic upscaled reservoir, the true reservoir attribute values to match the history data are unknown. The upscaled model contains a similar heterogeneity to the refined model. It is divided into five regions with different geometries, area and volume, and different geological properties. The model presents four uncertain attributes per region. The attributes are horizontal permeability, vertical permeability, coefficient and the maximum value of the water relative permeability on Corey’s equation. The first simulation model has a total of 20 uncertain attributes.
The second reservoir model is called UNISIM-I-H (Avansi and Schiozer, 2014 and 2015). The geological model has 3.5 million active cells and uses core and well logging data, 2D and 3D seismic data provided by Brazilian National Petroleum Agency - ANP and Petrobras (released public data). It uses structural, facies and petrophysical models from the Namorado field, located in the Campos Basin, Brazil (www.unisim.cepetro.unicamp.br/unisim-i/index.php/category-unisim-i-h). Based on the geological model in a high-resolution grid, an upscaling procedure to a medium reservoir scale was necessary to decrease the computational effort. A simulation grid cell resolution was defined with 100 x 100 x 8m blocks to reflect reservoir behavior and heterogeneities. It was discretized into a corner point grid (81 x 58 x 20 cells, with 36,739 active total cells). The model presents 18 uncertain attributes. They are 12 porosity multipliers for each regions, one horizontal permeability multiplier, one vertical permeability multiplier for the entire reservoir, water-oil contact, and two coefficients which correlate porosity with horizontal permeability. The production strategy was defined with 25 wells (4 vertical producers, 10 horizontal producers and 11 injectors). The vertical wells NA1D, NA2, NA3D and RJS19 were the pilot vertical wells in this field. They produced for 4 years and then were shut down for one year. Production resumed in the sixth year with all 14 producers and 11 injection wells for six more years.
1.3.	Description of the work
The thesis is structured with four scientific articles summarized in this section, highlighting the main contributions and how they are connected. The articles in full extension are presented in the following chapters.
André Carlos Bertolini, Célio Maschio and Denis José Schiozer.
Journal of Petroleum Science and Engineering, May, Volume 78, Issue 1, July 2011, Pages 32-41.
The first article shows the influence of the objective function in the HM process. An assisted HM process always requires two distinct parts: a parameterization to select the uncertain attributes of the model and an automatic procedure that minimizes the distance between the observed production and the simulation model curves. This article focuses in the second part, where an objective function is necessary to mathematically represent the quality of the model. Eight global objective functions were evaluated and different initial reservoir attribute sets were tested to increase reliability.
The method was applied in the validation model containing 20 uncertain attributes and the sequential quadratic programming (SQP) was the chosen optimization process. Partial objective functions (POF) considered in this application were: oil production, water production and bottom-hole pressure.
The results showed that the simple error (SE) and the squared error (SqE) functions were the best two performers. The main difference was the optimization speed of the matching. SqE function obtained a faster mismatch reduction along the number of simulations. On the other hand, SE function achieved the highest global HM, considering the same limit of simulations runs. The main contributions of this article to the thesis are as following: (1) to show that more attention is needed by the objective function used in the HM process due to its influence on the performance of the optimization method. Although the quality of the matching does not guarantee a good model, assisted procedures frequently rely on a good performance of the optimization method, so the choice of the objective function is important; (2) to indicate the need for different equations to account for the mismatch between history and simulated data, including the objective function SqE. This function was further improved through the additional of a positive sign (simulated data below the history data) or a negative sign (simulated data above the history data), a normalization step, and then used in the following articles.
1.3.2.	Article 2: “A Methodology to Evaluate and Reduce Reservoir Uncertainties using Multivariate Distribution”
André Carlos Bertolini, Célio Maschio and Denis José Schiozer.
Journal of Petroleum Science and Engineering, Volume 128, April 2015, Pages 1-14
The second article presents a new process to evaluate and reduce reservoir uncertainties using multivariate analysis, incorporating the interaction between reservoir properties. The Latin Hypercube (LHC) sampling technique was applied on the first stage of the method to provide the variability of the reservoir uncertain attributes. On the second stage, the gap between history and simulated data was associated with a combination of attribute variation. The process uses a smooth mismatch data set from the selected objective functions and polynomial fitting to identify the attribute interval which minimizes the mismatch. The objective function SqE function from article 1 was used to evaluate the mismatch between history and simulated data.
The methodology deliverables were a reduced reservoir attributes range, which provided a set of simulation models with improved history matching; and a multivariate sensitivity matrix. The matrix showed the relationship between the expected reservoir behavior and reservoir uncertain attributes. The method was firstly applied in the validation model with 20 uncertainty attributes described in article 1, and subsequently in the UNISIM-I-H reservoir model which is based on the Namorado field, Campos basin, Brazil.
The contribution of this article was a method that provides a set of improved simulation models and a reduced uncertainty range, even with a limited number of simulation runs and without proxy model. The method supports the real-time HM subject (article 4). Applying it synchronously with new data incorporation reduces the reservoir uncertainty over time.
1.3.3.	Article 3: “Principal Component Analysis for Reservoir Uncertainty Reduction”
André Carlos Bertolini and Denis José Schiozer.
Journal of the Brazilian Society of Mechanical Sciences and Engineering, p. 1-11, 2015.
Similarly to article 2, this work focuses on reservoir uncertainty reduction. It is noticed from the previous article that big dataset interpretation might become a complex task. The data integration and mainly its proper use is a challenge, especially in full field models with larger
number of wells and functions. The method described in article 2 is still valid for full field models, although the number of simulated measurements to properly characterize the reservoir might reach high numbers and turn its application impractical. It becomes critical with a high number of wells and when more measurements become available to analyze reservoir performance. As an alternative to overcome this issue, article 3 works with Principal Component Analysis (PCA) to reduce the interpretable dataset dimension.
Using the validation synthetic reservoir model with 20 uncertainty attributes, the PCA method was applied and its results showed that five principal components covered approximately 95% of the problem variability (from 15 original simulated measurements). This significant dataset dimension reduction facilitated the reservoir interpretation. Reservoir uncertainties were reduced and most of the simulated measurements considered in the application had a history matching improvement. Ultimately, the models used for reservoir forecast were better calibrated for reservoir management.
The main contribution of this work to the thesis was the new uncertainty evaluation method capable of reducing the dimension of the problem by providing a set of improved simulation models and a reduced uncertainty range. It also supports the real-time HM subject, allowing a reservoir uncertainty reduction over time.
1.3.4.	Article 4: “Use of a Probabilistic Approach to Perform History Matching Tracking over Simulation Time”
André Carlos Bertolini and Denis José Schiozer.
Submitted to Journal of Petroleum Science and Engineering
Article 4 focuses on real-time history matching. We propose a sequence of steps to regularly evaluate the numerical model performance over time. Working with a numerical model carries challenging characteristics to maintain calibrated models over time. The reservoir model may not be updated in time for several reasons, such as are time, cost and expertise. Another process that commonly contributes to an irregular model updating over time is the HM evaluation criteria. Often, a rigorous method does not exist to regularly validate the HM. Faced with this risk, the desired approach is a continuous model evaluation, combined with model updating and model reassessment as needed.
It is proposed a real time probabilistic history matching workflow to regularly evaluate the model performance over time. This new method is composed of nine steps, and works with an acceptance range applied to the history dataset. It is associated with matching quality indicators, which allow a practical and efficient way to provide support for reservoir decisions.
We used both reservoir models to validate the method. The reservoir models were evaluated against the acceptance range annually. The method managed to maintain a set of calibrated models for the simulation period and the reservoir uncertainties were quantified using the multivariate analysis method presented in article 2. The uncertainty reduction tool narrowed reservoir attribute ranges, using observed dynamic data. The annual results showed the importance of real time evaluation and reservoir model updating to guarantee calibrated reservoir models over time.
The pillars to support the real-time HM methodology were described in the previous articles through objective functions, uncertainty reduction methods and reservoir evaluation tools. The integration of these methods, tools and analysis were performed on article 4. This article provides the main contribution of the thesis. It is the core article of the real-time history matching. The nine-step workflow proposes a new methodology to add new information into the HM evaluation while still incorporating the reduction of reservoir uncertainty through new information over time.
10
2.	ARTICLE 1: Influence of the Objective Function in the History
Matching Process
André Carlos Bertolini, Célio Maschio and Denis José Schiozer
Journal of Petroleum Science and Engineering, May, Volume 78, Issue 1, July 2011,
Pages 32-41
12
Contents lists available at ScienceDirect
Journal of Petroleum Science and Engineering
journal homepage: www.elsevier.com/locate/petrol
Influence of the objective function in the history matching process
André Carlos Bertolini *, Denis José Schiozer * 1
UNICAMP, Brazil
ARTICLE INFO	ABSTRACT
Article history: Received 19 January 2010 Accepted 10 April 2011 Available online 1 May 2011	An assisted history matching process always requires two distinct parts: a parameterization to select the uncertain attributes of the model and an automatic procedure that minimizes the distance between the observed production and the simulation model curves. The focus of this work is the second part, where an objective function is necessary to represent mathematically the quality of the model. However, due to the
Keywords: history matching simulation objective function reservoir	complexity of the models, this function is frequently a combination of several functions that represent the quality of the match in several wells and less attention is given to the influence of the objective function in the optimization process. This paper proposes a study to show the influence of a global objective function on the history matching process using a synthetic reservoir model with 20 uncertain attributes. Results of the quality matching index of eight different global objective functions are compared at the end of the process. The optimized simulation models, generated by the optimization phase with different global objective functions, are compared with the base model and production history. © 2011 Elsevier B.V. All rights reserved.
1.	Introduction
The objective of the history matching process is the calibration of the numerical simulation models of petroleum fields. The objective of the history matching is to get better predictions; however, when the process is done, it is not possible to compare with the prediction so the quality of the model is frequently measured by the quality of the matching. The idea is that the production prediction is more reliable when the simulator results are coherent with the past observed data. The focus of this work is to show the behavior of the objective function that measure the quality of matching and the influence of this objective function in the optimization process.
Usually, the history matching process requires great computational effort. It is an inverse problem and is complex due to the high number of uncertainties in the reservoir characterization phase.
Several techniques have been applied to minimize the computational effort to simulate all possible scenarios of the reservoir. The computational effort is also linked to the efficiency of the process used to optimize an objective function that represents the quality of the history matching.
This function is, in general, a weighted combination of all of the partial objective functions (POF) that need to be minimized and that represent the production and pressure history of the field. These
* Corresponding author. Tel.: +55 21 81098648.
E-mail addresses: acberto@dep.fem.unicamp.br (A.C. Bertolini), denis@dep.fem.unicamp.br (D.J. Schiozer).
1 Tel.: +55 19 35213339.
0920-4105/$ - see front matter © 2011 Elsevier B.V. All rights reserved. doi:10.1016/j.petrol.2011.04.012
partial functions may have different units and several orders of magnitude due to the different variables and rates of the wells and diverse quality of the initial history matching for each function.
In general, less attention is given to the weights attributed to partial objective functions for the construction of the global objective function (GOF). This paper shows the influence of the objective function in the history matching process. Eight GOF are used in the assisted process. Different initial reservoir attributes sets are tested to increase reliability and to avoid the influence of optimization algorithm in the final results. In this sense, it is important to verify whether the choice of the objective function can bring a significant reduction in the number of simulations and, consequently, in the total time required for the process.
1.1. Objectives
The objectives of this paper are: (1) the study of the influence of different types of global objective functions in the history matching process and (2) the verification of the possible improvement that the choice of the objective function can bring to optimization step of the assisted history matching process.
2.	Literature review
There are several studies involving assisted history matching and many types of analyses with different objective functions (OF). In general, the OF is described without a previous explanation of its functionality and performance. The paper written by L. Kent Thomas (Thomas et al., 1971) minimizes, in a least-square sense, the error between the set of observed and calculated performance data in the
optimization process based on Gauss-Newton. Eq. (1) shows the objective function:
E = E wM^-p^f	(1)
where pkbs is the observed data, pkalc is the calculated data and wk the weight factors.
The described algorithm was capable of improving the linear and nonlinear function correlation with a reasonable number of simulations; however, a study of the global objective function was not shown. In a similar way, Chen et al. (1973) and Maschio &amp;amp; Schiozer (2005) used the squared variation between historical and simulated data presented in Eq. (1). Chen demonstrated a significant saving in computing time using reservoir properties as a continuous function of position rather than as a uniform function in a certain number of zones. Maschio &amp;amp; Schiozer (2005) presented a methodology using a direct search optimization technique, in order to accelerate the history matching process. Three methods were integrated: independent objective function, multiple starting points and linear search.
Watson &amp;amp; Lee (1986) showed an algorithm based on Marquardt's modification of the Gauss-Newton method for minimization of leastsquare functions. The performance of the algorithm is evaluated by history matching actual production data using an analytical dual porosity model.
Cullick et al. (2006) studied proxy model performance using a neural network to accelerate the history matching. The paper demonstrated that the neural network is an excellent proxy for the numerical simulator over the trained parameter space. The objective function was also squared. However, in order to emphasize the importance of particular data or time, a weight is assigned. In order to consider data with different absolute ranges, there is a scaling factor. The objective function is defined in Eq. (2).
ob=	w ( h ('	(2)
where, i is the data type, t is time, w(i) is the weight for the ith data, w(i,t) is the weight for the ith data at the time t, sim(i,t) is simulated data, hist(i,t) is historical data and scale(i) is scale for the ith data type.
In the history matching process, Gomez et al. (1999) used the squared objective function normalized in the process of global optimization known as “tunneling”. He concluded that the method is an alternative to immediate reformulation of the problem if the first minimum found does not represent an acceptable match.
Dean et al. (2008) presented that the prior knowledge of each model w in the ensemble can be probabilistically expressed through a prior probability density function p(w). Bayes theorem allows an update with prior beliefs by calculating a posterior probability, using the likelihood. The prior beliefs change as we compare the model output with the observed data.
The maximum likelihood estimate of w is defined to be the model which maximizes the likelihood function or equivalently, minimizes the objective function. They concluded, under the assumptions that data measurement errors are independent Gaussians, that the leastsquares estimate is equivalent to the maximum likelihood estimate. However, the objective function is, in general, merely described, without any further study of its efficiency and functionality.
3.	Methodology
Fig. 1 represents the process used in this study that starts with the selection of the uncertain attributes, followed by the construction of the base simulation model, the variation limits for each attribute and, finally, the optimization process, using a different global objective function (GOF).
Fig. 1. Proposed methodology flowchart.
The base model is the reference for the history matching process. The definition of each attribute's variation interval is defined through the uncertainty limits of the geological characterization. At the end of this phase, a geological simulation model and the variation range of the uncertain attributes are obtained.
The global objective functions are then selected to be used in the optimization process. The GOF are described in Table 1, where the index s represents simulated data, h, historical data, b, base model data, m, total number of partial objective functions (POF), n, total number of data, ws, simple weight, wsD, dynamic simple weight, wq, quadratic weight, and wqD, dynamic quadratic weight.
The proposed methodology uses different global objective functions to test the performance in the matching process. The evaluation of the history matching during the optimization process is made through the GOF.
After the optimization process, a comparison function is tested according to the history matching objectives. The outputs of the optimization stage are the optimized simulation models of each GOF, represented by uncertain attribute values, and the GOF that achieved
Table 1
Global objective functions.
GOF	Description	Formula	
SE	Simple error	m	n SE — E E (|hji-Sji|) j—1 i—1	(3)
NE	Normalized error	n m E (¡hJ»-sn|) NE — E 1—-	- J—1 E (|hi-bi|) i — 1	(4)
WNE	Weighted normalized error	m	E (\hjl -SiD	(5)
		j—1 E(|hji-bi|)	
DWNE	Dynamic weighted normalized error	n m	E (|hj i-sjiD DWNE — E wsDj -i — 1 j—1	E(|hji-bi|) i —	(6)
SqE	Square error	m	n SqE — E E (hji-Sji)2 j—1 i—1	(7)
NSE	Normalize square error	n	o m E (hji-Sji) NSE — E '	- J—1 E (hji-bji)2 i — 1	(8)
WNSE	Weighted normalized square error	m	E (hji-Sji) WNSE — E wj — 1 j—1 E (hji-bji)2 i — 1	(9)
DWNSE	Dynamic weighted normalized square error	n	„ m	E (hji-Sjd DWNSE — E	- j—1	E (hi-bji)2 i — 1	(10)
response for validation of the methodology. It is divided into five regions with different forms, area and volume, with different geological properties among them. The application is an upscale model from a refined reservoir. The historical data used in the POF calculations was obtained from the refined model. Although the application is a synthetic reservoir the real attribute values are unknown.
The corner point grid showed in Fig. 3 has 2550 cells distributed in 30(I) X 1 7(J) x5(K). The reservoir has five producer wells and five injector wells, a producer/injector pair for each region is located in the same reservoir position. The reservoir cells of the injector wells are Injector 1 (I4 J 1 -6K5); Injector2 (I 1 4 J 1 -9K5); Injector3 (I20-29J6K5); Injector4 (I3J8-17K5) and Injector5 (I10-28J14 K5) and for the producer the cells are Prod1 (I4J1-6 K1); Prod2 (I14J1-9 K1); Prod3 (I20-29J6 K1); Prod4 (I3J8-17 K1) and Prod5 (I10-28J14 K1).
The model presents four uncertain attributes per region. The attributes are horizontal permeability in the X direction (Kx), vertical permeability in the Z direction (Kz), coefficient of Corey's Eq. (11) for water relative permeability (ExW) and the maximum value of the water relative permeability in Corey's equation (Krw0). Corey's equation for water relative permeability shows the last two attributes. However, the simulation model has a total of 20 uncertain attributes.
— krw0 ■

r (sw-swc) iExw k1~SWc~SOr )J
(11)
the best reduction in the comparison function. Each application and history match stage will lead to a specific comparison function.
4.	Application
The reservoir model used in the application of the methodology is shown in Figs. 2 and 3. The reservoir is synthetic, with known
where, KrW is the water relative permeability, SW is the water saturation, SWC is the connate water saturation and, finally, Sor is the residual oil saturation.
The permeabilities Kx and Kz are modified in the simulation models through multiplier numbers. The limits are 0.5 and 2.0, which represent the half and the double of the absolute permeability Kx and Kz of the base model. The base model is the unitary reference of the absolute permeability multipliers. On the other hand, the attributes ExW present a variation range from 1 to 5 and the attributes krw0 from 0.15 to 0.90. Table 2 shows the reservoir model attributes used in each
Region3
Region 2
Regionl
Regions
Region4
10.000
10.000
20.000
30.000
20 000
0.00 0.50
0 00 1.00
30.000
1.00 miles
2.00 km
Fig. 2. Mapped reservoir regions.
Porosity (a)
0 10.000
Porosity K layer: 1 (b)
1 1 I 1 1 20.000
0 I
30.000 , , I ■ ,
20,000
, ■ I . ,
i.................  1	°
0 10,000
Porosity K layer: 5 (C)
1 r 1
20,000
30,000
&lt;Zl " CD -O._
O -
CM _
0 10,000
I................I	■ ■ ■ ■
Fig. 3. Porosity distribution (a); porosity layer 1 and producers (b); porosity layer 5 and injectors (c).
initial point set including the Set 1 which is the base simulation model.
The partial objective functions (POF) considered in this application were oil production (bbl/day), water production (bbl/day) and bottom-hole pressure (psi). The well production strategy used in the simulation had a surface liquid limit of 30,000 bbl/day and the bottom hole pressure limit of 3000 psi. The oil production target was informed in the simulator for each simulated date.
The sequential quadratic programming - SQP was the chosen optimization process. SQP is a method resulting from the application of the Newton method to the minimization of the Lagrange function of the problem and it is one of the most used methods in nonlinear
1 1 I.............
30,000
Table 2
Reservoir model attributes for each initial set.
		Reservoir attributes	Initial values				
			Set 1	Set 2	Set 3	Set 4	Set 5
Permeability multipliers	Region 1	Kx1	1.00	2.00	0.50	0.50	2.00
		Kz1	1.00	2.00	0.50	2.00	0.50
	Region 2	kx2	1.00	2.00	0.50	2.00	0.50
		kz2	1.00	2.00	0.50	0.50	2.00
	Region 3	kx3	1.00	2.00	0.50	0.50	2.00
		kz3	1.00	2.00	0.50	2.00	0.50
	Region 4	kx4	1.00	2.00	0.50	2.00	0.50
		kz4	1.00	2.00	0.50	0.50	2.00
	Region 5	kx5	1.00	2.00	0.50	0.50	2.00
		kz5	1.00	2.00	0.50	2.00	0.50
Corey's equation	Region 1	Exw1	2.20	5.00	1.00	3.00	1.00
attributes		KrW01	0.60	0.90	0.15	0.80	0.20
	Region 2	Exw2	1.10	5.00	1.00	4.00	2.00
		KrW02	0.80	0.90	0.15	0.50	0.80
	Region 3	Exw3	4.00	5.00	1.00	2.00	4.00
		KrW03	0.50	0.90	0.15	0.70	0.30
	Region 4	Exw4	1.30	5.00	1.00	5.00	2.00
		KrW04	0.70	0.90	0.15	0.20	0.70
	Region 5	Exw5	4.30	5.00	1.00	3.50	2.00
		KrW05	0.80	0.90	0.15	0.40	0.90
optimization problems (Venkataraman, 2001). The idea of this method is to approximate, in each iteration, the nonlinear problem for quadratic programming (QP) subproblems with linear restrictions. The subproblems are created using the Hessian matrix approximation of the Lagrange function through the Quasi-Newton method with BFGS (Broyden Fletcher Goldfarb Shanno) approach (Vanderplaats, 1984). The solution of these subproblems generates a specific search direction for the linear search method.
Therefore, the SQP optimization consists of three-step iteration: to update the Hessian matrix of the Lagrange function, to solve the subproblems of quadratic programming and, finally, to accomplish the linear search and evaluate the value of the function. Matlab software presents the fmincon (Biran &amp;amp; Breiner, 2002) function as a SQP optimization method.
The fmincon is a local optimization function that results in a small disturbance in the variables of a project space, in agreement with the restrictions. As a consequence, the fmincon convergence is related to the initial values. For the application in this paper, the maximum number of evaluations during the optimization process was set to 640 (this number was chosen after some previous tests to guarantee the minimized result for all GOF).
In order to generalize results, four other sets, shown in Table 2, were tested. The same five initial point sets were used for each GOF. The first set is the base model, the second and third sets are the upper and lower attributes limits.
For the study of the history matching process's performance behavior, eight global objective functions were used and are defined in the Table 1, all of them working with the POF data defined above.
The multiplier weights of four considered GOF were calculated by well and by POF. In this application, there are three POF (oil production, water production and bottom-hole pressure) and five production wells, totaling 15 multiplier weights. Eqs. (12) and (13) show the formula for simple and quadratic weight.
WSPOF W —
NEPOF W Max (NEPOF )
(12)
nsepof w
WqpOF W — Max (NSEpof)	(13)
where the index s represents simple weight, q, quadratic weight, POF, the partial objective function, and w, the well.
The largest normalized error between measured and simulated data (NE) for each POF represents the denominator of the equation. The division of the SE of the well over the denominator is used to obtain the weight for the considered POF (in a similar way as NSE). The weight values are in a range of zero for better-matched wells, and one for wells with the worst history matching.
The dynamic weight follows the same equation; however, it is calculated after each simulation of the optimization cycle shown in Fig. 1. The calculation of every cycle provides an adjustment of the weights according to the improvement or worsened performance of each well and POF. In the static case, the weight is calculated only once at the beginning of the optimization cycle.
One comparison function was chosen for this application; the simple error (SE) function. The outputs from the comparison function of each well and POF were gathered through the Euclidean norm of the SE vector. In this application, this vector has 15 fields (three POF with five production wells). The Euclidean norm is calculated through Eq. (14).
IIXII =	(Xi )2)/2	(14)
where, X is the comparison function component of the vector.
5.	Results comparison
With the objective of creating a quality matching indicator (4), Eq. (14) was divided by the Euclidean norm of the base model. The indicator 4 is calculated through Eq. (15).
(E (Xi)2
*/2
' 15	]/2
E (XM)2
(15)
* =
The interpretation of 4 is direct: values greater than 1 represent a worsening in the history matching; equal to 1, the model is having the same performance of the base model; and smaller than 1, the model presents improvements in the history matching. Therefore, in the application, we have the quality matching indicator for simple error (4se).
The ideal would be to compare the quality of production prediction but that is not the objective of this work. Another possible alternative would be the comparison of all global objective functions but too many results would be presented with basically the same conclusions. So we are showing the influence of the objective functions in 4.
6.	Results
The 4se and the number of required simulation to reach the minimum 4SE of each optimized model are shown in Fig. 4. The upper plots display the result of each set for each GOF. In the lower plots the average and the standard deviation are presented. Looking at the 4SE values smaller than 1, it is clear that all GOF obtained improvements in the history matching (base model). The SE and SqE GOF were the best two performers. Further those GOF obtained a consistent number of simulations to reach the minimum 4SE in all initial point sets.
We can notice different behaviors along the optimization cycles in Fig. 5 for each set. The GOF dynamically weighted DWNE and DWNSE obtained reduced values of 4SE as shown in Table 3. However, they had a limited profile along the simulations for almost all sets. It can be noticed that there was not a gradual improvement of the history matching with the optimization process. The dynamic weight alters the GOF at every simulation, varying the forecast and the efficiency of the optimization method.
The reduction of 4SE obtained by WNE and WNSE GOF was expressive already in the first simulations. The optimization of the initial point set 1 and 5 show this profile and it can be visualized in Fig. 5. We can attribute these effects to the given initial weight of the GOF. At the beginning of the process, the optimization method prioritized POF and wells with the worst history matching.
Fig. 4. Number of simulation and 4Se result summary.
Fig. 5. Quality matching indicator (^SE) for GOFs listed in Table 1.
Finally, the SE and SqE GOF presented a gradual decrease of AI'SE. Both obtained improvements in the history matching, arriving at 83% of reduction in AI'SE (Average SE GOF), according to the values shown
in Table 3. The main difference was the speed of the decrease. Looking the Fig. 5, for all initial point sets the SqE GOF obtained a faster AI'SE reduction along the simulations compared with the SE GOF.
Table 3
Minimum ^SE values vs. number of simulations.
	Global objective function - GOF							
	SE	NE	WNE	DWNE	SqE	NSE	WNSE	DWNSE
^se set 1 (base model)	0.171	0.352	0.244	0.345	0.181	0.324	0.237	0.299
^se set 2	0.150	0.327	0.236	0.600	0.249	0.445	0.284	0.362
^se set 3	0.139	0.417	0.262	0.456	0.180	0.251	0.274	0.378
^sEset4	0.190	0.336	0.197	0.358	0.277	0.471	0.335	0.273
^se set 5	0.192	0.267	0.295	0.413	0.169	0.347	0.289	0.421
Average	0.168	0.340	0.247	0.434	0.211	0.367	0.284	0.347
Standard deviation	0.023	0.054	0.036	0.103	0.048	0.091	0.035	0.060
Number of simulations to reach the minimum (Set 1)	252.00	97.00	443.00	72.00	139.00	125.00	73.00	483.00
Number of simulations to reach the minimum (Set 2)	247.00	267.00	160.00	273.00	115.00	168.00	223.00	204.00
Number of simulations to reach the minimum (Set 3)	229.00	629.00	240.00	345.00	219.00	179.00	361.00	223.00
Number of simulations to reach the minimum (Set 4)	282.00	458.00	538.00	151.00	195.00	289.00	320.00	590.00
Number of simulations to reach the minimum (Set 5)	186.00	438.00	612.00	180.00	219.00	591.00	470.00	125.00
Average	239.20	377.80	398.60	204.20	177.40	270.40	289.40	325.00
Standard deviation	35.32	202.66	193.02	106.60	47.80	189.15	149.93	200.15
PRODI
40.000 S’30.000 5 B O 20.000 w 2 re i 10,000 6 0					
		: i i			
		i :	:			
					• :
1991199219931994199519961997199819992000
Time (Date)
PROD2		
5 30,000	! ! H	: i i : i
	i i IsiStK	: : i ; ;
B O 20,000&amp;lt;0		
	! ! !	I	!	!	I
	: : : ;	
i 10.000	: ; ; :	
		
o	: ; i !	: : : : :
0		: : :
1991199219931994199519961997199819992000
Time (Date)
PROD3
40,000		::::::::
		::::::::
¡5* to non	■ :	■	1	1	1	L	*	j	j
73		j	;	;	j	j	;	j	i
		
		
J3		
.O		&gt; 1 1 1 &amp;lt;■ ■ •
		1 1 1 1 • ■ • 1
non nnn.		
		
CO		• 1 1 1 • • • •
•		
**		
re		
		
— 10.000		
		
o		
0		:	: i :	!	:
1991199219931994199519961997199819992000
Time (Date)
PROD4
40,000'			i				
5 30.000' w		j	i				
		yw-™-n,					
B e		J	j				
Q 20.000- CO							
		: : : :			■		
« i - 10,000' o							
		•	I		■		
O'		■	j				
PROM
40.000-]	::::::::::
	! : i i : i ; : i i
	
	
	
	
	
-a	■	i	i	■■■■■■
	■	«	•	•■•ii
o ?o non	
co	•	t	1	■	■'	&gt;	1	1
©	
A	
re	
K	’ ’ ! ! : • ■ ’ ! •
	
	
O	::::::::::
0	
	1991199219931994199519961997199819992000
	Time (Date)
1991199219931994199519961997199819992000
Time (Date)
O	History
Base
■■■■■■■ NE
..... NSE
— WNSE
DWNSE
DWNE
Fig. 6. Oil production for each GOF (Set 1).
PROD?
25.000
4V
5
&lt;» 20.000
—"15.000 o tn
~ 10.000 Of
1991199219931994199519961097199819902000
Time (Date)
PRODS
20.000
5
5.000
-S 15.000
o
W 10.000
0J~—
1901199219931904199510961997199819992000
Time (Date)
Fig. 7. Water production for each GOF (Set 1).
WNSE DWNSE DWNE
For this application, the SE global objective function obtained the best performance in the history matching process, considering the SE comparison function.
The history matching data of the POF, oil production, water production and bottom-hole pressure for each one of the GOF optimized models, were compared by well. Although the oil production on each simulated date had been informed in the simulator, the oil POF was considered in the objective function. Preliminary test showed the oil production matching decrement when oil POF was not considered in the OF.
The optimized simulation model for each GOF and for the initial point set 1 (base model) are displayed, using the oil POF, in the Fig. 6. The oil production did not show much variation. The opposite happened with water production and bottom-hole pressure POF. The water production shown in Fig. 7 presented great variations.
Table 3 summarizes the values obtained by the GOF with the SE comparison function for all initial point sets.
In a similar way, the bottom-hole pressure POF had variations according to Fig. 8.
At the end of the methodology, SE, SqE, WNE and WNSE GOF obtained similar results according to Table 3. However, the behaviors along the simulations were different. In a general way, the quadratic functions showed an accentuated reduction at the beginning of the optimization process since it prioritizes points of larger difference among simulated and observed data. On the other hand, the simple functions obtained a deeper reduction of the indicator, however, with a large number of simulations. These results consequently reflected in the history matching of oil and water production, and in the bottom hole pressure.
Even with similar Al'Sk results, some of the POF behaviors were not unique among the wells as showed in Figs. 6, 7 and 8. The application with 20 uncertain attributes presented multiple combinations and a complex solution such as real reservoir models.
PRODI
Time (Date)
PR002
7.580 ■		
	5	j	I	I	:	:	;	i	;
— 6.580	'ML	
	V ' “LA'Cl*— '	 ’	■	...	
u&gt;	- ‘i. 	‘	.....	
Q.	——■ i	'"■-v * —	■	*	■	.	j	
		
Q.		
5.580 CD		!	L		^*"4.	*	1	1		
		
—		
o 5 4,580			■	•_			■	* . - -
	I	. » • ,■ _ _ 4 &gt;	■	•	—k	'	’
	•	• ■ ■ ■ ■ '
		
	19911992 19931994 19951996 1997 19981999 2000	
Time (Date)
PRO05
PROD3
7.580		
	:::::::::	
6,580 to 3;		
	::::::	
I BHP co a o				
	£ j Í	
		
4.580 3.580	■	■	• Y	'	*	i	r	
	:	:	:	: : :	:	:	:	:	
1991199219931994199519961997199819992000
Time (Date)
PROD4
7.580 — 6.580 CO a Q_ X 5.580 tn "5 4 580							
	s	J						
							
	■	i		b- **	&gt;aJ			
	■		■			—	
	19911992 1993199419951996199719981999 2000						
Time (Date)
Time (Date)
O	History
Base
»■*» SE
■■«■■■■ NE
SqE
----- NSE
WNSE
DWN5E
DWNE
Fig. 8. Bottom-hole pressure for each GOF (Set 1).
7.	Conclusions
The results presented in this work yield the following conclusions:
(1)	This work showed that more attention must be given to the objective function used in the history matching process due to its influence on the performance of the optimization method. Although the quality of the matching does not guarantee a good model, assisted procedures frequently relies on a good performance of the optimization method so the choice of the objective function is important.
(2)	This work show the study of just one model; nevertheless, the results showed different performances for the GOF, indicating the need for a previous study of the objective function for each application.
(3)	A smaller number of simulations was obtained with the square error global objective function (Eq. 7). Therefore, it is the most indicated function for this example
(4)	The simple error global objective function (Eq. 3) presented good results but the convergence was slow.
(5)	Normalized and weighted functions did not present improvements over the square error for this example. Therefore, they must be further investigated in other cases.
For future works, the optimization process will be (1) studied with multiple objective functions (Yang et al., 2009), (2) divided into stages with different limit rules of optimization, being flexible for GOF changes when the established limit of the stage is reached.
Nomenclature
OF	objective function
GOF	global objective function
POF	partial objective function
¥	quality matching indicator
KrW	water relative permeability
Set	initial reservoir attribute values
Sw	water saturation
Swc	connate water saturation
Sor	residual oil saturation
Exw	coefficient of Corey's equation for water relative permeability
krW0	maximum value of the water relative permeability in Corey's
equation
Kx	permeability in X direction
Ky	permeability in Y direction
ws	simple weight
wq	quadratic weight
wsD	dynamic simple weight
wqD	dynamic quadratic weight
SQP	sequential quadratic programming
QP	quadratic programming
BFGS	Broyden Fletcher Goldfarb Shanno
w	well
b	base
h	historical
s	simulated
fmincon	Matlab local optimization function
Cullick, A.S., Johnson, D., Shi, G., 2006. Improved and more rapid history matching with a nonlinear proxy and global optimization. SPE 101933 prepared for presentation at the 2006 SPE Annual Technical Conference and Exhibition, held in San Antonio, 24-27 September.
Dean, S.O., Albert, C.R., Ning, L., 2008. Inverse theory for petroleum reservoir characterization and history matching. Cambridge University Press.
Gomez, S., Gosselin, O., Barker, J.W., 1999. Gradient-based history matching with a global optimization method. SPE 71307, revised for publication from paper 56756, first presented at the 1999 SPE Annual Technical Conference and Exhibition, held in Houston, 3-6 October.
Maschio, C., Schiozer, D.J., 2005. Development and application of methodology for assisted history matching. SPE 94882 presented at the SPE Latin-American and Caribbean Petroleum Engineering Conference, Rio de Janeiro, Brazil, 20-23 June.
Thomas, L.K., Hellums, L.J., Reheis, G.M., 1971.A nonlinear automatic history matching technique for reservoir simulation models. SPE 3475 presented at the SPE 46th Annual Fall Meeting, held in New Orleans, 3-6 October.
Vanderplaats, G.N., 1984. Numerical optimization techniques for engineering design: with applications. Mcgraw-Hill, New York.
Venkataraman, P., 2001. Applied optimization with Matlab programming. Wiley-Interscience.
Watson, A.T., Lee, W.J., 1986. A new algorithm for automatic history matching production data. sPe 15228 prepared for presentation at the Unconventional Gas Technology Symposium of the SPE, held in Louisville, 18-21 May.
Yang, C., Card, C., Nghiem, L., 2009. Economic optimization and uncertainty assessment of commercial SAGD operations. J. Canadian Petroleum Technol. 48 (9) September.
References
Biran, A., Breiner, M., 2002. Matlab for Engineers. Prentise Hall.
Chen, W.H., Gavalas, G.R., Seinfeld, J.H., Wasserman, M.L., 1973. A new algorithm for automatic history matching. SPE 4545 presented at the SPE-AIME 48 th Annual Fall Meeting, held in Las Vegas, 30 September.
3.	ARTICLE 2: A Methodology to Evaluate and Reduce Reservoir
Uncertainties using Multivariate Distribution
André Carlos Bertolini, Célio Maschio and Denis José Schiozer
Journal of Petroleum Science and Engineering, Volume 128, April 2015, Pages 1-14
24
Contents lists available at ScienceDirect
Journal of Petroleum Science and Engineering
journal homepage: www.elsevier.com/locate/petrol
A methodology to evaluate and reduce reservoir uncertainties using multivariate distribution
Andre Carlos Bertolini*, Celio Maschio* 1, Denis Jose Schiozer2
State University of Campinas - UNICAMP, Brazil
ARTICLE INFO
ABSTRACT
Article history:
Received 11 April 2013
Accepted 2 February 2015
Available online 20 February 2015
Keywords:
reservoir uncertainty multivariate sensitivity reservoir simulation history matching Latin hypercube interaction among reservoir properties
History matching is a challenging and time-consuming task related to reservoir simulation. Probabilistic approaches using dynamic data are often used to reduce reservoir uncertainties and improve matching. This work presents a new process to evaluate and reduce reservoir uncertainties using multivariate analysis incorporating the interaction between reservoir properties.
The proposed uncertainty reduction workflow provides a multivariate approach without the use of proxy models, allowing understanding of the reservoir response through the R2 matrix as well as more reliable reservoir predictions. The methodology offers a quantitative analysis and a new tool to evaluate and reduce uncertainties. The process uses a Latin Hypercube (LHC) to sample the reservoir attribute range and a smoothed mismatch data set from the LHC selected objective functions. The attribute interval, which minimizes the mismatch, is identified through polynomial fitting. The main objective is to reduce uncertainties considering the reservoir attributes range and a multivariate sensitivity matrix.
The methodology was firstly applied to a simple synthetic reservoir simulation model with 20 uncertainty attributes and we drew the following conclusions: (1) R2 sensitivity matrix clearly showed the key physical features of the reservoir model; (2) all reservoir attributes ranges were reduced, providing a set of simulation models with improved history matching. We successfully applied to the UNISIM-I-H reservoir model based on Namorado field, Campos basin, Brazil.
© 2015 Elsevier B.V. All rights reserved.
1.	Introduction
Different stages of reservoir life, from exploration to abandonment phases, require several types of methodologies and tools to improve confidence in production prediction. The proper use of these methods affects the reliability of the decisions in developing and managing reservoirs.
Among important tools, reservoir simulation plays a key role in integrating disciplines such as geophysics, geology, petrophysics and fluid mechanics. It predicts alternative scenarios to support management decisions. In addition, considering reservoir uncertainties allows reservoir simulation to make probabilistic predictions. Today, even with more complex reservoir models, the effect of many uncertain parameters can be investigated with the evolution of computer facilities.
As the number of uncertain attributes is very high, it is common practice to select the most critical through a sensitivity analysis. It is a simple and direct interpretation of the case as it shows the direct
* Corresponding author. Tel.: + 55 21 32168119.
E-mail addresses: andre@dep.fem.unicamp.br (A.C. Bertolini), celio@dep.fem.unicamp.br (C. Maschio), denis@dep.fem.unicamp.br (D.J. Schiozer).
1	+ 55 19 35211235.
2	+ 55 19 35213339.
http://dx.doi.org/10.1016jj.petrol.2015.02.003
0920-4105/© 2015 Elsevier B.V. All rights reserved.
relationship between reservoir properties and reservoir responses. However, while this method may provide satisfactory results, for instance, increasing the understanding of the relationships between input and output variables, for complex reservoirs models, these results are insufficient to solely inform decisions. The relationship between the attributes is not always determined using univariate analysis and this relationship can be important for several applications.
An alternative to overcome this is multivariate analysis. It corresponds to methods that try to explore interaction between factors to better understand the effects of uncertainties. More often, studies are conducted with statistical tools that include a global response to the problem.
In this paper, we present a novel process to evaluate and reduce reservoir uncertainties using multivariate analysis. Several approaches have been used to estimate and to reduce uncertainties successfully. Bissel (1997) and Bennett and Graf (2002) combined geostatis-tical modeling and gradient technique to generate many priori models for a better matching. It also compares using the gradzone method in which groups of grid cells in the model are modified using constraints, for instance, proximity to the wellbore, prior variograms and a selection of grid groups that allow property change within limits.
Kalman filters applied by Gu and Oliver (2004), also achieve satisfactory results, such as improvement in assisted history matching
(HM) and an estimate of uncertainty in future reservoir performance, both with a significant reduction in computational costs.
The application used by Liu and McVay (2010) is a real-time reservoir modeling studying the Markov Chain Monte Carlo (MCMC) method. The authors showed that assimilating data, HM, and forecasting continuously over time can result in forecast-uncertainty ranges that narrow with time when compared with traditional methods. In addition, the continuous simulation process allows us to calibrate uncertainty estimates over time.
Manceau et al. (2001) presented a fully-integrated methodology using statistical methods to quantify the risk associated with deterministic uncertainties, for instance, petrophysics and well locations, and stochastic uncertainties, such as geostatistical realization and matched reservoir models. They used experimental design, surface response and joint modeling method to evaluate the risk with all “deterministic”, “controlled” and “stochastic” uncertainties.
Risso et al. (2011) compared different sampling techniques in which the Derivative Tree, Monte Carlo and Latin Hypercube methods were used in a synthetic reservoir with 4 uncertain attributes. Although all three methods present a satisfactory result, the Latin Hypercube has the best results considering precision and number of simulations. Similarly, Maschio et al. (2005) applied the Derivative Tree technique to quantify the impact of uncertainties on the HM process and in the production forecast. In addition to the proposed methodology, the application shows that management of uncertainties in the prediction phase is important and that it can be considered in the HM stage.
Fig. 1. Reservoir uncertainty reduction workflow.
Emerick and Reynolds (2012) combined the Ensemble Kalman filter (EnKF) and Markov Chain Monte Carlo (MCMC) methodologies to obtain a relatively efficient algorithm for sampling the posterior probability density function (PDF) for reservoir-model parameter. They tested the method on a small 3D two-phase-flow reservoir, allowing a long Markov chain creation for comparison. EnkF-MCMC narrows the spread of reservoir predictions, resulting in histograms significantly closer to those obtained with the long MCMC case. In summary, the application of EnkF-MCMC improves the data matches from EnKF by generating samples of higher-probability regions of the posterior PDF.
Recently Ferreira et al. (2014) studied the emulator methodology applied to uncertainty reduction quantification. It uses a stochastic representation of the computer model to quantify the reduction in the parameter input space from production data over different periods. Using a five-spot synthetic case the authors showed the importance of using emulators in the uncertainty reduction and HM process. At an early stage, identifying the hypothetical real field permeability and possible values for channel positioning reduced the uncertainties.
Reservoir uncertainty has been studied for many years with different techniques and objectives. This paper presents a modified workflow based on the procedure given by Maschio and Schiozer (2013), with the addition of a smoothing step to capture the reservoir response trend along the attribute range, and a sensitivity matrix step to aid the uncertainty analysis and local HM processes. The Latin Hypercube (LHC) sampling technique is applied in the first stage of the methodology to provide the variability of the reservoir uncertain attributes. In the second stage, the gap between history data and simulated data is linked to a combination of attribute variation. The process uses a smoothed mismatch data set from the selected OF and polynomial fitting to identify the attribute interval, minimizing the mismatch.
The proposed methodology aims primarily to evaluate and reduce reservoir uncertainties, while improving the global history matching (HM) and, secondly, to provide a sensitivity analysis of reservoir response and attributes aiding the uncertainty analysis process.
Fig. 2. Moving average outputs with different y terms for a set of 100 data points. By taking the arithmetic means of subsequences of y terms, red curve - 2 terms, yellow - 4, green - 6, and blue - 8 (from MathWorld - A Wolfram Web Resource). (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)
Table 1
The R2 sensitivity matrix structure.
Reservoir attributes	Objective functions		
	OF1 misfit	OF2 misfit	OFm misfit
A1	RA1 OF1	RA1 OF2	RA1 OF1m
A2	Ra2_OF1	Ra2_OF2	RA2_OFm
			J
An	RAn_OF1	RAn8/5_OF2	RAn_OFm
The methodology is applied to a synthetic reservoir with twenty uncertain attributes and in the UNISIM-I-H model (based on the Namorado field, Campos Basin, Brazil), where the objective functions (OFs) are oil and water production rates and bottom-hole pressure. We examine the uncertainty reduction every cycle of the loop shown in Fig. 1 and the principal properties influencing the reservoir model through the sensitivity matrix.
2.	Methodology
The workflow in Fig. 1 shows the proposed methodology. The first step is reservoir characterization from defined attributes and
Fig. 3. Schematic example of two OF misfits (OF1 and OF2), the corresponding polynomial 1 and 2 (Poll and Pol2), the average polynomial and the distribution (modified from Maschio and Schiozer, 2013).
uncertainty limits. In the next step, Latin Hypercube sampling generates a distribution of plausible sets of attribute values. The amount of desired models (samples) varies according to the number of reservoir attributes.
LHC returns an a-by-b matrix, W, containing a Latin hypercube sample of a divisions on each of b variables. For each column of W, the a divisions are randomly distributed with one from each interval (0,1/a), (1/a,2/a),..., (1-1/a,1), and are randomly permuted. Given a and b, the matrix W can be compared with the maximum number of combination given by (a!)b-1.
After that, objective functions must be selected. The models are run in the simulator and the misfit for all OF between dynamic (historical) and simulated data is obtained. Data reorganization follows to study the misfit profile along reservoir attribute variation.
Before any processing, a moving-average smoothing algorithm as described by Achelis (1995) is applied individually to each misfit function. The algorithm removes the outlier results while preserving underlying patterns. The moving average is a smoothing method that provides a time series, constructed by taking averages of several sequential values of another time series. So taking an average of the points near an observed point provides a reasonable estimate of the trend. Fig. 2 shows the moving average for a set of 100 data points, by taking the arithmetic means of subsequences terms. This process provides the next stage with the smooth misfit data collection to fit a polynomial for each attribute.
The polynomial correlates the normalized OF misfit with the attribute range. The normalization uses the maximum misfit range among all OF. We calculate the coefficient of determination R2 for each polynomial and, at the end, obtain an R2 sensitivity matrix between reservoir attributes and OF misfit. Therefore, at this stage
Porosity (a)
Region2
Regionl
Region5
Region4
0.00 0.501.00 miles
0.00 1.00 2.00 Km
0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24 0.25
Porosity K layer: 5(c)
Porosity K layer: 1(b)
0.00 0.501.00 miles
0.00 0.501.00 miles
0.00 1.00 2.00 Km
0.00 1.00 2.00 Km
o - o _ o
O -o__ o' _
CM
O -o -o__ o' _
CM
o - - o _ _ o
Fig. 4. Case 1 reservoir model.
o
o - o _ o
o - o _ o
_ NJ o
—	o
-	o _ o
o -O -o _ o' _
the multivariate sensitivity study is completed and can be used for future applications. Table 1 shows the R2 sensitivity matrix structure.
In Table 1, each matrix element represents the quality of fit of a model. For instance, RAi_oFi element shows how well the polynomial fits the OF1 misfit using all LHC experiments the OF, n is the number of reservoir attributes and m is the number of OF.
Then, we assess the final objective to further reduce uncertainty and prioritize each OF. For instance, the user may want to
prioritize water breakthrough, so the user will attach high weights to calculate the water production OF. Otherwise, the process continues giving unitary weight to each OF.
At this point, we apply a filter to the R2 sensitivity matrix to select the high matrix values. Each selected polynomial is a function of a reservoir attribute and the OF misfit. The key difference from traditional methods is that reservoir attributes are modified together with all the uncertain attributes (LHC sampling). With this procedure,
Table 2
Base model reservoir attributes and their limits - case 1.
Reservoir attributes Multipliers
Limits	Kxi	KX2	Kx3	Kx4	KX5	Kzi	Kz2	Kz3	Kz4	Kz5
Lower	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50
Base	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00
Upper	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00
Corey's equation
Limits	ExpoW1	Krw1 *	ExpoW2	Krw2*	ExpoW3	Krw3*	ExpoW4	Krw4*	ExpoW5	Krw5*
Lower	1.00	0.15	1.00	0.15	1.00	0.15	1.00	0.15	1.00	0.15
Base	2.20	0.60	1.10	0.80	4.00	0.50	1.30	0.70	4.30	0.80
Upper	5.00	0.90	5.00	0.90	5.00	0.90	5.00	0.90	5.00	0.90
Fig. 5. Reservoir attribute range versus normalized square error (blue), smoothed NSE (red) and polynomial (black) for water production at Prod3 well, cycle 1 - Study test 1. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)
each polynomial not only represents the misfit trend along a unique attribute variation, but also shows the relationship between misfits and a combination of attribute variations.
Next, all the filtered polynomials are combined to create a global misfit response per attribute. Fig. 3 shows a schematic example with two OF misfits, polynomials, average polynomial (global misfit) and the distribution. The average polynomial becomes the input data, which is used to fit a probability distribution (black curve in Fig. 3). The distribution prioritizes the range of attributes over the lower global misfit. Different distribution percentiles can be chosen to conservatively reduce the range, using low percentiles, for instance, P25 or more severe reduction with high percentiles (P90).
At this stage, the models are run with the reduced attribute ranges and evaluated using a match quality indicator. If the indicator does not improve the results, the process is restarted, using results from the previous cycle. Otherwise, the last step is to improve the local HM and consequently the attribute range. The workflow is completed if the quality criterion and the local HM are achieved. The process stays in the loop until a specific criterion is met.
Aiming to create a match quality indicator (¥), we gathered, through the Euclidean norm, the outputs from the misfit function of each well and OF. A square error function shown in Eq. (1) was selected according to Bertolini and Schiozer (2011) to characterize the misfit.
cl
SqEm =	(hi - sf)2	(1)
i = 1
where the index s represents simulated data, h, historical data, d, total number of data, and m, number of OF. However, the match quality indicator (¥) is obtained dividing the Euclidean norm by the Euclidean norm of the base model.
, . fr- 1 ™2f	(2)
[PL 1 (SqEw)2] =
The interpretation of is direct. Values greater than 1 represent a worsening in the HM; values equal to 1 represent that model has the same performance of the base model; and values smaller than 1 represent improvements in the HM.
This work focuses on uncertainty reduction and on multivariate sensitivity matrix based on history reservoir data. Neither the conventional HM, nor optimization under uncertainty, which identifies the best set of models to make predictions, is studied in this paper.
2.1.	Case 1 - synthetic reservoir model
The first case study uses an upscaled model from a refined reservoir. The porosity was upscaled through the arithmetic average using the method for permeability as described by Maschio and Schiozer (2003). It is a technique based on a heterogeneity coefficient (Dykstra-Parsons), and upper and lower permeability limits. The history data used in the OF calculations were obtained from the refined model, in which 30,600 cells are distributed in 90 x 34 x 10 blocks and of a single porosity type. Horizontal permeability varies from 10 to 1900 mD, with a median of 373 mD and standard deviation of 284 mD. The vertical permeability has the same heterogeneous distribution, with a median of 6.8 mD and standard deviation of 105 mD. The porosity distribution has a median of 0.19 and a standard deviation of 0.05. Although it is a synthetic upscaled reservoir, the true reservoir attribute values to match the history data are unknown. The upscaled base case model contains a similar heterogeneity to the refined model. It is divided into five regions, shown in the top right of Fig. 4 with different geometries, area and volume, and different geological properties. The model presents four uncertain attributes per region.
The attributes are horizontal permeability in the X direction (Kx), vertical permeability in the Z direction (Kz), coefficient of Corey (Eq. (3)) for water relative permeability (ExpoW) and the maximum value of the water relative permeability in Corey's equation (krwn). Corey's equation
Table 3
Cycle 1 R2 sensitivity matrix - study test 1.
Cycle 1		Objective functions														
R2	matrix	Prodi			Prod2			Prod?			Prod4			Prodi		
		Oil	Water	BHP	Oil	Water	BHP	Oil	Water	BHP	Oil	Water	BHP	Oil	Water	BHP
		B92	| 0.06	B*	| 0.13	| 0.16	|o.22	0.02	0.03 |o.29		0.04	|0.29	|0.18	|o.23	|o.24	B-39
	K.2	| 0.12	■&gt;.33	| 0.09	■88	B-88	■.85	| 0.13	b-23	0.11	|o.26	|o.l6	|o.25	| 0.07	| 0.07	|o.21
	Kx3	|o.2O	| 0.05	|o.l7	0.05	| 0.05	|).39	■90	■74	I87	|o.l9	|d.39	| 0.03	¡0.14	| 0.14	|o.l7
	K«4	|o,17	| 0.05	|p.48	|0.27	|o.24	|o.2O	| 0.12	|0.18	b33	1.94	|o.16	■95	0.04	| 0.04	
	Kx5	|o.21	| 0.07	| 0.15	|o.2O	|o,15	| 0.13	0.02	| 0.08	|d.28	|o.23	|o,18	|o,19	■90 B89 ^85		
	K,i	|o.2O	|o.21	|0.27	|o.32	[o.3O	|o,18	|C.33	B.32	¡0.20	|o.24	|o.2O	|o.24	0.00	0.00	B-27
	*z2	|o.2O	|o.22	| 0.13	■72	B-74	|o.l5	¡0.19	B.31	|o.2O	|o.25	|o.28	|o,18	¡0.31	|0.30	|o.17
2	Ku	| 0.08	| 0.07	| 0.05	|o,16	|o,28	|o.21	■81	■80	|).41	¡0.17	|o,19	|o.2O	|0.31	b-32	B-33
3 -n	K!a	|o.21	| 0.11	|0.17	| 0.11	| 0.11	| 0.11	| 0.08	I0-17	0.02	| 0.10	| 0.05	|0.30	|o,16	|o,17	■■44
ro	K,s	| 0.06	Jo. 22	| 0.11	B32	|o.28	|o.36	| 0.12	¡011	|o,19	0.02	|o,16	|p.46	B59	B59	| 0.14
o	ExpoWl	B'3	B*97	|0.20	|c.28	|o.34	|o.22	|0.30	|o.2O Id. 32		0.06	| 0.08	| 0.07	l&lt;	|o.3O	Bso
&gt;	Kjwl*	B63	B64	|o.24	|0.20	|o,18	■•54	|o.32	b-27	|D.26	¡0.17	| 0.05	|o.2O	|o,19	|o,19	Bso
&lt;u (£.	EXpoW2	■-44	|o.21	|0.28	B&gt;	■66	B.67	|o,19	b23	0.04	10.31	| 0.06	¡0.16	|0.31	B.33	| 0.14
	w	| 0.14	| 0.05	| 0.02	B-52	■si	|o.32	0.01	0.03	0.07	| 0.14	|o.l9	|o.21	0.03	| 0.03	|o.25
	^xpoWS	■•48	| 0.10	|o.39	|o.23	|o.26	| 0.08	B83	B89	B82	[ 0.07	| 0.12	| 0.04	0.04	| 0.03	| 0.03
	K™3‘	|0.22	|c.28	|o.26	| 0.11	| 0.13	|o.22	B74	■91	■78	| 0.07	|o.21	|0-33	|o.29	|0.28	B52
	^xpoW4	| 0.13	■•49	| 0.02	| 0.07	| 0.06	¡0.42	|o.23	b-23	|0.17	■so	■•93	|o.l5	|o.34	|o.33	|o.l9
		B67	| 0.12	B-42	| 0.11	| 0.11	■_47	| 0.08	| 0.05	|).36	|o.34	■68	|o.45	f.45	B.45	B-79
	^xpoWS	|o.3O	|o.26	|0.19	|o.24	|o.3O	|P-46	|0.33	■ 35	|0.28	B-42	| 0.03	■•57	B82	■83	■66
	K™s’	|o.28	|d.28	| 0.10	| 0.07	| 0.04	| 0.07	|o.l8	b-29	|o.22	|0.29	|p.30	| 0.15	B82	B83	■■36
for water relative permeability shows the last two attributes. However, the simulation model has a total of 20 uncertain attributes.
Krw
krw
q ExpoW
Pw ~ Swir
(3)
n
where Krw is the water relative permeability, Sw is the water saturation, Swr is the irreducible water saturation and, Sor is the residual oil saturation.
The permeabilities Kx and Kz are modified in the simulation models through multiplier numbers. The limits are 0.5 and 2.0, which represent half and double the absolute permeability Kx and Kz of the base model. The base model is the unitary reference of the absolute permeability multipliers, while the attributes of ExpoW present a variation range from 1 to 5 and the attributes of km* from 0.15 to 0.90. Table 2 presents a reservoir attribute summary.
The corner point grid shown in Fig. 4 has 2550 cells distributed in 30 x 17 x 5 blocks. The reservoir has five producer wells and five injector wells, the producer/injector pair for each region is located in the same reservoir position. The reservoir cells of the injector wells are Injectorl (4;1-6;5); Injector2 (14;1-9;5); Injector3 (20-29;6;5); Injector4 (3;8-17;5) and Injector5 (10-28;14;5) and for the producer the cells are Prod1 (4;1 -6;1); Prod2 (14;1-9;1); Prod3 (20-29;6;1); Prod4 (3;8-17;1) and Prod5 (10-28;14;1).
The objective functions (OF) considered in this case were oil production (m3/day), water production (m3/day) and bottom-hole pressure (KPa) for the five production wells. In total 15 functions were considered. The well production strategy used in the simulation had a surface liquid limit of 4770 m3/day and the bottom hole pressure limit of 20,684 KPa. The maximum liquid rate on each simulated date was input into the simulator. The simulations used the commercial IMEX software.
The constraints for the injector wells were the maximum surface water rate of 4770 (m3/day) and the maximum bottom hole pressure of 82,737 KPa.
Three study tests were analyzed. From previous runs, 150 Latin Hypercube samples captured the mismatch trend versus reservoir
parameter change. Study test 1 uses 150 samples from LHC and 20 uncertain parameters, which provides a 150 x 20 (W) matrix; moving average process with 10% of the number of samples. Study test 2 uses the same set of samples and parameters, but without the smoothing stage. Finally, Study test 3 uses only 50 Latin Hypercube samples (50 x 20 matrix) and a moving average of 10% to demonstrate the impact of a reduced number of samples on the proposed method. For all tests, we used the four cycles presented in Fig. 1 and the likelihood distribution P25 to select the new attribute range.
We normalized the mismatch between simulated and history data between the maximum and minimum simulated values for all three OF. Finally, we used the square error function, providing the normalized square error (NSE) data.
2.2.	Result 1 - synthetic reservoir model
2.2.1. Study test 1: moving average technique applied to smooth data for 150 LHC experiments
On this particular test, the methodology outputs per step are presented according to the sequence presented in Fig. 1. Fig. 5 illustrates the smoothing and polynomial fitting stage in the first cycle. It shows the water production normalized square error (NSE) for Prod3 well; the smooth NSE and the polynomial of degree 3 for all experiments selected by LHC sampling technique. Note that for most of the attributes the NSE and even the smoothed NSE do not have a clear trend. We concluded that other attributes are affecting the water production for these cases, here called interaction effect among the attributes.
Table 3 clearly shows the NSE versus reservoir attributes. The matrix R2 shows how well the OF is associated with the reservoir attribute, where oil represents oil production OF; Water, water production OF; and BHP, bottom hole pressure OF. Numbers closer to 0 indicate that the polynomial does not fit the data very well, while R2 closer to 1 indicates a good fit. The highlighted column in Table 3 shows the R2 for those polynomials presented in Fig. 5. Applying a R2 &gt; 0.3 cutoff, only seven polynonials out of twenty were selected for water rate in Prod3 well.
Prodi
2500
2000
OOO History ■ Base model
Cycle 1
^■i Cycle 2 Cycle 3 Cycle 4
4000
5000
4000
3000
2000
1000
Prod4
1000
Prod5
4000
3000
2000
1500
1000
500
50	100
Prodi
4000
3000
2000
1000
Prod2
50	100
Prod2
3000
2000
1000
Prod3
50
Prod3
100
2500
2000
1500
1000
500
50	100
Prod4
50	100
Prod4
4000
3000
2000
1000
50	100
Prod5
0
r X104
x10
50	100
Time (month)
50	100
Time (month)
Fig. 6. Objective function responses for all cycles - study test 1. (For interpretation of the references to color in this figure, the reader is referred to the web version of this article.)
x10
100
Time (month)
x10
50	100
Time (month)
0
0	50	100
X1Q4	Prod5
50	100
Time (month)
In Fig. 6, all OF considered in this case are combined. The different colors are associated with the cycles. The black circle curves represent the history data and the dotted black lines, the base model. In cycle 1 the simulation model responses are scattered around the history data
due to the wide range of the reservoir attributes. On the other hand, the cycles 2, 3 and 4 show a thin belt closer to the desired response. Following the sequence presented in Fig. 1, the polynomials with R2 &gt; 0.3 were combined to give a unique output for each attribute.
Number of experiments (HCL)
Number of experiments (HCL)
Fig. 7. Evolution of the match quality indicator - study test 1.
Cycle 1 ^AVERAGE = 16227	*
** &gt;	* * -
	* *
** *	* *** *■ ****** *
• * +* * *	♦* * * t *	# . *	&gt; * * * *	*	u,* * V *	** *	/ ** ■ iw ********* */♦»* ’»;4 •• V.
Cycle 4
Wave rag f= 0.2311
Table 4
Cycle 3 R2 sensitivity matrix - study test 1.
Cycle 3		Objective functions														
R2	matrix	Prodi			Prod2			Prod3			Prod4			Prodi		
		Oil	Water	BHP	Oil	Water	BHP	Oil	Water	BHP	Oil	Water	BHP	Oil	Water	BHP
	K«i	(.53	|o.u	(.99	10.13	| 0.14	(.20	| 0.07	1 0.11	1 0.10	| 0.12	(.21	| 0.09	(.23	(.26	| 0.07
	«x2	(.20	(.35	| 0.14	(.90 (88 (93			| 0.06	(.16	(.25	(.16	| 0.05	| 0.09	(.19	(.20	(.33
	*x3	| 0.10	| 0.03	(.29	J.49	J.48	(.37	J.95 J).89 J).87 |o.47				| 0.07	(.32	(.16	(.16	(.13
	*x4	0.04	1 0.10	| 0.10	(.18	(.20	| 0.11	| 0.14	|0.23	|0.17	J.80	[0.I8	|o.97	0.05	| 0.06	(.34
	*xS	1 0.11	1 0.12	(.33	(.19	(.19	| 0.09	| 0.09	(.17	(.16	(.40	(.20	| 0.08	(•71	(.71	(93
	«zl	(.16	| 0.07	(.32	0.03	| 0.03	| 0.15	(.41	(.44	(.31	| 0.11	(.18	B-71	| 0.09	| 0.10	(.48
	«z2	|0.25	(.29	(.25	|0.27	(.24	(.21	| 0.07	| 0.06	(.22	(.47	| 0.03	(.44	(.29	(.28	| 0.11
	Kz3	1 0.10	| 0.06	| 0.10	1 0.10	| 0.08	(.20	(.53	(.61	(.41	(.25	(.17	(.13	(.23	(.24	(.36
□	Kz4	I 0.06	| 0.13	| 0.09	0.04	| 0.05	(.19	| 0.06	(.16	I 0.01	0.03	| 0.09	| 0.04	0.03	| 0.03	(.54
4-» ro	KzS	| 0.14	(.17	(.25	0.04	| 0.04	(.32	(.17	(.19	| 0.14	10.13	(.17	(.40	(.32	(.33	(.18
o		(.93	(.98	| 0.03	0.01	1 0.01	| 0.04	Io.21	10.15	(.39	[o.48	| 0.02	(.37	(.32	Io. 31	| 0.10
&gt; cu	Krwl*	K-47	(.49	1 0.11	(.53	(59	| 0.07	(.35	(.35	| 0.08	(.32	| 0.06	(.26	(.36	(.35	| 0.07
&lt;D or	^xpoW2	(.20	(.25	(.40	(66	(.62	(.83	(.22	(.17	| 0.04	| 0.10	I 0.01	| 0.10	(.34	(.34	| 0.07
		| 0.09	| 0.02	| 0.06	¡0.41	(.38		| 0.04	| 0.03	| 0.07	(.34	(.21	| 0.04	(.30	(.29	(.24
	^xpoW3	| 0.09	I 0.11	(.26	| 0.07	| 0.08	| 0.07	K75	|D.9C |p.86 | 0.16			(.36	| 0.16	(.19	(.19	(.22
	«iwS*	(.42	(.36	(.29	|0.32	(.28	(.21	(.48	(71	ft’45	| 0.04	(.24	| 0.14	(.26	(.27	(.16
	^xpoW4	B-56	(.25	| 0.14	(.43	(.42	(.20	(.22	(.24	(.19	(.53	(.39	(.19	(.23	(.22	(.17
	Kzw4*	0.01	| 0.10	| 0.17	(.28	(.26	(.19	(.22	(.17	(.22	(.52	(60	(.17	B-59	(.59	(.16
	^xpoWS	(.22	(.23	| 0.07	(.35	(.37		(.27	(.27	(.26	(.16	(.3?	(.27	(.67	(.66	(81
	K™s*	(.47	(.50	0.01	(.37	(.39	| 0.06	| 0.11	| 0.11	| 0.13	(.27	(.25	| 0.11	B-57	(56	(.36
Finally, a likelihood function was applied, providing a relationship between the attribute range and OF misfit. The final attribute ranges are presented in Fig. 8.
From Fig. 6 and Table 3, note that it is important to analyze several reservoir behaviors when applying the proposed methodology.
(I)	Observe that even considering 20 uncertain attributes in the upscale model, it may not capable of representing the history data. Therefore, either other reservoir attributes that were not considered uncertain are contributing to a mismatch, or different range limits are needed on the current 20 uncertain attributes;
(II)	All OF considered for this case showed an improvement along the cycles. The methodology combines all the OF responses and adjusts the best attribute interval to improve the global matching between observed and simulated data. Wells with comparatively lower rates, such as Prodi and Prod4 wells for water rate, showed a wider spread around the history data.
We know that objective functions combined in one general equation delivers globally improved matched models, but to achieve this sometimes they do not necessarily deliver the same for local functions with lower rates, and consequently lower SqE. Further, Bertolini and Schiozer (2011) showed that simple and squared error functions influence the HM optimization process, which may affect this method as well. However, the methodology prioritizes OFs with high accumulative difference between simulated and history data;
(III)	The R2 sensitivity matrix shows how each attribute correlates with OFs. The optimization of the attribute ranges with higher R2 coefficients can lead to better local HM (last check of the proposed workflow - Fig. 1), for instance, Prodi well for water rate.
(IV)	The number of simulation runs is the number of LHC samples multiplied by the number of cycles. For Study test 1, 150 simulation runs were used in each cycle (LHC 150 x 20) to support the uncertainty reduction.
Prodi - water rate
|ooo Normalized square error (NSE)	Smooth NSE ^—Polynomial
x10S	x10S
8 -------&lt;------■------.------,----- 8 ---------■-------------•--------
1	1.5	2	2.5	3	3.5 0.4	0.5	0.6	0.7	0.8	0.9
ExpoWl	Krwi*
Fig. 8. NSE, smoothed NSE and polynomial for water rate Prod1 well - study test 1.
The match quality indicator, F, described above was used to evaluate the HM improvement along the cycles. Fig. 7 shows F in all four cycles for every simulation model.
The R2 sensitivity matrix, cycle 3, in Table 4 shows that ExpoW1 and Krw1n have the first and third highest R2, respectively for water rate Prodi well.
Fig. 8 shows the NSE, smoothed NSE and the polynomial along the ExpoW1 and Krw1n range in cycle 3. The lower NSE for ExpoW1 were allocated between the attribute range (multiplier) 1.0, lower
limit (LL) and 2.0, upper limit (UL) and from 0.70 (LL) to 0.90 (UL) for the Krw1n attribute. These intervals are slightly different from the final ranges of cycle 4, which consider all three OFs and the five producer wells. In cycle 4, ExpoW1 varies from 1.05 (LL) to 3.30 (UL) and Krw1n from 0.454 (LL) to 0.8725 (UL). Fig. 9 shows the uncertainty reduction from the original attribute ranges (Table 2) to the cycle 4 ranges and the modified ExpoW1IKrw1 ranges.
Note that interaction effect mentioned previously affects simulation results when ExpoW1 and Krw1* attributes interval are changed.
Time (month)
Time (month)
Time (month)
Time (month)
Fig. 10. Cycle 4 models (green) and cycle 4 modified models (magenta) responses - Study test 1. (For interpretation of the references to color in this figure legend, the reader is referred to the web version of this article.)
ooo History
Time (month)
Prod2
Prod3
4000
Prodi
Prod3
Prodi
Prod2
Prod3
Time (month)
Time (month)
Time (month)
5000
4000
3000
2500
Fig. 11. Objective function response for all cycles - study test 2.
Prodi
	5000 4000 3000 2000 1000		5000 4000 3000 2000 1000			
	0	..	0			
2000
1000
Prod4
5000
	50	100
	Prod2	
2000
1500
1000
500
50	100
Prod4
50	100
Prod4
3000
4000
Prod5
4000
3000
2000
1000
50
Prod5
100
2000
1000
100
x 10
50
X10'	Prod5
50	100
Time (month)
50	100
Time (month)
From Table 4 we can predict which OF will be most influenced. When the modified ranges stay in the lower OF NSE interval, there are insignificant variances in the results. On the other hand, the results change more when the ranges are modified to the upper OF NSE interval. This change occurred in Prod4 well for oil and water rates. The modified ExpoW1IKrw1* attribute ranges improved Prodi water rate results, but changed Prod4 oil rate and, consequently, the water rate. Fig. 10 shows the reservoir model results from cycle 4 and the results from ExpoW1IKrw1* modified attribute ranges. Note the R2 for Prod4 oil rate function is 0.48 for ExpoW1 and 0.32 for Krw1 *. Therefore,
the right attributes can be locally adjusted according to R2 sensitivity matrix.
2.2.2.	Study test 2: raw data for 150 LHC experiments
Unlike Study test 1, the moving average smoothing technique was not used in Study test 2. The OF curves presented in Fig. 11 are evenly spread for the last cycle.
The raw NSE in this test shows an unsatisfactory trend and consequently provides low R2 coefficients. Therefore, the polynomials
Number of experiments (HCL)
Fig. 12. Evolution of the match quality indicator - study test 2.
Cycle 1	*		Cycle 2
Waverage= 1-6227		3.5	Waverage= 1-0224
Cycle 3	*		Cycle 4
V'werage= 06642		1.2	V'average= °-4366
* * * * * *
**
* * * ** *
*	*	J
.1.	J, -*• **** * „
Fig. 13. UNISIM-I-H model: porosity map and well locations.
do not identify the reservoir attributes range to reduce the OF error functions. The match quality indicator plotted in Fig. 12 reflects this issue.
Comparing the results of Study tests 1 and 2, we can see that the smooth technique helped filter the data and extract the principal trend.
2.2.3.	Study test 3: moving average technique applied to smooth data for 50 LHC experiments
Considering only the match quality indicator, Study test 3 performed well compared with Study test 2, which used 150 LHC samples. The^AVE for Study test 3 was 0.2797 in cycle 4, compared with ¥AVE equal to 0.2311 for Study test 1 and ¥AVE equal to 0.4365 for Study test 2. Even with one third of models from Study test 2, Study test 3 presented better results. The applied smoothing technique extracted the principal trend even with fewer models.
2.3.	Case 2 - UNISIM-I-H reservoir model
The geological model has 3.5 million active cells and uses core and well logging data, 2D and 3D seismic data provided by Brazilian
National Petroleum Agency - ANP and also from Petrobras (released public data). It uses structural, facie and petrophysical models from Namorado field, located in the Campos Basin, Brazil. Avansi and Schiozer (2015) describe the details of the UNISIM-I-H model.
The dataset contains the well log information for 56 wells drilled through the upper Macae formation (Meneses and Adams, 1990). This field is one of the main reservoirs in the Campos Basin, largely comprised of sandstone of turbidite (Guardado et al., 1989a, 1989b, 2000). The 3D seismic volume and 2D seismic lines are available in the public dataset from ANP. These data are used to derive structural (reservoir boundary limit; top, bottom, sequences and faults) and sedimentological (zones and horizons) information for reservoir characterization.
Based on the geological model in a high-resolution grid, an upscaling procedure to a medium reservoir scale was necessary to decrease the computational effort. A simulation grid cell resolution was defined with 100 x 100 x 8 m3 blocks to reflect reservoir behavior and heterogeneities. It was discretized into a corner point grid (81 x 58 x 20 cells, with 36,739 active total cells). Porosity was upscaled through an arithmetic volume weighted method to ensure that the hydrocarbon pore volume remained constant when upscaling (additive property characteristics). Permeability was upscaled
Fig. 14. UNISIM-I-H reservoir regions and Fault F1.
Table 5
Original (cycle 1) reservoir attribute range for UNISIM-I-H model.
Limits	Reservoir attributes
	Mpor1	MpoR2	Mpor3	Mpor4	Mpor5	Mpor6	Mpor?	Mpor8	Mpor9
Lower	0.70	0.70	0.70	0.70	0.70	0.70	0.70	0.70	0.70
Base	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00
Upper	1.30	1.30	1.30	1.30	1.30	1.30	1.30	1.30	1.30
Limits	Mporw	Mporn	Mporn	MKh	MKV	WOC (m)	CoeffA	CoeffB	ExpoW
Lower	0.70	0.70	0.70	0.50	0.50	3095.00	0.085	-0.150	1.00
Base	1.00	1.00	1.00	1.00	1.00	3095.00	0.085	0.000	3.00
Upper	1.30	1.30	1.30	3.00	3.00	3105.00	0.095	0.150	5.00
using a flow-based upscaling technique described by (Deutsch, 1989). When an isotropic permeability is upscaled, the effective results become anisotropic; three effective permeabilities in all directions (i, j and k) are then obtained for the upscaled reservoir model. Fig. 13 shows the porosity map and the well locations.
The original volume of oil is 130 million m3, the oil density is 28° API and the fluid model is the Black Oil. The production strategy was defined with 25 wells (4 vertical producers, 10 horizontal producers and 11 injectors). The vertical wells NA1D, NA2, NA3D and RJS19 were the pilot vertical wells for this field. They produced for 4 years and then were closed for one year. The production restarted in the sixth year with all 14 producers and 11 injection wells for six more years.
In this work the UNISIM model was divided into twelve regions, as shown in Fig. 14. The model presents 18 uncertain attributes. Table 5 presents the limits for each attribute. They are 12 porosity multipliers (Mpor), one horizontal permeability multiplier (Mkh), one vertical permeability multiplier (Mkv) for the entire reservoir, wateroil contact (WOC), coefficient A (CoeffA) and coefficient B (CoeffB) of Eq. (4) which correlates porosity (&lt;ph) with horizontal permeability (Kh), and ExpoW of Eq. (3). The vertical permeability without any
multiplier was defined as 10% of the horizontal permeability.
Kh = 10[(^xCoeffA)~ CoeffB]	(4)
The oil rate and the water injection rate on each simulated date was input into the simulator. The BHP was limited to 15,000 KPa as a minimum for producer wells and a maximum of 35,000 KPa for injector wells. The maximum liquid rate was set to 3000 m3/day for producer wells and 6000 m3/day for injector wells. A Study test was run using 100 samples from LHC (100 x 18 matrix); moving average process with 20% of the number of samples; the three cycles presented in Fig. 1 and the likelihood distribution P50. The same OFs were evaluated, oil production (m3/day), water production (m3/day) and bottom-hole pressure (KPa) for 14 production wells. In total 42 functions were considered.
2.4.	Result 2 - UNISIM-I-H reservoir model
Fig. 15 shows the oil and water rate functions, and BHP for all vertical wells. The different colors represent the cycles and the black circle curves, the history data. Cycle 1 (cyan curves) uses the
Fig. 15. Vertical wells objective function responses for all cycles - UNISIM-I-H model. (For interpretation of the references to color in this figure, the reader is referred to the web version of this article.)
Table 6
Reduced (cycle 3) reservoir attribute range for UNISIM-I-H model.
Limits	Reservoir attributes
	Mpor-!	MpoR2	Mpor3	Mpor4	Mpor5	Mpore	Mpor7	Mpors	Mpor9
Lower	1.03	1.01	1.16	0.85	1.07	0.96	0.85	0.80	0.83
Base	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00
Upper	1.15	1.13	1.28	0.93	1.193	1.08	0.97	0.92	0.95
Limits	Mporw	Mporn	Mporn	MKh	MKV	WOC	CoeffA	CoeffB	ExpoW
Lower	0.77	0.96	0.83	1.86	1.58	3101.04	0.094	-0.019	2.00
Base	1.00	1.00	1.00	1.00	1.00	3095.00	0.085	0.000	3.00
Upper	0.89	1.07	0.94	2.36	2.10	3103.02	0.098	0.037	2.75
Field oil rate (m3/D)
x 10*
OOO History Cycle 1 Cycle 2 Cycle 3
120 Months
Field water rate (m3/D)
x 104
Average BHP x 10	producer wells (KPa)
0	40	80	120 Months
0	40	80	120
120 Months
Fig. 16. Field objective function responses for all cycles and the evolution of the match quality indicator - UNISIM-I-H model.
2	Match quality indicator (y/J
	I ITeycM = «.9861	= 0.8511 y._,rl,3 = 0.477 |
1.5	****** * ** * * *--
	
1 0.5	*	** *J&gt;	* *	*	* ’%£**** ****vAlv*tW ******* *$ **M’*A^*%^
	20	40	60	80	100
Number of experiments (HCL)
original attribute range presented in Table 5. Over the three cycles the reservoir range of attributes was reduced using P50 for cycle 2 and P65 percentile for cycle 3. The simulation results moved closer to the history data. A similar behavior was achieved for the horizontal wells.
From cycle 1 to cycle 2 (red curves) the method was applied without the need of local adjustment based on R2 sensitivity matrix. Since the model responses followed the history data trend, the reduced attribute ranges were used without local correction in the following cycle. From cycle 2 to cycle 3 (green curves) the water production in some wells did not improve as expected. We then used the R2 matrix and identified the ExpoW of Eq. (1) as the most influential attribute for water production. However, at cycle 3 the attribute ranges were reduced again and the ExpoW attribute was modified based on R2 sensitivity matrix. Table 6 shows the reduced reservoir attribute range at cycle 3.
Even with the attribute ExpoW modified in cycle 3 for a better water production match, the simulated results of some wells showed asymmetrical results around the history data. For instance, the NA2 well had higher water rate results than the history data for most models. This happened because the method prioritized the global matching between observed and simulated data as described in item (II) from case 1.
Fig. 16 presents the field performance results and the match quality indicator through the cycles. The history BHP average was calculated from the start of production (84th month). The history BHP average was calculated from the 80th month for the injector wells.
Over the cycles the three field functions results moved closer to the history data and the match quality indicator/ improved.
3. Conclusions
•	The methodology presented in this work yields uncertainty reduction of reservoir properties using dynamic data. All the ranges of reservoir attributes dropped along the cycles, providing a set of simulation models with improved HM for both cases;
•	The proposed methodology provided an R2 sensitivity matrix showing the relationship between the expected reservoir behavior and the
reservoirs uncertain attributes. We presented an example to show how the matrix helps understanding the interaction between objective functions and reservoir attributes, and how it should be used to locally adjust the simulation model (Study test 1 from case 1). This work did not perform the local HM using optimization algorithms because the objective was only the first step (uncertainty reduction) but this will be addressed in future works;
•	This methodology provided a set of improved simulation models without the use of proxy models, avoiding an additional complex step of similar techniques. The multivariate approach allows understanding of the reservoir response through the sensitivity matrix and also allows future analysis and reservoir predictions;
•	The methodology showed that even a reduced number of experiments (Study test 3 from case 1) achieved better results than Study test 2, which used 3 times more models;
•	The smoothing technique helped obtain the general trend between reservoir attributes and the OF misfit selected in both cases. Comparing the results of Study test 1 and 2 from case 1, and results from Study test 2 and 3, showed that this technique was fundamental to improve the overall matching;
•	The global HM indicator clearly showed the improvement in every cycle. In both cases, the normalized Euclidean norm from the selected OF was used. The evaluation method will vary according to the objective of each study;
•	The definition of uncertainties of reservoir attributes and their range showed to be critical for both cases. With few and/or wrong attributes, and narrow ranges the proposed method will perform under the optimal solutions.
Nomenclature
LHC	Latin hypercube
HM	history matching
BHP	bottom-hole pressure
WOC	water-oil contact
R2	coefficient of determination
MCMC	Markov Chain Monte Carlo
OF	objective function
F	match quality indicator
Krw	water relative permeability
Sw	water saturation
Swir	irreducible water saturation
Sor	residual oil saturation
Expow	coefficient of Corey's equation for water relative
permeability
krw*	maximum value of the water relative permeability in
Corey's equation
Kx	effective permeability in X direction
s	simulated data
h	history data
SqE	square error
y	number of terms used	in the moving average algorithm
a	number of LHC divisions
b	number of variables
W	LHC matrix with a-by-b dimension
porosity
Kh	horizontal permeability
m	number of OF
d	number of data points
References
Achelis, Steven B., 1995. Technical Analysis From A to Z. Second Printing. McGraw-Hill, pp. 184-192.
Avansi, G.D., Schiozer, D.J., A New Approach to History Matching Using Reservoir Characterization and Reservoir Simulation Integrated Studies, OTC, 4-5 Maio, Houston, Estados Unidos, 2015.
Bennett, F., Graf, T., 2002. Use of geostatistical modeling and automatic history matching to estimate production forecast uncertainty - a case study. In: Proceedings of SPE 74389, International Petroleum Conference and Exhibition, Mexico, 10-12 February.
Bertolini, A., Schiozer, D., 2011. Influence of the objective function in the history matching process. J. Pet. Sci. Eng. 78 (1), 32-41.
Bissel, R.C., 1997. Combining geostatistical modeling with gradient information for history matching: the Pilot Point Method. In: Proceedings of SPE 38730 Annual Technical Conference and Exhibition, San Antonio, Texas, USA, 5-8 October.
Deutsch, C., 1989. Calculating effective absolute permeability in sandstone/shale sequences SPEForm. Eval. 4 (3), 343-348.
Emerick, A.A., Reynolds, A.C., 2012. Combining the ensemble Kalman filter with Markov Chain Monte Carlo for improved history matching and uncertainty characterization. In: Proceedings of SPE 141336-PA, SPE Reservoir Simulation Symposium Held in The Woodlands, Texas, USA.
Ferreira, C., Vernon, I., Schiozer, D.J., Goldstein, M., 2014. Use of emulator methodology for uncertainty reduction quantification. In: Proceedings of SPE 169405-MS, Latin American and Caribbean Petroleum Engineering Conference Held in Maracaibo, Venezuela, 21-23 May.
Gu, Y., Oliver, D.S., 2004. History matching of the PUNQ-S3 reservoir model using the ensemble Kalman filter. In: Proceedings of SPE 89942, Annual Technical Conference and Exhibition, Houston, Texas, USA, 26-29 September.
Guardado, L.R., Gamboa, L.A.P., Lucchesi, C.F., 1989b. Petroleum geology of the Campos Basin, Brazil, a model for a producing Atlantic Type Basin: Part 2. AAPG Spec. Vol. A13242
Guardado, L.R., Spadini, A.R., Brandao, J.S.L., Mello, M.R., 2000. Petroleum system of the Campos Basin, Brazil. In: Proceedings of M.R.M.a Petroleum Systems if the South Atlantic Margins: AAPG Memoir 73, pp. 317-324.
Liu, C., McVay, D.A., 2010. Continuous Reservoir-Simulation-Model Updating and Forecasting Improves Uncertainty Quantification. SPE 119197.
Guardado, L.R., Gamboa, L.A.P., Lucchesi, C.F., 1989a. Petroleum geology of the Campos Basin, Brazil, a model for a producing Atlantic type Basin: Part 1. AAPG Spec. Vol. A132, 33.
Manceau, E., Mezghani, I., Zabalza-Mezghani, I., Roggero, F., 2001. Combination of experimental design and joint modeling methods for quantifying the risk associated with deterministic and stochastic uncertainties - an integrated test study. In: Proceedings of SPE 71620 Annual Technical Conference and Exhibition held in New Orleans, Louisiana, 30 September-3 October.
Maschio, C., Schiozer, D., 2003. A new upscaling technique based on Dykstra-Parsons coefficient: evaluation with streamline reservoir simulation. J. Pet. Sci. Eng. 40, 27-36.
Maschio, C., Schiozer, D., 2013. A new procedure to reduce uncertainties in reservoir models using statistical inference and observed data. J. Pet. Sci. Eng. 110, 7-21.
Meneses, S.X.d., Adams, T., 1990. Ocorrências de resistividades anômalas no Campo de Namorado, Bacia de Campos.. Rio de Janeiro, Brasil.
Maschio, C., Schiozer, D., Moura Filho, M.A.B., 2005. Methodology to quantify the impact of uncertainties in the history matching process and in the production forecast. In: Proceedings of SPE 96613 Prepared for Presentation at the SPE Annual Technical Conference and Exhibition, Dallas, Texas, USA.
Risso, F.V.A., Risso, V.F., Schiozer, D.J., 2011. Risk analysis of petroleum fields using Latin hypercube, Monte Carol and derivative tree techniques. J. Pet. Gas Explor. Res. 1 (1), 014-021.
4.	ARTICLE 3: Principal Component Analysis for Reservoir Uncertainty Reduction
André Carlos Bertolini and Denis José Schiozer
Journal of the Brazilian Society of Mechanical Sciences and Engineering, p. 1-11, 2015.
40
CrossMark
REVIEW PAPER
Principal component analysis for reservoir uncertainty reduction
André Carlos Bertolini* 1 • Denis José Schiozer1
Received: 25 February 2015 / Accepted: 27 May 2015
© The Brazilian Society of Mechanical Sciences and Engineering 2015
Abstract Reservoir monitoring considering all measurements and simulator outcomes available nowadays can become a complex task. The data integration and mainly the proper use of the big datasets is a challenge, especially in full field studies. This scenario of increasing data availability is an ongoing process due to new measurement technologies, high computational power and the reservoir characterization complexity. We propose to identify reservoir measurements that best represent the overall reservoir behavior using the Principal Component Analysis mathematical procedure. In addition, this procedure allows a reduction of the dataset dimension for a faster and more efficient reservoir analysis. Latin Hypercube sampling is used to sample the reservoir attribute range and the principal component of the measurements are integrated to identify the attribute interval that minimizes the simulation mismatch. The methodology is applied to a reservoir simulation model with 20 uncertainty attributes. Three study tests were performed using different percentiles in the likelihood distribution, which can conservatively or severely reduce the attribute ranges. The method achieved a coverage of approximately 95 % of the problem variability using five out of fifteen original principal components. Reservoir uncertainties were reduced and most of the simulated measurements had a significant history matching improvement.
Technical Editor: Marcelo A. Trindade.
** André Carlos Bertolini
andre@dep.fem.unicamp.br
Denis José Schiozer
denis@dep.fem.unicamp.br
1	UNICAMP, Campinas, Brazil
Keywords Uncertainty reduction • History matching • Reservoir simulation • Principal components • Mismatch
List of symbols
m	Number of observations (models)
n	Number of variables
X	Original data
b	Principal component
Y	New data (called	Score)
M	Raw data matrix
MADJ	Adjusted matrix
C	Covariance matrix
N	New matrix
E	Matrix containing the eigenvectors
ET	Transpose of the E matrix containing the
eigenvectors
w	Reservoir uncertainty attributes
KrW	Water relative permeability
SW	Water saturation
SWir	Irreducible water saturation
SOR	Residual oil saturation
ExpoW	Coefficient of Corey's equation for water rela-
tive permeability
krw*	Maximum value of the water relative perme-
ability in Corey's equation
Kx	Effective permeability in X direction
KZ	Effective permeability in Z direction
V	Match quality indicator
h	History data
y	Simulated data
d	Number of data points
Abbreviations
PCA	Principal component analysis
PC	Principal component
KPCA	Kernel principal component analysis
DCT	Discrete cosine transform
LSP	Least square projection
LL	Lower limit
ProjClus	Projection by Clustering
SM	Simulated measurement
SqE	Square error
SqER	Square error ratio
UP	Upper limit
LHC	Latin hypercube
1	Introduction and objectives
More than ever, engineers are looking for different reservoir measurements to understand the complexity of reservoir behavior. Previously, bottom-hole pressure, oil, and water production rates were the most commonly analyzed outputs. Today, other simulator outcomes and reservoir measurements are used to properly characterize the reservoir, for instance, compositional and fine grid model simulations and in situ measures such as fluid density and viscosity. This issue becomes critical with a high number of wells and measurements available to evaluate reservoir performance. In addition, the availability of computational power and the reservoir characterization complexity allows the inclusion of a larger number of reservoir uncertain attributes on the reservoir studies.
In order to reduce a dataset dimension, a common practice is the selection of the critical measurements at a point in time, leaving other measurements out of the interpretation. This approach can lead to the consideration of unnecessary data or, worse, it can neglect important datasets that may be indispensable for future reservoir analysis. Based on this scenario, Principal component analysis (PCA) is an alternative to overcome dataset selection difficulties. It is a mathematical procedure, which, in summary, identifies the correlation among the datasets and combines them in a different coordinate system.
PCA is a multivariate method that was proposed by Pearson in 1901 and was developed by Hotelling in 1933 [6]. The objective of PCA is to reduce the dimension of the datasets based on the correlation among them. The new variables, called principal components (PCs), are sorted from the highest variance to the lowest and are uncorrelated.
2	Literature review
Sarma et al. [10] presented a new approach of automatic history matching (HM) using Kernel PCA. They used a new parameterization, called Kernel Principal Component Analysis, KPCA. It enables the preservation of arbitrarily high order statistics of random fields, which allows the
representation of complex geology. The gradient-based HM technique was combined with KPCA and the results demonstrated an accurate matching and, more important by the retention of the geological features.
Dadashpour et al. [4] used PCA to speed up porosity and permeability estimations. The gradient-based approach was used to minimize the misfit from production and offset timelapse seismic data, using the most sensitive PCs. The discrete cosine transform (DCT) on those PCs proved to be a fairly efficient technology to hasten the parameter estimation.
Differently from the previously described studies, [9] presented a history matching review, considering manual and automatic HM, gradient and non-gradient methods, and the reparameterization techniques, including PCA. In discussions, the authors suggested that no single method is the best. Rather, the best technique depends on the parameters of the problem and the data that need to be matched, and also computing power and time availability.
Another work involving PCA in HM, done by [5], showed a comparison among recent multidimensional schemes. The Least Square Projection (LSP), Projection by Clustering (ProjClus) and PCA were used to examine the relationship between exploration of search space and the uncertainty in predictions of reservoir production. It was concluded that a multidimensional approach should accompany assisted HM workflows in order to evaluate their performance, and that exploration of the search space is critical for uncertainty quantification. Furthermore, the authors concluded that the choice of convergence speed versus sampling coverage is affected by the targets of the project and the available computer resources.
History matching, uncertainty reduction and PCA have been studied for many years and recently the multidimensional approach from PCA combined with reservoir studies has become a promising integrated process for HM. This paper presents a modified workflow based on the procedure given by [7] and [2], with the addition of a data smoothing step to capture the reservoir response trend along the attribute range, and the PCA tool, which reduces the interpretable dataset dimension saving time and computational power. It supports an assisted HM, identifying the reservoir measurements that best represent the overall reservoir behavior and provides uncertainty reduction using the highly sensitive components from PCA.
3	Methodology
Taking m observations of n correlated variables, three criteria are used to describe the PCA; (1) there are exactly n PCs, each one being a linear combination of the observed variables as shown in Eq. 1; (2) the PCs are mutually orthogonal (i.e., perpendicular and uncorrelated); (3)
Fig. 1
Eigenvectors for each SM—Principal Component 1 (a) and Eigenvalues—Cumulative Variability (b)
the components are extracted in the order of decreasing variance.
Y = Bixi + B2X2 + • • • + bnXn	(1)
where Xt is the original data, bt is the principal component and Y is the new data, called Score.
The conventional PCA method is composed of three steps. The starting point is the conditioning of the data, which identifies the m observations and n variables, forming the raw data matrix M. The average of each variable is then calculated and subtracted from M. The final output from this step is the adjusted matrix MADJ.
The next step is the calculation of the covariance matrix, C, from the adjusted matrix MADJ. In the following step, eigenvectors and eigenvalues of matrix C are calculated. Finally, the last step is the data transformation set to the new basis. The new matrix N is obtained from Eq. 2.
N -^eigenvectors '	(2)
where £jgenvectors are the transpose of the E matrix containing the eigenvectors.
The purposes of this study are: (1) identification of the reservoir measurements that best represent the overall reservoir behavior; (2) reduction of the dataset dimension for a fast and efficient reservoir analysis and (3) provision of a reservoir uncertain reduction method using the high variability components from PCA.
The PCA workflow for reservoir uncertainty reduction starts defining the base simulation model, the reservoir uncertainties and the attribute range for each uncertainty. The base model and the original attribute range are the reference for future comparison. Next, the w reservoir attribute ranges are explored through a probabilistic approach to create representative simulation models. The ensemble of models (m) is designed to cover most of the problem variability and, ideally, to represent all reservoir performance scenarios. The amount of desired models (samples) varies according to the number of reservoir attributes.
The m models are run on the simulator and the desired simulated measurements (SMb SM2, SM3,...,SMn) are obtained. The n number of SMs can vary from few measurements, for instance, in the case of a single well modeling, to several dozens of measurements in a full field model. The data matrix has m models (observations) and n simulated measurements (SMs). Instead of using the SM, a common practice in reservoir engineering is the use of a misfit, which is the difference between history measurements and SMs. A misfit is preferable as it directly shows the quality of the simulation model. Each SM misfit has a different trend along reservoir attribute variation. This trend might not be clear due to high dispersion of the misfit values. At this point, we apply individually a smoothing technique to each SM misfit. It creates w smoothed data matrices, one for each reservoir attribute. This technique removes the outlier results while preserving underlying patterns.
Some SMs can be correlated. Instead of analyzing the full smoothed matrix, which can become impracticable when n assumes large numbers, the PCA is applied to reduce the dimension of the data matrix m x n. The b coefficient shown in Eq. 1 are the matrix eigenvectors. Coefficients close to zero indicate that the SM, which is multiplied by the coefficient, is not affecting the variability of the principal component (PC) to any extent and coefficient close to plus or minus one present a key SM that must be considered. Figure 1a shows the PC1 matrix eigenvectors illustration for SMn. On the other hand, the matrix eigenvalues, shown in Fig. 1b, are associated with the variability of each principal component and are in order of decreasing variance. Normally, the last PCs are left out of the new data matrix (called Score), due to low variability, reducing the dimension of the matrix. Furthermore, the relationships between PCs and reservoir attribute ranges are preserved.
After the PCA application, w new matrices (Score matrices) are created with m lines and n columns (principal components). Removing the lower variability PCs, the Score matrix dimensions are reduced. Figure 2 illustrates the
Attribute interval	Attribute interval	Attribute interval
Fig- 2 From the original data matrix to the high variability components and attribute range selection
input data, which is used to fit a probability distribution (black curve in Fig. 3).
! 0	□ PCI (66.7%) o PC2 (28.9%)
— Poll	---Pol2
0.5	2.5	4.5
Attribute interval
Fig. 3 Schematic example of two PC misfits (PC1 and PC2). The corresponding polynomial 1 and 2 (Poll and Pol2), the weighted average polynomial and the distribution (modified from [2])
4 Case study
process with the misfit data matrix (Fig. 2a) with four SMs, the 4 PCs and their cumulative variability are presented in Fig. 2b and the reduced Score matrix (PC1 and PC2) are presented in Fig. 2c. The cumulative variability from PC1 and PC2 are close to 95 % and PC3 and PC4 Score can be discarded.
Taking Fig. 2 as an example and considering the variability of 66.7 % for PC1 and 28.9 % for PC2, the optimum attribute range is showed in the gray area on Fig. 2c, from the lower limit (LL) to the upper limit (UL).
The last step is the attribute interval selection. We use polynomial fitting to correlate the PCs with the attribute range. Each polynomial is a function of a reservoir attribute and the Score PC misfit. The polynomials are used to create a global misfit response per attribute. Figure 3 shows a schematic example with PC1 and PC2 misfits, with cumulative variability of 70 and 30 % respectively, polynomial, weighted average polynomial (global misfit) and the distribution. The weighted average polynomial becomes the
The methodology was applied to a synthetic case, where the simulation model is an upscaled model from a refined reference reservoir (described by [1]), which was used to extract the history data. It has 30,600 cells distributed in 90 x 34 x 10 blocks and a single porosity type. Horizontal permeability varies from 10 to 1900 mD, with a median of 373 mD and standard deviation of 284 mD. The vertical permeability has the same heterogeneous distribution, with a median of 6.8 mD and standard deviation of 105 mD. The porosity distribution has a median of 0.19 and a standard deviation of 0.05. Although it is a synthetic upscaled reservoir, the true reservoir attribute values to match the history data are unknown. The upscaled base case model contains a similar heterogeneity to the refined model. The reservoir has five producer and five injector wells, each producer/ injector pair is located in one of the five reservoir regions, which has different geological characteristics. The model presents four uncertain attributes per region: horizontal permeability in the X direction (Kx), vertical permeability in the Z direction (Kz), Corey’s coefficient (Eq. 3) for water relative permeability (ExpoW), and the maximum value of the water relative permeability in Corey’s equation (^rw*).
Krw
— Krw
* .
(Sw	Swir)
(1 - Swir - Sor)
ExpoW
(3)
where Krw is the water relative permeability, Sw is the water saturation, Swir is the irreducible water saturation and, finally, Sor is the residual oil saturation. Therefore, the simulation model has a total of 20 uncertain attributes.
Table 1 Base model reservoir attributes and their limits
Limits	Reservoir attributes									
	Multipliers									
	Kx1	Kx2	Kx3	Kx4	Kx5	KZ1	Kz2	Kz3	Kz4	Kz5
Lower	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50
Base	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00
Upper	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00
Limits	Reservoir attributes									
	Corey’s equation									
	ExpoW1	K * Krw1	ExpoW2	K * Krw2	ExpoW3	K * Krw3	ExpoW4	K * Krw4	ExpoW5	Krw5*
Lower	1.00	0.15	1.00	0.15	1.00	0.15	1.00	0.15	1.00	0.15
Base	2.20	0.60	1.10	0.80	4.00	0.50	1.30	0.70	4.30	0.80
Upper	5.00	0.90	5.00	0.90	5.00	0.90	5.00	0.90	5.00	0.90
The permeabilities Kx and Kz are modified in the simulation models through multipliers. The limits are 0.5 and 2.0, which represent the half and the double of the absolute permeability Kx and Kz of the base model. The base model is the unitary reference of the absolute permeability multipliers, while the attributes ExpoW present a variation range from 1 to 5 and the attributes of krw from 0.15 to 0.90. Table 1 presents the reservoir attribute summary.
The corner point grid has 2550 cells distributed in 30 x 17 x 5. The reservoir has five producer wells and five injector wells; a producer/injector pair for each region is located in the same reservoir position. The reservoir cells of the injector wells are: Injector1 (4;1-6;5), Injector2 (14;1-9;5), Injector3 (20-29;6;5), Injector4 (3;8-17;5), and Injector5 (10-28;14;5). For the producer wells the cells are: Prod1 (4;1-6;1), Prod2 (14;1-9;1), Prod3 (20-29;6;1), Prod4 (3;8-17;1), and Prod5 (10-28;14;1).
The simulated measurements (SMs) considered in this case study were: oil production (m3/day), water production (m3/day), and bottom-hole pressure (KPa), for five production wells. In total, 15 SMs were considered. The well production strategy used in the simulation had a surface liquid limit of 4770 m3/day and a bottom-hole pressure (BHP) limit of 20.7E+3 kPa. The oil rate on each simulated data was input into the simulator. The constraints for the injector wells were the maximum surface water rate of 4770 (m3/day) and the maximum bottom hole pressure of 82.7E+3 kPa.
With the objective of creating a match quality indicator (V), the outputs from the normalized misfit function of each well and SMs were gathered through the Euclidean norm. The normalization uses the maximum misfit range among all SM. A square error function shown in Eq. 4 was selected according to [Bertolini and Schiozer [1]] to characterize the misfit.
= —
(5)
d
SqE„ =	(hi - si )2	(4)
1=1
where the index s represents simulated data, h, historical data, d, total number of data, and n, number of SM. However, the match quality indicator (V) is obtained dividing the Euclidean norm by the Euclidean norm of the base model.
n -&gt; SqEt) 2
1=1
(t (SqEbi)2}
The interpretation of V is direct. Values greater than 1 represent a worsening in the HM; values equal to 1 represent that model has the same performance of the base model; and values smaller than 1 represent improvements in the HM.
In addition to the V global indicator, the square error ratio (SqER) was used for each SM and well. The ratio is between the simulated square error (SqE) and the maximum acceptable square error (SqEM) for each SM. The acceptance range may vary for each application. The environment in which the measurements are taken, sensor technology and resolution, the sampling acquisition interval and desired HM quality are some factors that might help in getting a representative range.
In order to provide the SqER signal, the error function divided by the absolute error function was used as a multiplier. A positive signal means that simulated results have lower values compared with the observed data, and a negative signal means the opposite. The SqER is calculated in Eq. 6.
SqER„ =
d
(hi - Si)
1=1
~d
(hi - si)
i=1
SqEn =	SqEN
SqEMn	lE«l SqEMrc
(6)
where the index s represents simulated data, h, historical data, d, total number of data, and n, number of SM. SqER interpretation is also direct: values between — 1 and 1 indicate that the well is within the acceptance range of the HM.
The Latin Hypercube (LHC) sampling technique was applied to create the representative models. It is a statistical method for generating a distribution of plausible sets of attribute values. [8] compared different sampling techniques in which the Derivative Tree, Monte Carlo and Latin Hypercube methods were used in a synthetic reservoir with 4 uncertain attributes. Although all three methods present a satisfactory result, the Latin Hypercube has the best results considering precision and number of simulations. The amount of desired models (samples) will vary according to the number of reservoir attributes.
The moving average was used for the smoothing technique. It was described by [3] and is applied to remove noise from datasets while preserving underlying patterns. So, taking an average of the points near an observation will provide a reasonable estimate of the trend at that observation.
Previous simulation runs showed that 50 models were able to capture most of the reservoir responses. The following results are based on 50 models from the probabilistic approach LHC, and the moving average smoothing process with 15 % of the number of models. The acceptance range was ±250 bbl/day for oil production, ±500 bbl/day for water production, and ±4000 kPa for BHP. After the PCA calculation, three study tests were performed using different percentiles in the likelihood distribution.
5 Results
Considering the 15 simulated measurements, which for this case study are misfits between history and simulated data, and 50 experiments, the original data matrix is formed by 50 (m) x 15 (n). For each uncertain attribute, the moving average was applied, providing 20 Score matrixes m x n. The proposed methodology was applied to those matrixes and the PCs with higher variability for each attribute are presented in Fig. 4 as blue bars. In general, only five PCs or less were required to cover more than 95 % of the variability. The solid blue line in Fig. 4 shows the cumulative variability.
Taking only the cumulative PC1 and PC2 variability, the lowest value is approximately 70 % for the £xpoW1 attribute and most are above 80 % or even higher than 90 %. For
Fig. 4 Principal Components for all 20 uncertain attributes; cumulated variability from PC1 and PC2 achieved 70 % or higher percentages
Table 2 PC1 and PC2 variability percentage										
	Variability									
	Kx1 (%)	(%)	Kx3 (%)	Kx4 (%)	Kx5 (%)	Kz1 (%)	Kz2 (%)	Kz3 (%)	Kz4 (%)	Kz5 (%)
PC1	75.6	82.2	94.8	59.8	55.0	69.9	83.6	90.0	54.7	64.3
PC2	14.5	11.6	3.1	29.1	20.4	19.1	7.3	5.3	23.3	16.9
Accumulative	90.0	93.8	98.0	88.9	75.4	89.0	90.9	95.3	78.0	81.2
	Variability									
	ExpoW1 (%)	Krw1 (%)*	ExpoW2 (%)	Krw2* (%)	ExpoW3 (%)	KIW3 (%)*	ExpoW4 (%)	Krw4* (%)	ExpoW5 (%)	Kw5* (%)
PC1	45.2	62.7	80.8	79.0	65.9	68.3	71.4	78.2	63.0	73.7
PC2	24.6	20.7	9.1	8.7	14.9	10.6	16.4	13.7	21.8	11.9
Accumulative	69.8	83.4	90.0	87.6	80.8	78.9	87.9	91.9	84.8	85.6
Fig. 5 PC1 and PC2 for all 20 uncertainty attributes showing the weights for each SM
all study tests, PC1 and PC2 were the components used to achieve the results presented in this paper. Table 2 shows the PC1 and PC2 variability percentage for each attribute. The average PC1 and PC2 variability (20 attributes) are 70.9 and 15.2 % respectively.
Apart from the variability of the components, the methodology provides the matrix eigenvectors (weights) of the SMs. The SMs contributing more significantly to PC1 and PC2 are shown in Fig. 5. For each attribute, the eigenvectors are the weights for the SMs on the principal components. For instance, attribute ExpoW4 has Prodi well BHP, Prod2 well oil production and BHP, Prod3 well water production and BHP, Prod4 well oil production and BHP, and, finally, Prod5 well BHP with higher influence on PC1 (blue
bars). On the other hand, Prod2 well oil production and BHP, Prod3 well BHP, Prod4 well oil production and BHP, and Prod5 well water production and BHP have the high weights on PC2 (red bars).
Aiming for a complete analysis of the principal components, it is also important to associate those weights with the variability of each PC. Considering ExpoW4 once again, the PC1 has approximately 71.4 % of the variability and PC2 only 16.4 %. Table 3 shows the SMs cumulative weights for the 20 attributes.
Using the PC1 and PC2 results, the attribute ranges were reduced between LL and UL according to Fig. 2c. Different percentiles were chosen, P50 for a conservatively range reduction, P75 and a more severe reduction with P90.
Table 3 Cumulative weights for PC1 and PC2 components
Cumulative weights														
	Prod well 1		Prod well 1			Prod well 1			Prod well 1			Prod well 1		
	Oil	Water BHP	Oil	Water	BHP	Oil	Water	BHP	Oil	Water	BHP	Oil	Water	BHP
PC1	0.4	0.0 -2.0	1.5	-0.8	-2.6	0.0	-3.1	-2.8	-0.1	0.0	-2.6	0.1	-0.3	-2.0
PC2	0.1	0.0 -1.2	-0.3	-0.3	-1.4	0.0	0.4	0.6	-0.7	0.1	-1.1	0.1	-0.2	-0.6
5000
2000
Prodi
Prod2
Prod3
Prod4
Prod5
ooo History ....Base model
Original 50 models
— PCAwith P75
1000
4000
0®---------—--------*---e
0	50	100	0
Time (month)
Prodi
3000
50	100
Time (month)
Prod2
Time (month) Prod2
Time (month) Prod3
100
Time (month) X104 Prod4
0	50	100
Time (month) Prod5
50	100
Time (month)
Prod5
2
0	50	100
Time (month)
50	100
Time (month)
50	100
Time (month)
0	50	100	0	50	100	0
Time (month)	Time (month)
Fig. 6 Original 50 models and 50 models after the proposed PCA methodology with P75
Therefore, three study tests were performed using these percentiles.
Figure 6 shows the original models from LHC and the red curves are the models generated after the proposed methodology with P75. The black circles are the history data and the dotted blue lines are the base model. The cyan curves are the original models from LHC and the red curves are the models generated after the proposed methodology. The reduction and positioning of the new attribute range presented in Fig. 7, resulted in an overall HM improvement. Note that Kz1, ExpoW1, and Krw1* ranges were not reduced because the misfit along the original range was almost constant.
Fig. 7 Original and PCA P75 reduced attribute ranges
Fig. 8 SqER distribution for oil and water production and BHP. Original dataset is shown in black, P50 in green, P75 in red and P90 in blue for Prod Wells 1-5
Prodi	Prod2	Prod3	Prod4	Prod5
•20-j	1
■25
The SqER for the four datasets are presented in Fig. 8. On each box, the central mark is the median, the edges of the box are the 25th and 75th percentiles, and the whiskers extend to the most extreme data points not considered outliers. Some comments regarding each SM class are relevant and described below.
SqER: BHP values were similarly improved; all five producer wells present the square error in the same order of magnitude. It can also be noticed on Table 3 and Fig. 5 for the P75 dataset. The BHP weights are quite similar. The original dataset showed a spread SqER values, varying mainly from -23 to 3. For P50, P75 and P90, the distributions were narrowed. P75 and P90 datasets have included all producer wells within the acceptance range (gray band between —1 and 1).
SqER: Oil Production values increased slightly for Prod2, Prod4 and Prod5 wells when comparing the original data with P90 dataset. As expected, the SqER—Oil Production distribution varied from 0 to a positive number, which means that simulated oil production is always equal to or lower than the history data. For the P90 dataset, mainly for Prod4 and Prod5 wells, the SqER values were moved out of the acceptance range. Therefore, in order to validate the P90 dataset for reservoir forecast,
a model assessment and recharacterization must be performed to improve the HM in those wells.
SqER: Water Production values gradually decreased with the increase of the percentile. Although all producer wells had improved the water production matching, the level of improvement was different among them. Due to the low water production rate, Prodi and Prod4 wells had a slight SqER change between the datasets. The other three wells, which have a high production rate, had a more consistent reduction. The weights presented in Table 3 for the P75 dataset show the same trend; small weights for Prodi and Prod4 wells and high weights for the other wells. The original dataset showed a spread SqER values, varying mainly from —2 to 18. For P50, P75 and P90 datasets, the SqERs values were moved to the acceptance range with the exception of Prod3 well. Although SqER values from the P90 dataset showed the best result for the Prod3 well, it crossed the SqER acceptance limit for Prod4 well. In general, all three datasets reduced the water production SqER values, but similarly to oil production, a model assessment and recharacterization must be performed to improve the HM in those wells.
The global match quality indicator V from original models, P50, P75, and P90 datasets are shown in Fig. 9a. As the
Number of experiments from HCL	Datasets
Fig- 9 Global match quality indicator and its distribution for original, P50, P75, and P90 datasets
percentile increased, all three study tests showed a significant improvement in the global indicator and a narrowed distribution between the 50 models, which are presented in Fig. 9b.
6 Conclusions
We presented a reservoir uncertainty reduction workflow based on the procedure given by [7]. Smoothing technique and PCA were integrated into the workflow to capture the misfit trend along each reservoir interval and reduce the interpretable dataset dimension respectively. The method identified the more influent reservoir measurement and provided an HM improved set of models. From this workflow, the following conclusions were drawn:
•	In this application, the interpretable dataset dimension was reduced by one third of the original size. Five principal components covered approximately 95 % of the problem variability (from 15 original SMs). In reservoir with a larger number of wells and SMs, the use of the reduced dimension dataset represents a faster uncertainty analysis and reservoir forecast.
•	The application of the proposed method might work as an alternative to reduce the time and computation power required to process full field studies.
•	Reservoir uncertainties were reduced (Fig. 7) and the global history matching improved (Figs. 8, 9). The results from higher percentile study provided the highest global HM improvement and the worst local HM, mainly for oil production function. The compromise with this range is the balance between reservoir uncertainty reduction and the quality of reservoir forecast. In
this work, the P90 dataset must be reassessed to honor the acceptance interval.
•	Differently from other methodologies that normally require a large number of simulations to evaluate the reservoir, the proposed method used 50 models, which were sufficient to provide the principal components for this application.
•	The combined interpretation of eigenvector's matrix and eigenvalue's vector provided the interaction between different reservoir behaviors and uncertain attributes, which can be useful for local HM.
•	The results showed that a combined interpretation between global and local HM indicators is the preferable approach. Considering only global indicators may lead to a very poor match in some of the wells.
•	Estimation of the acceptance ranges is a key stage for a proper history matching evaluation. Whenever we do not know the measurement errors and/or a reasonable tolerance margin for the reservoir model, a sensitivity analysis with different estimated values is recommended to build a set of quality measurement scenarios.
Further studies, particularly in model reparametrization requirements, to mitigate the scenario where the simulated results are totally out of the acceptance range, will be addressed in a future work.
References
1.	Bertolini A, Schiozer D (2011) Influence of the objective function in the history matching process. J Pet Sci Eng 78(1):32-41
2.	Bertolini AC, Maschio C, Schiozer DJ (2015) A methodology to evaluate and reduce reservoir uncertainties using multivariate distribution. J Pet Sci Eng 128:1-14 (Abril)
3.	Biran A, Breiner M (1995) MATLAB for engineers. Addison-Wesley, Reading
4.	Dadashpour M, Rwechungura R (2011) Fast Reservoir Parameter Estimation by Using Effect of Principal Components Sensitivities and Discrete Cosine Transform, SPE 141913 was selected for presentation at the 2011 SPE Reservoir Simulation Symposium held in The Woodlands. Texas, USA
5.	Hajizadeh Y, Amorin EP, Sousa MC (2012) Building Trust in History Matching: The Role of Multidimensional Projection, SPE 152754 was selected for presentation at the EAGE Annual Conference &amp;amp; Exhibition incorporating SPE Europec held in Copenhagen, Denmark
6.	Jolliffe IT (2002) Principal component analysis, 2nd edn. Springer, New York
7.	Maschio C, Schiozer D (2013) A new procedure to reduce uncertainties in reservoir models using statistical inference and observed data. J Pet Sci Eng 110:7-21
8.	Risso FVA, Risso VF, Schiozer DJ (2011) Risk analysis of petroleum fields using Latin hypercube, Monte carlo and derivative tree. J Pet Gas Explor Res 1(1):014-021
9.	Rwechungura R, Dadashpour M, Kleppe J (2011) Advanced history matching technique reviewed, SPE 142497 was selected for presentation at the SPE Middle East Oil and Gas Show and Conference held in Manama, Bahrain
10.	Sarma P, Durlofsky LJ, Aziz K, Chen WH (2007) A new approach to automatic history matching using kernel PCA, SPE 106176 was selected for presentation at the 2007 SPE Reservoir Simulation Symposium held in Houston. Texas, USA
52
5.	ARTICLE 4: Use of a Probabilistic Approach to Perform History
Matching Tracking over Simulation Time
André Carlos Bertolini and Denis José Schiozer
Submitted to Journal of Petroleum Science and Engineering, January 2015
54
Use of a Probabilistic Approach to Perform History Matching Tracking over Simulation Time
Authors:	Andre Carlos Bertolini (andre@dep.fem.unicamp.br)
Denis Jose Schiozer (denis@dep.fem.unicamp.br)
Abstract
Numerical reservoir simulation is widely used in the industry for reservoir management, allowing full data integration. A challenging and consuming task related to reservoir simulation is the history matching process. No closed-form solutions exist for this complex inverse problem, and any solutions that are determined may not be unique. The history data that are used as the observed response of the reservoir to some stimulus are subject to noise and error, which also contribute to the lack of any exact, unique solution.
The history matching process is recently treated using probabilistic approaches, where dynamic data reduces uncertainty of reservoir attributes to quantify risk, allowing more robust decision analysis based on uncertain production forecast. In this probabilistic context, we propose a sequence of steps to evaluate the model performance regularly over time. This new method is composed by nine steps and works with an acceptance range applied to the history dataset. It included an uncertainty reduction tool and is associated with match quality indicators, which allows a practical and efficient way to give support for reservoir decisions. The acceptance range formulation considers a relative and fixed measurement error. These errors are based on (1) the quality of the measurement, which may vary according to sensor specifications, flow conditions in the well, and measurement conditions, and (2) the desired quality of the solution for each objective-function specified in the problem that represents the deviation from history data.
We used a synthetic reservoir to validate the method and the UNISIM-I-H reservoir model, which is based on the Namorado field, Campos basin, Brazil. The reservoir models were evaluated annually against the acceptance range. The method managed to maintain a set of calibrated models for the simulation period and the reservoir uncertainties were reduced. A multivariate analysis method was applied to both reservoir models to reduce the reservoir uncertainty. The results show the importance of a continuous evaluation tool, which guarantees calibrated models for reservoir management decisions, and the need for continuous reservoir model updating over the simulation time.
1.	Introduction
Petroleum reservoir management has been discussed and defined by many authors in the literature. Reservoir management practice relies on use of financial, technological, and human resources, while minimizing capital
investment and operating expense to maximize economic recovery of oil and gas from a reservoir (Thakur, 1996). It is based on a series of decisions that enables oil and gas companies to meet their technical and business objectives. Management, economics, legal and environmental disciplines are some of the topics included in reservoir management. The process requires models of the reservoir system and the ability to predict the consequences of implementing possible and alternative strategies. The reliability of reservoir predictions is closely related to the amount of reservoir information and the understanding its behavior. Reservoir characterization, a vital part of the model creation process, involves generating an editable and mathematical subsurface model. However, the details and type of mathematical reservoir modeling depends on data gathering and management. Reservoir characterization is a continuous process that must be updated as new information is gathered. It starts with the acquisition and interpretation of data from different disciplines. Secondly, data integration is used to build the initial model and finally, the most challenging and time consuming task of the reservoir characterization, which is the history matching (HM) process. This step is an inverse problem, which adjusts reservoir attributes by history matching production data. The solutions are not unique, nor exact solutions exist for these cases (Oliver et al., 2008). The history data used as the observed reservoir response to stimuli are subject to noise and error, which may also prohibit a close-form, exact solution.
HM keeps evolving as new reservoir measurements become available and computer power availability increases. Manual and assisted HM tools have been published over the years, using different mathematical tools and focusing on different reservoir applications. In this paper, we propose a new HM workflow with three objectives:
1)	To include measurement error and a tolerance margin for all history data before the history matching evaluation;
2)	To synchronize the history data sampling frequency with the history matching workflow, capturing the reservoir trends along the production period in the model.
3)	To provide a quality indicator and an efficient graphical way to evaluate the reservoir model performance over time.
New observed dynamic data provide additional reservoir information and help reducing reservoir uncertainties. All new data must be assimilated and incorporated while history matching. Furthermore, reservoir management is performed by evaluating several data and quality indicators, so the HM method must allow reservoir management decisions in a practical and efficient way.
2.	Literature review
Several approaches have been used to estimate and reduce uncertainties successfully. The procedure by Maschio and Schiozer (2013) show a methodology to reduce uncertainties of reservoir attributes using statistical inference based on observed data. This method offers two main advantages. The first is robustness, since it can be applied to complex cases with a high number of uncertain attributes. The second advantage is modifiability, which allows selecting the number of iterations and the number of simulations for each iteration, to meet a desired quality of results.
Slotte and Smprgrav (2008) present the combination of experimental designs and history matching tools to generate a probabilistic production forecast. Schaaf et al. (2008) used similar combination with a Bayesian framework, a posterior distribution of the most sensitive parameters were derived from the a priori distribution and a non-linear proxy model of the likelihood function. Several history matched models together with a posterior parameter distribution were used to obtain probabilistic production profiles.
Liu et al. (2010) use real time reservoir modeling to study the Markov-Chain Monte-Carlo (MCMC) method. The continuous simulation process provides a mechanism for calibrating uncertainty estimates over time. From assimilating data, history matching, and continuously forecasting over time, the authors showed that the resulting forecast uncertainty ranges are narrowed with time when compared with traditional methods.
Emerick and Reynolds (2012) combined the Ensemble Kalman filter (EnKF) and Markoc Chain Monte Carlo (MCMC) methodologies to obtain a relatively efficient algorithm for sampling the posterior probability density function (PDF) for reservoir-model parameter. They tested the method on a small 3D two-phase-flow reservoir, allowing a long Markov chain creation for comparison. EnkF-MCMC narrows the spread of reservoir predictions, resulting in histograms significantly closer to those obtained with the long MCMC case. In summary, the application of EnkF-MCMC improves the data matches from EnKF by generating samples of higher-probability regions of the posterior PDF.
Maschio et al. (2005, 2009) proposed a method to integrate history matching and uncertainty analysis using discrete levels of uncertainty (discrete probability density functions - pdf) combined through the derivative tree technique. The method was successfully applied in cases with a small number of attributes.
Kalman filters applied by Gu et al. (2005), also achieve satisfactory results, such as improvement in assisted history matching (HM) and an estimate of uncertainty in future reservoir performance, both with a significant reduction in computational costs.
Rwechungura et al. (2011) reviews HM methods and its advancement to date. The paper covers manual and automatic HM, minimization algorithms including gradient methods such as conjugate, steepest descent, Gauss-Newton and QuasiNewton and non-gradient methods, such as evolutionary strategies, genetic algorithm and Kalman filter. All methods were evaluated using a data set based on data from the Norne Field in the Norwegian Sea provided by Statoil and its partners. The authors suggest a computer cluster availability assessment to support the HM method selection. The performance of derivative-free methods, in terms of absolute computing times, could be similar to that of adjoint-based optimizers. Furthermore, they concluded that no single method is the best; rather the best method for HM depends on the parameters of the problem and the data that need to be matched.
3.	The Theory
History matching concepts have been applied for many years as part of the dynamic reservoir characterization. The HM process is an inverse problem, it identifies unknown reservoir parameter values, providing a best fit between observed and simulated data. Figure 1 shows the conventional HM sequence.
Figure 1 - Conventional history matching workflow
The conventional workflow starts with the first reservoir simulation model (A), which comes from a multidisciplinary team normally composed by geologists, geophysics and engineers. Using the results from the initial model, the next step is a comparison between observed and simulated results (B). If the initial model is able to reproduce the observed dynamic data within the geological constrains (C), the model is calibrated (D) and can be used for reservoir prediction (E). On the other hand, if the initial model does not match the observed data, which is normal, the simulation model is modified (F). The modifications should respect and vary inside the geological, geophysical and engineering ranges defined previously during the reservoir evaluation by the multidisciplinary team. After, the modified model is run (G) and the results are compared again with the observed data (B).
4.	The Problem
Numerical reservoir models carries challenging features that remain over the reservoir life. For instance, the addition of new reservoir information into the model and local mismatch between observed and simulated data. Another challenge is the process to maintain calibrated models over the production period. It requires a continuous effort from the field asset team, which is not always achieved along the production period of the reservoir. Furthermore, HM is commonly performed in the initial field development phase. After the initial HM, the calibrated models are used over the coming years to offer reservoir forecasts. Even with new observed data available, the first calibrated models are normally used to make production forecasts without considering recent observed data. The three main difficulties while updating a reservoir model over time are: required try and error time to achieve satisfactory HM results, cost of man-hour and human expertise.
An inefficient HM evaluation criteria can also contribute to poor reservoir forecasts over time. Often, a rigorous method does not exist to regularly validate the HM. For instance, when the calibrated model cannot capture the water breakthrough or the bottom-hole pressure (BHP) trend, a reservoir evaluation tool must identify such model deficiencies early on. If the model deficiencies is not identified by the model evaluation, the initial calibrated models will continue providing production forecasts over the years without any update, probably leading to erroneous forecasts. Faced with this risk, the desired approach is a rigorous model evaluation, combined with model assessment and updating as needed.
Apart from the HM challenges, the quality of the observed data and the reservoir characterization must be considered in every reservoir simulation study. Tolerance margins and measurement errors from the observed data leads to the concept of an acceptance range (AR). The range varies according to (1) the quality of the measurements, which is related to sensor specifications, flow conditions in the well and measurement conditions, and (2) the field characterization quality and the desired HM quality. Bertolini et al. (2013) studied a reservoir parameter inversion method, for interference well testing interpretation, which considered the pressure measurement errors. They proposed a similar formulation of the objective function using a constant and relative errors to change the weights of the individual pressure measurements.
The method described in this paper allows rapid HM tracking over the simulation time. In the next section, the method is presented in detail, broken down into several phases. In summary, an acceptance range (AR) for the observed data is defined, this AR is then used to identify the mismatch between the simulation model and the observed measurements.
5.	The Proposed Method
Reservoir simulation models provide a set of simulated data for each well and for each function. The square-error function (equation 1) was chosen based on the results presented by Bertolini and Schiozer (2011) to represent the mismatch between history and simulated data. The authors showed the influence of different error functions on reservoir simulation optimization performance and the advantages of a square-error function.
d
SE = £(h, -i, )2	(1)
i=1
where 1 represents the simulated data, h the history data (measured data of the past), d, total number of data, and m, number of simulated measurement (SM). SqE is calculated for SM and every well.
The AR functions (Far) were calculated using a tolerance margin (Tm) and a history data percentage, obtained through relative measurement error (Mre), as shown in equation 2.
FAR, = DOBS, ± DOBS, ■ M RE ± TM	(2)
where Dobs represents the observed data, and d, total number of data.
Tm and Mre estimation for a real reservoir model requires an investigation regarding measurement conditions, such as downhole or surface measurements, individual or combined production rates, sensor resolution and the quantity and quality of information available to build the reservoir model. Oil rate measurements are more precise (expected lower Tm and Mre values) due to the petroleum regulatory agency requirements. A tighter error associated to oil rate measurements is needed since taxes are based on them. Brazilian National Petroleum Agency - ANP uses oil rates to calculate, for instance, royalties, special participation, landowners fees and research &amp;amp; development (R&amp;amp;D) investments. In the literature, measurement errors are also commonly assumed to be Gaussian with zero mean, and have a standard deviation value (g) for each function (Emerick and Reynolds, 2011 and Tavassoli et al., 2004). Emerick and Reynolds estimate measurement error g by smoothing the observed data using a moving average and subtracting the observations from the smoothed data. Then, they compute the relative error by diving each data difference by the value corresponding to the smoothed data.
The simulated square error SqE over the maximal acceptable square error SqEAR for each simulated value gives the square error ratio (SqER). In order to provide the SqER signal, the simple error function divided by the absolute error
function was used as a multiplier. A positive outcome to the equation means that simulated results have lower values
compared with the observed data, and a negative outcome means the opposite.
SqERm=
t (hi - st)
i=1____________
t h - st)
i=l
SVEm
SqEmAR
(3)
The AR may vary for each application. The environment, in which the measurements are taken, the sensor technology and its resolution, and finally field characterization quality, are some factors that might help to determine a representative range.
SqER interpretation is direct: values between -1 and 1 indicate that the well is within the AR of the history matching.
The method works with a set of x models, which present the possible scenarios based on the reservoir uncertainties. These are created using a statistical sampling technique, which may use methods such as Latin Hypercube or Monte Carlo. The SqER values are used to create the HM tracker graphic (Figure 2A). Each function F is assigned to a targeted reservoir or well response, such as water rate, oil rate and bottom-hole pressure. The hatch rectangle limited by the SqER values +1 and -1 defines the acceptance range for the observed data. Figure 2A shows six different SqER distribution positions that may occur while studying a reservoir. Each cross represents the result of a reservoir model. The following features are valid for each distribution position.
Al. The SqER values are within the AR. This agreement means that the current models are matching the history data range for F1 (Figure 2A). The models are ready to make predictions.
All. The SqER values are above, below and inside the AR. To allow proper predictions, an uncertainty reduction method should be applied to move most of the models within the AR.
AIII. All SqER values are higher than +1. In practice, the simulated measurements are below the observed data. Either other reservoir attributes that were held constant are contributing to a mismatch or different limit ranges are needed. A model reassessment is required because the x models no longer honor the history data.
AIV. All SqER values are lower than -1. In practice, the simulated measurements are above the observed data. Either other reservoir attributes that were held constant are contributing to a mismatch or different limit ranges are needed. However, a model reassessment is required because the x models no longer honor the history data.
AV. The SqER values are below and inside the AR. Some models were able to honor while others are above the history data range. It is probably an indicator that the reservoir attributes have a wider or different uncertainty range. An appropriate uncertainty reduction method may help to move the models result inside the AR. Otherwise, a model reassessment is required to guarantee that most of the models are within the AR.
AVI. The SqER values are above and below the AR. The simulated measurements are below and above the observed data. None of the models were able to honor the history data range. Future prediction cannot be performed using these models; instead, the model must be reassessed.
Figure 2 - History matching tracker graphic
Apart from the different SqER positions in Figure 2A, the HM tracker graph can accommodate several functions from different wells. Finally, each function is associated with a time period. The matching function evolution can also be tracked over the simulation time. Figure 2B shows different scenarios that may evolve during the HM process. For instance, five years of simulation time, from T1 to T5 and the HM evaluation time every year are presented in Figure 2B for function Fl. Three main behaviors may occur, considering that all the models in the first time step are inside the AR and that five years of observed data are known.
BI. The SqER values may vary within the AR over the five years. This is ideal and there is no need to update the model. The models honor the new Dobs every year;
BII. If the SqER values move towards the upper boundary over time, the simulated results are below the observed data. If the models move out of AR over simulation time, for instance, at T4, additional uncertainty analysis is needed. The need to update the model occurs when most of the models are outside the AR;
Bill. If the SqER values are crossing the lower boundary, the simulated results are above the observed data. The same approach as case II must then be taken.
The HM tracker graph facilitates the decision to continue with or to update the current simulation model, which is ultimately used for reservoir management.
The probabilistic history matching workflow starts with the initial simulation model and the uncertainties of the reservoir. The uncertainties and their range are commonly related to the data and reservoir characterization quality and availability. So, even with advanced reservoir characterization techniques available, the development and management of reservoirs still carry uncertainty. The second stage in Figure 3 is the simulation run of representative scenarios. At this point, a sampling technique helps select a set of models to cover most of the possible reservoir responses. The number of models (samples) to cover the search space varies with the number of reservoir attributes. Risso et al. (2011) compared different sampling techniques in which the Derivative Tree, Monte Carlo and Latin Hypercube methods were used in a synthetic reservoir with 4 uncertain attributes. Although all three methods present a satisfactory result, the Latin Hypercube provides the best results considering precision and number of simulations.
Figure 3 - Probabilistic history matching workflow
After the reservoir characterization and running the representative models, the Dobs are incorporated into the models in Stage 3. Here the simulated results are compared to real data. Stage 4 is the first evaluation process, checking if the representative models can reproduce simulated results within the AR. The HM SqER indicators and the HM tracker graph are used at this stage; the SqER values are the quality indicators for each well and each function considered in the HM process. If the SqER value is outside the AR (Figure 2A - III, IV and VI), the next stage is model reparametrization (Stage 9). At this point, we know if the current models and their uncertainty attribute range could not be reconciled with simulated and observed data within the proposed AR. Ideally, the multidisciplinary team responsible for the model construction will reanalyze the model. Some options to mitigate the problem are the inclusion of new reservoir uncertainties, the variation range of the attributes, or even a complete geological recharacterization. The next step after
the model reparametrization is returning to Stage 2. The workflow stays in the loop until the simulated results agree with the observations within the AR.
If the HM tracker graph shows the SqER values within (Figure 2A - I) or crossing the AR (Figure 2A - II and IV), the process continues moving to the next stage: the uncertainty reduction in Stage 5. In Stage 5, we know if some or all representative models honor the observed data within the proposed AR. Some functions may have a wider distribution (Figure 2A - II), indicating that some models are within, while some models are outside of the AR. Other functions show a narrow response (Figure 2A - I), meaning that all representative models are already within the AR. Any method may be applied at this stage to reduce the uncertainty range of the reservoir attributes.
The second evaluation process is Stage 6. Before any reservoir prediction, this evaluation stage guarantees that all simulation results are inside the AR. After Stage 5, some functions narrow down the result distribution, reducing SqER distribution into the AR. For example, the distribution from Figure 2A - II may become similar to distribution from Figure 2A - I after Stage 5. The opposite can also occur: even after the uncertainty analysis stage, the models may still provide results out of the AR. In this case, the next step is the model reparametrization (Stage 9). Even the functions that had the values within the AR at Stage 4 must be checked again. The uncertainty reduction method may worsen the results of specific functions while improving others.
Stage 7 is the prediction under uncertainty. A simple filter is applied to the original set of models discarding the outlier models, which are outside the AR and easily recognized in the HM tracker graph. The representative models are then used to predict the selected functions and well performances. These predictions guide the reservoir management decision.
The final stage is a check for new observation data Dobs. Stage 8 should be synchronized with the Dobs acquisition frequency. If no new Dobs is available, the workflow ends, and the representative models used to make the prediction in stage 7 are the calibrated models. If new Dobs are available, the process moves to Stage 3 again. The process loop from Stage 3 to Stage 8 is expected to continue during the entire production life of a reservoir. Each selected reservoir function is monitored using the HM tracker graph shown in Figure 2B. For each new set of Dobs a new SqER distribution is created in this graph. In summary, the proposed workflow is evaluating and controlling the SqER distribution inside the AR.
The common HM approaches deal with history data as discrete observed values. Measurement errors and the addition of tolerance margins are rarely included in history data in the literature. The proposed method facilitates the conventional HM analysis described in Figure 1. It allows a consistent HM evaluation over the reservoir production period combining the history data with an acceptance range. This method may initially require an additional set-up effort if compared with the convention HM. On the other hand, the workflow from Figure 3 establishes a rigorous quality tracking process and a multivariate uncertainty reduction method proposed by Bertolini et al. (2015). The method was positively applied to the same reservoir models presented in the work (case study 1 and 2), at a static production period. Furthermore, although the method still requires a manual HM approach in some stages of the workflow, it tends to save computational power and human resources along the production time period.
6. Case Study 1: Synthetic Reservoir Model
The selected reservoir model is divided into five regions (Figure 4A) with different geometries, areas, volumes and properties (Figure 4A and 4B). It is an upscaled model from a refined reservoir. The porosity was upscaled through the arithmetic average using the permeability methodology described by Maschio and Schiozer (2003). The history data serving as true reference were obtained from the refined model.
Although case study 1 is a synthetic upscaled reservoir, with known response for validation of the methodology, the true reservoir attribute values that shall match the history data are unknown. The porosity distribution for the bottom reservoir layer is presented in Figure 4C. Figure 4D shows the top layer. The upscaled base-case model maintained the heterogeneities from the refined model.
Region3
Region2
Region5
Region4
Porosity (a)
0.00 0.501.00 miles
0.00 1.00 2.00 Km
0.16 0.17 0.18 0.19 0.20 0.21 0.22 0.23 0.24 0.25
Porosity K layer: 5(c)
Porosity K layer: 1(b)
_o
0.00 0.501.00 miles
0.00 0.501.00 miles
0.00 1.00 2.00 Km
0.00 1.00 2.00 Km
o -O -o_ o' _
O -O -o _ o' _
O " o -o__ o' _
CXI
O -O -o _ o' _
O ■ o -o__ o' _ CXI
_o o - o _ o
_ N) _o o
- o _ o
_o o - o _ o
_o o - o _ o
_ N)
__O
—	O
-	o _ o
Figure 4 - Case study 1 reservoir model
The reservoir uncertainties are horizontal permeability in the X direction (Kx), vertical permeability in the Z direction (Kz), Corey coefficient (Equation 4) for water relative permeability (Expow), and the maximal water relative permeability in Corey’s equation	Corey’s equation for water relative permeability provides the last two attributes. However,
the simulation model presents four uncertain attributes per region.
K = k *.
rw	rw
(v - V )
w wir
- ExpoW
(i - v - v )
wir or
(4)
where, Km is the water relative permeability, Sw is the water saturation, Swir is the irreducible water saturation and, finally, Sor is the residual oil saturation.
The absolute permeabilities Kx and Kz are modified in the simulation models through multiplier numbers. The limits are
0.5 and 2.0, which represent half and double the absolute permeability Kx and Kz of the base model. The base model uses
the unitary multiplier for K and K. Alternatively, the attributes Expow present a variation range from 1 to 5 and the
attributes K,w* from 0.15 to 0.90. Table 1 summarizes the reservoir attributes.
Table 1 - Base model reservoir attributes and their limits for case study 1
	Reservoir attributes									
	Multipliers									
Limits	Kxi	Kx2	Kx3	Kx«	Kxs	Kzi	K:2	K23	K24	KzS
Lower	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50
Base	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00
Upper	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00
	Corey's equation									
Limits	ExpoW1	Km*	ExpoW2	Km*	ExpoW3	Km*	ExpoW4	Km*	Expo W5	Km*
Lower	1.00	0.15	1.00	0.15	1.00	0.15	1.00	0.15	1.00	0.15
Base	2.20	0.60	1.10	0.80	4.00	0.50	1.30	0.70	4.30	0.80
Upper	5.00	0.90	5.00	0.90	5.00	0.90	5.00	0.90	5.00	0.90
The reservoir has five horizontal producer wells (Pl, P2, P3, P4 and P5) and five horizontal injector wells (Il, 12, 13, 14 and 15), each producer / injector pair for each region is located in the same reservoir position. The corner point grid shown in Fig. 4 has 2550 cells distributed in 30x17x5 blocks. The reservoir cells of the injector wells are Inj 1 (4;1-6;5); Inj2 (14;1-9;5); Inj3 (20-29;6;5); Inj4 (3;8-17;5) and Inj5 (10-28;14;5) and for the producer the cells are Prodi (4;1-6;1); Prod2 (14;1-9;1); Prod3 (20-29;6;1); Prod4 (3;8-17;1) and Prod5 (10-28;14;1). The well production strategy used in the simulation had a surface liquid limit of 4770 (m3/day); the BHP limit of 20684 KPa for the producer wells and the minimal BHP of 82737 KPa for the injector wells.
The multiwell history dataset for this case study has oil production measurements (m3/day) with Tm = 50 m3/day and Mre = 10%, water production measurements (m3/day) with Tm = 350 m3/day and Mre = 10% and BHP measurements (KPa) with Tm = 1000 KPa and Mre = 10%. These values were selected using previous simulation tests with this synthetic reservoir model.
Although the oil rate target on each simulated date is informed into the simulator, the oil production mismatch was one of the analyzed functions in the proposed method. Preliminary tests showed the oil rate mismatching increase when oil function was not included in the uncertainty reduction process. The simulator uses the oil targets to honor the oil rate history data.
7. Case Study 1: Results and Discussion
Using the 20 uncertainty attributes and their upper and lower limits (Table 1), a total of 50 models were generated to represent the search space (Stage 2 from the proposed workflow). From preliminary runs, a set of 50 models could represent the reservoir trend for this case study. The statistical sampling tool selected was Latin Hypercube (LHC). LHC returns an axb matrix, W, containing a Latin hypercube sample of a divisions on each of b variables. For each column of W, the a divisions are randomly distributed with one value from each interval (0,1/a), (1/a,2/a),..., (1-1/ a,1); these values are randomly permuted. The dimensions of the matrix W were 50x20 (number of models and number of attributes). Before the reservoir prediction step, we increased the number of reservoir models to 400 using the reduced reservoir attribute ranges (Stage 5) and the same statistical sampling tool (LHC) with a 400x20 matrix W. The need for a larger set of models for reservoir prediction is discussed in the next sections.
We used the multivariate analysis method, described by Bertolini et al. (2015) to evaluate and reduce the reservoir uncertainties in Stage 5 of the workflow. The methodology offers a quantitative analysis and a new tool to evaluate and reduce uncertainties. The process uses a Latin Hypercube (LHC) to sample the reservoir attribute range and a smoothed mismatch data set from the LHC selected objective functions. The attribute interval, which minimizes the mismatch, is identified through polynomial fitting. After, the models are run with the reduced attribute providing an improved history matching for most of the simulated measurements. This method is applied every time that a new observed data (Dobs) is assimilated into the proposed HM workflow. Dobs provides new reservoir information, which might change the performance of the reservoir models. When the set of models are still valid (Stage 4), the application of the uncertainty reduction method keeps searching for the optimum attributes ranges, using the previous ranges. Otherwise, when the models are reparameterized, the application of the uncertainty reduction method started with new attribute ranges.
The total simulation period was limited to ten years and the first years of the simulation were used to validate the method. The acquisition of Dobs was set annually. From year one to four, the workflow presented in Figure 3 was applied step by step. Figure 5 shows the reservoir response for the five producer wells using the original attribute range from Table 1 in solid cyan lines (50 models), the AR in dotted red lines, base model in solid red line, and the observed data in black. The top graphs are oil rate in m3/day, middle graphs are water rate in m3/day, and bottom graphs are the BHP in KPa.
6000
Prodi
Prod2
Prod3
Prod4
Prod5
■Q
g 4000
2000
Original models ■•■■■AR
...Base model
ccoofloBS
o
£
6
O' 5000
S 4000 E
■o 3000 p
t 2000
5 1000
O'
6
^0123466789 10
Time (years)
0123456789 10
Time (years)
0123456789 10 0123456789 10 0123456789 10 Time {years)	Time (years)	Time (years)
Figure 5 - Reservoir response from the 50 models (cyan curves) with the original attribute range; acceptance range
(red dotted lines); base model (red curves) and observed data (black circles) - Full simulation period (Casel)
The HM tracker graph for the tenth year is presented in Figure 6 showing the SqER quality indicator for each well and SM. The oil rate function (SqER - Oil rate) has no problems, the simulator results are inside the AR. Conversely, the SqER for water rate and BHP both exceed the -1 to 1 interval (AR). In the following subsections, the workflow from Figure 3 was applied to evaluate the performance of the simulation models.
-1
-2
SqER - Oil rate
15
10
Pl
P5
P2 P3 P4
Producer Wells
(at 10th year)
SqER - Water rate
5
0
Pl
P5
P2 P3 P4
Producer Wells
(at 10th year)
5
0
-5
-10
-15
-20
+		+ +				
						± -
						
						= n
						
						
						
						: ¥
						’ i ■
						5	zl
						
Producer Wells
(at 10th year)
5
4
3
2
1
0
Figure 6- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 10th year (Casel)
7.1	The first year
For the annual acquisition frequency, the initial set of observed data is at the end of the first production year. At this time the reservoir uncertainties and the representative models are ready, and the Dobs from the first year were added into the models. The next step is the model evaluation against the new Dobs (Stage 4 in Figure 3). With only a year of simulation time, most of the 50 models have a similar response. Figure 7 shows the HM tracker graphic at the first year.
For oil and water rates and for the five producer wells, the 50 simulation results are the same. However, the HM tracker graphic shows a flat line for those functions and wells between the -1 to 1 interval, except P3 well for SqER water rate. Although the SqER BHP results present different responses, they are mostly within the AR.
Producer Wells
(at lsxyear)
		- - - =	-
i	i i nun hi II I II IIIIIIIIBII		Ill
			
Figure 7- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st year (original models -Casel)
No model from the original set represented the P3 well water rate history data. Even with a year of observed data, the models failed to honor the observed data with the inclusion of the AR. The output for the Stage 4 is negative, so models must be reparameterized. The reservoir model was analyzed in greater depth, looking for the parameters that most strongly affect the water production at the P3 well (Bertolini et al., 2015). The models were improved after three manual attempts, passing from Stage 1 to 4 of the workflow. The two main changes were the porosity distribution in region 3 and the Expow3 range reduction from 1 - 5 to 1 - 2. Figure 9 shows the HM tracker graph for the updated models for the first year.
Figure 8- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st year (reparameterized
	
■ + + =	= + + ■
	
	s	■
■ + + 1	1 + + ■
	
models - Casel)
Compared with Figure 7 (original models), the results presented in Figure 8 had very similar responses for oil rate and
BHP functions. The main change occurred in the P3 well for the SqER water rate. It presents a wide range of results, with the median inside the AR. Therefore, this set of models is ready for the next stage in the workflow.
The multivariate uncertainty reduction method described by Bertolini et al. (2015) reduced the new ranges (Table 2).
Ten of the twenty parameter ranges were narrowed after the application of the method, including the Expow3 range of 1 - 2. The HM graphic is shown in Figure 9.
Table 2 - Original and reduced reservoir attributes after uncertainty reduction method at 1St year (Case 1)
	Reservoir attributes - original range (white) and reduced range (gray)									
	Multipliers									
Limits	KX1	Kx2	Kx3	Kx4	Kx5	Kzi	Kz2	Kz3	Kz4	KzS
Lower	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50	0.50
Lower	0.92	0.55	0.92	0.50	0.50	0.81	0.50	1.07	0.50	0.73
Upper	1.65	1.29	1.66	2.00	2.00	1.57	2.00	1.80	1.22	1.46
Upper	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00	2.00
	Corey's equation									
Limits	ExpxPOl	Km*	ExpoW2	Krw2*	ExpoW3	Krw3*	ExpxP04	Km*	Expo W5	Km*
Lower	1.00	0.15	1.00	0.15	1.00	0.15	1.00	0.15	1.00	0.15
Lower	1.00	0.15	1.00	0.15	1.00	0.42	1.00	0.15	1.00	0.49
Upper	5.00	0.90	5.00	0.90	2.00	0.79	5.00	0.90	5.00	0.86
Upper	5.00	0.90	5.00	0.90	5.00	0.90	5.00	0.90	5.00	0.90
Figure 9- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st year (reparameterized
models and uncertainty reduction method applied - Casel)
+	
■ + + =	^ + + ■
	
Producer Wells (at lSIyear)
		+ +		■		
- +	+			+	+	-
		+				
Producer Wells
(at 1st year)
+	
mi inn II ■■III I ■Hill I	i mu I Hill in i iii mm
	
Producer Wells
(at l5tyear)
Two main changes occurred after Stage 5 (Figure 9). The P3 well for SqER oil rate results spread slightly within the AR while the P3 well for SqER water rate function moved into the AR, away from the upper outliers. With the SqER distributions presented in Figure 9, Stage 6 receives a positive output, and the process moves to Stage 7 for the reservoir predictions. From the 400 models generated using the attribute ranges from Table 2 and the 400x20 LHC matrix, 103 were discarded using the filter (models with any SqER out of AR). The original 50 models, Dobs, base model and the 297 representative reparameterized models are presented in Figure 10. The vertical dashed line represents the present, on the left, the past and on the right, the future reservoir behavior.
Prodi	Prod2	Prod3	Prod4	Prod5
01 23456789 10 01 23456789 10 01 23456789 10 01 23456789 10 01 23456789 10
Time (years)	Time (years)	Time (years)	Time (years)	Time (years)
Figure 10 - Case 1 reservoir response from the 50 original models with 1 year of history data; Dobs; base model and
297 reparameterized models. On the left of vertical dashed line is past reservoir behavior and on the right is future.
Stage 8 is the last check in the proposed workflow, guaranteeing the use of recent Dobs. In case of new Dobs, the process starts again at Stage 3. The following sections present the results from the 2nd, 3rd and 4th years.
7.2	The second year
At the end of the second production year, new Dobs are available; their use brings a better reservoir understanding. Using the reparameterized 50 models from the previous year, the HM tracker graph is presented in Figure 11 for the first and second year.
Figure 11- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st and 2nd year (Case 1)
Most of SqER distributions maintain the same positions from the first year. The most representative change was the P3 well for oil rate function, which expanded the result distribution within the AR. However, the reservoir prediction can still be obtained from 281 (filtered at 2nd year) reparameterized models from the first year.
7.3	The third year
After three years of production, the HM graph shows an intensified increase in SqER trends from the 2nd year such as the Oil and Water rate for well P3, shown in Figure 12. The SqER BHP distributions and the P3 well SqER oil rate expand with time, although they are all within the AR. The SqER water rate for the P2 and P5 wells shows a small increase; as does the SqER water rate for the P3 well. This well was out of range and therefore forced a model reparametrization in the first year; now it varies within the AR, indicating consistency and validating the model
modification. At the 3rd year, 260 representative models from the first year still honor the observed data within the acceptance range.
Producer Wells	Producer Wells	Producer Wells
(at 1st, 2nd and 3rd year)	(at 1st, 2nd and 3rd year)	(at 1st, 2nd and 3rd year)
Figure 12- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 1st, 2nd and 3rd year (Case 1)
7.4	The fourth year
Similar trends occurred after the inclusion of the observed data from the fourth year. Now, some trends that appeared in the third year have intensified; the SqER water rate values for the P2 and P5 wells are moving out of the AR. This evolution means that the observed data from the fourth year were included in the representative models at Stage 3; but at Stage 4, 84% of the models were no longer able to match the new Dobs. After filtering (Stage 7), only 65 representative models from the first year honored the observed data within the AR. Figure 13 shows the SqER distribution trends from 1st to 4th year.
Producer Wells	Producer Wells	Producer Wells
(From 1st to 4th year)	(From 1st to 4xh year)	(From 1st to 4xh year)
Figure 13- HM tracker graph for SqER oil and water rate, and SqER BHP functions from 1st to 4th year (Case 1)
Since most of SqER water rate values for P2 and P5 wells are out of the AR, a new model reparametrization is now required (Stage 9). However, at this time the reservoir model was reassessed again, Expow2 and Expows attribute ranges were also reduced to 1 - 2, and Kw*and Kw* from 0.5 to 0.9.
Applying these changes, we ran 50 reparameterized models in the simulator. Figure 14 shows the HM tracker graph from 1st to 4th year. The SqER values are either within the AR for most of the functions or at least more symmetrically distributed around the zero, except for some functions that have outliers larger than 1 or -1. These results allow progression to the next stage.
Producer Wells	Producer Wells	Producer Wells
(From 1" to 4'" year)	(From 1st to 4'' year)	(From 1st to 4’" year)
Figure 14- HM tracker graph for SqER oil and water rate, and SqER BHP functions from 1st to 4th year
(reparameterized models - Casel)
With the same multivariate uncertainty reduction method in the 4th year, the attribute range was reduced. SqER oil rate for P2 and P3 wells and SqER water rate for P2, P3 and P5 wells closer to or moved into the AR. The opposite occurred to SqER BHP for Pl well where few SqER values are higher than the AR. Figure 15 presents the SqER values after applying the uncertainty reduction method.
(From 1st to 4th year)	(From 1st to 4th year)	(From l5tto 4th year)
Figure 15- HM tracker graph for SqER oil and water rate, and SqER BHP functions from 1st to 4th year
(reparameterized and uncertainty reduction method applied - Casel)
From the 400 models generated using the 400x20 LHC matrix and the new attribute range from 4th year, 74 were discarded using the filter. The original 50 models, Dobs, base model and the 326 representative reparameterized models are presented in Figure 16.
01 23456789 10 0123456789 10 0123456789 10 0123456789 10 01 23456789 10 Time (years)	Time (years)	Time (years)	Time (years)	Time (years)
Figure 16- Case 1 reservoir response from the 50 original models; Dobs; base model and 326 reparameterized models
(in the 1st to 4th years and uncertainty reduction method applied in the 1st and 4th year). On the left of vertical dashed
line is past reservoir behavior and on the right is future behavior
7.5	General process for n years
The loop continues during the reservoir production period. According to the Dobs acquisition frequency, the representative models used to make prediction are checked against the observed data with AR at Stage 8. The HM tracker graphic is also updated every time there is a new Dobs. It is a quick evaluation tool for the user managing the reservoir. Apart from the visual graphic tool, the implementation of an assisted workflow based on Figure 3, and different levels of reservoir response alerts can be set up using conventional computer codes. The number of simulation models inside all ARs for each set of models are showed in Figure 17. At the 1st year, the original set of models (white bars in Fig.17) and the set of reparameterized and optimized models at 1st year (gray bars in Fig.17) were history matched using the proposed workflow. In the following years, these sets are making reservoir forecasts. The set of reparameterized and optimized at 4th year (black bars in Fig. 17) was history matched at 4th year and the following year are reservoir forecasts.
YEARS
Figure 17- Number of simulation models inside all ARs - Casel
8. Case Study 2: UNISIM-I-H Reservoir Model
The full description of UNISIM-I-H model is presented by Avansi and Schiozer (2014). It uses structural, facies and petrophysical models from Namorado field, located in Campos Basin, Brazil. The geological model has 3.5 million active cells and it uses core and well logging data, 2D and 3D seismic data provided by Brazilian National Petroleum Agency - ANP and also from Petrobras (released public data).
Based on the geological model in a high-resolution grid, an upscaling procedure to a medium reservoir scale was necessary to decrease the computational effort. A simulation grid cell resolution was defined with 100 x 100 x 8 m blocks to reflect reservoir behavior properly and heterogeneities. It was discretized into a corner point grid (81 x 58
x 20 cells, with 36,739 active total cells). Porosity was upscaled through an arithmetic volume weighted method to ensure that the hydrocarbon pore volume remained constant when upscaling (additive property characteristics). Permeability was upscaled using a flow-based upscaling technique described by Deutsch (1989). When an isotropic permeability is upscaled, the effective results become anisotropic; three effective permeabilities in all directions (i, j and k) are then obtained for the upscaled reservoir model. In this work, 12 reservoir regions were defined using well location and their influences to the total reservoir production. The fluid model is Black Oil, oil density is 28° API and the original volume of oil of the model is 130 million m3. The production strategy was defined with 25 wells (4 vertical producers, 10 horizontal producers and 11 injectors). Figure 18 shows the porosity map and the well locations.
Fig. 18 - UNISIM-I-H porosity map and well locations
The vertical wells NA1D, NA2, NA3D and RJS19 were the pilot vertical wells for this field. They produced the field for 4 years and then were closed for one year. Production resumed in the sixth year with all 14 producers and 11 injectors for six more years. The model presents 18 uncertain attributes. Table 3 indicates the limits for each attribute. They are 12 porosity multipliers (Mpor), one horizontal permeability multiplier (Mkh), one vertical permeability multiplier (Mkv) for the entire reservoir, water-oil contact (WOC), coefficient A (CoeffA) and coefficient B (CoeffB) of Eq.5, which correlates porosity ($,) with horizontal permeability (Kh), and	of Eq.4.
The vertical permeability without any multiplier was defined as 10% of the horizontal permeability.
Table 3 - Base model reservoir attributes and their limits for case study 2
	Reservoir attributes								
Limits	Mpori	Mpor2	Mpor3	Mpor4	Mpors	Mpors	Mpor7	Mpors	Mpors
Lower	0.70	0.70	0.70	0.70	0.70	0.70	0.70	0.70	0.70
Base	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00	1.00
Upper	1.30	1.30	1.30	1.30	1.30	1.30	1.30	1.30	1.30
									
Limits	Mporio	Mporu	Mpori2	MKh	MKV	WOC (m)	CoeffA	CoeffB	ExpoW
Lower	0.70	0.70	0.70	0.50	0.50	3095.00	0.040	1.00	2.00
Base	1.00	1.00	1.00	1.00	1.00	3095.00	0.045	1.15	3.00
Upper	1.30	1.30	1.30	3.00	3.00	3105.00	0.050	1.30	5.00
The oil rate and the water injection rate on each simulated date was input into the simulator. The BHP was limited at 15000 KPa as a minimum for producer wells and at a maximum of 35000 KPa for injector wells. The maximum liquid rate was set to 3000 m3/day for producer wells and 6000 m3/day for injector wells. The same SMs were evaluated, oil production with Tm = 25 m3/day and Mre = 7.5%, water production with Tm = 125 m3/day and Mre = 15% and BHP for producer wells with Tm = 250 KPa and Mre = 15%, for 14 producer. In total, 42 functions were considered.
9. Case Study 2: Results and Discussion
Only vertical wells (NA1D, NA2, NA3D and RJS19 well) produce during the first four years. At the 1st year the SqER oil rate presents the biggest values and most of the models are out of the AR. Water rate is insignificant with one year of production, so SqER water rates are within the AR. SqER BHP are spread within and out of the AR. Figure 19 (upper plots) shows SqER for the 100 original simulation models (Set1) generated through LHC. Table 4 presents the number of models within each function and the number of models within all acceptance ranges (ARs). After the filter, Set1 has 32 models within all ARs. An uncertainty reduction tool optimized reservoir attribute ranges for Set1. An overall improvement for SqER was achieved, from 32 models (Set1) to 60 (Table 4) models (Set2) inside all ARs. Fig. 19 (lower plots) shows the SqER for the new set of models (Set2).
At the 4th year, the last year before the full field production with all 25 wells, a new reservoir attribute assessment was performed through the uncertainty reduction tool using 4 years of history data. Set3 represents the 100 optimized models at the 4th year. Fig. 20 shows the SqER until the 4th year for Set3.
We evaluated the reservoir models again after one year of full field production. At this time (7th year), 14 producer wells and 11 injector wells were active. Fig. 21 (upper plots) shows the Setl SqER for each well and function. Similarly to Setl, Set2 and Set3 models also result in unmatched BHP for Prod5 and Prod14 wells (Table 4). None of the models from Setl, Set2 or Set3 were within all 42 ARs (3 functions and 14 wells). However, at the time the reservoir model was reparameterized. The reservoir model was analyzed in greater depth, with changes in the porosity distribution around Prod5 and Prod14 wells and the water relative permeability. New models were created (Set4) using the original attribute ranged from Table 3 and LHC W (100 x 18). The uncertainty reduction tool then optimized the models (Set5). Fig. 21 (lower plots) shows the Set5 SqER for each well and function.
Figure 19- HM tracker graph for SqER oil and water rate, and SqER BHP at 1st year (upper plot - original models
Setl and lower plot - optimized models Set2) - Case2
1234123412341234
Years
NA1A	NA2	NA3D	RJS19
Vertical producer wells (From 1st to 4th year)
vertical producer wells (From 1st to 4th year)
SqER - BHP (Set 3)

Figure 20- HM tracker graph for SqER oil and water rate, and SqER BHP from 1st to 4th year (optimized models Set3 - Case2)
	
th1	
11 =	= --
= = :	+ +
i: *	+ ■
SqER - BHP (Set 1)
Figure 21- HM tracker graph for SqER oil and water rate, and SqER BHP functions at 7th year (upper plot - original
models Setl and lower plot - optimized models Set5) - Case2
Figures 22, 23 and 24 present the results for Dobs, Setl, Set4 and Set5. The vertical dashed line represents present reservoir behavior, with the past on the left, and future on the right. The number of models within all ARs for Set4 and Set5 at the 7th year, are 10 and 21 respectively (Table 4). Field oil and water production, and average BHP are shown in Fig. 25. Table 4 shows the numbers of models within the ARs for each set of models and functions.
Figure 22 - Oil rate from 100 original models (Setl); 100 reparameterized models (Set4) and 100 optimized models
(Set5). On the left of vertical dashed line is past reservoir behavior and on the right is future behavior (Case 2)
2000
1500
1000
500
0
2000
1500
1000
500 0
2000
1500
1000
500 0
NA1A
RJS19
1 23456789 10 11 Time (years)
NA2
Water rate (m3/D)
NA3D
PROD005
1 23456789 10 11 Time (years)
1 23456789 10 11 Time (years)
1 23456789 10 11 Time (years)
1 23456789 10 11 Time (years)
PRQD008
PRQD009
PRQD010
PRQD012
PRODQ14
PRODQ24A
PRQD021
PRODQ23A
PRODQ25A
ooDobs —Setl — Set 4 —Set 5 —AR
Figure 23 - Water rate from 100 original models (Setl); 100 reparameterized models (Set4) and 100 optimized
models (Set5). On the left of vertical dashed line is past reservoir behavior and on the right is future behavior (Case 2)
BHP (KPa)
x10 NA1A  NA2  NA3D
X104 PROD008	PROD009	PROD010
----------------'--------- ----------------1--------- ----------------r"
		1					PT
x104 PROD021	PROD023A	PROD024A
						■ I	
			jwtr mvJlk'vl'U irAWV'8l	Iw.	■			
1 23456789 10 11 1 23456789 10 11 1 23456789 10 11
Time (years)	Time (years)	Time (years)
RJS19  PRQD005
PROD025A
23456789 10 11 Time (years)
1 23456789 10 11 Time (years)
ooDobs —Setl —Set 4 —Set 5 —AR I
Figure 24 - BHP from 100 original models (Setl); 100 reparameterized models (Set4) and 100 oplimiz.ed models
(Set5). On the left of vertical dashed line is past reservoir behavior and on the right is future behavior (Case 2)
16000
14000
12000
10000
8000
6000
4000
2000
Field oil production (m3/d)
Time (years)
14000
12000
10000
8000
6000
4000
2000
0
Field water production (m3/d)
x10'
Average BHP (KPa)
4
Time (years)
oo Dobs —Setl —Set 4 —Set 5 —AR
Time (years)
Figure 25 - Field reservoir response from 100 original models (Setl); 100 reparameterized models (Set4) and 100 optimized models (Set5). On the left of vertical dashed line is past reservoir behavior and on the right is future behavior (Case 2)
Table 4 and Figure 26 show the numbers of models within the ARs for each set of Case 2 models and functions. At the 1st year, the original set of models (Setl) and the set of optimized models at 1st year (Set2) were history matched using the proposed workflow. In the following years, these sets are making reservoir forecasts. The set of optimized at 4th year (Set3) was history matched at 4th year and the following year they are making reservoir forecasts. Finally, the set of reparameterized models at 7th year (Set4) and the set of reparameterized and optimized models at 7th year (Set5) were history matched at 7th and from 7th to 11th year the sets are making reservoir forecasts.
Table 4 - Numbers of models inside the ARs for each set of models and functions - Case Study 2
	Number of models inside the AR - Oil Rate														
	Set 1 - Year			Set 2 - Year			Set 3 - Year			Set 4 - Year			Set 5 - Year		
Wells	1st	4th	7th	1st	4th	7th	1st	4th	7th	1st	4th	7th	1st	4th	7th
NA1A	97	90	81	100	100	100	100	100	100	100	98	93	100	100	99
NA2	100	72	55	100	99	92	100	99	99	100	98	88	100	99	99
NA3D	70	57	40	99	98	79	99	99	96	97	93	91	100	100	100
RJS19	77	81	83	100	100	100	100	100	100	99	99	100	100	100	100
PROD5	100	100	100	100	100	100	100	100	100	100	100	79	100	100	93
PROD8	100	100	100	100	100	100	100	100	100	100	100	100	100	100	100
PROD9	100	100	100	100	100	100	100	100	100	100	100	100	100	100	100
PROD10	100	100	100	100	100	100	100	100	100	100	100	100	100	100	100
PROD12	100	100	100	100	100	100	100	100	100	100	100	99	100	100	100
PROD14	100	100	100	100	100	100	100	100	100	100	100	85	100	100	99
PROD21	100	100	89	100	100	99	100	100	99	100	100	100	100	100	100
PROD23A	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD24A	1OO	1OO	57	1OO	1OO	74	1OO	1OO	91	1OO	1OO	98	1OO	1OO	1OO
PROD25A	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
					Number of models inside the AR					- Water Rate					
	Set 1 - Year			Set 2 - Year			Set 3 - Year			Set 4 - Year			Set 5 - Year		
Wells	1st	4th	7th	1st	4th	7th	1st	4th	7th	1st	4th	7th	1st	4th	7th
NA1A	1OO	99	99	1OO	1OO	1OO	1OO	1OO	1OO	1OO	99	99	1OO	99	99
NA2	1OO	44	23	1OO	68	33	1OO	73	6O	1OO	64	83	1OO	32	7O
NA3D	1OO	47	3O	1OO	65	3O	1OO	91	47	1OO	1OO	99	1OO	1OO	99
RJS19	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD5	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	92	1OO	1OO	98
PROD8	1OO	1OO	96	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD9	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD1O	1OO	1OO	88	1OO	1OO	99	1OO	1OO	99	1OO	1OO	99	1OO	1OO	99
PROD12	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	99	1OO	1OO	99
PROD14	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD21	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD23A	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD24A	1OO	1OO	89	1OO	1OO	99	1OO	1OO	99	1OO	1OO	99	1OO	1OO	99
PROD25A	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
					Number of models inside the AR -						BHP				
	Set 1 - Year			Set 2 - Year			Set 3 - Year			Set 4 - Year			Set 5 - Year		
Wells	1st	4th	7th	1st	4th	7th	1st	4th	7th	1st	4th	7th	1st	4th	7th
NA1A	79	85	91	92	1OO	1OO	1OO	1OO	1OO	96	99	99	1OO	1OO	1OO
NA2	1OO	76	84	1OO	1OO	1OO	1OO	1OO	1OO	1OO	99	1OO	1OO	99	1OO
NA3D	1OO	1OO	99	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
RJS19	76	97	99	62	99	1OO	48	99	1OO	62	98	99	63	1OO	1OO
PROD5	1OO	1OO	1	1OO	1OO	1	1OO	1OO	O	1OO	1OO	83	1OO	1OO	73
PROD8	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD9	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD1O	1OO	1OO	98	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO
PROD12	1OO	1OO	96	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	85	1OO	1OO	99
PROD14	1OO	1OO	3	1OO	1OO	O	1OO	1OO	O	1OO	1OO	99	1OO	1OO	1OO
PROD21	1OO	1OO	67	1OO	1OO	99	1OO	1OO	99	1OO	1OO	1OO	1OO	1OO	1OO
PROD23A	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	98	1OO	1OO	99
PROD24A	1OO	1OO	46	1OO	1OO	93	1OO	1OO	87	1OO	1OO	43	1OO	1OO	66
PROD25A	1OO	1OO	96	1OO	1OO	1OO	1OO	1OO	1OO	1OO	1OO	9O	1OO	1OO	83
	Number of models inside all ARs (oil, water rates and BHP)														
	Set 1 - Year			Set 2 - Year			Set 3 - Year			Set 4 - Year			Set 5 - Year		
	1st	4th	7th	1st	4th	7th	1st	4th	7th	1st	4th	7th	1st	4th	7th
	32	16	O	6O	52	O	47	65	O	53	52	1O	63	32	21
1	2	345	6789	10	11
YEARS
Figure 26- Number of simulation models inside all ARs - Case 2
Having the observed data available for the next years, we noted from Figure 26 that the models history matched at
7th year are no longer valid (inside all ARs) in the following year. It reinforces the advantages of using a continuous
HM workflow, allowing a faster model reassessment as needed and ultimately, providing reliable reservoir forecasts.
10. Conclusions
We propose a sequence of steps to continually evaluate the model performance over the simulation period. This method works with an acceptance range (AR) applied to the multiwell history dataset. The method is composed by nine-step workflow, which incorporates an uncertainty reduction tool and a HM indicator graph over time. The graph provides a practical and efficient way to support reservoir decisions. The acceptance range formulation considers relative measurement errors and tolerance margins from field characterization quality.
In this application, the reservoir models were annually evaluated against the acceptance range. The method maintained a set of calibrated models for the simulation period. The multivariate analysis method reduced reservoir uncertainties. This uncertainty reduction tool narrowed reservoir attribute ranges, minimizing the mismatch. The workflow was applied and described in detail from the first to the ninth step. We reparameterized the models twice, in the first and fourth years for Case 1, and once (seventh year) for Case 2 to honor the new observed data included in the HM.
The results presented annually showed the importance of continuous evaluation, and reservoir model updating to guarantee calibrated reservoir models over time. Furthermore, this application and its results lead to the following observations:
•	Measurement errors and tolerance margins were incorporated in the observed data, providing an acceptance history range, which was used to evaluate the reservoir model while performing HM.
•	Estimation of the relative measurement errors and the tolerance margin is a key stage for a proper history matching procedure and prediction. Whenever we do not know the measurement errors and/or a reasonable tolerance margin for the reservoir model, a sensitivity analysis with different estimated values is recommended to build a set of acceptance range scenarios.
•	A rigorous measurement error determination and tolerance margins associated with reservoir characterization improves the evaluation of the simulation models. Minimizing the effect of measurement conditions, for instance, individual well rate measurement and precise depths of pressure gauges, and a refined reservoir characterization, allow tighter evaluation criteria applied during HM.
•	For full field model reservoir, the method facilitates the model performance evaluation through the squared-error values of functions and wells, in a unique HM tracker graphs. This graph tracks the set of the reservoir models throughout the simulation period, which ideally should be synchronized with history data sampling frequency.
•	The method allows an easily assisted HM implementation based on the proposed tracker plot (Figure 2). The main loop from Stage 3 until Stage 8 in Figure 3 can be automated using computer codes.
•	The uncertainty analysis was performed using a multivariate analysis method proposed by Bertolini et al. (2015). Different tools and uncertainty reduction methods can be selected according to the number and type of the reservoir uncertainties. The production period can also determine reservoir management priorities, which may affect the reservoir uncertainty evaluation.
Nomenclature
HM - History matching
LHC - Latin Hypercube
AR - Acceptance range
Krw - Water relative permeability
Sw - Water saturation
Swir - Connate water saturation
Sor - Residual oil saturation
Expow - Coefficient of Corey’s equation for water relative permeability
Krw* - Maximum value of the water relative permeability in Corey’s equation
Kx - Effective permeability in X direction
Ky - Effective permeability in Y direction
SM - simulated measurement
s - Simulated data
h - History data
d - Number of data points
m - Number of simulated measurement
Dobs - Observed data
SqE - Square error
SqER - Square error ratio
a - Number of LHC divisions
b - Number of variables
W - LHC matrix with a-by-b dimension
x - Number of simulation models
Far - Acceptance range function
Tm - Tolerance margin
Mre - Relative measurement error
BHP - Bottom hole pressure
g - Standard deviation
References
•	Bertolini A., Schiozer D., 2011. Influence of the objective function in the history matching process. Journal of
Petroleum Science and Engineering, May, Volume 78, Issue 1, July 2011, Pages 32-41.
•	Emerick, A. A. and Reynolds, A. C., 2011. History Matching a Field Case Using the Ensemble Kalman Filter With
Covariance Lacalization. SPE 141216-PA, SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.
•	Emerick, A. A. and Reynolds, A. C., 2012. Combining the Ensemble Kalman Filter With Markov Chain Monte Carlo for Improved History Matching and Uncertainty Characterization. SPE 141336-PA, SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.
•	Maschio, C., Schiozer, D., 2013. A new procedure to reduce uncertainties in reservoir models using statistical inference and observed data. Journal of Petroleum Science and Engineering, Volume 110, October 2013, Pages 721.
•	Oliver, D. S., Reynolds A. C., Liu N., 2008. Inverse Theory for Petroleum Reservoir Characterization and History Matching. Cambridge University Press.
•	Zhou, W., Gupta, S., Banerjee, R., Poe, B., Spath, J., and Thambynayagam, M., 2013. Production Forecasting and Analysis for Unconventional Resources. Paper IPTC 17178-MS presented at the International Petroleum Technology Conference, Beijing, China, 26-28 March.
•	Risso, F. V. A., Risso, V. F., Schiozer, D. J., 2011. Risk Analysis of Petroleum Fields using Latin Hypercube, Monte Carol and Derivative Tree Techniques. Journal of Petroleum and Gas Exploration Research Vol. 1(1) pp. 014-021, September.
•	Slotte, P.A., Sm0rgrav, E., 2008. Response surface methodology approach for history matching and uncertainty assessment of reservoir simulation models. In: Proceedings of the Europec/EAGE Annual Conference and Exhibition, 9-12 June. SPE113390. Rome, Italy.
•	Schaaf, T., Coureaud, B., Labat, N., 2008. Using experimental designs, assisted history matching tools and Bayesian framework to get Probabilistic production forecasts. In: Proceedings of the SPE Europec/EAGE Annual Conference and Exhibition, 9-12June. SPE113498. Rome, Italy.
•	Liu, C., McVay, D. A., 2010. Continuous Reservoir-Simulation-Model Updating and Forecasting Improves Uncertainty Quantification. SPE 119197.
•	Maschio, C., Schiozer, D.J., Moura Filho, M.A.B., 2005. A methodology to quantify the impact of uncertainties in the history matching process and in the production forecast. In: Proceedings of the Annual Technical Conference and Exhibition, 9-12 October. SPE96613. Dallas, Texas.
•	Maschio, C., Schiozer, D.J., Moura Filho, M.A.B., Becerra, G.G., 2009. A methodology to reduce uncertainty constrained to observed data. SPE Reserv. Eval. Eng. (SPE 111030) 12(1), 167-180.
•	Maschio, C., Schiozer, D., 2003. A new upscaling technique based on Dykstra-Parsons coefficient: evaluation with streamline reservoir simulation. Journal of Petroleum Science and Engineering 40, 27- 36.
•	Tavassoli, Z., Carter, J. N., King, P. R., 2004. Errors in History Matching. SPE 86883-PA
•	Thakur, G.C., 1996. What is Reservoir Management? Journal of Petroleum Technology, Volume 48, Number 6, June. SPE 26289-MS.
•	Bertolini, A. C., Booth, R. J., Morton, K. L., Fitzpatrick, A. J., 2013. Design of Objective Function for Interference Well Testing. OTC-24513MS. Paper was presented at the Offshore Technology Conference Brasil held in Rio de Janeiro, Brazil, 29-31.
•	Bertolini, A. C.; Maschio, C.; Schiozer, D. J., 2015. A Methodology to Evaluate and Reduce Reservoir Uncertainties Using Multivariate Distribution, Journal of Petroleum Science and Engineering, v. 128, pp. 1-14, Abril.
•	Gu, Y. and Oliver, D.S., 2004. History Matching of the PUNQ-S3 Reservoir Model Using the Ensemble Kalman Filter.SPE 89942, Annual Technical Conference and Exhibition, Houston, Texas, U.S.A., 26-29 September.
•	Deutsch, C., 1989. Calculating Effective Absolute Permeability in Sandstone/Shale Sequences SPE Formation Evaluation, 4(3): 343 -348.
•	Avansi, G.D., Schiozer, D.J., 2015. A New Approach to History Matching Using Reservoir Characterization and Reservoir Simulation Integrated Studies, OTC, 4-5 May, Houston, USA.
92
6.	CONCLUSIONS
We proposed a methodology to calibrate reservoir simulation models considering four main steps: (1) a comparison scheme to identify appropriate objective functions for HM processes, (2) an uncertainty reduction method that uses multivariate analysis, incorporating the interaction between reservoir properties, (3) an uncertainty evaluation method capable of reducing the dimension of the problem through principal component analysis (PCA) and (4) a real-time history matching method that rigorously evaluates the HM quality and identifies the model updating and model reassessment need over time. Furthermore, there are some important results specific to each of the four articles, which should be highlighted.
From article 1, the following conclusions are drawn:
•	HM results are influenced by objective function formulation. Although the quality of the matching does not guarantee a good model, assisted procedures frequently relies on a good performance of the optimization method. However, the optimization functions should be carefully chosen.
•	Simple error function computed using history minus simulated data achieved the highest HM improvement. On the other hand, the optimization convergence was gradual and slow, requiring a large number of simulations.
•	The quadratic error function presented significant HM improvements at the beginning of the optimization process, even with a reduced number of simulations. It prioritizes points of larger difference, which accelerates the optimization solution.
•	The quadratic error function was selected and used in the next articles. Before, the function was further improved through the addition of sign, indicating an overestimation or a underestimation of the simulation results, and normalized for the use in multiobjective evaluation.
The methodology presented in article 2 is innovative and integrates mathematical tools to reduce reservoir uncertainties using dynamic data. Some of the results to be highlighted are as following:
•	The smoothing technique helped obtaining the general trend between reservoir attributes and the objective function misfit selected in both reservoir models. The examples showed that even using a large number of models (from the Latin Hypercube), the HM improvements are not significant when the smooth misfit is not used.
•	A lower number of simulations and consequently less computation power are required while using the smoothing technique applied to misfit functions. In addition, this methodology provided a set of improved simulation models without the use of proxy models, avoiding an additional complex step of similar techniques.
•	The methodology allows checking the relationship between the expected reservoir behavior and the reservoirs uncertain attributes through a sensitivity matrix. The matrix is a relevant tool to support HM and it was used to identify the critical attributes that influence the reservoir responses. The optimization of these attributes using the higher R2 coefficients is powerful to achieve better local HM.
Article 3 results are an extension of the methodology developed in the previous article. The additional conclusions are the following:
•	The size of the interpretable dataset is a critical factor for a reservoir evaluation. The time required and solution space coverage are the elements often associated with an efficient big dataset interpretation. The PCA method presented in article 3 efficiently reduced the size of the dataset, and consequently the computation time required to narrow the reservoir uncertainty.
•	Solution space coverage is controlled by the number of principal components. All principal components will fully cover the variability of the problem. The selection of a reduced number of principal components is a compromise between computational power (time to run models and number of simulations) and quality of the solution.
•	Interpretation between global and local match indicators was being the preferable HM approach. Considering only global match indicators may lead to a very poor match in some of the wells.
Some points to highlight concerning the real time HM method (article 4) are listed below:
•	Measurement errors and tolerance margins were included in the history matching process. It compares the simulation results against the history data and an acceptance range. The method allows a flexible model selection, avoiding restricted model selection based only on a fixed dataset.
•	The proposed workflow synchronizes the HM model evaluation with the history data acquisition, allowing model update and reparametrization as needed.
•	A proper estimation of relative measurement errors and tolerance margin provides the quality of the expected solution. The high quality and amount of reservoir data are usually proportional to the quality of the solution.
•	A new HM evaluation criteria was implemented and tested for both reservoir models. It is inside the probabilistic real time workflow, and works integrated with the reservoir uncertainty and model reparametrization stages. The evaluation provides a quality indicators and a HM tracker graph for each function and well, which establishes a rigorous quality tracking process over time.
96
7.	FUTURE WORK
The following points are the subjects to extend the proposed methods described in this thesis.
•	Application of PCA uncertainty reduction method in a more complex reservoir with a large number of wells and objective functions.
•	For reservoir models where reservoir property distributions created through geostatistics techniques are used as uncertainty attributes, for instance, porosity or permeability, are used to represent geological uncertainty, a new algorithm might be required to include them as uncertain reservoir attributes.
•	For some reservoirs, different HM priorities might be targeted, such as water breakthrough, gas-oil ratio or BHP match. The use of different curve fitting and smoothing techniques allow different weights for each function and an improved attribute range selection focuses on HM priorities.
•	Perform an integration between the proposed real-time workflow and optimization techniques. Optimization algorithm would search for the best attribute combinations using the reduced reservoir attributes from the real-time HM method.
•	Apply the real-time HM method for a real case and on an ongoing history matching process.
98
REFERENCE
Achelis, Steven B., 1995. Technical Analysis from A to Z. Second printing, McGraw-Hill, pp. 184-192.
Avansi, G. D.; Schiozer, D. J., "A New Approach to History Matching Using Reservoir Characterization and Reservoir Simulation Integrated Studies", OTC, 4-5 May, Houston, United States, 2015.
Avansi, G.D., Schiozer, D.J., “Reference and Simulation Model UNISIM-I: Geological Modeling under Uncertainties and Reservoir Development Application” accepted for publication to the International Journal of Modeling and Simulation for the Petroleum Industry, April 2014, Brazil.
Bennett, F. and Graf, T., 2002. Use of Geostatistical Modeling and Automatic History Matching to Estimate Production Forecast Uncertainty - A Case Study. SPE 74389, International Petroleum Conference and Exhibition, Mexico, 10-12 February.
Bertolini A., Schiozer D., 2011. Influence of the objective function in the history matching process. Journal of Petroleum Science and Engineering, May, Volume 78, Issue 1, July 2011, Pages 32-41.
Bertolini, A. C., Booth, R. J., Morton, K. L., Fitzpatrick, A. J., 2013. Design of Objective Function for Interference Well Testing. OTC-24513MS. Paper was presented at the Offshore Technology Conference Brasil held in Rio de Janeiro, Brazil, 29-31.
Bertolini A., Schiozer D., Maschio, C., 2015. A methodology to evaluate and reduce reservoir uncertainties using multivariate distribution. Journal of Petroleum Science and Engineering, Volume 128, April 2015, Pages 1-14.
Bertolini, A. C., Schiozer, D. J., 2015. Principal component analysis for reservoir uncertainty reduction. Journal of the Brazilian Society of Mechanical Sciences and Engineering, 1-11.
Biran, A. and Breiner M., 2002. Matlab for Engineers. Prentise Hall.
Bissel, R. C., 1997. Combining Geostatistical Modeling with Gradient Information for History Matching: The Pilot Point Method. SPE 38730 Annual Technical Conference and Exhibition, San Antonio, Texas, U.S.A., 5-8 October.
Chen, W.H., Gavalas, G.R., Seinfeld, J.H., Wasserman, M.L., 1973. A new algorithm for automatic history matching. SPE 4545 presented at the SPE-AIME 48th Annual Fall Meeting, held in Las Vegas, 30 September.
Craig, EE, et al., 1977. Optimized Recovery Through Continuing Interdisciplinary Cooperation," JPT (July 1977) 755.
Cullick, A.S., Johnson, D., Shi, G., 2006. Improved and more rapid history matching with a nonlinear proxy and global optimization. SPE 101933 prepared for presentation at the 2006 SPE Annual Technical Conference and Exhibition, held in San Antonio, 24-27 September.
Dadashpour, M., Rwechungura, R., 2011. Fast Reservoir Parameter Estimation by Using Effect of Principal Components Sensitivities and Discrete Cosine Transform, SPE 141913 was selected for presentation at the 2011 SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.
Dean, S.O., Albert, C.R., Ning, L., 2008. Inverse theory for petroleum reservoir characterization and history matching. Cambridge University Press.
Deutsch, C., 1989. Calculating Effective Absolute Permeability in Sandstone/Shale Sequences SPE Formation Evaluation, 4(3): 343 -348.
Emerick, A. A. and Reynolds, A. C., 2012. Combining the Ensemble Kalman Filter With Markov Chain Monte Carlo for Improved History Matching and Uncertainty Characterization. SPE 141336-PA, SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.
Emerick, A. A. and Reynolds, A. C., 2012. Combining the Ensemble Kalman Filter With Markov Chain Monte Carlo for Improved History Matching and Uncertainty Characterization. SPE 141336-PA, SPE Reservoir Simulation Symposium held in The Woodlands, Texas, USA.
Ferreira, C., Vernon, I., Schiozer, D.J. and Goldstein, M., 2014. Use of Emulator Methodology for Uncertainty Reduction Quantification. SPE 169405-MS, Latin American and Caribbean Petroleum Engineering Conference held in Maracaibo, Venezuela, 21-23 May.
Gomez, S., Gosselin, O., Barker, J.W., 1999. Gradient-based history matching with a global optimization method. SPE 71307, revised for publication from paper 56756, first presented at the 1999 SPE Annual Technical Conference and Exhibition, held in Houston, 3-6 October.
Guardado, L.R., Gamboa, L.A.P. and Lucchesi, C.F., 1989a. Petroleum Geology of the Campos Basin, Brazil, a Model for a Producing Atlantic Type Basin: PART 1. AAPG Special Volumes, A132: 33.
Guardado, L.R., Gamboa, L.A.P. and Lucchesi, C.F., 1989b. Petroleum Geology of the Campos Basin, Brazil, a Model for a Producing Atlantic Type Basin: PART 2. AAPG Special Volumes, A132: 42.
Guardado, L.R., Spadini, A.R., Brandao, J.S.L. and Mello, M.R., 2000. Petroleum System of the Campos Basin, Brazil. In: M.R.M.a Petroleum Systems if the South Atlantic Margins: AAPG Memoir 73, pp. 317-324.
Gu, Y. and Oliver, D.S., 2004. History Matching of the PUNQ-S3 Reservoir Model Using the Ensemble Kalman Filter.SPE 89942, Annual Technical Conference and Exhibition, Houston, Texas, U.S.A., 26-29 September.
Hajizadeh, Y., Amorin, E. P, Sousa, M. C., 2012. Building Trust in History Matching: The Role of Multidimensional Projection, SPE 152754 was selected for presentation at the EAGE Annual Conference &amp;amp; Exhibition incorporating SPE Europec held in Copenhagen, Denmark.
Jolliffe, I., 1986, Principal Component Analysis: Springer-Verlag Inc.
Liu, C., McVay, D. A., 2010. Continuous Reservoir-Simulation-Model Updating and Forecasting Improves Uncertainty Quantification. SPE 119197.
Manceau, E., Mezghani, I., Zabalza-Mezghani, I., Roggero, F., 2001. Combination of Experimental Design and Joint Modeling Methods for Quantifying the Risk Associated with
Maschio, C., Schiozer, D., 2003. A new upscaling technique based on Dykstra-Parsons coefficient: evaluation with streamline reservoir simulation. Journal of Petroleum Science and Engineering 40, 27- 36.
Maschio, C., Schiozer, D.J., 2005. Development and application of methodology for assisted history matching. SPE 94882 presented at the SPE Latin-American and Caribbean Petroleum Engineering Conference, Rio de Janeiro, Brazil, 20-23 June.
Maschio, C., Schiozer, D., Moura Filho, M.A.B., 2005. Methodology to Quantify the Impact of Uncertainties in the History Matching Process and in the Production Forecast. SPE 96613 prepared for presentation at the SPE Annual Technical Conference and Exhibition, Dallas, Texas, U.S.A.
Maschio, C.; Schiozer, D.J, "A New Methodology for Assisted History Matching Using Independent Objective Functions", Petroleum Science and Technology, pp. 1047-1062, v. 26, 2008.
Maschio, C., Schiozer, D. J., de Moura Filho, M. A. B., &amp;amp; Becerra, G. G. (2009, February 1). A Methodology To Reduce Uncertainty Constrained to Observed Data. Society of Petroleum Engineers. doi:10.2118/111030-PA
Maschio, C., Schiozer, D., 2013. A new procedure to reduce uncertainties in reservoir models using statistical inference and observed data. Journal of Petroleum Science and Engineering, Volume 110, October 2013, Pages 7-21.
Meneses, S.X.d. and Adams, T., 1990. Ocorrências de resistividades anômalas no Campo de Namorado, Bacia de Campos., Rio de Janeiro, Brasil.
Oliver, D. S., Reynolds A. C., Liu N., 2008. Inverse Theory for Petroleum Reservoir Characterization and History Matching. Cambridge University Press.
Risso, F. V. A., Risso, V. F., Schiozer, D. J., 2011. Risk Analysis of Petroleum Fields using Latin Hypercube, Monte Carol and Derivative Tree Techniques. Journal of Petroleum and Gas Exploration Research Vol. 1(1) pp. 014-021, September.
Rwechungura, R., Dadashpour, M., Kleppe, J., 2011. Advanced History Matching Technique Reviewed, SPE 142497 was selected for presentation at the SPE Middle East Oil and Gas Show and Conference held in Manama, Bahrain.
Sarma, P., Durlofsky, L. J., Aziz, K., Chen, W. H., 2007. A New Approach to Automatic History Matching Using Kernel PCA, SPE 106176 was selected for presentation at the 2007 SPE Reservoir Simulation Symposium held in Houston, Texas, U.S.A.
Schaaf, T., Coureaud, B., Labat, N., 2008. Using experimental designs, assisted history matching tools and Bayesian frame work to get Probabilistic production forecasts. In: Proceedings of the SPE Europec/EAGE Annual Conference and Exhibition, 9-12June. SPE113498. Rome, Italy.
Slotte, P.A., Sm0rgrav, E., 2008. Response surface methodology approach for history matching and uncertainty assessment of reservoir simulation models. In: Proceedings of the Europec/EAGE Annual Conference and Exhibition, 9-12 June. SPE113390. Rome, Italy.
Thakur, G.C., 1996. What is Reservoir Management? Journal of Petroleum Technology, Volume 48, Number 6, June. SPE 26289-MS.
Thomas, L.K., Hellums, L.J., Reheis, G.M., 1971. A nonlinear automatic history matching technique for reservoir simulation models. SPE 3475 presented at the SPE 46th Annual Fall Meeting, held in New Orleans, 3-6 October.
Vanderplaats, G.N., 1984. Numerical optimization techniques for engineering design: with applications. Mcgraw-Hill, New York.
Venkataraman, P., 2001. Applied optimization with Matlab programming. Wiley-Interscience.
Watson, A.T., Lee, W.J., 1986. A new algorithm for automatic history matching production data. SPE 15228 prepared for presentation at the Unconventional Gas Technology Symposium of the SPE, held in Louisville, 18-21 May.
Zhou, W., Gupta, S., Banerjee, R., Poe, B., Spath, J., and Thambynayagam, M., 2013. Production Forecasting and Analysis for Unconventional Resources. Paper IPTC 17178-MS presented at the International Petroleum Technology Conference, Beijing, China, 26-28 March.
Tavassoli, Z., Carter, J. N., King, P. R., 2004. Errors in History Matching. SPE 86883-PA</field>
	</doc>
</add>