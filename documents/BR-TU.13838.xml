<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.13838</field>
		<field name="filename">19973_DISSERTA%c3%87%c3%83O%20Ianyqui%20Falc%c3%a3o%20Costa.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">
 
 

 

UNIVERSIDADE FEDERAL DE PERNAMBUCO 

CENTRO DE TECNOLOGIA E GEOCIÊNCIAS 

DEPARTAMENTO DE ENGENHARIA CIVIL 

PROGRAMA DE PÓS-GRADUAÇÃO EM ENGENHAIRA CIVIL 

 

 

 

 

 

 

 

 

 

 

 

 

 

IANYQUI FALCÃO COSTA 

 

 

 

 

 UM MÉTODO PARA MUDANÇAS DE ESCALAS HETEROGÊNEAS E ESTOCÁSTICAS 

 

 

 

 

 

 

Recife 

2018 



 
 

 

IANYQUI FALCÃO COSTA 

 

 

 

 

 

 

 

UM MÉTODO PARA MUDANÇAS DE ESCALAS HETEROGÊNEAS E ESTOCÁSTICAS 

 

 

 

 

 

 

Dissertação submetida ao curso de Pós-

Graduação em Engenharia Civil da Universidade 

Federal de Pernambuco, como parte dos 

requisitos necessários à obtenção do grau de 

Mestre em Engenheira Civil. 

 

Área de concentração: Petróleo.  

Linha de Pesquisa: Simulação e Gerenciamento 

de Reservatórios de Petróleo 

 

Orientador: Prof. Dr. Ramiro Willmersdorf. 

Coorientador: Prof. Dr. Ézio da Rocha Araújo. 

 

 

 

 

Recife 

2018 



 
 

 

 

 

 

 

 

 

 

 

 
 

                                                                                      

 

 

 

 

 

 

 

 

 

 

 
Catalogação na fonte 

Bibliotecária: Neide Mesquita Gonçalves Luz / CRB4-1361 (BCTG) 
 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

   
   
C837m Costa, Ianyqui Falcão.   

  Um método para mudanças de Escalas Heterogêneas e Estocásticas / Ianyqui Falcão 
Costa. – Recife, 2018. 

  79 f.: il., fig. tab. 
 
  Orientador: Prof. Dr. Ramiro Willmersdorf. 
  Coorientador: Prof. Dr. Ézio da Rocha Araújo. 
  Dissertação (Mestrado) – Universidade Federal de Pernambuco. CTG. Programa de 

Pós-Graduação em Engenharia Civil, 2018. 
                     Inclui Referências.  
 

1. Engenharia Civil. 2. Taxa de distorcão. 3. Simulação de reservatórios. 3. Mudanças 
de escalas. 4. Algaritmo de Arimoto. 5. Resfriamento determinístico.  I. Willmersdorf, 
Ramiro (Orientador). II. Araújo, Ézio da Rocha (Coorientador). III.Título. 

  
 
 

  624 CDD (22. Ed.)               UFPE-BIBCTG/2018-189 
 

 
  
 
         

 

         



 
 

 

 

 

 

 

 UNIVERSIDADE FEDERAL DE PERNAMBUCO 

PROGRAMA DE PÓS-GRADUAÇÃO EM ENGENHARIA CIVIL 

 

A comissão examinadora da Defesa de Dissertação de Mestrado 

  

 

UM MÉTODO PARA MUDANÇAS DE ESCALAS HETEROGÊNEAS E ESTOCÁSTICAS 

 

defendida por 

 

 

Ianyqui Falcão Costa 

 

 

Considera o candidato APROVADO 

 

 

 

Recife, 27 de fevereiro de 2018 

 

 

Orientador - Prof. Dr. Ramiro Brito Willmersdorf – UFPE 

Coorientador - Prof. Dr. Ézio da Rocha Araújo - UFPE 

 

 

Banca Examinadora: 

 

 

___________________________________________ 

 

Prof. Dr. Ramiro Brito Willmersdorf - UFPE 

(orientador) 

 

 

__________________________________________ 

Prof. Dr. Alessandro Romario Echevarria Antunes – UFPE 

 (examinador externo) 

 

 

__________________________________________ 

Prof.ª Dr.ª Liliane de Allan Fonseca – UFPE 

 (examinadora externa) 



 
 

AGRADECIMENTOS 

 

Aos meus pais e familiares que, com muito carinho ? apoio, não mediram esforços para que fosse 

possível atingir meus objetivos. 

Meus agradecimentos aos amigos, companheiros de trabalhos ? irmãos na amizade que fizeram 

parte da minha formação ? que vão continuar presentes em minha vida. 

Aos meus orientadores, Prof. Dr. Ézio Araújo e Prof. Dr. Ramiro Willmersdorf, que aceitaram 

este desafio e acreditaram no sucesso desta dissertação, por sua vontade ? incentivo.  

Sinceros agradecimentos a todos aqueles que de alguma forma doaram um pouco de si para que 

este trabalho se tornasse possível. 

  



 
 

RESUMO 

 

Esta dissertação utiliza um modelo probabilístico de aprendizagem (soft clustering) de dados para a 

realização de mudanças de escalas com físicas e parâmetros heterogêneos. São utilizadas técnicas de 

Aprendizagem Não Supervisionada (Unsupervised Learning), como a clusterização, em conjunto 

com o algoritmo de Resfriamento Determinístico (Determinístic Annealing), proposto por Rose, K. 

(1991), que, diferente do Resfriamento Simulado (Simulated Annealing), não fica aprisionado em 

mínimos locais. Os elementos da Teoria da Informação como a Entropia, Entropia Conjunta, Entropia 

Condicional, Entropia Relativa, Informação Mútua e Distorção Média, propostos por Shannon, C. E. 

(1948), são utilizados em conjunto com medidas das físicas de interesse para avaliar a qualidade das 

diversas soluções possíveis que ponderam arbitrariamente entre a maximização da similaridade dos 

parâmetros e a qualidade das respostas. O modelo proposto nessa dissertação é aplicado a diferentes 

problemas de física e propriedades heterogêneas, porém unidimensionais, com equações diferenciais 

de segunda ordem, inclusive a depleção, por injeção de água, de um reservatório de petróleo. 

 

Palavras chave: Taxa de distorção. Simulação de reservatórios, Mudanças de escalas. Algoritmo de 

Arimoto. Resfriamento Determinístico. 

  



 
 

ABSTRACT 

 

This dissertation uses a probabilistic soft clustering model (soft clustering) to perform scale changes 

with heterogeneous parameters and physical parameters. In this paper, we propose the use of 

Unsupervised Learning techniques, such as clustering, in conjunction with the Determinístic 

Annealing algorithm, proposed by Rose, K. (1991), which, unlike Simulated Annealing, is not trapped 

in local minima. The elements of Information Theory such as Entropy, Joint Entropy, Conditional 

Entropy, Relative Entropy, Mutual Information and Mean Distortion, proposed by Shannon, C. E. 

(1948), are used in conjunction with physical measures of interest to evaluate the quality of diverse 

possible solutions that arbitrarily weighting between the maximization of the similarity of the 

parameters and the quality of the answers. The model proposed in this dissertation is applied to 

different problems of physics and heterogeneous, but one dimensional, properties with second order 

differential equations, including the depletion by water injection of a petroleum reservoir. 

 

Keywords: Distortion rate. Reservoir Simulation. Upscaling. Arimoto’s Algorithm. Deterministic 

Annealing. 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 



 
 

LISTA DE ILUSTRAÇÕES 

 

Figura 2.1: Teoria da Informação como valores extremos da Teoria da Comunicação........................23 

Figura 2.2: Relação da Teoria da Informação e suas Áreas de Aplicação............................................23 

Figura 2.3: Relação entre Informação Mútua e Entropia.....................................................................31 

Figura 2.4: Algoritmos de Compressão de Dados...............................................................................32 

Figura 2.5 – Função Taxa de Distorção...............................................................................................36 

Figura 3.1 – Esquema Local-Local, ou LL, de malhas encaixadas. (Redução de cardinalidade com 

? = 9, problema plano........................................................................................................................39 

Figura 3.2 – Esquema Semilocal-Local, ou SL, de malhas encaixadas, tendo como limite o esquema 

Global-Local, ou GL...........................................................................................................................40 

Figura 3.3 – Redução da Dimensão Probabilística. Não há bijeção entre as realizações de ? e de ?...41 

Figura 3.4 – Algoritmo de Simulação Determinística em paralelo......................................................49 

Figura 4.1 – Barra elástica ou reservatório unidimensional monofásico em regime permanente........50 

Figura 4.2 - Curva da Distorção Média com a Informação Mútua, Exemplo 1....................................51 

Figura 4.3 - Densidade e Distribuição das realizações nas duas escalas, Exemplo 1, apenas 1 

macroelemento...................................................................................................................................54 

Figura 4.4 - Distribuição das realizações do deslocamento (pressões) na macroescala, microescala e 

exata. Exemplo 1, apenas 1 macroelemento........................................................................................55 

Figura 4.5 - Distorção × Taxa, ?(1) = 1,5, Exemplo 2, para 1 macroelemento.................................55 

Figura 4.6 - Densidade dos parâmetros para ?(1) = 1,5, Exemplo 2, para 1 macroelemento.............56 

Figura 4.7 – Distribuição de ?(0) e ??(0) para  ?(1) = 1,5, Exemplo 2, macromalha com 1 

macroelemento....................................................................................................................................58 

Figura 4.8 - Densidades de ??(0),  e ?(0)para  ?(1) = 1,5, Exemplo 2, macromalha com 10 

macroelementos..................................................................................................................................58 

Figura 4.9 - Distorção × Taxa, ?(1) = 2,7, Exemplo 3, para 1 macroelemento.................................60 

Figura 4.10 - Densidade dos parâmetros para ?(1) = 2,7, Exemplo 3, para 1 macroelemento...........61 

Figura 4.11 – Distribuição de ?(0) e ??(0) para ?(1) = 2,7, Exemplo 3, macromalha com 1 

macroelemento...................................................................................................................................61 

Figura 4.12 - Densidades de ?(0) e ??(0) para  ?(1) = 2,7, Exemplo 3, macromalha com 10 

macroelementos..................................................................................................................................62 

Figura 4.13 – Distribuições nas duas escalas para  ?(1) = 1,5;indicando valores médios e desvios 

padrão para ?(0) e ??(0)....................................................................................................................66 



 
 

Figura 4.14 – Distribuição nas duas escalas ?(1) = 3,0; indicando valores médios e desvios padrão 

para ?(0) e ??(0)................................................................................................................................67 

Figura 4.15 - Microescala do reservatório...........................................................................................68 

Figura 4.16 - Permeabilidades na micromalha....................................................................................69 

Figura 4.17 – Modelo na Macroescala do Reservatório.......................................................................70 

Figura 4.18 -  Velocidades médias no reservatório nas duas escalas....................................................72 

Figura 4.19 – Saturações médias no reservatório nas duas escalas, 360 dias.......................................72 

Figura 4.20 – Saturações médias no reservatório nas duas escalas, 750 dias.......................................73 

Figura 4.21 – Pressões médias no reservatório nas duas escalas, 360 dias...........................................73 

Figura 4.22 – Pressões médias no reservatório nas duas escalas, 750 dias...........................................74 

 

  



 
 

LISTA DE TABELAS 

 

Tabela 4.1: Resumo dos Resultados obtidos no exemplo 2.a).............................................................57 

Tabela 4.2: Resumo dos Resultados obtidos no exemplo 2.b).............................................................58 

Tabela 4.3: Resumo dos Resultados obtidos no exemplo 2.c).............................................................59 

Tabela 4.4: Resumo dos Resultados obtidos no Exemplo 3.a).............................................................63 

Tabela 4.5: Resumo dos Resultados obtidos no Exemplo 3.b)............................................................64 

Tabela 4.6: Resumo dos Resultados obtidos no Exemplo 3.c).............................................................65 

Tabela 4.7: Resumo dos Resultados obtidos no exemplo 4.................................................................67 

Tabela 4.8: Resumo dos resultados obtidos no exemplo 5...................................................................71 

 

 

 

  



 
 

SUMÁRIO 

 

1            INTRODUÇÃO...............................................................................................................12 

1.1    GENERALIDADES ......................................................................................................... 12 

1.2    REVISÃO DA LITERATURA ........................................................................................ 14 

1.2.1          O problema geral de mudança de escalas heterogêneas e estocásticas ...................... 14 

1.2.2          Reservatórios de petróleo. Soluções determinísticas. .................................................. 16 

1.2.3          Reservatórios de petróleo. Solução Estocástica. .......................................................... 18 

1.3    OBJETIVOS DA PESQUISA .......................................................................................... 19 

1.4    ESBOÇO DA DISSERTAÇÃO ...................................................................................... .20 

2            FUNDAMENTAÇÃO TEÓRICA..................................................................................22 

2.1     ELEMENTOS DA TEORIA DA INFORMAÇÃO ........................................................ 22 

2.1.1 Entropia .......................................................................................................................... 24 

2.1.2 Entropia Conjunta e Entropia Condicional ................................................................ 27 

2.1.3 Entropia Relativa e Informação Mútua ...................................................................... 28 

2.2     COMPRESSÃO DE DADOS.......................................................................................... 31 

2.2.1 Algoritmos de Compressão de Dados .......................................................................... 31 

2.2.1.1        Compressão de Dados Sem Perda ................................................................................... 32 

2.2.1.2        Compressão de Dados com Perda.................................................................................... 33 

2.2.1.2.1     Clusterização ................................................................................................................... 33 

a)                Quantização e Distorção ................................................................................................. 33 

b)                Medição da Eficiência .................................................................................................... 34 

c)                Quantização Relevante .................................................................................................... 35 

d)                Teoria da Taxa de Distorção ........................................................................................... 35 

3             MULTIESCALAS HETEROGÊNEAS E ESTOCÁSTICAS....................................38 

3.1     REDUÇÃO DA CARDINALIDADE. MALHAS ENCAIXADAS ............................... 39 

3.2     REDUÇÃO DA DIMENSÃO PROBABILÍSTICA ....................................................... 41 

3.3     MEDIDAS DE DISTORÇÃO ......................................................................................... 42 



 
 

3.4     ALGORITMO DE ARIMOTO (DE SUBSTITUIÇÕES SUCESSIVAS) ...................... 43 

3.5     ALGORITMO DE ROSE (DA) ...................................................................................... 44 

4             APLICAÇÕES................................................................................................................50 

5             CONCLUSÕES E TRABALHOS FUTUROS............................................................75 

                  REFERÊNCIAS.............................................................................................................77 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 



12 
 

 
 

1 INTRODUÇÃO 

1.1 GENERALIDADES 

Este texto trata de métodos numéricos para mudanças de escalas espaciais estocásticas e 

heterogêneas. Por heterogêneas subtende-se que as físicas das escalas podem ser distintas e os seus 

parâmetros são estocásticos e heterogêneos no domínio espacial. Neste trabalho supõe-se, no entanto, 

que as físicas e os parâmetros são estacionários no tempo, embora esta não seja uma limitação das 

técnicas envolvidas. Dos fenômenos descritos pelas físicas, não se exige uma separação de escalas. 

Fluxo em meio poroso é um exemplo típico onde não há separação de escalas espaciais, e que as 

técnicas aqui desenvolvidas podem ser aplicadas com sucesso. Há sempre duas físicas envolvidas no 

processo de transferência de escalas. A de menor (maior) escala será doravante, e 

indiscriminadamente, denominada de microescala (macroescala), cujo domínio foi discretizado por 

uma malha suficientemente densa, uma micromalha (macromalha), para a solução acurada das suas 

equações reinantes (Weinen e Engquist, 2003). A acurácia das soluções dadas pela macromalha é 

dependente da acurácia das soluções fornecidas pela micromalha. A acurácia dada pela micromalha 

que, geralmente, é resolvida por adaptação com uma sequência adequada de malhas e avaliação de 

erros a posteriori das soluções, não é tratada neste texto. 

Simulações computacionais e diversos experimentos revelam que o comportamento dos materiais 

(sintéticos ou naturais) utilizados na engenharia resulta de suas interações em diferentes escalas de 

comprimento. Tradicionalmente, são utilizados métodos numéricos como elementos finitos, 

diferenças finitas, e suas variantes, para simulações computacionais. No entanto, para casos em que 

o sistema em uma microescala seja amplamente afetado pela variabilidade das propriedades 

mecânicas ou físicas dos materiais, é necessário que a densidade da malha utilizada seja suficiente 

para capturar acuradamente a heterogeneidade da microescala, o que resulta, em geral, em um sistema 

de equações muito grande para ser resolvido em tempo hábil (Koutsorelakis, 2007). Além disso, a 

densidade a malha necessária à obtenção de resultados acurados depende do método de discretização 

envolvido, ou pode mesmo não existir para um determinado método (Falk e Osborne, 1994). 

Outro aspecto de grande importância, que é geralmente ignorado nos métodos numéricos 

tradicionais, está relacionado com as incertezas. De fato, grande parte dos materiais utilizados na 

engenharia demonstram aleatoriedades locais em sua microestrutura. Além das incertezas associadas 

à estrutura do material, aquelas associadas às medições são também inevitáveis, mesmo quando 

realizadas em ambiente e condições adequadas. Essas últimas não são tratadas neste texto – para 

tratamento desses casos, ver, por exemplo, Mendes (2014) e Fonseca (2015). 



13 
 

 
 

Há uma grande necessidade de formular métodos para mudanças de escalas, ou de múltiplas 

escalas (multiescalas), com os quais seja possível incorporar informações relevantes da microescala 

na macroescala de maneira eficiente, fornecendo soluções (variáveis de estado) médias acuradas na 

macroescala. Diferentemente dos métodos de mudanças de escalas (upscaling), os métodos 

multiescalas podem objetivar também fornecer soluções acuradas ao nível da microescala. Diz-se, 

nesse caso, que o modelo da macroescala é generativo, pela sua capacidade de interpolar os 

resultados para a microescala. Alguns desses métodos não se preocupam em fazer uma explícita 

mudança de escalas dos parâmetros, mas apenas garantir soluções acuradas na macromalha, ou 

mesmo na micromalha. 

Nesta dissertação, é proposto um modelo probabilístico que incorpora as incertezas associadas 

aos detalhes microscópicos e às suas soluções, produzindo macromalhas com características 

estatisticamente similares à micromalha, e com controlável grau de acurácia nas suas soluções.  Esse 

modelo probabilístico é baseado nas técnicas utilizadas em aprendizagem de dados (machine 

learning, soft clustering). 

Os elementos da Teoria da Informação são utilizados com o objetivo de mensurar a informação 

contida nos parâmetros da escala microscópica e a avaliar a aproximação entre as soluções produzidas 

pelas duas escalas enquanto o aumento de escala é realizado. Especificamente, é efetuada uma 

substituição de uma microescala de alta densidade de informação por uma macroescala com baixa 

densidade de informação, cuja qualidade probabilística é determinada minimizando a distorção média 

entre as soluções dadas pela macroescala e pela microescala. De fato, garante-se um equilíbrio 

arbitrário (dependente de um hyperparâmetro, ?) entre a maximização da similaridade probabilística 

entre as informações providas pelas duas escalas e a proximidade probabilística entre as suas 

respostas. 

Por fim, a metodologia proposta efetua uma redução simultânea da dimensão do espaço 

geométrico (domínio) e do espaço probabilístico discretizado. A redução da dimensão do domínio 

discreto (de sua cardinalidade) é arbitrada pelo analista quando da escolha da macromalha (número 

de elementos, número de equações), enquanto que a redução das dimensões probabilísticas (tamanho 

da amostra ou número de realizações estocásticas) é escolhida como consequência da proximidade 

desejada entre a macro e a micro solução. 

O algoritmo principal deste trabalho é o algoritmo de Arimoto (conhecido como de Blahut-

Arimoto, um método de substituições sucessivas para distribuições) para obtenção das densidades de 

probabilidades, em conjunto com o algoritmo de Resfriamento Determinístico (Deterministic 

Annealing, DA) para a obtenção das amostras na macroescala. O algoritmo final é um produto da 



14 
 

 
 

miscigenação entre a Teoria da Informação, a Mecânica Estatística, a otimização estocástica, e a 

otimização determinística clássica (steepest descent), onde os gradientes do funcional a ser 

extremado, em relação às distribuições e às realizações são determinados analiticamente. 

O método proposto pertence à classe de métodos de multiescalas heterogêneas, da forma como 

definidos por Weinan e Engquist (2003). Ele pode ser utilizado nos esquemas micro-macro dos tipos 

Global-Local (GL), Semiglobal-Local (SL) e Local-Local (LL). Esquemas to tipo (·)-Global 

necessitam de algoritmos mais gerais do que o DA aqui implementado e serão objetos de futuros 

estudos. As duas malhas envolvidas são encaixadas, de forma que a reconstrução das variáveis de 

estado ao nível da microescala pode ser efetuada resolvendo um problema de Dirichlet ou um 

problema misto (Dirichlet-Neumann) em cada macroelemento. Essa reconstrução, entretanto, não é 

tratada neste texto. 

 

1.2 REVISÃO DA LITERATURA 

1.2.1 O problema geral de mudança de escalas heterogêneas e estocásticas 

O desideratum da Mecânica Computacional é resolver seus problemas corriqueiros com malhas 

que capturem a menor escala de seus dados e da sua física (Aarnes e Lie, 2004). Em engenharia de 

reservatórios essa escala é a da malha geocelular, que pode conter mais do que meia centena de 

milhões de elementos, células ou blocos. Isso não é possível hoje, como também não é desejável. A 

menos de alguns problemas especiais, ou localizados, os problemas de engenharia podem ser 

resolvidos acuradamente em escalas bem superiores. A cada escala de comprimento haverão físicas 

apropriadas, que resultam em sistemas de equações diferenciais e integrais com parâmetros, naturais 

(propriedades dos solos, fluidos, e definição geométrica das fácieis, em engenharia de reservatório, 

por exemplo) ou artificiais (distribuição de britas em algumas dimensões e formas em uma matriz de 

cimento, areia e aditivos, por exemplo, em engenharia do concreto estrutural) apropriados a cada 

escala em questão. Na matemática atual, uma forma possível e conveniente de descrever tais 

parâmetros que permeiam as distintas escalas, é por meio de estatística e probabilidades. Desta forma, 

as heterogeneidades, dos parâmetros e das equações que regem cada escala, dão origem à necessidade 

de métodos para a transposição de escalas heterogêneas e estocásticas. 

Apesar da evidente necessidade do tratamento estocástico dos parâmetros das equações 

diferenciais (também, das ações externas, das condições de contorno e das condições iniciais), nas 

últimas décadas a literatura tem dado mais ênfase ao estudo de mudanças de escalas apenas com 

parâmetros heterogêneos e determinísticos, e muito menos ao seu tratamento estocástico, 

Koutsourelakis (2007), Chen e Durlofsky (2008).  



15 
 

 
 

Quando a solução do sistema de equações é determinística e estacionária, notadamente nos 

sistemas elípticos, a solução na micromalha (que pode ser única, a depender das condições de 

contorno) é dada pela condensação dos graus de liberdade internos, formando os clássicos 

superelementos (macroelementos).  Nas discretizações pelo método dos elementos finitos por 

modelos de equilíbrio ou de compatibilidade, as operações de transposição de escalas, com a mesma 

física, de problemas elípticos são elementares. A crítica costumaz, em simulação de reservatórios, 

aos métodos de compatibilidade é que os campos de velocidades em quaisquer das malhas não 

conservam a massa. Entretanto, quando são usados modelos mistos, híbridos ou diferenças finitas e 

volumes finitos, que buscam conservação da massa, a transposição de escalas oferece algumas 

dificuldades operacionais (Kippe, Aarnes e Lie, 2007). 

Uma primeira dificuldade de caráter puramente computacional surge quando o sistema possui 

parâmetros estocásticos e a dimensão do espaço probabilístico é alta (tipicamente, centenas a milhares 

de realizações), uma vez que cada realização, em princípio, necessita ser condensada, uma por vez. 

Entretanto, claro está que este esforço inusitado é absolutamente desnecessário, mesmo que 

paralelizado. Uma vez que os detalhes internos aos superelementos foram condensados, a dimensão 

do novo espaço probabilístico estará, naturalmente, reduzida. A grande questão é determinar quais e 

quantos serão esses novos modelos (realizações).  

Esse é o caso de mudanças de escalas das permeabilidades absolutas em simulação de 

reservatórios. Por exemplo, em uma dimensão geométrica, a solução exata para cada microrealização 

é dada pela média harmônica dos elementos condensados de um dado superelemento. Se a 

distribuição dos parâmetros da micromalha é dada por ?? realizações, a descrição equivalente da 

resposta será dada por ?? ? ?? macrorrealizações, e, consequentemente, a regra das médias 

harmônicas, ou qualquer outra regra puramente geométrica, não mais se aplica. Não há uma aplicação 

bijetiva entre os dois espaços probabilísticos. Essencialmente, esse trabalho procura determinar quais 

são essas macrorrealizações, ótimas ou quase ótimas, em algum sentido dado, conhecida a 

macromalha e um conjunto de dados de entrada e suas respostas nas duas escalas envolvidas. 

Os procedimentos utilizados neste trabalho para mudanças de escalas preveem a possibilidade de 

existência de distintas físicas nas escalas envolvidas. É conveniente escrever essas equações 

estacionárias no tempo sob a forma residual, 

?(?,?,?) = 0,     na microescala,    (1.1) 

?(?,??,?) = 0,     na macroescala,      (1.2) 

onde ? representa as variáveis de estado no domínio, ??? , representam os parâmetros espacialmente 

distribuídos e sensíveis a mudanças de escalas, e ??? identifica um evento, amostra ou realização, 



16 
 

 
 

do espaço amostral ?, distintos, porém, em cada escala. Nessas equações, tanto ?(?) quanto ?(?) 

representam um ou mais equações da física subjacente. Para o caso mais simples de modelos black-

oil de reservatórios, exemplos de distintas físicas podem ser encontrados, por exemplo, em Durlofsky 

e Chen, 2012, e em Pal (2011), por exemplo, para reservatórios carbonáticos. 

Tem-se observado que os procedimentos de mudança de escalas podem ser fortemente 

dependentes das condições de contorno utilizadas. Além disso, é bem conhecido que, quando o 

tamanho do elemento está próximo à escala física ou comprimento de correlação da heterogeneidade, 

as variáveis primárias e suas derivadas calculadas nessas malhas podem conter grandes erros. Quando 

a microescala é periódica, eles são chamados de erros de ressonância. Em qualquer caso, esses erros 

aumentam quando o tamanho dos elementos aproxima-se da menor escala física. Utilizando esquemas 

do tipo Semilocal-(·) pode eliminar a dependência das condições de contorno e reduzir os erros de 

ressonância (Wu, Efendiev e Hou (2002). A razão geométrica entre os macros e os microelementos 

são também uma das principais fontes de erros. Ou seja, a redução da cardinalidade deve ser, 

idealmente, moderada e bem distribuída ao longo do domínio. 

 

1.2.2 Reservatórios de petróleo. Soluções determinísticas. 

A simulação numérica direta de fluxos em meios porosos de formações rochosas na malha 

geocelular é muito difícil devida também à complexidade dos sistemas dinâmicos. Computações 

acuradas de alta resolução sempre requerem um enorme tempo de CPU e grande necessidade de 

memória computacional. Por outro lado, geralmente, é suficiente predizer as soluções dos problemas 

em larga escala com certa acurácia. A prática usual é aumentar a escala da resolução espacial do meio 

heterogêneo. Para fluxos monofásicos, o meio é descrito apenas pelo campo de permeabilidades 

absolutas, que pode ser muito oscilatório (Wu, Efendiev e Hou, 2002). O objetivo da mudança ou 

aumento de escala é achar uma representação da permeabilidade em uma macromalha tal que o fluxo 

de larga escala ou médio possa ser corretamente calculado nessa malha. 

Uma importante consequência da mudança de escala é o surgimento de anisotropia. Mesmo que 

as permeabilidades absolutas sejam isotrópicas, no aumento de escala elas virão a constituir-se em 

um tensor de segunda ordem. O fato de que ainda hoje muitos simuladores limitam-se a tratar 

permeabilidades como matrizes diagonais, diminui a motivação para o tratamento correto das 

permeabilidades na macroescala. 

Considerando o caso mais geral no qual as malhas e as quantidades de fluxo são descritas em 

coordenadas curvilíneas ortogonais, Zijl e Trykozko (2001) mostram que, preferivelmente, as 

mudanças de escala devem satisfazer três requisitos (i, ii e iii).  



17 
 

 
 

i - as macropressões devem ser iguais à média espacial das micropressões e, ao mesmo tempo, as 

derivadas das macropressões devem ser iguais às derivadas médias da micropressões. Diz-se que há 

uma conservação da força motriz. 

ii - conservação da equação de continuidade: os macrofluxos componentes vezes os macrofatores 

devem ser iguais aos microfluxos vezes os microfatores. Os fatores são unitários nas malhas 

cartesianas. Decorre um claro significado: o macrofluxo é o microfluxo médio, similarmente ao caso 

anterior para pressões. 

iii – conservação da equação de dissipação: a macrodissipação por unidade de volume deve ser 

igual à microdissipação por unidade de volume. 

Infelizmente, como apontado por Zujl e Trykozko (2001), esses três requisitos superespecificam 

as mudanças de escalas. Em meios porosos em perfeitas camadas e em meios porosos periódicos os 

três requisitos podem ser satisfeitos simultaneamente. A mudança de escala em um meio poroso 

perfeito é quase trivial. Em geral, somente dois dos três requisitos podem ser satisfeitos 

simultaneamente. Uma mudança de escala baseada em média volumétrica pode ser feita, então, de 

três formas, importantes, em qualquer que seja o método utilizado para mudança de escalas. Em 

médias volumétricas: 1) Médias de Pressão e Fluxo (PF), 2) Médias de Pressão e Dissipação (PD), e, 

3) Médias de Fluxo e Dissipação (FD).  

A mudança de escalas para sistemas monofásicos requer, essencialmente, a obtenção do campo 

?? de permeabilidades absolutas na macroescala. Para problemas bifásicos e multifásicos há 

necessidade de, adicionalmente, gerar as novas funções ???
?  de permeabilidades relativas, funções da 

saturação, onde o índice ? identifica as fases. Neste caso, as equações (1.1) e (1.2) a serem resolvidas, 

serão dependentes do tempo ?,  

?(?,?,???, ?,?) = 0,     na microescala,    (1.3) 

?(?,??,???
? , ?,?) = 0,     na macroescala.     (1.4) 

No processo de mudança de escalas, essas equações são resolvidas com combinações apropriadas 

de condições de contorno de Dirichlet e Neumann, com algum dos esquemas LL, SL, GL. Para 

campos de permeabilidades complexos, como os canalisados e os carbonáticos com vugs e fraturas, 

não fica claro, a priori, quais as condições de contorno mais adequadas a serem impostas, Chen e 

Durlofisky (2008). As condições de contorno ótimas são obtidas por comparação entre as respostas 

das equações (1.1) e (1.2). Em jogo está o grande esforço computacional, que deve ser reduzido. 



18 
 

 
 

1.2.3 Reservatórios de petróleo. Solução Estocástica. 

Os problemas estocásticos requerem muito mais esforço computacional. Um dos objetivos dos 

esquemas propostos na literatura é diminuir esse esforço e ainda manter a qualidade da resposta 

quando comparada com a da micromalha. Existe uma clara compreensão de que não há necessidade 

de fazer a mudança de escala para todas as realizações. Nesse caso, as medidas de acurácia serão 

feitas sobre as estatísticas desejadas, como por exemplo, valores característicos como P50, P10, P90, 

ou sobre à própria distribuição da resposta, como um todo, Chen e Durlofsky (2008), Durlofsky e 

Chen (2012), e Costa, Fonseca e Araújo (2017). 

Aparentemente, Aarnes e Efendiev (2007), foram os primeiros a publicarem uma solução 

numérica para a mudança de escalas estocásticas em reservatórios de petróleo, utilizando uma forma 

do método dos elementos finitos mistos para múltiplas escalas, MsFEM. A ideia básica foi construir 

funções de base que além de capturarem as informações da microescala, resolvem a variabilidade 

espacial ao longo das realizações estocásticas. Isso é feito selecionando uma pequena família de 

realizações com dispersão suficiente, e calculando um conjunto de funções de base para cada 

realização. Chen e Durlofsky (2008) desenvolveram um conjunto de procedimentos que 

denominaram de ensemble level upscaling, EnLU. A sua metodologia consiste, em uma primeira fase, 

em determinar as permeabilidades absolutas e porosidades de todas as realizações, fase denominada 

de primitiva. Esta fase parece ser suficiente para pequenas reduções da cardinalidade ou ordem dos 

modelos, e para realizações obtidas por meio de estatística de dois pontos (variogramas). Em uma 

segunda fase é feita a mudança de escala das permeabilidades relativas parametrizando-as e utilizando 

estimativas estatísticas baseadas em clusterização de uma pequena amostra dos resultados, no plano 

das velocidades médias e seus desvios padrões, de 10% das realizações, para todos os 

macroelementos. São utilizados clusteres determinísticos (hard clustering). Utilizam um simulador 

de código aberto em volumes finitos. Neste caso, a mudança de escalas pode ser feita sobre as 

mobilidades e fluxos fracionários de Bluckley-Leverett, com resultados mais acurados (Romeu e 

Noetinger, 1995). 

Em Chen, Park e Durlofsky (2011), melhorias são introduzidas no EnLU, dentre elas, a adoção 

de diferentes procedimentos para regiões no entorno dos poços e entre poços. Nas regiões no entorno 

dos poços são também escaladas a taxa total de fluxo dos poços, aumentando o número de clusters 

nos planos das velocidades medias e, agora, dos seus coeficientes de variação, complementados por 

simulações sequenciais Gaussianas (geoestatística) para reproduzir alguma estrutura espacial das 

realizações escaladas, permitindo diminuir o número de realizações a serem utilizadas nas aplicações 

(3% nas suas aplicações). 



19 
 

 
 

Os procedimentos acima foram recentemente generalizados para comportar simulações de 

modelos composicionais de reservatórios (Li e Durlofsky, 2015). A mudança de escala primária foi 

também recentemente utilizada na otimização estocástica de campos de reservatórios, incluindo as 

posições dos poços, e utilizando uma sequência de modelos em múltiplas escalas com a intenção de 

acelerar a convergência do método de Monte Carlo, com uma ordem de grandeza nos ganhos médios 

dos tempos de processamentos (Aliyev e Durlofsky, 2015). 

Nos procedimentos adotados neste trabalho, são utilizados clusteres estocásticos (soft clustering); 

a manutenção da estrutura geoestatística e geológica (contida nas realizações) é feita por meio de 

medidas de similaridades do seu conteúdo de informações; enquanto que a redução do número de 

realizações é dependente da acurácia desejada dos resultados; todos decorrentes de um procedimento 

de otimização estocástico-determinístico, automático e globalmente convergente (Koutsourelakis, 

2007). Procedimentos de otimização estocástico-determinísticos são mais econômicos e acurados do 

que procedimentos puramente estocásticos (Fonseca, 2015). Também, a metodologia usada neste 

trabalho é transparente às físicas subjacentes (black-oil, fraturados, cavernosos, composicionais, etc), 

e de seus métodos de solução numérica. 

 

1.3 OBJETIVOS DA PESQUISA 

A análise probabilística de sistemas realistas regidos por equações diferenciais e integrais 

resolvidas por métodos numéricos requer a solução de sistemas com dezenas a centenas de milhares, 

ou mesmo milhões, de incógnitas, repetidas tantas vezes quantas forem as realizações estocásticas.  

Isso é muito agravado quando a análise probabilística está sendo efetuada dentro de ciclos iterativos 

de controle em malha fechada ou otimização estocástica. Estima-se que menos de uma centena dessas 

avaliações em micromalha seja possível nos tempos atuais (Grico e Koutsourelakis, 2017). 

Um caminho evidente para contornar essa limitação é fazer uso de mudanças de escalas de espaço 

e tempo, em conjunto com uma redução do espaço probabilístico. Desta forma, a solução dos 

problemas na microescala se dará apenas para produzir as macrorealizações, que se espera poder 

resolver o problema com acurácia suficiente. 

Dadas centenas a milhares de realizações estocásticas da microescala, uma das soluções é fazer 

uma mudança de escala para cada realização, como em Durlofsky e Chen, 2012 para as 

permeabilidades absolutas. Isso, no entanto, não reduz a dimensão do espaço probabilístico, 

obviamente necessário, haja vista a perda de detalhes das macrosoluções.  

Sendo assim, o objetivo principal deste trabalho é investigar aspectos matemáticos e 

computacionais de um metodologia para efetuar uma redução simultânea das dimensões dos modelos 



20 
 

 
 

(sua cardinalidade) e da dimensão probabilística (número de realizações necessárias para uma dada 

precisão probabilística), proporcionando a oportunidade de aumentar a capacidade de análises 

estocásticas, principalmente as inseridas dentro de ciclos de controle estocásticos ou em malha 

fechada, e de otimização estocástica. 

Nesse sentido, como mostrado anteriormente, os procedimentos propostos trazem algumas 

melhoras em relação aos hoje praticados (por exemplo, em Durlofsky e Chen, 2012): o número de 

realizações é apenas dependente da acurácia da resposta estabelecida a priori; as realizações são 

obtidas a partir de um procedimento de otimização globalmente convergente; a estrutura 

geoestatística é mantida em um nível desejado pelo engenheiro de reservatórios; consistentemente, 

utiliza clusters estocásticos (soft clustering); é independente das físicas que regem o comportamento 

da micro e da macroescalas.   

É objetivo deste trabalho também servir de base para aplicações mais gerais como na solução 

de problemas de simulação estocástica de reservatórios carbonáticos, com a presença simultânea da 

física de Darcy, em uma miscigenação de microescalas, para os meios porosos, da física de Stokes 

para regiões vugulares e cavernas, junto com modelos apropriados para o tratamento de fraturas em 

diversas escalas (Pal, 2011) e Araújo, Willmersdorf e Fonseca (2011). 

Finalmente, este trabalho tem um predominante aspecto teórico-investigativo, no sentido de 

iniciar a busca e avaliação das potencialidades de uma corrente de metodologias com base nas 

recentes técnicas de inferência estatística e aprendizado de dados - machine learning, em direção à 

matemática do deep learning - com a percepção de que, enfatizando, não mais do que uma dezena a 

uma centena de análises na microescala são, nos dias atuais, possíveis para propagação de incertezas 

geoestatísticas nos grandes reservatórios, como os carbonáticos, sem separação de escalas, em 

múltiplas físicas, do pré-sal. 

 

1.4 ESBOÇO DA DISSERTAÇÃO 

No próximo capítulo serão apresentados os fundamentos teóricos que permearam este trabalho, 

como resultado da mistura de técnicas estatísticas e probabilísticas contidas na Teoria da Informação 

e na Mecânica Estatística, em especial na Termodinâmica.  

No Capítulo 3 são descritos o algoritmo probabilístico de Arimoto que implementa a Rate-

distortion Theory; o algoritmo estocástico-determinístico, Deterministic Annealing (DA), de Rose 

(1991, 1994, 1998), para extrair as macrorealizações, com a sua versão paralela e generalizada para 

múltiplas físicas dada em Costa, Fonseca e Araújo (2017). 



21 
 

 
 

No Capítulo 4 são feitas algumas aplicações unidimensionais para avaliar o comportamento do 

conjunto das técnicas envolvidas, da forma como codificadas, procurando detectar suas virtudes e 

suas desvantagens. 

No Capítulo 5 são sumarizadas as principais conclusões, como também discutidas quais seriam 

algumas possíveis soluções para as limitações encontradas, bem como algumas possíveis 

generalizações analíticas e algorítmicas.  

  



22 
 

 
 

2 FUNDAMENTAÇÃO TEÓRICA 

Neste capítulo são apresentados alguns elementos da Teoria da Informação que serve de base para 

os procedimentos de mudança de escala utilizados neste trabalho. Os elementos da Teoria da 

Informação foram extraídos, essencialmente, de Cover (2006). Existem fortes motivos para rever 

alguns elementos dessa teoria.  

Os procedimentos utilizados neste trabalho para mudança de escala têm como base aquela 

disciplina. A transformação do campo discreto de parâmetros estocásticos ? sobre micromalha para 

o campo discreto de parâmetros estocásticos ? definido na macromalha utiliza uma generalização dos 

procedimentos de compressão de dados com perdas e da Teoria da Taxa de Distorção. Essa 

generalização se dá pela redução simultânea cardinalidade de ? e da dimensão do espaço 

probabilístico, e pela generalização do conceito de medida de Distorção. Na Teoria da Informação, 

as medidas de Distorção dizem respeito às diferenças entre os campos ? e ?, enquanto que neste texto 

a Distorção é medida pelas diferenças entre as respostas ou solução dos problemas subjacentes, em 

uma e outra escala, presumivelmente, com distintas físicas, métodos e algoritmos para resolvê-las. 

 

2.1 ELEMENTOS DA TEORIA DA INFORMAÇÃO 

Com sua origem na Teoria da Comunicação, a Teoria da Informação foi desenvolvida com o 

objetivo de tratar problemas de compressão e transmissão de dados, na qual, a sua mais importante 

contribuição foi realizada por Shannon (1948), ao desenvolver distintos modos de mensurar as 

redundâncias em sinais de comunicação, comprimi-las, sem perder as principais características da 

informação e transmiti-las de forma que o receptor as assimile sem distorções excessivas. A figura 

(2.1), em sua área hachurada, ilustra todo o conjunto de possíveis esquemas de Comunicação e como 

a Teoria da Informação, fazendo o uso de uma importante propriedade como a Informação Mútua, ?, 

se relaciona em um problema de Compressão de Dados, onde deseja-se representar uma variável 

aleatória ? com uma alta quantidade de informação por uma outra variável aleatória ? com uma 

menor quantidade de informações e sem as redundâncias presentes inicialmente em ? a partir da 

minimização da Informação Mútua ou de Transmissão de Dados, na qual a maximização da 

Informação Mútua está relacionada com a confiabilidade e qualidade da transmissão de informações 

de uma variável aleatória ? em um canal com quantidade de ruído controlado de maneira que a 

variável aleatória ? interprete com a maior confiabilidade possível.   

 

 

 



23 
 

 
 

Figura 2.1 - Teoria da Informação como valores extremos da Teoria da Comunicação.  

 

Fonte: Cover, 2006 

 

Figura 2.2 - Relação da Teoria da Informação e suas áreas de aplicação.  

 

Fonte: Cover, 2006 

 

Apesar de ter sua origem na Teoria da Comunicação, a Teoria da Informação possui um grande 

campo de atuação na própria Teoria da Comunicação, na Ciência da Computação, na Física, na 

Matemática, na Teoria das Probabilidades, na Estatística e na Economia. A figura 2.2 ilustra seu 

relacionamento com diversas áreas. 



24 
 

 
 

Na seção seguinte, os elementos da Teoria da Informação são apresentados de forma que, ao final, 

define-se a Informação Mútua como sendo um caso particular da Entropia Relativa entre variáveis 

aleatórias, tanto discretas quanto continuas e suas propriedades. 

 

2.1.1 Entropia 

O conceito físico da Entropia está relacionado tanto ao grau de desorganização da matéria quanto 

à tendência de sua desorganização. Na Termodinâmica, pressupõe-se que em um sistema fechado a 

entropia nunca diminui, só podendo aumentar. Desta afirmação conclui-se que a entropia é um estado 

dinâmico que varia em função do estado inicial de organização da matéria e do tempo, caracterizando 

um processo irreversível. Entretanto, ao relacionar a entropia com a Teoria da Informação, faz-se 

necessário a utilização de uma outra abordagem, definida por Ludwing Boltzmann, na qual a entropia 

é definida em termos estatísticos dentro de um contexto mecânico, L. Brillouin (2013). Sendo assim, 

define-se que a entropia é a medida da quantidade média de incerteza de uma variável aleatória. 

     Seja ? uma variável aleatória discreta definida como: 

? = {?? ? ? = 0,±1,…,±?}.    (2.1) 

onde ?? é um número inteiro e (2? + 1) é o número total de níveis discretos, e que um evento ? =

?? tenha a probabilidade: 

?? = ?(? = ??).                    (2.2) 

     Com a exigência de que haja consistência probabilística: 

0 ? ?? ? 1?? ?? = 1
?
?=?? .     (2.3) 

     Após a ocorrência de um evento ? = ?? com probabilidade ?? há um ganho na quantidade de 

informação, ?, que se define por: 

?(??) = ???(
1

??
) = ??????.               (2.4) 

em que o logaritmo pode ter base qualquer. Destaca-se quando a base possui valor 2 ou ?, na qual a 

entropia é medida em bits ou nats, respectivamente.  

      A expressão acima possui as três seguintes propriedades: 

? ?(??) = 0 ???? ?? = 1.                        (2.5) 

   Obviamente, se o resultado de um evento for absolutamente correto, nenhuma informação é ganha 

pela sua ocorrência. 

? ?(??) ? 0 ???? 0 ? ?? ? 1.                   (2.6) 

    Isto é, a ocorrência de um evento ? = ?? fornece alguma ou nenhuma informação, mas nunca uma 

perda de informação. 



25 
 

 
 

? ?(??) &gt; ?(??) ???? ?? &amp;lt;??.                   (2.7) 

     Isto é, quanto menos provável for um evento, mais informação é ganha através da sua ocorrência. 

   Do que foi apresentado acima sabe-se que a quantidade de informação ?(??) é uma variável 

aleatória discreta com probabilidade ??. Ao trabalhar com valores médios de?(??), no intervalo 

discreto e completo de 2? + 1, chega-se a definição de Entropia, que é dado por: 

?(?) = ???[?(??)] = ? ???(??) = ?? ???????
?
?=??

?
?=?? ,                  (2.8) 

onde ??? é o operador de esperança matemática na distribuição ??, com os seguintes limites: 

0 ? ?(?) ? ???(2? + 1).        (2.9) 

onde (2? + 1) é o número total de níveis discretos. Além disso pode-se afirmar que: 

? ?(?) = 0, se e somente se a probabilidade ?? = 1para algum ?, e as probabilidades restantes 
no conjunto forem todas nulas; este limite inferior da entropia corresponde a nenhuma 

incerteza. 

? ?(?) = ???(2? + 1), se e somente se ?? = 1 (2? + 1)?  para todo ? (i.e., todos os níveis 
discretos são equiprováveis); este limite superior da entropia corresponde à incerteza máxima. 

Note que, na definição da Entropia utilizam-se apenas os valores da função densidade de 

probabilidade, não sendo necessários os valores da variável aleatória ?. 

Analogamente define-se a Entropia diferencial para uma variável aleatória continua como: 

?(?) = ?? ??(?)?????(?)?? = ??[?????(?)??]
?

??
.                     (2.10) 

A justificativa segue abaixo: 

   Toma-se o limite da variável aleatória continua ? como a forma limite de uma variável aleatória 

discreta que assume o valor ?? = ???, onde ? = 0,±1,±2,…,??? se aproxima de zero. Por 

definição, a variável aleatória continua ? assume um valor no intervalo [??,?? + ??] com 

probabilidade ??(?|?)??. Assim, permitindo que o ?? se aproxime de zero, a Entropia ordinária da 

variável aleatória continua ? pode ser escrita no limite como: 

?(?) = ? lim
???0

? ??(??)??log(??(??)??)
?
?=??                                  (2.11) 

  = ? lim
???0

[ ? ??(??)(log ??(??))?? + log?? ? ??(??)??

?

?=??

?

?=??

]                    

= ?? ??(?)log??(?)??
?

??

? lim
???0

log??? ????
?

??

                                             

= ?(?) ? lim
???0

log??,                                                    

onde, na penúltima linha fez-se o uso da equação (2.10) e do fato de que a área total sob a curva da 

função de densidade de probabilidade ??(?) é unitária. No limite quando ?? se aproxima de zero, 



26 
 

 
 

?????? se aproxima do infinito. Isto significa que a Entropia de uma variável continua é 

infinitamente grande. Intuitivamente, esperava-se que isto fosse verdade porque uma variável 

aleatória contínua pode assumir um valor qualquer no intervalo (??,?) e a incerteza associada com 

a variável tende ao infinito. Evitou-se o problema associado com o termo ????? adotando ?(?) como 

uma Entropia Diferencial, com o termo ?????? servindo como referência. Além disso, como a 

informação processada pelo sistema estocástico como uma entidade de interesse é realmente a 

diferença entre dois termos de Entropia que têm uma referência em comum, a informação será a 

mesma que a diferença entre os termos de Entropia Diferencial correspondentes. Com isso justifica-

se perfeitamente o uso do termo ?(?) como a Entropia Diferencial da variável aleatória continua ?. 

Assim como para o caso discreto, a Entropia de uma variável aleatória continua não faz o uso do 

valor da variável ?, mas apenas sua probabilidade ??(?). 

Abaixo apresentam-se algumas das propriedades da Entropia Diferencial: 

? Da definição da Entropia Diferencial ?(?), vê-se que uma translação não altera o seu valor, 
i.e.: 

?(? + ?) = ?(?),                                                          (2.12) 

onde ? é uma constante. 

? Outra propriedade útil de ?(?) é: 

?(??) = ?(?) + log |?|                                                    (2.13) 

onde ? é um fator de escala. Para provar essa propriedade, primeiro utiliza-se o fato de que a área sob 

a curva de uma função de densidade de probabilidade é unitária, então: 

?? =
1

|?|
?? (

?

?
)                                                               (2.14) 

Usando a definição de ?(?), escreve-se: 

?(?) = ??[log??(?)] = ??[log(
1

|?|
?? (

?

?
))]?(?) = ??[log?? (

?

?
)] + log|?|.(2.15) 

Colocando ? = ?? nesta relação, temos: 

?(??) = ?? ??(?)log??(?)??
?

??
+ log|?|?(??) = ?(?) + log|?|.           (2.16)] 

Generalizando para o caso de um vetor aleatório ? multiplicado por uma matriz ? têm-se: 

?(??) = ?(?) + log|det (?)|,                                            (2.17) 

onde o ??? (?) é o determinante da matriz ?. 



27 
 

 
 

2.1.2 Entropia Conjunta e Entropia Condicional 

Seguindo as mesmas definições da Entropia para uma variável aleatória unidimensional, é 

possível incorporar para duas variáveis aleatórias, o que se define como Entropia Conjunta. As duas 

variáveis aleatórias (?,?) são tratadas como apenas um vetor unidimensional, portanto não há 

diferença entre as definições como apresentado abaixo: 

A Entropia Conjunta ?(?,?) de um par de variáveis aleatórias discretas (?,?) com distribuição 

de probabilidade conjunta ?(?,?) é definido como: 

?(?,?) = ?? ? ?(?,?)???[?(?,?)],??????                              (2.18) 

que também pode ser expressa como: 

?(?,?) = ??(?,?){???[?(?,?)]}.                                      (2.19) 

    A Entropia Condicional de uma variável aleatória, a definimos como o valor esperado das 

Entropias das distribuições condicionais calculadas em relação à média da variável aleatória 

condicionada. Portanto: 

?(?|?) = ? ?(?)?(?|? = ?)? ? ? = ?? ?(?)? ?(?|?)log[?(?|?)]? ? ?? ? ?        (2.20) 

= ? ? ? ?(?,?)log[?(?|?)]

? ? ?? ? ?

?(?|?) = ??{log[?(?|?)]}                              

     Outra definição pode ser obtida ao relacionar a Entropia Condicional e a Entropia Conjunta, 

?(?,?) = ? ? ? ?(?,?)log[?(?,?)]

? ? ?? ? ?

= ? ? ? ?(?,?)log[?(?)?(?|?)]

? ? ?? ? ?

 

= ? ? ? ?(?,?)log[?(?)]

? ? ?? ? ?

? ? ? ?(?,?)log[?(?|?)]

? ? ?? ? ?

  

= ? ? ?(?)log[?(?)]

? ? ?

? ? ? ?(?,?)log[?(?|?)]

? ? ?? ? ?

              

= ?(?) + ?(?|?).                                                                                          (2.21) 

      Na qual a Entropia Conjunta ?(?,?) é a Entropia de uma variável aleatória ?(?) somada a 

Entropia Condicional de uma outra variável aleatória condicionada a X ?(?|?). 

     Essa relação apresentada anteriormente pode ser ampliada para mais de duas variáveis aleatórias, 

como por exemplo: 

?(?,?|?) = ?(?|?) + ?(?|?,?).                                      (2.22) 



28 
 

 
 

       Analogamente, para o caso contínuo têm-se, 

?(?|?) = ???(?,?)log?(?|?)????                                   (2.23) 

Sabendo que: ?(?|?) = ?(?,?) ?(?)? , chega-se a: 

?(?|?) = ?(?,?) ? ?(?),                                               (2.24) 

ou, 

?(?,?) = ?(?|?) + ?(?).                                               (2.25) 

Com um cuidado adicional para as entropias que forem infinitas. 

 

2.1.3 Entropia Relativa e Informação Mútua 

Após a apresentação dos conceitos sobre Entropia Condicional e Entropia Conjunta, é possível 

definir mais dois conceitos de fundamental importância na Teoria da Informação. A Entropia Relativa 

e a Informação mútua, nas quais vão servir de base para o desenvolvimento dos próximos tópicos. 

  A Entropia Relativa ou Distância de Kullback-Leibler, Kullback e Leibler (1951), ou, 

simplesmente, distância KL, é uma medida de distância entre duas distribuições de probabilidade. Ou 

seja: 

???(?(?)||?(?)) = ? ?(?)log
?(?)

?(?)? ? ?
 ,                                           (2.26) 

onde diz-se que a Entropia Relativa é uma medida de ineficiência em assumir que a distribuição de 

probabilidade de uma variável aleatória correta é ?(?) quando na verdade é ?(?), ou, simplesmente, 

mede a similaridade entre duas dadas distribuições. 

A distância KL possui as propriedades: 

? Tem sempre um valor positivo ou zero. Para o caso especial quando ?(?) = ?(?), temos um 
casamento perfeito entre as duas distribuições e ?(?||?) é exatamente igual a zero. 

? É invariante em relação às seguintes variações nas componentes do vetor ?: 

a) Permutação da ordem na qual as componentes estão arranjadas. 
b) Escalamento de amplitude 
c) Transformação não-linear e monótona. 

 

Apesar de entender a Entropia Relativa como uma distância entre distribuições de probabilidades, 

ela não satisfaz a condições de simetria e do triângulo de desigualdades. No entanto, é prático entendê-

la como uma distância. 

Pode-se escrever a distância KL também como: 



29 
 

 
 

???(?(?)||?(?)) = ??(?) {log[
?(?)

?(?)
]}      (2.27) 

   Define-se a Informação Mútua como a quantidade de informação em que uma variável aleatória 

contém sobre uma outra variável aleatória. Ou seja, é a redução da incerteza de uma variável aleatória 

em relação ao conhecimento de outra.  

   Matematicamente, têm-se que a Informação Mútua é a Entropia Relativa entre a distribuição 

conjunta ?(?,?) e o produto das marginais ?(?) e ?(?) de duas variáveis aleatórias ? e ?. 

?(?;?) = ? ? ?(?,?)log[
?(?,?)

?(?)?(?)
]? ? ?? ? ? = ???[?(?,?)||?(?)?(?)]           (2.28) 

= ??(?,?) {log[
?(?,?)

?(?)?(?)
]}                                                

   A Informação Mútua possui importantes propriedades e relações com a Entropia. 

? A Informação Mútua ?(?;?) é a redução da incerteza de ? devido ao conhecimento de ?, 

?(?;?) = ? ? ?(?,?)log[
?(?,?)

?(?)?(?)
]? ? ?? ? ? = ? ?(?,?)log[

?(??)

?(?)
]?,?                (2.29) 

= ???(?,?)log[?(?)]

?,?

+ ??(?,

?,?

                                             

= ???(?,?)log[?(?)]

?,?

? (???(?,?)log[?(?|?)]

?,?

)                                   

= ?(?) ? ?(?|?).                                                                      

? A informação mútua entre ? e ? é simétrica, portanto, 

        ?(?;?) = ?(?;?),                                                           (2.30) 

onde a Informação Mútua ?(?;?) é uma medida de incerteza sobre a saída ? do sistema que é 

resolvida observando-se a entrada ? do sistema, e a informação mútua ?(?;?) é uma medida da 

incerteza sobre a entrada do sistema que é resolvida observando-se a saída do sistema.  

? A Informação Mútua entre ? e ? nunca é negativa, 

 ?(?;?) ? 0                                                                             (2.31) 

   Na verdade, esta propriedade afirma que não se pode perder informação, em média, observando a 

saída do sistema ?. Além disso, a informação mútua é zero se e somente se a entrada e a saída do 

sistema forem estatisticamente independentes. 

? A Informação Mútua entre ? e ? pode ser expressa em termos da entropia de ? como, 



30 
 

 
 

?(?;?) = ?(?) ? ?(?|?),                                                      (2.32) 

onde ?(? ? ?) é uma Entropia Condicional. O lado direito é a média de ensemble da informação 

transmitida pela saída ? do sistema, menos a média de ensemble da informação transmitida por ? 

dado que já conhecemos a entrada ? do sistema. Esta última quantidade, ?(? ? ?), transmite 

informação sobre o ruído do processamento, em vez de informação sobre a entrada ? do sistema. 

? A entropia é um caso especial da Informação Mútua, pois: 

?(?;?) = ?(?) ? ?(?|?) = ?(?)                                           (2.33) 

Devido a essa última expressão, a Informação Mútua pode ser chamada de Informação Própria. 

Analogamente, para o caso continuo, a Entropia Relativa será, 

???(??||??) = ? ?? log[
??(?)

??(?)
]??

?

??
,                                        (2.34) 

em que ? é finita apenas se ?? está contida em ??, e, para a Informação Mútua, 

?(?;?) = ? ? ??,?(?,?)
?

??
???[

??,?(?,?)

??(?)??(?)
]????.

?

??
                          (2.35) 

 A sua relação com a Entropia: 

?(?;?) = ?(?) ? ?(?|?) = ?(?) ? ?(?|?) = ?(?) + ?(?) ? ?(?,?).     (2.36) 

E, ainda, fica fácil de verificar que, 

?(?,?) = ???(?(?,?)||?(?)?(?)).                                      (2.37) 

Abaixo, apresenta-se uma figura que ilustra bem a relação da Informação Mútua com a Entropia. 

 

 

 

 

 

 

 

 

 

 

 

 



31 
 

 
 

Figura 2.3 - Relação entre Informação Mútua e Entropia. 

 

Fonte: Cover, 2006 

 

Após a definição da Informação Mútua, é possível indicar o motivo de sua importância, o que 

será feito após uma breve apresentação sobre compressão de dados e suas técnicas. 

  

2.2 COMPRESSÃO DE DADOS 

Nas últimas décadas, foi possível testemunhar uma grande transformação nas formas de 

comunicação. Essas transformações ocorrem, e continuarão a ocorrer, devido ao crescimento da 

própria Internet, do desenvolvimento de telefones celulares e ainda a mais recente comunicação áudio 

visual. Normalmente, seria impossível fazer a utilização de televisores digitais, de escutar músicas 

em um tocador de MP3 ou fazer o uso de outras tecnologias em tempo hábil sem o uso da compressão 

de dados. Sendo assim, define-se a compressão de dados como sendo a técnica da representação de 

dados de maneira compacta, em que seus algoritmos são utilizados com a finalidade de reduzir a 

quantidade de informação necessária para representar algum objeto em estudo. 

 

2.2.1 Algoritmos de Compressão de Dados 

Ao tratar de algoritmos de compressão de dados, é preciso saber que na verdade estamos nos 

referindo a dois tipos de algoritmos. Um algoritmo em que faz o uso dos dados de entrada ? e realiza 

representações ?? de maneira compactada e um outro algoritmo, de reconstrução, que utiliza a 

representação compactada ?? para reconstruir ?. Abaixo segue uma figura ilustrativa: 



32 
 

 
 

Figura 2.4 - Algoritmos de Compressão de Dados

 

Fonte: Khalid, 2006 

 

Sabendo-se da necessidade de um algoritmo de reconstrução, classificam-se os algoritmos de 

compressão de dados em dois tipos: compressão de dados sem perda, em que reconstrói um ? idêntico 

ao ? de entrada, e compressão de dados com perda, no qual, geralmente, fornece uma compressão 

bem maior que algoritmos de compressão de dados sem perda, mas com um ? diferente de ?. 

 

2.2.1.1 Compressão de Dados Sem Perda 

Técnicas de compressão de dados sem perdas, como o próprio nome sugere, não envolve nenhuma 

perda de informação. Esses casos, em que nenhuma informação é perdida, possuem interessantes 

aplicações, pois os dados de entrada originais podem ser recuperados posteriormente após a 

compressão.  

Esse tipo de compressão é utilizado em aplicações que não toleram nenhum tipo de divergência 

entre a informação inicial e a fornecida pela compressão. Pode-se citar como exemplos de que uma 

pequena distorção na informação fornecida pode trazer interpretações completamente opostas à 

desejada: informações bancárias, imagens fornecidas por satélites, imagens fornecidas por 

ressonância magnética e até mesmo simples mensagens de texto. 

Existem muitos outros casos em que a compressão de dados sem perda deverá ser utilizada, mas 

existem também outras situações em que a compressão precise ser mais acentuada, mesmo que à 

reconstrução da informação possua alguma distorção. Nesses casos aplicam-se algoritmos de 

compressão de dados com perda. 



33 
 

 
 

2.2.1.2 Compressão de Dados com Perda 

Técnicas de compressão de dados com perda envolvem a perda da informação ao fornecer o 

resultado final da compressão. Em casos que os dados fornecidos são diferentes do resultado 

encontrado após a compressão, ficam impossibilitados de recuperar os valores iniciais através dos 

dados comprimidos. Entretanto, com a possibilidade de gerar resultados com uma distorção aceitável, 

algoritmos com perda podem chegar a compressões de dados bem maiores que algoritmos sem perda 

de dados.  

Como exemplo, podem-se citar casos de armazenamento ou transmissão de discurso, em que em 

muitos casos não há a necessidade de armazenar ou transmitir exatamente cada valor de cada amostra. 

Em casos de reconstrução de vídeos, no qual a visualização exata pode ser desprezada caso não 

forneça resultados tendenciosos. 

Antes de apresentar maneiras de medir a eficiência dos algoritmos de compressão de dados, é 

apresentado um tipo de algoritmo de compressão de dados com perdas de extrema importância. 

 

2.2.1.2.1 Clusterização 

As técnicas de clusterização consistem em formar subgrupos, os mais homogêneos possíveis, de 

um conjunto de dados, de tal forma que cada cluster resultante incorpora um ou mais padrões 

representativos. As técnicas de clusterização são classificadas como um algoritmo de compressão de 

dados com perda, pois os detalhes dos dados são ignorados e somente os representantes de cada 

cluster são utilizados no processamento ou na tomada de decisão, não conseguindo assim, retornar 

aos dados iniciais. 

Sua aplicação percorre as mais diversas áreas como: aprendizado de máquina (Machine 

Learning), reconhecimento de padrões (pattern recognition) e processamento de imagens e sinais 

(image and signal processing). 

 

a) Quantização e Distorção 

Na Teoria da Aproximação, uma densidade pode ser aproximada por funções, de diversas formas, 

como por aproximações por séries polinomiais em todo o suporte, por discretização da função 

densidade com polinômios de distintas ordens em diferentes partes do suporte (elementos finitos), ou 

por misturas Gaussianas. Na Teoria da Informação, as aproximações devem ser eminentemente 

discretas, e não funcionais. Esse processo de aproximação é chamado de quantização, em analogia 

com a Mecânica Estatística.  



34 
 

 
 

Seja a variável aleatória ??(0,?) e sua representação ?. O problema de quantização consiste em 

encontrar os valores, em algum sentido ótimo, para ? e suas regiões do suporte associadas. Seja o 

ótimo definido pelo mínimo de 

 ?(?;?) = ??(?,?)[?(?,?)] = ??(?,?)[(? ? ?)
2].                                (2.38) 

 Cada representação de ? recebe o nome de pontos de código ou de reprodução, ou átomo. Neste 

texto, para reforçar o sentido estatístico do processo, dar-se-á preferência aos nomes como realização 

ou amostra. Levando em conta o sinal da variável, para duas realizações, como a função é quadrática, 

a solução é o centroide das duas metades da distribuição, dados pelo par (?1,?2) =

(??2? ?? ,?2? ?? ). O conjunto ?, o alfabeto, de regiões é uma partição de Dirichlet ou Voronoi. 

Associado ao par (?1,?2), há um par de probabilidades associadas (?1,?2) = (1 2? ,1 2? ), 

satisfazendo a equação de consistência, ?1 + ?2 = 1. O algoritmo que generaliza esse procedimento 

para um número qualquer realizações é chamado de Algoritmo de Lloyd, ou k-mean. Quando a 

variável aleatória é um vetor, definindo um campo aleatório, ele é chamado de Algoritmo de Lloyd 

Generalizado. 

A equação (2.38) define a esperança matemática de uma medida de distorção ?(?,?), quadrática. 

Diversas medidas de distorção podem ser definidas, a depender dos objetivos do problema. Medidas 

de distorção mais convenientes ao problema de mudança de escala serão definidas posteriormente. 

Muito importante, neste instante, é atentar para o fato de que quanto maior for o número de 

realizações utilizadas, ou taxa, menor será a medida de distorção. 

 

b) Medição da Eficiência 

A eficiência dos algoritmos de compressão de dados pode ser medida de diversas maneiras, dentre 

as quais podem ser citadas: a medida de complexidade do algoritmo utilizado, a memória 

computacional necessária para a implementação do algoritmo, a velocidade com que um algoritmo é 

executado em determinada máquina, a quantidade de dados comprimidos e, por fim, o quão próximo 

os dados reconstruídos estão dos dados fornecidos. Uma atenção especial será dada às duas últimas 

maneiras de medição. 

   Em relação à quantidade de dados comprimidos, as medidas podem ser feitas basicamente, de duas 

maneiras, são elas:  

? Taxa de Compressão (de informações probabilísticas): Mede a proporção da quantidade de 
informação antes e depois da realização da compressão dos dados, sendo expressa em termos 

de fração ou de porcentagem. 



35 
 

 
 

? Taxa, ou Taxa de quantização (de informações probabilísticas): expressa a quantidade de 
informação de maneira absoluta. A medição é realizada, em termos absolutos, comparando-o 

antes e o depois da compressão. 

Essas definições de taxas são essencialmente estocásticas, diferente de qualquer outra taxa 

determinística conveniente a um determinado problema. 

A proximidade dos dados reconstruídos com os dados fornecidos, por sua vez, é medida pela 

distorção, discutida na seção anterior. Como se verá adiante, este trabalho utiliza medidas de 

distorção quadráticas, porém, conceitualmente, diferente da Teoria da Informação.  

 

c) Quantização Relevante 

Seja ? o campo aleatório original quantizado pela sequência de realizações {??}?=1
?? , cada uma 

com sua probabilidade ?(?), e seja ? o campo aleatório comprimido e quantizado por realizações 

{??}?=1
?? , com probabilidades associadas ?(?). Os campos são finitos, e a compressão soft será feita 

com taxa determinística, ?? ? ??, a priori estabelecida. As probabilidades associadas ao campo 

comprimido serão obtidas por marginalização, 

?(?) = ? ?(?|?)?(?)???                                                   (2.39) 

Na Teoria da Informação, bem como nas diversas áreas de suas aplicações, as cardinalidades dos 

dois campos são iguais, ????(?) = ????(?) = ?.  Neste trabalho, como decorrência do 

estabelecimento de uma macromalha, ou uma compressão geométrica hard, as cardinalidades serão 

diferentes, quais sejam, 

 ? = ????(?),   ? = ????(?),   ??? ? ? ?.                                 (2.40) 

 

d) Teoria da Taxa de Distorção 

No processo de compressão, o que determina a qualidade da quantização? O primeiro fator é a 

taxa de informação. Porém, ela sozinha não caracteriza uma boa quantização por que pode sempre 

ser reduzida, desprezando detalhes do campo original. Há, portanto, uma necessidade de estabelecer 

restrições adicionais. 

Na Teoria da Taxa de Distorção, de Shannon e Kolmogorov (Cover, 2006), essa restrição é dada 

pela esperança matemática da distorção, 

?(?;?) = ??(?,?)[?(?,?)] = ? ? ?(?|?)?(?)?(?,?)?????? ,                    (2.41) 



36 
 

 
 

após marginalização, equação (2.39). Existe uma relação monótona de equilíbrio entre a taxa de 

quantização e a distorção: quanto maior a taxa, menor a distorção que se pode obter. Essa taxa, ?), 

é definida como a mínima taxa alcançável sob uma dada restrição, ???, na esperança matemática da 

distorção, 

?(?) ? min
?(?,?):?(?;?)&lt;???

?(?;?).                                            (2.42) 

 

Figura 2.5 – Função Taxa de Distorção.  

 

Fonte: Autor 

 

Encontrar a função da taxa de distorção é um problema variacional, que pode ser resolvido com 

auxílio de um multiplicador de Lagrange, ?,  para impor a restrição à distorção. Isso posto, resta 

minimizar o funcional, 

?[?(?|?))] = ?(?;?) + ??(?;?),                                               (2.43) 

sobre todas as distribuições ?(?|?), consistentes, ou seja, ? ?(?|?) = 1.???  Essa última condição 

exige mais um multiplicador de Lagrange ?(?) para cada ?; o funcional ser a extremado torna-se: 

?[?(?|?))] = ?(?;?) + ??(?;?) + ? ?(?)??? ? ?(?|?)??? ,                      (2.44) 

onde ambos, ? e ?, não devem ser negativos. O problema declarado pelo funcional (2.44) pode 

também ser resolvido pelo seu funcional complementar, 

??[?(?|?))] = ?(?;?) + ??(?;?) + ? ?(?)??? ? ?(?|?)??? .                     (2.45) 



37 
 

 
 

Os funcionais ? e ??  são simultaneamente extremados pela mesma densidade ?(?|?) e para ? =

??1. 

A solução do problema é dada pelo seguinte e bem conhecido resultado: 

Teorema 1 (Arimoto, 1972; Cover, 1991, 2006; Tishby, Pereira e Bialek, 1999). A solução do 

problema variacional 

??

??(?,?)
= 0,                                                              (2.46) 

para densidades ?(?,?) consistentes, é dada pela forma exponencial 

?(?|?) =
?(?)

?(?,?)
????(?,?),                                                 (2.47) 

onde ?(?,?) é uma função de normalização dada por 

?(?,?) =
?(?)

?(?)
= ? ?(?)????(?,?)??? .                                      (2.48) 

Além do mais, o multiplicador de Lagrange ?, determinado pelo valor da esperança matemática 

da distorção, ?, é positivo e satisfaz 

??

??
= ??,                                                               (2.49) 

onde ? é dado pela equação (2.42). 

É importante fazer alguns comentários adicionais. 

Comentário 1. A positividade do multiplicador de Lagrange ? é uma consequência da 

convexidade da função taxa de distorção, ?, dada pela equação (2.43).  

Comentário 2. A densidade dada pela equação (2.47) é conhecida por densidade de Gibbs, e 

converge para o delta de Dirac quando ? vai a zero. 

Comentário 3. A prática em machine learning e deep machine learning é fazer a quantização para 

um valor pré-especificado de ?; normalmente ? = 10?3 é considerado um bom parâmetro. O valor 

realmente adequado é obtido por experiência. 

  



38 
 

 
 

3) MULTIESCALAS HETEROGÊNEAS E ESTOCÁSTICAS 

Foi observado, no desenrolar do texto apresentado até agora, que duas são as principais diferenças 

entre a Teoria da Informação e o procedimento de aumento de escala preconizado neste trabalho. Ele 

corresponde, de certo modo, a uma extensão do trabalho de Weinan e Engquist (2003) para modelos 

estocásticos. 

A primeira diferença diz respeito às distintas cardinalidades entre os dois campos estocásticos, o 

de entrada, que descreve o campo paramétrico do sistema de equações na microescala, e o 

comprimido, que descreve o campo paramétrico no sistema de equações da macroescala. O campo 

original, dessa forma, é duas vezes comprimido. Uma compressão hard, promovida pela redução do 

modelo geométrico, da micromalha para a macromalha, (redução de sua cardinalidade), e uma 

compressão soft, ou probabilística, promovida por um algoritmo de compressão de dados da Teoria 

da Informação, configurando uma redução na dimensão probabilística. 

A segunda diferença acontece na Teoria da Taxa de Distorção, onde as distorções são mensuradas 

pelas diferenças entre valores dos dois campos, enquanto que este trabalho mede a distorção entre as 

soluções dos sistemas que regem o comportamento das distintas físicas nas duas escalas envolvidas. 

A redução do esforço computacional pela redução da ordem dos modelos (cardinalidade das 

realizações) e pela redução da dimensão probabilística (número de realizações) pode ser estimada. 

Suponha um problema elíptico e linear. A micromalha (macromalha) tendo cardinalidade ?(?), 

e dimensão probabilística ??(??), com relações ? = ?? ???  e ? = ? ?? . Se os sistema de equações 

é resolvido pelo método direto o tempo de solução (número de multiplicações) será proporcional ao 

cubo das cardinalidades. Assim, a redução de esforço será proporcional a ?3?. Para uma compressão 

com ? = 100, ou macroelemento contendo dez microelementos, e quantização com ? = 20, ou cinco 

por cento das realizações originais, típicas, a redução total será ?3? = 2 × 107. Em um problema que 

não seja linear essa redução aumentará em pelo menos uma ordem de grandeza. Porém, se o sistema 

de equações for muito grande, haverá grandes vantagens em resolvê-los iterativamente, com esforço 

proporcional ao quadrado da cardinalidade, pelo qual ?3? = 2 × 105 para os problemas lineares. Se 

a metodologia puder ser aplicada em problemas dependentes do tempo e que não sejam lineares, o 

esforço final será pelo menos duas ordens de grandezas menor para problemas sintéticos e 

acadêmicos. Esse é o caso, por exemplo, de simulação de reservatórios. Imagine-se agora que as 

simulações sejam partes de um problema de otimização estocástica, interna a um problema de 

controle estocástico. A redução do esforço computacional, será ainda muito maior. 

Neste Capitulo são discutidas as estratégias e os algoritmos envolvidos nos procedimentos aqui 

utilizados para aumento de escalas heterogêneas e estocásticas. 



39 
 

 
 

3.1  REDUÇÃO DA CARDINALIDADE. MALHAS ENCAIXADAS 

No procedimento de aumento de escala, pressupõe-se que as malhas envolvidas, a micromalha e 

a macromalha, estejam encaixadas, figuras 3.1 e 3.2, e que estão à disposição os códigos para resolver 

os respectivos sistemas de equações que regem os dois subproblemas. Sobrepondo as duas malhas, 

os macroelementos cobrem seus microelementos correspondentes. A solução exata para problemas 

elípticos e determinísticos discretizados por elementos finitos com modelos compatíveis consiste em 

condensar os graus de liberdade internos ou bolhas, vez que os espaços de soluções são hierárquicos. 

Na versão codificada neste trabalho, o código do macroelemento deve ser capaz de resolver certo 

problema inverso, a ser descrito posteriormente. Isso é apenas uma limitação da codificação ora feita, 

que tem caráter essencialmente investigativo e experimental. Isso não é uma limitação dos 

procedimentos propostos. Os resultados obtidos no decorrer deste trabalho sugerem que um maior 

esforço na codificação dos procedimentos para suplantar essa limitação é plenamente justificável. 

Isso será discutido posteriormente. 

Sendo ? o domínio discretizado, nos procedimentos aqui adotados o campo ou parâmetro espacial 

?(?) em um ponto? ? ?, é suposto possuir um, e apenas um, valor em cada elemento da micromalha. 

Para métodos (como por exemplo, elementos finitos) que permitam sua variação dentro de um 

elemento, adotar-se-á algum valor médio no seu interior (isso também é um problema de aumento de 

escala). O valor escalado para ??(?) é, de fato, resultante de uma homogeneização. Muito embora a 

física subjacente, eventualmente, não admita uma homogeneização matemática, o procedimento aqui 

utilizado fará essa homogeneização com um erro estabelecido pela taxa de distorção. Em alguns 

desses casos a distorção pode ser alta, Cover (2006). 

 

Figura 3.1 – Esquema Local-Local, ou LL, de malhas encaixadas. (Redução de cardinalidade com ? = 9, 

problema plano).  

 

Fonte: Weinan e Engquist, 2003. 



40 
 

 
 

As figuras 3.1 e 3.2 mostram duas formas distintas de efetuar a mudança de escalas. Na primeira, 

Local-Local, ou LL, apenas os elementos diretamente envolvidos são levados em conta. No sistema 

Semilocal-Local, ou SL, envolve-se a malha de interesse por camadas de outros elementos. Como 

discutido anteriormente, um procedimento SL é menos suscetível aos erros inevitáveis de condições 

de contorno e aos erros de ressonância. O esquema ideal, GL, terá um tempo de CPU muito alto, e o 

seu uso, a não ser para questões investigativas, não é justificado. Idealmente, as condições de contorno 

a serem utilizadas na solução do problema local da micromalha são retiradas da solução do problema 

resolvidos na micromalha (L, SL ou G). Na prática, condições de contorno menos específicas são 

utilizadas. Esses procedimentos são discutidos em caráter geral em Weinan e Engquist (2003), e em 

Chen e Durlofsky (2012) para o caso de reservatórios de petróleo. 

 

Figura 3.2 – Esquema Semilocal-Local, ou SL, de malhas encaixadas, tendo como limite o esquema 

Global-Local, ou GL.   

 

Fonte: Weinan e Engquist, 2003. 

 

 

 

 

 

 

 

 

 



41 
 

 
 

3.2 REDUÇÃO DA DIMENSÃO PROBABILÍSTICA 

A falta de bijeção entre as quantizações é, certamente, a mais importante consequência do uso de 

métodos de clusterização, por permitir uma redução das dimensões probabilísticas controladas, 

simultaneamente, pela acurácia, da representação e pela acurácia das respostas nas duas escalas. A 

figura 3.3 ilustra a relação entre as duas quantizações. 

 

Figura 3.3 – Redução da Dimensão Probabilística. Não há bijeção entre as realizações de ?e de ?.  

 

Fonte: Koutsourelakis, 2007. 

 

A quantização do espaço probabilístico da macromalha é controlada pela temperatura. 

Normalmente, há necessidade apenas de escolher uma quantização que não seja a ótima pela escolha 

de uma temperatura específica. Para aumentar a probabilidade de encontrar a configuração de 

equilíbrio no método semi-probabilístico aqui utilizado, é recomendável iniciar o resfriamento em 

uma temperatura maior do que a final desejada.  

A quantização correspondente à temperatura nula, normalmente, não pode ser encontrada. Existe 

uma temperatura mínima, ou distorção mínima, ou taxa máxima, que uma dada compressão pode 

alcançar (Culver, 2006), chamada então de taxa de compressão ótima. Resfriar até o menor valor de 

temperatura possível é um exercício puramente investigativo. 

Na taxa de compressão ótima é muito provável que o campo gerado na macromalha tenha perdido 

a sua estrutura geoestatística (característica dos variogramas na geoestatística de dois pontos, ou a 

descaracterização dos canais na geoestatística de três pontos). Desta forma, para ser preditiva, a 

compressão deve ater-se a valores razoáveis de temperatura. 

A similaridade entre os campos goestatísticos das duas escalas deve ser verificada visualmente. 

Claramente, uma boa preditividade somente pode ser verificada a posteriori, após o campo tiver sido 



42 
 

 
 

mais depletado ao decorrer do tempo, embora se possam desenvolver técnicas para aumentar a 

probabilidade preditiva. Essa é uma área investigativa muito interessante. A área de ajuste ao 

histórico também se preocupa com essas questões. Sabe-se que os ajustes de históricos não podem 

deter-se apenas ao ajuste dos modelos aos dados de produção. A capacidade preditiva dos modelos 

ajustados depende também de sua fidelidade à estrutura geoestatística. 

O casamento entre o ajuste ao histórico de produção e o aumento de escala dos reservatórios, pelo 

conhecimento do autor, ainda não foi feito. 

 

3.3 MEDIDAS DE DISTORÇÃO 

Idealmente, as medidas de distorção a serem utilizadas devem satisfazer duas condições: serem 

funções convexas, e serem finitas quando os seus argumentos forem finitos. Isso garante a 

convexidade, e, portanto, a unicidade da solução para cada valor de ?, do problema variacional 

estabelecido pela equação (2.44). 

Nas aplicações deste trabalho foram adotadas duas medidas quadráticas para a distorção. Em 

princípio, ?(?,?):??? × ??? ? ?+, Uma primeira medida de interesse é dada por, 

?(?,?) = (?(?) ? ?(?))
2
,                                               (3.1) 

onde ?(?) e ?(?) são as soluções dos sistemas de equações na micro e na macroescala, 

respectivamente. Aquelas soluções não precisam ater-se as variáveis de estado, mas, podem ser 

estendidas a variáveis econômicas, por exemplo. As letras, minúscula em ?(?) e maiúscula em ?(?), 

servem para enfatizar a possibilidade de utilização de diferentes físicas. 

Essas respostas correspondem à estatística de uma solução em todo o domínio, ?, ou em parte 

dele ?? ? ?, mesmo que em um único ponto do domínio. Pelas características dos procedimentos 

propostos, é de esperar-se que valores médios ou característicos sejam obtidos com menor distorção. 

Exemplos de valores característicos em reservatórios de petróleo são as estatísticas P5, P10, P50, 

etc., do valor presente líquido de um problema de gerenciamento de reservatórios, ou de valores de 

pressões em uma simulação de reservatórios. 

Em casos, como alguns descritos acima, é conveniente utilizar expressões que representem 

médias aritméticas amostrais, do tipo, 

?(?,?) =
1

?
? (??(?) ? ??(?))

2
,??=1                                            (3.2) 



43 
 

 
 

onde o índice ? pode indicar, por exemplo, cada uma das ? componentes das respostas em um 

determinado ponto, ou em pontos distintos, do domínio. A esperança matemática da distorção 

continua a mesma da equação (2.38),  qual seja, 

?(?;?) = ??(?,?)[?(?,?)]                                                   (3.3) 

 

3.4 ALGORITMO DE ARIMOTO (DE SUBSTITUIÇÕES SUCESSIVAS) 

Uma consequência da formulação variacional discutida no Capítulo 2, sintetizada no Teorema 1, 

é que ela propicia um algoritmo iterativo, Arimoto (1972) e Blauht (1972), para a determinação 

consistente densidades ?(?|?) e ?(?), dadas pelas equações (2.39) e (2.47). Assim, o algoritmo 

determina a partição ótima do suporte das realizações, mas não os valores representativos de ?.  

Neste trabalho, é essencial também determinar aqueles valores representativos, para um dado 

valor de ?, bem como o valor ótimo que minimize a distorção, dada a partição. O algoritmo 

Deterministic Annealing (DA), aqui utilizado, e discutido adiante, resolve os dois problemas. 

O problema consiste em satisfazer as equações (2.39) e (2.47) de forma autoconsistente. Um 

processo natural é resolver aquelas equações por substituições sucessivas, até uma precisão pré-

estabelecida. O seguinte Lema auxiliar estabelece a convergência global para esse caso. Convergência 

global é uma altamente desejável propriedade que possuem alguns algoritmos de aproximarem-se da 

resposta desejada, o tanto quanto se queira, para todo e qualquer ponto de partida. 

 

Lema 2. (Csiszár e Tusnády, 1984). Seja ?(?,?) = ?(?|?)?(?) uma distribuição conjunta. Então, a 

distribuição ?(?) que minimiza a Entropia Relativa ou divergência KL, ??? é a marginal 

?(?) = ??(?|?)?(?)

???

. 

Especificamente,  

?(?;?) = ???[?(?,?)||?(?)?(?)] = min
?(?)

???[?(?,?)||?(?)?(?)]. 

De forma equivalente, a distribuição ?(?) que minimiza a esperança matemática da entropia, 

??(?)

???

???[?(?|?)||?(?)], 

é também a marginal ?(?) = ? ?(?|?)?(?).???  



44 
 

 
 

A prova desse Lema é consequência direta de que a entropia relativa não é negativa. Ele 

garante que as equações (2.39) e (2.47) provêm do mesmo princípio variacional. 

 

Teorema 3. (Algoritmo de Arimoto, 1972). As equações (2.39) e (2.47) são satisfeitas 

simultaneamente no mínimo do funcional, equação (2.44), 

? = ???(?)[?(?,?)] = ?(?;?) + ??(?;?), 

onde a minimização é feita independentemente sobre os conjuntos convexos de densidades 

consistentes, {?(?)} e {?(? ? ?)}, 

???
?(?)

???
?(?|?)

?[?(?);?(?|?)]. 

Essas condições independentes correspondem precisamente às equações (2.39) e (2.47). 

Denotando uma etapa iterativa por ?, 

{
 

 ?? (?|?) =
??(?)

??(?,?)
????(?,?)

??+1(?) = ? ??(?|?)?(?)
???

 

onde a função de normalização ??(?,?) é atualizada a cada iteração ? pela equação (2.48). Além 

disso, aquelas iterações convergem para um único mínimo do funcional ?, no conjunto convexo das 

duas densidades. 

Para prova desse teorema, ver Cover (2006). Como observado anteriormente, os valores 

quantizados, em particular os valores ótimos que minimizam a distorção, serão obtidos com auxílio 

do DA. 

 

3.5 ALGORITMO DE ROSE (DA)  

O Deterministic Annealing (DA, Recozimento Determinístico) é a versão determinística do 

Simulated Annealing (SA, Recozimento Simulado) que recebe este nome devido à sua analogia ao 

processo de recozimento físico-químico de materiais, no qual o processo de resfriamento controlado 

inicia-se a altas temperaturas de tal forma a aumentar o tamanho dos cristais e reduzir os seus defeitos, 

enquanto o equilíbrio térmico é mantido. A solução conjunta ótima, sendo a de Gibbs, torna o SA um 

algoritmo atraente. 

O SA é utilizado para encontrar o mínimo global de uma função com um grande número de 

variáveis, como na Mecânica Estatística do Equilíbrio, no processo de quantização, quando a 

precisão não é um item fundamental. Dentro dos ciclos de resfriamento há um algoritmo estocástico 

(normalmente, o algoritmo de Metropolis ou alguma variante) para a determinação da configuração 



45 
 

 
 

de equilíbrio em cada temperatura. A cada nova temperatura, a solução, ou estado de equilíbrio, 

eventualmente, aumenta o número de quantas (realizações). Esse, portanto, seria um método ideal 

para o processo de compressão proposto nesse trabalho, não fora a sua imprecisão nos valores e 

probabilidades associadas da quantização. Essa imprecisão é uma qualidade inerente aos algoritmos 

estocásticos, que pode ser resolvido por hibridização com um algoritmo determinístico (Fonseca, 

2015). 

O DA (Rose, 1991, 1994, 1998) faz essa hibridização substituindo o algoritmo estocástico no 

interior do SA pelo steepest descent (SD), produzindo um novo algoritmo com muito melhores 

propriedades de convergência. O inconveniente é que, pelo menos em princípio, o gradiente 

necessário no SD deve ser analítico (portanto, algoritmos livres de derivadas, e desprovidos de algum 

complemento determinístico, devem ser evitados), significando que esse gradiente deve ser 

determinado para cada medida de distorção escolhida. O SA e o DA, na busca do mínimo global 

(nem sempre desejado, normalmente, é suficiente uma solução soft), determina uma sucessão de 

mínimos locais de extrema importância na Teoria da Informação (machine learning) e nos 

procedimentos aqui preconizados para o aumento de escala. 

Contrariamente ao SA, não há prova de convergência para o mínimo global, no caso geral, mas 

apenas de convergência global. Entretanto, como estabelecido anteriormente neste texto, cada 

problema local do DA (cada temperatura ou valor de ?) utilizado neste trabalho é convexo, e a 

extremização do funcional é também um problema convexo, conforme o Teorema 3.  

O procedimento de mudança de escala proposto neste trabalho, pelo fato de a redução geométrica 

(reduced order) ser estabelecida pelo usuário, ao criar os macroelementos de acordo com a sua 

percepção, é efetuado macroelemento a macroelemento, em um dos esquemas LL ou SL, sem 

qualquer prejuízo à generalidade dos procedimentos. Matematicamente, o espaço de realizações ? 

terá uma única variável aleatória, com ?? realizações ? ? ?. As ?? amostras, realizações, ou quantas, 

poderão ser, doravante, e eventualmente, indexadas: ??,? = 1,…,??. 

O aspecto crucial no DA é a determinação do gradiente do funcional ótimo em relação a cada 

amostra ??. Para isso, é conveniente utilizar o funcional complementar, dado pela equação (2.45), 

??[?(?|?))] = ?(?;?) + ??(?;?) + ? ?(?)??? ? ?(?|?)??? . 

Substituindo a densidade ótima, de Gibbs, nesse funcional, obtém-se, 

?? = ?? ??(?)log??(?)?
?
?(
?

??????

+ ?? + ??(?)

???

??(?|?)

???

. 

É conveniente escrever a distribuição ótima, equação (2.48), como, 



46 
 

 
 

??(??|?) =
?(??)

?(?,?)
?
?
?(?,??)

?  .                                                 (3.4) 

O gradiente a ser utilizado no método do steepest descente é obtido a partir da seguinte condição 

necessária de mínimo, para uma dada macrorealização (os termos com ?? desaparecem devido à 

condição de Kuhn-Tucker), 

???

???
= ? ?(?)??? ??(??|?)

??(?,??)

???
= 0.                                           (3.5) 

Para o caso das distâncias dadas pela equação (3.1), essa última expressão, equação (3.5), toma a 

forma, 

???

???
= 2? ??(??|?)?(?)[?(??) ? ?(?)]???

??(??)

???
                              (3.6) 

= 2[?(??)?(??) ? ?(?,? ?)]
??(??)

???
= 0 ,                                                  

resultando em, 

?(??)?(??) = ?(?;??),                                                   (3.7) 

onde, 

?(?;??) = ??(?,??)[?(?)] = ? ??(??|?)?(?)?(?)??? ,                       (3.8) 

e, finalmente, 

?? = ?
?1 [

??(?,??)
[?(?)]

?(??)
] = ??1 [

?(?;??)

?(??)
]                                        (3.9) 

 

O problema inverso no macroelemento declarado na equação (3.9) tem apenas uma dimensão, 

uma variável, porém, em algumas situações de interesse, ele não é um problema linear, exigindo um 

processo iterativo, a uma variável, na sua solução. 

Deve-se notar, equação (3.9), que o valor da realização depende diretamente da esperança 

matemática conjunta e condicionada, ??(?,??), da resposta da microescala, ponderada inversamente 

pela probabilidade do quanta, ?(??). 

A alternativa certa à solução analítica da equação (3.9) é utilizar o steepest descent na forma 

numérica utilizando a equação (3.6), calculando precisamente o gradiente, 
??(??)

???
. Note, porém, que, 

tendo o problema apenas uma variável, deve ser suficiente a estimativa do gradiente por diferenças 

finitas com alta precisão. 

Já para o caso das distâncias definidas pela equação (3.2), a equação (3.5) toma a forma, 

???

???
= 2? ??(??|?)?(?)? [??(??) ? ??(?)]

???(??)

???

?
?=1??? = 0,               (3.10) 



47 
 

 
 

portanto, 

?(??)? ??(??)
???(??)

???
=??=1 ? ??(??|?)?(?)? ??(?)

???(??)

???

?
?=1??? ,             (3.11) 

Por consequência, não é possível eliminar as derivadas da resposta na macromalha, e determinar 

um valor para a realização com facilidade. 

Uma alternativa é fazer o aprendizado para cada uma das ? funções separadamente, utilizando a 

distância definida pela equação (3.1). Note, entretanto, que o problema tem apenas uma variável, 

permitindo diversas possíveis soluções analíticas e numéricas. 

Mas, é ainda possível encontrar um macroelemento equivalente fazendo ?(??) = ??(??), para 

cada ?, que aprenderá a resposta média aritmética das ? funções. Nesse caso, 

?(??)?(??) = ? ??(??|?)?(?)
1

?
? ??(?)
?
?=1??? ,                         (3.12) 

e, por fim, como antes, 

?(??)?(??) = ?(?;??),                                             (3.13) 

onde,  

?(?;??) = ??(?|??)[???(?)] = ? ??(??|?)?(?)???(?)??? ,                    (3.14) 

é a esperança matemática conjunta e condicionada da média aritmética,???(?),  das ? respostas na 

microescala, dada por  

???(?) =
1

?
? ??(?),
?
?=1                                                     (3.15) 

e, finalmente, 

?? = ?
?1 [

?(?;??)

?(??)
].                                                    (3.16) 

 

Na próxima página está o algoritmo DA na sua forma paralela (PDA). O algoritmo parte de uma 

temperatura suficientemente alta. Na dúvida sobre o valor da temperatura inicial, o algoritmo pode 

ser codificado com ?, e inicializado com ? = 0. Essa parece ser a forma preferida na literatura na 

área de tecnologia da informação, onde, na maioria das vezes, as realizações obtidas com um único 

valor finito de ? é suficiente. Há inúmeras aplicações com ? = 10?3. 

Não se conhece, a priori, a quantidade de realizações para uma dada temperatura. Por isso, a cada 

nova temperatura, trabalha-se com a possibilidade de que o número de realizações vai dobrar. A 

suficiência da aproximação da resposta exata é verificada com duas constantes fornecidas pelo 



48 
 

 
 

analista, ?1 e ?2. Uma para o controle de convergência do valor das realizações e outra para suas 

probabilidades, e reunir em um só quanta, dois quantas próximos. O Algoritmo está codificado para 

a distorção dada pela equação (3.1). Para a distorção dada pela equação (3.2), com ?(??) = ??(??), 

para cada ?, a expressão da distorção na declaração (2)a. do Algoritmo, passa a ser, 

2

1

( , ) [ ( ) ( )]
M

j k k i j

i

d x y R y r x
?

? ?? . 

Essa expressão é mais condizente com o conceito de clusterização do que a mais geral equação (3.2). 

Enquanto que ?? na declaração (2)e. passa ser dada pela equação (3.14). 

  



49 
 

 
 

Figura 3.4 – Algoritmo de Simulação Determinística em paralelo. 

 

Algoritmo PDA: Parallel Deterministic Annealing 

Para a distância  ?(?,?) = (?(?)? ?(?))
2
. 

(1) Inicie com 1,K ?  um valor suficientemente alto max ,T T?  um fator 1,? ?  1y  arbitrário, 1 1,q ?  1,?

2
?  tolerâncias para convergências, e fT  um valor final próximo de zero, faça  1 ,T? ?  0fT ? . 

(2) Para 1, 2,..., ,k K?  em paralelo para cada realização da microescala. 

a. Calcule as RN distâncias a ,ky  
2

( , ) [ ( ) ( )] ,
j k k j

d x y R y r x? ?  

b. Calcule os RN denominadores, 
1

( ) exp[ ( , )],
K

j i j ii
Z x q d x y?

?
? ??  

c. Calcule as RN  densidades condicionais, 
exp[ ( , )]

( | ) ,
( )

k j i

k j

j

q d x y
p y x

Z x

??
?  

d. Estime a marginal de ,ky  
1

( ) ( | ),
RN

k j k jj
q p x p y x

?
? ?  

e. Estime 
1

( ) ( | ) ( ),
RN

k j k j jj
G p x p y x r x

?
? ?  

f. Resolva o problema unidimensional 
1
( ),k

k

k

G
y R

q

?
?  

(3) Verifique com 1,?  a convergência para ky  e .kq  Se não satisfeita, repita a etapa (2). De outra 

forma, continue para a etapa (4), 

(4) Estime a distorção média e o indicador, (em paralelo), 

a. A distorção média, 
1 1

( ) ( | ) ( , ),
RK N

j k j j kk j
D p x p y x d x y

? ?
? ? ?  

b. O indicador, 
1 1

( | )
( ) ( | ) log ,

RK N k j

j k jk j
k

p y x
I p x p y x

q? ?
? ? ?  

(5) Reduza a temperatura, .
f

T T T?? ?  

(6) Dobre o número de realizações, ou seja, inicialize ,K k ky y? ?  ,K k kq q? ?  1k K? K , faça 2K K?

, vá para (2). 

(7) Elimine as redundâncias com 2?  em ,Y  determine ,Rn K?  e consolide , 1, , .k Rq k n? K  Fim. 
 

Fonte: o Autor 

  



50 
 

 
 

4 APLICAÇÕES 

Nessa seção realizaremos aplicações de maneira que seja possível analisar o procedimento 

apresentado nas seções anteriores. Todos os 5 exemplos desta seção foram estudados com um modelo 

Global-Local. 

 

Exemplo 1  

Considere (Koutsourelakis, 2007) a equação diferencial de segunda ordem com uma variável 

a coeficientes estocásticos com ? ?? , ?  o espaço amostral, 

?

??
[?(?,?)

??

??
] = 0, ? ? [0,1],                                               (4.1) 

com condições de contorno mistas, ?(0) = 0 e ?(1) = ?(1)
??

??
|
?=1

. 

Essa equação corresponde tanto a um problema de fluxo monofásico em regime permanente 

em um meio poroso com pressão e velocidade prescritas; quanto uma barra elástica com força e 

deslocamento prescritos.  

 

Figura 4.1 – Barra elástica ou reservatório unidimensional monofásico em regime permanente.

 

Fonte: o Autor. 

 

A variabilidade do parâmetro ?(?,?) é dada por,  

?(?,?) = 1 + 0,5???(2?
?

?0
+ ?(?))                                   (4.2) 

onde o ângulo de fase ?(?) é uniformemente distribuído no intervalo [0,2?], e a constante ?0 

caracteriza o comprimento ou escala de correlação da heterogeneidade espacial. Para cada realização, 

há um parâmetro equivalente, ou efetivo, dado pela média harmônica dos seus valores no domínio. 

Para pequenos valores do comprimento de correlação a variância é pequena e a distribuição do 

parâmetro efetivo pode ser dada pela sua média harmônica apenas. 



51 
 

 
 

O problema consiste em encontrar a distribuição equivalente para a determinação de ?(1) 

quando o comprimento de correlação for grande, tipicamente, maior do que o domínio.  

A micromalha escolhida possui 1000 elementos. Para ?0 = 1 100? , o campo estocástico foi 

descrito por 100 realizações da microescala, e calculadas as 100 soluções (1)p , uma para cada 

realização. São então estimadas as realizações da macroescala, orientadas para a estimativa de (1).p  

O problema é essencialmente determinístico e o resultado é uma única realização com o parâmetro 

dado pela média harmônica. A esperança matemática da distorção é nula. 

Tomando ?0 = 10 ? 1, maior do que a extensão do domínio geométrico, e simulando 1000 

realizações da microescala, foram calculadas novamente as macrorealizações, com o mesmo objetivo 

de determinar ?(1). A Figura 4.2 mostra o gráfico da Taxa pela Distorção. Para evitar que o algoritmo 

permaneça aprisionado em um mínimo local, foram utilizadas apenas ?? = 500 realizações por meio 

de seleções aleatórias, durante o resfriamento, dos valores de ?(1) na microescala. A temperatura 

inicial utilizada foi ? = 100 com um resfriamento lento dado por 1 / 1.001?a . A Figura 4.3 mostra 

a densidade ótima das propriedades efetivas calculadas para a macroescala. As distribuições nas duas 

escalas são mostradas na figura. 4.4.  

 

Figura 4.2 - Curva da Distorção Média com a Informação Mútua, Exemplo 1.

 

Fonte: o Autor. 

 

 

 

 

 



52 
 

 
 

Figura 4.3 - Densidade e Distribuição das realizações nas duas escalas, Exemplo 1, apenas 1 macroelemento. 

 

Fonte: o Autor. 

 

Figura 4.4 - Distribuição das realizações do deslocamento (pressões) na macroescala, microescala e exata. 

Exemplo 1, apenas 1 macroelemento. 

 

Fonte: o Autor. 

 

 

 



53 
 

 
 

A figura 4.4, mostra a distribuição exata de p(1), obtida utilizando os parâmetros efetivos, 

????, ? = 1,…,1000, dados pelas médias harmônicas dos parâmetros dos elementos em cada 

realização i. A solução para cada realização i é dada por, 

 

                    ??(1) = ?(1)/???? = 1/????, (4.3) 

 

enquanto que as probabilidades ??[(??(1)] das 1000 realizações da solução ??(1), ? = 1,…,1000, 

são uniformemente distribuídas, e dadas por 

 

            ??[(??(1)] =
1
1000?  (4.4) 

 

As distribuições de p(1) na microescala e na macroescala também são mostradas na figura 4.4. 

A amostragem na microescala, para cada uma das realizações, foi obtida a partir da solução do sistema 

linear decorrente da discretização da equação (4.1). As probabilidades das N_R realizações na 

micromalha são uniformemente distribuídas com 1/??, onde ?? = 1000. 

 

           ?(1)??? ?? ?? ?? ?? = ?(1)????????  ? ? ??
?1 (4.5) 

 

A distribuição ótima da solução na macroescala foi obtida com as realizações ?? e suas 

respectivas probabilidades ??, decorrentes do PDA, conforme figura (4.3). As probabilidades 

??[??(1)] dos ??(1) ótimos são obtidas como, 

         ??(1) =
?(1)

??
 (4.5) 

 

             ??[??(1)] =
?[?(1)]

?(??)

1

??
=
?(??)

?1

??
 (4.6) 

onde, ?? = ?
1

?(??)

??
?=1   é uma constante de normalização, com ?? = 103. 

 

Na figura 4.4, nota-se uma pequena diferença entre os valores obtidos de ?(1) na microescala 

e na exata, na qual decorre do processo utilizado em seu cálculo, sendo a microescala através de 

sistemas lineares e a exata utilizando parâmetros efetivos. De modo que, tratando-se de um problema 

estocástico, pequenas variações podem ser encontradas para distintos métodos de solução.  



54 
 

 
 

Exemplo 2 

Este exemplo realiza um aumento de escala de uma micromalha com 1000 elementos para 

uma macromalha de 10 elementos de iguais comprimentos (baseado em Koutsourelakis, 2007). A 

equação diferencial é da mesma forma da equação (4.1), também no intervalo unitário, com condições 

de contorno de Dirichlet, (0) 0?p , e com (1)p  variando no intervalo [0,3] dividido, para efeito de 

cálculo, em 10 subintervalos iguais. O parâmetro estocástico, no entanto, não é linear, sendo função 

da derivada espacial de ?, na forma ?(??,?,?) nos seguintes moldes: 

?(??,?,?) = ??, se ?(?,?) ? 0,3 + 0,3?[??(?)],                                  (4.6) 

?(??,?,?) =
?(?)

1+?(?)
 ,?(?) = ?[??(?)], se ?(?,?) &gt; 0,3 + 0,3?[??(?)], 

onde ? ? [0,1], e ??(?), ??(?), são campos Gaussianos independentes com a mesma autocorrelação 

espacial dada por ?(??) = ???(?|??| ?0? ) e ?[?] é a distribuição acumulada Normal, padrão. 

Neste exemplo,?0 = 1 100 ?? 1. Foi utilizada uma micromalha com 1000 elementos. 

O objetivo do aumento de escala é a determinação de ?(0), para cada um dos 10 subintervalos 

iguais de ?(1) ? [0,3]. Para isso, inicialmente, foram realizadas 100 simulações da microescala de 

1000 elementos de iguais comprimentos e parâmetro dados pela equação 4.3, com o método de 

Newton-Raphson modificado, com o objetivo de estimar os valores de ?(0) para cada simulação, 

com ?(1) variando no intervalo [0,3], em 10 subintervalos. Para a determinação da quantidade ótima 

de realizações para cada macroelemento, foi utilizada a equação 3.2, onde, neste Exemplo 2, na 

determinação dos 10 valores de ?(0), e dos 10 de ??(0), foi utilizado o mesmo algoritmo de Newton-

Raphson modificado.  Para obtenção dos 10 valores na macromalha de ??(0), ??(1) foi aplicado em 

10 subintervalos do intervalo, com base na hipótese simplificadora de que há proporcionalidade de ? 

com o comprimento (?? = ? 10? ). 

a) Após a determinação da quantidade ótima de realizações da macroescala para cada 

macroelemento, foi realizada uma comparação entre o problema na microescala, (1000 elementos e 

100 realizações) com a macromalha composta pelos 10 macroelementos (? = 100), porém com 

apenas 10 realizações (? = 100). As figuras 4.4 a 4.6 e a tabela 4.1 mostram os resultados obtidos. 

As 10 realizações de cada macroelemento foram uniformemente amostradas de suas respectivas 

densidades, após o que foram normalizadas.  

Como resultado da extremamente pequena quantidade de realizações da macroescala, as 

médias para cada um dos 10 intervalos de ?? resultaram apenas razoáveis, com substancial redução 

artificial da incerteza, como esperado, demonstrada pelos pequenos desvios padrões.  

 



55 
 

 
 

Figura 4.5 - Distorção × Taxa, ?(1) = 1,5, Exemplo 2, para 1 macroelemento. 

   

Fonte: o Autor. 

 

Figura 4.6 - Densidade dos parâmetros para ?(1) = 1,5, Exemplo 2, para 1 macroelemento. 

 

Fonte: o Autor. 

 

 

 

 



56 
 

 
 

Figura 4.7 – Distribuição de ?(0) e ??(0) para  ?(1) = 1,5, Exemplo 2, macromalha com 1 macroelemento. 

 

Fonte: o Autor. 

 

 

 

 

Figura 4.8 - Densidades de ??(0),  e ?(0)para  ?(1) = 1,5, Exemplo 2, macromalha com 10 

macroelementos. 

 

Fonte: o Autor. 

  



57 
 

 
 

Tabela 4.1: Resumo dos Resultados obtidos no exemplo 2.a). 

?? = ?,???? ? ???? 

???? = ? ? ???? 

???? = ? ? ???? 

Tabela Resumo do Exemplo 2.a) 

??? ?(?) ???? ???? ?? 

?(?) 

?????? ?????? 
??????
??????

 ?????? ?????? 
??????
??????

 

? 0,3 3 × 10?32 0 1 5,9 × 10?17 5,0 × 10?16 0,117 0,3 0,3 1 

? 0,6 4,32 × 10?5 1,13 54 0,008 0,023 0,348 0,458 0,433 1,057 

? 0,9 3,82 × 10?5 1,80 32 0,017 0,047 0,361 0,507 0,479 1,060 

? 1,2 4,03 × 10?5 1,93 17 0,020 0,049 0,411 0,544 0,543 1,002 

? 1,5 3,77 × 10?5 2,17 19 0,051 0,069 0,742 0,545 0.565 0,963 

? 1,8 3,37 × 10?5 1,96 11 0,033 0,053 0,625 0,614 0,602 1,02 

? 2,1 3,62 × 10?5 2,22 14 0,035 0,701 0,504 0,726 0,667 1,088 

? 2,4 2,57 × 10?5 2,81 19 0,090 0,153 0,586 0,532 0,636 0,837 

? 2,7 2,89 × 10?5 2,78 19 0,034 0,125 0,268 0,662 0,686 0,965 

?? 3,0 2,89 × 10?5 2,69 21 0,064 0,123 0,518 0,782 0,812 0,963 

Fonte: o Autor. 

 

Observa-se que, no intervalo 2 e 3 onde, ?(1) = 0.6 e ?(1) = 0.9, encontra-se a região de 

interface da parametrização utilizada. Sendo assim, a região de maior variabilidade encontrada nesta 

aplicação. A partir dos resultados demonstrados na tabela 4.1 pode-se verificar que o algoritmo PDA 

conseguiu representá-la bem, visto que, assim como as razões entre as médias da macroescala e da 

microescala ficaram próximas à unidade, a quantidade encontrada de realizações, ??, para a 

macroescala, naqueles intervalos, foi bem superior do que os demais valores de ?(1). 

 De maneira geral, as ???? apresentaram bons resultados, com ordem de grandeza de 10
?5, 

adicionalmente, o primeiro intervalo, ?(1) = 0.3, por se tratar de um intervalo puramente 

determinsítico, apresentou um ???? bem inferior aos demais. A Informação Mútua apresentou 

resultados razoáveis, em se tratando de um problema não linear. Para os desvios padrões, observa-se 



58 
 

 
 

uma grande diferença entre os valores obtidos nas duas escalas, o reflexo disso é a razão entre os 

desvios das duas escalas estarem distantes da unidade. Já era esperado esse fato, já que a quantidade 

de realizações utilizadas na microescala é bem superior às utilizadas na macroescala.  

 

b) O procedimento é repetido com a seleção das 10 macrorealizações de maiores 

probabilidades, após o que, normalizadas. O macroelemento 1, determinístico, teve a sua realização 

repetida em cada uma das 10 macrorealizações.  

 

Tabela 4.2: Resumo dos Resultados obtidos no exemplo 2.b). 

?? = ?,???? ? ???? 

???? = ? ? ???? 

???? = ? ? ???? 

Tabela Resumo do Exemplo 2.b) 

??? ?(?) ???? ???? ?? 

?(?) 

?????? ?????? 
??????
??????

 ?????? ?????? 
??????
??????

 

? 0,3 3 × 10?32 0 1 5,9 × 10?17 5,0 × 10?16 0,117 0,3 0,3 1 

? 0,6 4,32 × 10?5 1,13 54 0,013 0,023 0,564 0,448 0,433 1,034 

? 0,9 3,82 × 10?5 1,80 32 0,034 0,047 0,728 0,501 0,479 1,047 

? 1,2 4,03 × 10?5 1,93 17 0,023 0,049 0,467 0,539 0,543 0.993 

? 1,5 3,77 × 10?5 2,17 19 0,053 0,069 0,769 0,522 0.565 0,923 

? 1,8 3,37 × 10?5 1,96 11 0,038 0,053 0,720 0,610 0,602 1,013 

? 2,1 3,62 × 10?5 2,22 14 0,046 0,070 0,660 0,710 0,667 1,064 

? 2,4 2,57 × 10?5 2,81 19 0,076 0,153 0,498 0,572 0,636 0,900 

? 2,7 2,89 × 10?5 2,78 19 0,049 0,125 0,392 0,643 0,686 0,938 

?? 3,0 2,89 × 10?5 2,69 21 0,085 0,123 0,696 0,788 0,812 0,971 

Fonte: o Autor. 

 

Os resultados obtidos pela tabela 4.2 demonstram uma certa melhora na precisão das razões 

das médias em relação à tabela 4.1, com exceção dos intervalos correspondentes ao ?(1) = 1,2, 

?(1) = 1,5 e ?(1) = 2,7. No entanto, as diferenças entre as razões das médias, nesses intervalos, não 



59 
 

 
 

são superiores à 5%. Além disso, é possível verificar que, mesmo com a redução da quantidade de 

realizações, foi possível obter resultados precisos e acurados para os dados em estudo, visto que, as 

razões das médias continuam próximas à unidade. 

 

c) O procedimento foi repetido com 5 macrorealizações de maiores probabilidades. 

Novamente, o macroelemento 1, determinístico, teve a sua realização repetida em cada uma das 5 

macrorealizações. 

 

Tabela 4.3: Resumo dos Resultados obtidos no exemplo 2.c). 

?? = ?,???? ? ???? 

???? = ? ? ???? 

???? = ? ? ???? 

Tabela Resumo do Exemplo 2.c) 

??? ?(?) ???? ???? ?? 

?(?) 

?????? ?????? 
??????
??????

 ?????? ?????? 
??????
??????

 

? 0,3 3 × 10?32 0 1 5,9 × 10?17 5,0 × 10?16 0,117 0,3 0,3 1 

? 0,6 4,32 × 10?5 1,13 54 0,009 0,023 0,393 0,429 0,433 0,991 

? 0,9 3,82 × 10?5 1,80 32 0,036 0,047 0,761 0,465 0,479 0,971 

? 1,2 4,03 × 10?5 1,93 17 0,023 0,049 0,471 0,521 0,543 0,960 

? 1,5 3,77 × 10?5 2,17 19 0,028 0,069 0,403 0,471 0.565 0,833 

? 1,8 3,37 × 10?5 1,96 11 0,021 0,053 0,389 0,571 0,602 0,948 

? 2,1 3,62 × 10?5 2,22 14 0,033 0,070 0,476 0,672 0,667 1,007 

? 2,4 2,57 × 10?5 2,81 19 0,060 0,153 0,391 0,625 0,636 0,983 

? 2,7 2,89 × 10?5 2,78 19 0,067 0,125 0,534 0,636 0,686 0,928 

?? 3,0 2,89 × 10?5 2,69 21 0,096 0,123 0,781 0,784 0,812 0,966 

Fonte: o Autor. 

 

Com uma redução ainda maior na quantidade de realizações, foi obtido os resultados da tabela 

4.3, na qual demonstra que as razões das médias, ainda, são aderentes à unidade. No entanto, verifica-

se que, quando a redução das realizações for acentuada, as estimativas dos resultados perdem sua 



60 
 

 
 

acurácia. Obtendo assim, uma estimativa precisa, mas não acurada. Isso é fácil de verificar, já que as 

razões das médias apesar de próximas à unidade, ficaram, em sua maioria, inferior à unidade, o que 

pode caracterizar um viés na estimativa das respostas. 

 

Exemplo 3 

Neste problema, são utilizadas as mesmas formulações e objetivos do exemplo 2. Entretanto, 

deseja-se que a física da macroescala seja linearizada, ou seja, ?(??,?,?) = ?(?,?), na equação 4.3, 

na tentativa de tornar os algoritmos de solução ainda mais eficientes. Como resultado dessa 

linearização, as físicas das escalas são distintas, e há um ganho computacional enorme. As figuras 

(4.7) a (4.9) e a tabela 4.2 mostram os novos resultados. Nota-se um aumento do erro da média, como 

era de se esperar. 

a) Procedimento com 10 macrorealizações uniformemente amostradas, após o que normalizadas. 

 

Figura 4.9 - Distorção × Taxa, ?(1) = 2,7, Exemplo 3, para 1 macroelemento. 

 

Fonte: o Autor. 

 

 

 

 

 

 



61 
 

 
 

Figura 4.10 - Densidade dos parâmetros para ?(1) = 2,7, Exemplo 3, para 1 macroelemento. 

 

Fonte: o Autor. 

 

Figura 4.11 – Distribuição de ?(0) e ??(0) para ?(1) = 2,7, Exemplo 3, macromalha com 1 macroelemento. 

 

Fonte: o Autor. 

 

 



62 
 

 
 

Figura 4.12 - Densidades de ?(0) e ??(0) para  ?(1) = 2,7, Exemplo 3, macromalha com 10 

macroelementos. 

 

Fonte: o Autor. 

  



63 
 

 
 

Tabela 4.4: Resumo dos Resultados obtidos no Exemplo 3.a) 

?? = ? × ???? 

???? = ? × ???? 

???? = ? × ???? 

Tabela Resumo do Exemplo 3.a) 

?????? ?(?) ???? ???? ?? 

?(?) 

?????? ?????? 
??????
??????

 ?????? ?????? 
??????
??????

 

? 0,3 2,8 × 10?32 0 1 5,9 × 10?17 5,0 × 10?15 0,117 0,3 0,3 1 

? 0,6 2,02 × 10?5 1,54 6 0,007 0,022 0.329 0,436 0,427 1,021 

? 0,9 2,00 × 10?5 1,90 14 0,016 0,034 0.468 0,509 0,514 1,000 

? 1,2 1,73 × 10?5 2,40 15 0,025 0,059 0.426 0,502 0,541 0,928 

? 1,5 1,62 × 10?5 2,43 14 0,030 0,071 0.417 0,521 0,588 0,886 

? 1,8 1,27 × 10?5 2,80 18 0,034 0,086 0.393 0,571 0,628 0,909 

? 2,1 1,75 × 10?5 2,61 15 0,066 0,086 0.766 0,589 0,630 0,935 

? 2,4 1,46 × 10?5 2,81 19 0,044 0,118 0.374 0,656 0,722 0,909 

? 2,7 1,39 × 10?5 2,83 15 0,047 0,108 0.437 0,769 0,757 1,016 

?? 3,0 1,95 × 10?5 2,57 14 0,050 0,094 0.533 0,841 0,841 1,000 

Fonte: o Autor. 

 Em relação aos resultados obtidos na tabela 4.2 e tabela 4.1, do exemplo base anterior. 

Observa-se que, para os intervalos entre ?(1) = 0.6 e ?(1) = 0.9, o algoritmo PDA, com a 

linearização da macroescala, não conseguiu captar toda a variabilidade da parametrização utilizada 

para a microescala, o que já era esperado, já que, a física da macroescala não é a mesma da 

microescala. Nota-se também, de uma maneira geral, que as razões das médias obtidas entre a micro 

e macroescala ficaram piores, entretanto, próximas à unidade. Ainda comparando os resultados entre 

a tabela 4.1 e 4.2, pode-se dizer que, ao analisar as razões das médias entre as duas escalas, o ganho 

computacional obtido com a linearização da macroescala pode ser favorecido em relação às perdas 

de precisão e acurácia das estimativas das respostas, já que, as razões ficaram próximas à unidade. 

 Assim como os resultados obtidos da tabela 4.1, os resultados apresentados na tabela 4.2 

demonstram que as ???? apresentaram bons resultados, com ordem de grandeza de10
?5, para o 

primeiro intervalo, ?(1) = 0.3, como é puramente determinístico, apresentou um Dmin bem inferior 

aos demais. A Informação Mútua apresentou bons resultados, considerando as diferentes físicas 

utilizadas durante a aplicação do PDA. Para os desvios padrões, observa-se uma grande diferença 



64 
 

 
 

entre os valores obtidos nas duas escalas, o que pode ser verificado pela razão entre os desvios das 

duas escalas diferirem da unidade. O que também já era esperado, já que também utilizamos uma 

quantidade de realizações utilizadas na macroescala bem inferior às utilizadas na microescala. 

b) O procedimento é repetido com a seleção das 10 macrorealizações de maiores probabilidades, 

após o que, normalizadas. O macroelemento 1, determinístico, teve a sua realização repetida 10 vezes. 

 

Tabela 4.5: Resumo dos Resultados obtidos no Exemplo 3.b) 

?? = ? × ???? 

???? = ? × ???? 

???? = ? × ???? 

Tabela Resumo do Exemplo 3.b) 

?????? ?(?) ???? ???? ?? 

?(?) 

?????? ?????? 
??????
??????

 ?
??????
??????

 

? 0,3 2,8 × 10?32 0 1 5,9 × 10?17 5,0 × 10?15 0,117 0,3 0,3 1 

? 0,6 2,02 × 10?5 1,54 6 0,007 0,022 0.320 0,434 0,427 1,017 

? 0,9 2,00 × 10?5 1,90 14 0,020 0,034 0.584 0,495 0,514 0,963 

? 1,2 1,73 × 10?5 2,40 15 0,023 0,059 0.395 0,480 0,541 0,888 

? 1,5 1,62 × 10?5 2,43 14 0,022 0,071 0.314 0,511 0,588 0,870 

? 1,8 1,27 × 10?5 2,80 18 0,028 0,086 0.320 0,551 0,628 0,878 

? 2,1 1,75 × 10?5 2,61 15 0,071 0,086 0.834 0,568 0,630 0,903 

? 2,4 1,46 × 10?5 2,81 19 0,057 0,118 0.485 0,614 0,722 0,850 

? 2,7 1,39 × 10?5 2,83 15 0,033 0,108 0.303 0,749 0,757 1,000 

?? 3,0 1,95 × 10?5 2,57 14 0,048 0,094 0.515 0,810 0,841 0,962 

Fonte: o Autor. 

 

Os resultados encontrados na tabela 4.4 e tabela 4.5, demonstram que, ao reduzir a quantidade de 

realizações para as 10 mais prováveis, há uma perda de precisão e de acurácia ao resolver o problema 

com a física linearizada. No entanto, essa perda de precisão e acurácia não é acentuada, com no 

máximo 10% de diferença entre as razões das médias obtidas pela tabela 4.4 e tabela 4.5. 

 

 



65 
 

 
 

c) O procedimento foi repetido com 5 macrorealizações de maiores probabilidades. Novamente, 

o macroelemento 1, determinístico, teve a sua realização repetida 10 vezes. 

 

Tabela 4.6: Resumo dos Resultados obtidos no Exemplo 3.c) 

?? = ? × ???? 

???? = ? × ???? 

???? = ? × ???? 

Tabela Resumo do Exemplo 3.c) 

?????? ?(?) ???? ???? ?? 

?(?) 

?????? ?????? 
??????
??????

 ?????? ?????? 
??????
??????

 

? 0,3 2,8 × 10?32 0 1 5,9 × 10?17 5,0 × 10?15 0,117 0,3 0,3 1 

? 0,6 2,02 × 10?5 1,54 6 0,008 0,022 0.383 0,444 0,427 1,038 

? 0,9 2,00 × 10?5 1,90 14 0,021 0,034 0.624 0,487 0,514 0,950 

? 1,2 1,73 × 10?5 2,40 15 0,018 0,059 0.314 0,455 0,541 0,842 

? 1,5 1,62 × 10?5 2,43 14 0,030 0,071 0.425 0,483 0,588 0,822 

? 1,8 1,27 × 10?5 2,80 18 0,037 0,086 0.426 0,546 0,628 0,852 

? 2,1 1,75 × 10?5 2,61 15 0,031 0,086 0.362 0,499 0,630 0,793 

? 2,4 1,46 × 10?5 2,81 19 0,022 0,118 0.190 0,586 0,722 0,812 

? 2,7 1,39 × 10?5 2,83 15 0,027 0,108 0.250 0,703 0,757 0,928 

?? 3,0 1,95 × 10?5 2,57 14 0,036 0,094 0.389 0,796 0,841 0,946 

Fonte: o Autor. 

 

Ao restringir mais ainda as realizações para as 5 mais prováveis, é possível comprovar a 

investigação realizada no item anterior. Ao analisar as razões das médias de cada intervalo das tabelas 

4.4, 4.5 e 4.6, percebe-se que há uma perda de precisão e acurácia dos resultados obtidos, já que, as 

razões se distanciam da unidade. No entanto, é possível verificar que a divergência não ultrapassa os 

20%. Na tabela 4.6, as razões das médias tendem a subestimar os valores médios em relação ao 

problema original, não linear na microescala. 

 

 

 



66 
 

 
 

Exemplo 4 

Ainda com o objetivo de melhorar a eficiência dos algoritmos utilizados neste trabalho, este 

exemplo 4, utilizou-se as mesmas parametrizações do exemplo 2, mas com duas significativas 

mudanças. A primeira é ainda a linearização da física na macroescala. A segunda está na forma do 

cálculo da distorção, feita agora com a equação (3.17), produzindo uma mesma macrodensidade para 

todos os macroelementos. As figuras 4.10 e 4.11 mostram os resultados. 

A tabela 4.7 sintetiza os resultados deste Exemplo 4. 

 

Figura 4.13 – Distribuições nas duas escalas para  ?(1) = 1,5; indicando valores médios e desvios padrão 

para ?(0) e ??(0). 

 

Fonte: o Autor. 

 

 

 

 

 

 

 

 

 

 



67 
 

 
 

Figura 4.14 – Distribuição nas duas escalas ?(1) = 3,0; indicando valores médios e desvios padrão 

para ?(0) e ??(0). 

 

Fonte: o Autor. 

Tabela 4.7: Resumo dos Resultados obtidos no exemplo 4. 

?? = ?,??????? 

???? = ? ? ????? 

???? = ? ? ???? 

Tabela Resumo do Exemplo 4 

??? ? 

??????. 
?(?) ???? ???? ?? 

?(?) 

?????? ?????? 
??????
??????

 ?????? ?????? 
??????
??????

 

? 0,3 

0,44 1,49 6 

5,9 × 10?17 5 × 10?16 0.117 0,3 0,3 1 

? 0,6 0,010 0,022 0.479 0,544 0,427 1,274 

? 0,9 0,016 0,034 0.468 0,606 0,514 1,179 

? 1,2 0,017 0,058 0.290 0,629 0,541 1,163 

? 1,5 0,010 0,071 0.142 0,653 0,588 1,111 

? 1,8 0,016 0,086 0.192 0,689 0,628 1,096 

? 2,1 0,017 0,086 0.195 0,713 0,630 1,133 

? 2,4 0,010 0,118 0.085 0,743 0,722 1,029 

? 2,7 0,015 0,108 0.140 0,770 0,757 1,017 

?? 3,0 0,014 0,093 0.147 0,801 0,841 0,953 

Fonte: o Autor. 



68 
 

 
 

 Após as modificações propostas nessa aplicação, observa-se da tabela 4.3, que novamente o 

algoritmo PDA não conseguiu captar toda a variabilidade da microescala, que, novamente, já era 

esperado. 

 Verifica-se também, a diferença na ordem de grandeza, bem superior em relação aos 

resultados da tabela 4.1 e 4.4, na estimativa do ????. O que resulta da tentativa de ajuste de apenas 

uma distribuição de probabilidade, para a macroescala, com toda a variabilidade da parametrização 

para a aplicação de ?(1) ? [0,3]. 

 Uma característica interessante dos resultados demonstrados na tabela 4.3, é que as razões das 

médias entre as duas escalas apresentam uma certa tendência de ajuste, razão das médias próxima à 

unidade, para aplicação de maiores valores de ?(1), o que demonstra o reflexo da mudança na forma 

do cálculo da distorção, da eq. (3.2) para a eq. (3.17). 

 De maneira geral. A Informação Mútua continuou apresentando resultados razoáveis, 

considerando todas as modificações propostas. Para os desvios padrões, continua-se a observar uma 

grande diferença entre os valores obtidos nas duas escalas, resultado da quantidade de realizações 

utilizadas na microescala que é bem superior às utilizadas na macroescala. 

Exemplo 5 

Neste exemplo 5 a metodologia proposta é aplicada em um reservatório unidimensional com fluxo 

bifásico, de óleo e água, e depleção por injeção de água, estudado por Emerick e Reynolds (2013). 

 

Figura 4.15 - Microescala do reservatório.  

 

Fonte: Emerick, A, Reynolds, A, (2013). 

 

 

 



69 
 

 
 

Figura 4.16 - Permeabilidades na micromalha. 

 

Fonte: Emerick, A, Reynolds, A, (2013). 

 

O reservatório possui 31 blocos de dimensões 50?? × 50?? × 50??. O logaritmo natural das 

permeabilidades, ?? (?), possuem uma função de autocorrelação exponencial com comprimento de 

correlação de 10 blocos, com média 5 e variância 1. A porosidade é constante e igual a 0,25, a 

viscosidade da água é 1?? e a do óleo, 2??. A pressão inicial no reservatório é de 3500??? e a 

compressibilidade do óleo, água e rocha são 10?5????1,10?6????1 e 5 × 10?6????1, 

respectivamente. Existe um poço injetor de água no primeiro bloco que opera com uma pressão de 

fundo de poço de 4000???. No último bloco há um poço produtor que opera a uma pressão de fundo 

de poço de 3000???.  Há um poço de observação de pressões no centro do reservatório. O período de 

produção é de 360 dias, com medidas mensais. O período de produção foi definido tal que há 

produção de água no poço de observação, mas não no poço produtor. A micromalha é mostrada na 

figura 4.12. 

 Os autores geraram um campo de permeabilidades descrito por 100 realizações igualmente 

prováveis, a partir do cenário mostrado na figura 4.13. Todos os dados do problema foram fornecidos 

pelos autores por meio de arquivos digitais, bem como o código executável do simulador por eles 

utilizado. O problema foi originalmente idealizado para comparação de métodos de para a solução de 

problemas inversos para os campos de permeabilidade. 

O exercício aqui consiste em determinar o novo campo de permeabilidades absolutas para a 

macromalha dada pela figura 4.14. Nela, as dimensões originais dos três blocos com poços foram 



70 
 

 
 

mantidas. Os demais blocos foram escalados dois a dois, ou seja, com ? = 2, resultando em uma 

macromalha de 17 blocos. Sabe-se que, nos problemas multifásicos, há também necessidade de 

mudança de escala das permeabilidades relativas, e que os reservatórios são mais sensíveis a essa 

mudança de escala se a redução da cardinalidade for alta. A redução da cardinalidade geométrica 

neste exercício é a redução uniforme mais baixa possível. Espera-se, portanto, que a ausência de 

mudança de escala das permeabilidades relativas seja muito pequena. 

 

Figura 4.17 – Modelo na Macroescala do Reservatório. 

 

Fonte: o Autor. 

 

As simulações de reservatórios utilizadas neste exemplo foram feitas com o MRST-2017b, Lie 

(2016), e a transposição de escala foi feita com os valores retirados das simulações quando o fluxo já 

está estacionário. 

O procedimento tem como partida a simulação das 100 realizações na micromalha. Essas são as 

únicas simulações realizadas na micromalha. Foram realizadas 14 mudanças de escala, uma para cada 

macroelemento, com condições de contorno de Dirichlet na simulação de cada macroelemento, e com 

a medida de distorção dada pela equação (3.2). 

As condições de contorno para cada macroelemento foram calculadas com os valores 

estacionários da micromalha, onde a pressão à esquerda (direita) é a pressão do microelemento à sua 

esquerda (direita). 

As respostas, ?(??), utilizadas na equação (3.2) foram as velocidades na interface de cada dois 

microelementos; enquanto que as respostas,?(??), são as velocidades no centro de cada 

macroelemento. 

Para a solução do problema inverso a uma variável, dado pela equação (3.9), 

?? = ?
?1 [

??(?,??)
[?(?)]

?(??)
] = ??1 [

?(?;??)

?(??)
], 



71 
 

 
 

dentre as três opções dadas por Zujl e Trykozko (2001), foi utilizada a primeira opção que 

corresponde à conservação da força motriz. Com essa opção,  

?? = ??
? =

????

??????
= 

?(?;??)?

?(??)(?????)
                                           (4.7) 

onde ??? é a velocidade média no centro do macroelemento, ? = 100?? é o seu comprimento, e ?? e ?? 

são as pressões na face da esquerda e da direita do macroelemento, respectivamente. 

A tabela 4.8 resume os dados e resultados deste exemplo. As figuras 4.19 e 4.22 mostram as 

saturações de água e óleo e as pressões do reservatório em 360 e 750 dias. 

Essas tabelas e figuras mostram um erro maior do que esperado. 

 

Tabela 4.8: Resumo dos resultados obtidos no exemplo 5. 

?? = ? × ????? 

?? = ? × ???? 

?? = ? × ???? 

Tabela Resumo do Exemplo 5 

????? 

????? 

 

??????  

× 107 
??í? ??á? ?? 

??? 

?????? ?????? 
??????
??????

 ?????? ?????? 
??????
??????

 

? 3,96 2.3 × 10?13 1.17 16 

4,47 × 10?6 3,1 × 10?6 1.44 8,73 × 10?6 5,47 × 10?6 1,60 

? 3,69 3.7 × 10?13 1.11 16 

? 3,47 2.8 × 10?19 1.20 18 

? 3,27 6.2 × 10?13 1.15 16 

? 3,10 3.8 × 10?13 1.15 17 

? 2,92 5.3 × 10?13 1.09 19 

? 2,72 2.5 × 10?20 1.15 20 

?? 2,42 3.5 × 10?13 1.17 17 

11 2,22 1.2 × 10?12 1.07 17 

12 2,02 1.7 × 10?12 1.18 30 

13 1,79 8.8 × 10?20 1.17 26 

14 1,56 9.7 × 10?13 1.14 25 

15 1,35 9.3 × 10?48 1.25 22 

16 1,08 3.7 × 10?13 1.18 33 

Fonte: o Autor. 

 

 

 

 



72 
 

 
 

Figura 4.18 -  Velocidades médias no reservatório nas duas escalas. 

 

Fonte: o Autor. 

 

Figura 4.19 – Saturações médias no reservatório nas duas escalas, 360 dias.

 

Fonte: o Autor. 

 

 



73 
 

 
 

Figura 4.20 – Saturações médias no reservatório nas duas escalas, 750 dias. 

 

Fonte: o Autor. 

 

Figura 4.21 – Pressões médias no reservatório nas duas escalas, 360 dias. 

 

Fonte: o Autor. 

 

 



74 
 

 
 

Figura 4.22 – Pressões médias no reservatório nas duas escalas, 750 dias. 

 

Fonte: o Autor. 

 

 Dos resultados obtidos na tabela 4.4, verifica-se que as ???? foram bem pequenas, com ordem 

de grandeza de 10?10 a 10?30, fato que decorre da aplicação do algoritmo PDA em apenas dois 

blocos (nas demais aplicações variavam de 100 a 1000). A Informação Mútua continua demonstrando 

resultados aceitáveis, para problemas não lineares.  

 A quantidade de realizações, ??, variou entre 16 e 33, o que demonstra a captação da 

variabilidade da microescala. 

 Para às razões do desvio padrão e da média das duas escalas, conclui-se que a distância entre 

a unidade e a razão obtida para o desvio padrão decorre do mesmo motivo que as aplicações 

anteriores, que devido à quantidade de realizações utilizada na macroescala ser bem inferior à 

microescala, impossibilita estimativas semelhantes. Já as razões das médias entre as duas escalas, 

apresentou um desvio maior que o esperado, o que não era esperado.  Acredita-se que melhores 

resultados seriam obtidos ao utilizar o problema inverso da eq. (3.9) em termos de pressões, ao invés 

de velocidades.  



75 
 

 
 

5 CONCLUSÕES E TRABALHOS FUTUROS 

A principal conclusão a ser tirada deste trabalho é que se justifica, plenamente, o 

desenvolvimento de um programa computacional para o usuário final. Esse programa utilizaria 

chamadas a um programa comercial, tal qual se faz hoje, corriqueiramente, para otimização do 

gerenciamento de reservatórios, na academia. Além disso, outras conclusões relevantes podem ser 

realçadas, quais sejam: 

1. Determinar a sucessão de distribuições desde uma dada temperatura até a distribuição ótima 

tem um custo computacional muito alto. 

2. A experiência nas aplicações em aprendizado de dados indica que deve ser feita uma escolha 

específica para a temperatura. O valor conveniente da temperatura deve ser investigado em 

aplicações específicas. 

3. O processo de mudança de escala estudado é bastante adequado para produzir modelos que 

estimem valores característicos de uma distribuição da solução. A técnica proposta pode 

então ser classificada como orientada ao objetivo. Imagina-se que deva ser muito importante 

nos problemas de controle estocástico (controle em malha fechada) e otimização estocástica. 

4. É claramente possível estimar uma distribuição completa. Para isso é apenas necessário 

utilizar conjuntos de dados simulados na micromalha que cubram toda a extensão dos dados 

das soluções e uma quantidade suficiente de realizações na macroescala. Entretanto, como 

indicado adiante, há técnicas mais apropriadas, como, por exemplo, alguma proveniente da 

análise matemática recentemente sugerida para deep learning (ver item 10, adiante). 

5. As técnicas propostas devem obter ganhos computacionais mais expressivos em problemas 

com domínio geométrico tridimensional. 

6. A aplicação dos métodos de Monte Carlo para Múltiplos Níveis (MSMC) em reservatórios 

com permeabilidades (ou físicas) heterogêneas exige que existam pelo menos três malhas 

encaixadas, física e probabilisticamente consistentes. O autor não conhece nenhum método 

de mudança de escala na literatura que atenda, simultaneamente, essas três exigências, além 

do proposto nessa dissertação. 

 

A experiência matemática e computacional adquirida no desenvolvimento deste trabalho 

sugere que a continuidade do processo investigativo possa vir a ser em direção a alguns pontos.  

7. Dado um ensemble com ?? realizações, não é possível saber a priori qual a quantidade de 

realizações a serem analisadas na microescala, senão após a simulação numérica de cada 

realização, e, talvez, após a análise da estatística. Em outras palavras, quais a realizações que 



76 
 

 
 

interessam, a priori, em um determinado problema? Essa pergunta decorre do fato que, para 

problemas realistas, a quantidade viável de simulações, ??, deve ser muito menor do que a 

quantidade ?? de realizações geocelulares, tipicamente, entre uma dezena e uma centena, 

?? ? [10,100] ? ??. Devem ser investigados procedimentos que evitem a simulação 

numérica de todas as realizações geocelulares. Podem-se facilmente vislumbrar algumas 

possibilidades que merecem investigação sistemática. 

8. Um possível procedimento alternativo ao DA consiste em estabelecer a priori, (e, talvez, 

adaptativamente) uma quantidade específica de macrorealizações, e utilizar um algoritmo 

estocástico-determinístico para minimizar diretamente o funcional ?[?(? ? ?)], ou seu 

complementar, ??[?(? ? ?)], ou alguma variante deles. Uma possibilidade é utilizar 

Inferência Variacional Estocástica para maximizar uma cota inferior de um desses funcionais. 

Essas mudanças podem permitir os esquemas (?)-Global que não são facilmente tratáveis 

pelas técnicas deste trabalho. 

9. Um problema computacional de interesse prático é a automatização da geração da 

macroescala para malhas com alguma generalidade, tais quais as hoje utilizadas pelos 

simuladores de reservatório. 

10. Uma importante extensão deste trabalho consiste em utilizar as ideias recentemente expostas, 

na literatura, Colyer (2017), para uma análise matemática (Tishby, Pereira e Bialek ,1999), de 

deep learning até então inexistente. A ideia consiste em estender a Teoria das Taxas de 

Distorção condicionando a solução à similaridade com uma terceira distribuição. Como 

consequência, a medida de distorção para a ser uma distância KL, o que parece ser uma 

solução eficiente para a mudança de escala de uma distribuição. 



77 
 

 
 

REFERÊNCIAS 

 

AARNES, J. E., EFENDIEV, Y. ; Mixed Multiscale Finite Element Method for Stochastic Porous 

Media Flows. SIAM Journal of Scientific Computing, Vol. 30, Núm. 5, 2319-2339. 

ALIYEV, E., DURLOFSKY, L. J.; Multilevel Field-Development using a Sequence of Upscaled 

Models. SPE 173198 MS, SPE Reservoir Simulation Symposium, USA, 2015. 

ALPADYDIN, E. Introduction to Machine Learning, second edition, The MIT Press, Cambridge, 

Massachusetts, London, England, 2010. 

ARAÚJO, E. da R., WILLMERSDORF, R. B, FONSECA, L. de A.; Simulação Estocástica em 

Múltiplas Físicas e Múltiplas Escalas de Reservatórios Carbonáticos. Plano de Pesquisa e 

Relatórios do Projeto SIGER2-UFPE-PETROBRAS(Cenpes), 27 de dezembro de 2011 a 26 de 

dezembro 2016. 

ARIMOTO, S.; An Algorithm for Computing the Capacity of Arbitrary Discrete Memoryless 

Channels. IEEE Transactions of Information Theory, Vol. IT-18, N. 1, Janeiro, 1972. 

BLAHUT, R. E.; Computational of Channel Capacity and Rate-Distortion Funcions. IEE 

Transactions on Information Theory, Vol. IT-18, Julho, 1972.  

BRILLOUIN L., Science and Information Theory: Second Edition, Dover Books on Physics, 2013.      

CHEN, Y., PARK, K., DURLOFSKY, L. J.; Statistical Assignment of Upscaled Flow Functions 

for an Ensemble of Geological Models. Computational Geoscience, 15, 35-51, 2011. 

COLYER, A.; On The Information Bottleneck Theory of Deep Learning. The Morning Paper, 

https://blog.acolyer.org/, 24 de Novembro, 2017 

COVER, T. M., THOMAS, J. A.. Elements of Information Theory, a John Wiley &amp;amp; Sons, INC., 

Publication, 1a. edição em 1991 e 2a. edição em 2006. 

COSTA, I. F., FONSECA, L. A., ARAÚJO, É. da R.; Heterogeneous Stochastic Multiscale, 

CILAMCE2017, XXXVIII Ibero-Latin American Congresso on Computational Methods in 

Engineering held in Florianópolis, Santa Catarina, Brasil, from November 5?? to 8??, 2017. 

OLIVER, D. S., REYNOLDS, A. C. e LIU, N., Inverse Theory for Petroleum Reservoir 

Characterization and History Matching, Cambridge University Press, 2008. 

https://blog.acolyer.org/


78 
 

 
 

DURLOFSKY, L. J, CHEN, Y., Ensemble-Level Upscaling for Efficient Estimation of Fine-Scale 

Production Statistics. SPE 106086,  SPE Journal, 406-411, December, 2008. 

DURLOFSKY, L. J., CHEN, Y., Uncertainty Quantification for Subsurface Flow Problems using 

Coarse-Scale Models. Numerical Analysis of Multiscale Problems, G. Graham et al. (eds), Lecture 

Notes in Computational Science and Engineering 83, 2012. 

EMERICK, A., REYNOLDS, A.; Investigation of the Sample Performance of Ensemble Based 

Methods with a Simple Reservoir Model. Compational Geoscience, Vol. 17, 325-350, 2013. 

GRIGO, C., KOUTSOURELAKIS, P.-S.; Baysian Model and Dimension Reduction for 

Uncertainty Propagation: Application in Random Media. ArXiv:1711.02475v1, [Stat.ML], Nov 

7, 2017. 

HILL, T. L., An Introduction to Statistical Thermodynamics, Dover Books on Physics 

HILL, T. L., Statistical Mechanics: Principles and selected Applications, Dover Books on Physics. 

KIPPE, V., AARNES, J. E., LIE, K.-A. ; A Comparision on of Multiscale Methods for Elliptic 

Problems in Porous Media Flow, 2007. 

KOUTSOURELAKIS, P.S., Stochastic upscaling in solid mechanics: Na exercise in machine 

learning. Journal of Computational Physics 226, 2007. 

KULLBACK, S., e LEIBLER, R. A.; On Information and Suficiency. Ann. Math. Statist., Vol. 22, 

Number 1, 79-86, 1951. 

LI, H., DURLOFSKY, L. J., Ensemble Level Upscaling for Compositional Flow Simulation. 

Computational Geoscience, 2015. 

LIE, K.-A. ; An Introduction to Reservoir Simulation using MATLAB. User Guide for the 

MATLAB Reservoir Simulation Toolbox (MRST). SINTEF ICT, December 2016. 

PAL, M.; A Unified Approach to Simulation and Upscaling of Single-Phase Flow through Vuggy 

Carbonates, Int. J. of Numer. Meth. Fluids, on-line publication, 2011. 

PAREKH, P. M., KATSELIS, D., BECK, C. L., SALAPAKA, S. M., Deterministic Annealing for 

Clustering: Tutorial and Computational Aspects. American Control Conference, Palmer House 

Hilton, Chicago, IL, USA, 2015. 



79 
 

 
 

ROMEU, R.; NOETINGER, B.; Calculation of Internodal Transmissivities in Finite Difference 

Models for Flow in Heterogeneous Porous Media, Water Resources Research, Vol. 31, 943-959, 

1995. 

ROSE, K., Deterministic Annealing, Clustering, and Optimization, PhD Thesis, California 

Institute of Technology. Pasadena, CA, 1991. 

ROSE, K., A Mapping Approach to Rate-Distortion Computation and Analysis, IEEE 

Transactions on Information Theory. vol 40, nº 6, 1994. 

ROSE, K., Deterministic Annealing for Clustering, Compression, Classification, Regression, 

and Related Optimization Problems. IEEE, vol 86, nº 11, 1998. 

SAYOOD, K., Introduction to Data Compression, 3rd edition, Elsevier, 2006 

SHANNON, C. E., A Mathematical Theory of Communication. Reimpressão com correções a 

partir de The Bell System Technical Journal, Vol. 27, 379-423, 623-656, July, October, 1948. 

SIMON, H., Redes Neurais: Princípios e Prática, 2ªedição, Bookman. 

TISHBY, N., PEREIRA, F. C., BIALEK, W.; The Information Bottleneck Method, ArXiv, abril, 

2000. 

WEINAN, E., ENGQUIST, B., The Heterogeneous Multi-scale Methods. Communication in 

Mathematical Sciences, Vol. 1, 87, 2003. 

WU, X. H., EFENDIEV, Y., HOU, T. Y.; Analysis of Upscaling Absolute Permeability. Discrete 

and Continuous Dynamic Systems – Serie B, Vol.2, Number 2, pp. 185-204, May, 2002. 

ZIJL, W., TRYKOZKO, A.; Numerical Homogenization of the Absolute Permeabilitity using the 

Conformal-Nodal and Mixed-Hybrid Finite Element Method. Transport in Porous Media, 44: 33-

62, 2001. 

 


</field>
	</doc>
</add>