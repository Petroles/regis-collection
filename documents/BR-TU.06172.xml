<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.06172</field>
		<field name="filename">10690_000767749.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">
UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL

INSTITUTO DE INFORMÁTICA

CURSO DE CIÊNCIA DA COMPUTAÇÃO

BRUNO ALLGAYER FEROLETO

Um Algoritmo de Médias Móveis para 
Interpretação de Sequências Deposicionais 

em uma Arquitetura para Interpretação 
Semântica de Imagens

Trabalho de Graduação.

Prof. Drª. Mara Abel
Orientador

Msc. Sandro Rama Fiorini
Co-orientador

Porto Alegre, Dezembro de 2010.



UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL
Reitor: Prof. Carlos Alexandre Netto
Vice-Reitor: Prof. Rui Vicente Oppermann
Pró-Reitora de Graduação: Profa. Valquiria Link Bassani
Diretor do Instituto de Informática: Prof. Flávio Rech Wagner
Coordenador do CIC: Prof. João César Netto
Bibliotecária-Chefe do Instituto de Informática: Beatriz Regina Bastos Haro



SUMÁRIO

 LISTA DE ABREVIATURAS E SIGLAS.........................................................5

 LISTA DE FIGURAS.......................................................................................6

 LISTA DE TABELAS......................................................................................8

 RESUMO........................................................................................................9

1 INTRODUÇÃO............................................................................................11

1.1 Motivação  .....................................................................................................................................11

1.2 Objetivos........................................................................................................................................12

1.3 Organização dos Capítulos...........................................................................................................12

2 INTERPRETAÇÃO SEMÂNTICA DE IMAGENS.......................................13

2.1 Agregados.......................................................................................................................................15
2.1.1 Evoluções da Abordagem dos Agregados...............................................................................17

2.2 Abdução..........................................................................................................................................18
2.2.1 Evoluções da Abordagem Abdutiva........................................................................................20

2.3 Orion...............................................................................................................................................21
2.3.1 Evoluções da abordagem Orion..............................................................................................24

2.4 Espaços Conceituais......................................................................................................................24
2.4.1 Evoluções da Abordagem dos Espaços Conceituais...............................................................29

2.5 Comparativo Entre as Abordagens.............................................................................................29

3 O FRAMEWORK S-CHART E O SISTEMA INTELISTRATA...................32

3.1 Framework S-Chart......................................................................................................................32

3.2 Sistema Intelistrata.......................................................................................................................34

3.3 Estratigrafia de Sequências..........................................................................................................35

4 UM NOVO ALGORITMO............................................................................38

4.1 O novo algoritmo...........................................................................................................................38
4.1.1 Curva de Tendências................................................................................................................40
4.1.2 Limites de Sequências Deposicionais.....................................................................................43



5 VALIDAÇÃO DA PROPOSTA...................................................................48

5.1 Comparativo de resultados: Novo algoritmo x Intelistrata.......................................................48

5.2 Testes em novos perfis de poços...................................................................................................54

6 CONCLUSÃO.............................................................................................59

6.1 Trabalhos Futuros.........................................................................................................................59

 REFERÊNCIAS............................................................................................60



LISTA DE ABREVIATURAS E SIGLAS

DL Description Logics (Lógica de descrição)

GSD Geometrical Scene Description

GUI Graphical User Interface

LDA Linear Discriminant Analysis (Discriminante Linear)

OWL Web Ontology Language



LISTA DE FIGURAS

FIGURA 2.1: EXEMPLO DE INTERPRETAÇÃO DE ANCORAMENTO 
SIMBÓLICO (FIORINI, S. R., 2009)...................................................................14

FIGURA 2.2 – FRAMEWORK BASEADO EM CONHECIMENTO PARA 
INTERPRETAÇÃO DE ALTO NÍVEL DE CENAS (NEUMANN, B. E R. 
MÖLLER, 2006) .................................................................................................16

FIGURA 2.3: ROBÔ LUDWIG (SHANAHAN, M. E D. A. RANDELL, 2004)
............................................................................................................................19

FIGURA 2.4: BLOCOS LEGO E SUAS ARESTAS (SHANAHAN, M. E D. A. 
RANDELL, 2004)................................................................................................20

FIGURA 2.5: OS 3 NÍVEIS DE ABSTRAÇÃO CORRESPONDENTES AOS 
SUB-PROBLEMAS REPRESENTADOS ATRAVÉS DE UMA IMAGEM 
MICROSCÓPICA DA BIOLOGIA (HUDELOT, C. ET AL., 2004)......................21

FIGURA 2.6: ANCORAMENTO SIMBÓLICO: 3 NÍVEIS E ONTOLOGIAS 
PARA COMUNICAÇÃO (HUDELOT, C. ET AL., 2004).....................................23

FIGURA 2.7: EXEMPLO DE ANCORAMENTO SIMBÓLICO CONSTRUÍDO 
A PRIORI (HUDELOT, C. ET AL., 2004)............................................................24

FIGURA 2.8: A ARQUITETURA PROPOSTA PELA ABORDAGEM DOS 
ESPAÇOS CONCEITUAIS E SEUS 3 DIFERENTES NÍVEIS (CHELLA, A. ET 
AL., 1997)...........................................................................................................25

FIGURA 2.9: UMA IMAGEM COM SEUS OBJETOS TRANSFORMADOS 
EM KNOXELS (CHELLA, A. ET AL., 1997)......................................................26

FIGURA 2.10: VARIAÇÃO DOS FATORES DE FORMA (CHELLA, A. ET 
AL., 2001)...........................................................................................................27



FIGURA 2.11: FRAGMENTO DE  CONHECIMENTO NO COMPONENTE 
TERMINOLÓGICO (CHELLA, A.  ET AL., 1997)..............................................28

FIGURA 2.12: SITUAÇÃO NO COMPONENTE TERMINOLÓGICO 
(CHELLA, A. ET AL., 1997) ..............................................................................28

FIGURA 2.13: MARTELO REPRESENTADO POR SEUS KNOXELS EM 
UM ESPAÇO CONCEITUAL (CHELLA, A. ET AL., 2001)................................29

FIGURA 3.1: ARQUITETURA DO FRAMEWORK S-CHART (FIORINI, S. 
R., 2009).............................................................................................................33

FIGURA 3.2: ARQUITETURA DO COMPONENTE DE INTERPRETAÇÃO 
(FIORINI, S. R., 2009)........................................................................................34

FIGURA 3.3: ARQUITETURA DO SISTEMA INTELISTRATA (FIORINI, S. 
R., 2009).............................................................................................................34

FIGURA 3.4: EXEMPLO DE PERFIL DE RAIO GAMA. EDITADO DE 
(FIORINI, S. R., 2009)........................................................................................37

FIGURA 4.1: WAVELET GAUSSIANA 2 (FIORINI, S. R., 2009).................39

FIGURA 4.2: EXEMPLO DE CURVA DENTE-DE-SERRA .........................39

FIGURA 4.3: CURVA DE TENDÊNCIAS......................................................42

FIGURA 4.4: “FALHA” DEVIDO A UMA QUEDA BRUSCA.......................44

FIGURA 4.5: QUEDAS BRUSCAS EM REGIÕES COM DIFERENTES 
AMPLITUDES DO VALOR GAMA.....................................................................45

FIGURA 5.1: COMPARAÇÃO DAS INTERPRETAÇÕES DO 
ESPECIALISTA E DO SISTEMA INTELISTRATA PARA O PERFIL DE POÇO 
TENNECO RATTLESNAKE STATE 2-12 (FIORINI, S. R., 2009).....................50

FIGURA 5.2: INTERPRETAÇÃO DO PERFIL DE POÇO TENNECO 
RATTLESNAKE STATE 2-12 PELO NOVO ALGORITMO...............................51

FIGURA 5.3: COMPARAÇÃO DAS INTERPRETAÇÕES DO 
ESPECIALISTA E SISTEMA INTELISTRATA PARA O PERFIL DE POÇO 
EXXON PRODUCTION RESEARCH CO. SEGO CANYON Nº 2 (FIORINI, S. 
R., 2009).............................................................................................................52



FIGURA 5.4: INTERPRETAÇÃO DO PERFIL DE POÇO EXXON 
PRODUCTION RESEARCH CO. SEGO CANYON Nº 2 PELO NOVO 
ALGORITMO......................................................................................................53

FIGURA 5.5: INTERPRETAÇÃO DO PERFIL DE POÇO CA-53 PELO 
NOVO ALGORITMO..........................................................................................56

FIGURA 5.6: INTERPRETAÇÃO DO PERFIL DE POÇO CA-79 PELO 
NOVO ALGORITMO..........................................................................................57

FIGURA 5.7: INTERPRETAÇÃO DO PERFIL DE POÇO CA-87 PELO 
NOVO ALGORITMO..........................................................................................58

LISTA DE TABELAS

TABELA 2.1: COMPARAÇÃO ENTRE ABORDAGENS SEMÂNTICAS DE 
RECONHECIMENTO DE OBJETOS.................................................................31

TABELA 5.1: RESULTADOS DO NOVO ALGORITMO...............................54



RESUMO

A interpretação semântica de imagens é atualmente uma das áreas mais exploradas 
da computação. Ao longo dos anos tentou-se descobrir a melhor forma de entender e 
reproduzir o processo cognitivo humano. Atualmente um dos pontos que mais chamam 
atenção é como extrair o real significado de uma imagem e suas associações. Uma das 
áreas  que  tem  necessidade  direta  desse  conhecimento  é  a  área  da  geologia  chamada 
Estratigrafia  e  sua  metodologia,  Estratigrafia  de  Sequências,  uma  das  mais  novas  e 
eficientes  ferramentas  cuja  correta  interpretação  dos  resultados  permite  uma  boa 
predição da formação dos sistemas deposicionais que orienta a  exploração de petróleo.

Dentro da área de interpretação semântica de imagens há diferentes trabalhos que 
apresentam  suas  arquiteturas  e  soluções  para  problemas  específicos.  Voltado  à 
estratigrafia de sequências há o sistema Intelistrata, arquitetado a partir do framework S-
Chart.  Neste  trabalho  é  apresentado  um  novo  algoritmo  para  o  componente  de 
processamento do sinal, tendo como objetivo uma melhor interpretação das imagens.

Para alcançar os objetivos foram utilizadas noções matemáticas de médias móveis e 
desvio padrão, visando identificar certos  aspectos  interessantes para a delimitação de 
limites de sequências deposicionais utilizando perfis de raios gama. A abordagem provê 
aos componentes de interpretação semântica de imagens do sistema Intelistrata dados 
mais precisos e, consequentemente, melhores resultados.

O  novo  algoritmo  utilizado  mostrou  ganhos  substanciais  em  relação  à  aplicação 
original ao identificar automaticamente limites de sequências deposicionais em poços 
exploratórios  utilizados  para  teste.  Os  ganhos  foram  tanto  em  qualidade  quanto 
eficiência nas demarcações de limites de sequência deposicionais. Contando com duas 
comparações feitas em relação ao sistema original houve acerto de 100%, contra 66% 
em relação às demarcações de limites de sequências deposicionais e eficiência de 75% 
na quantidade de marcações feitas contra 40% e 50% do sistema original. Ainda teve 
boa aproximação de marcações em outros perfis de poços, nas quais seus erros quando 
não  houve  marcação  precisa  em  relação  à  interpretação  feita  manualmente  por  um 
geólogo,  não  ultrapassaram  4%  do  tamanho  dos  poços.  As  maiores  discrepâncias 
aconteceram  em  poços  onde  mesmo  especialistas  tiveram  dificuldade  em  fazer  tais 
marcações  somente  com  a  informação  do  perfil  de  raios  gama,  o  que  aumenta  a 
credibilidade  do  novo  algoritmo  e  prova  seu  valor  como  ferramenta  de  auxílio  aos 
especialistas da área.

Palavras-Chave: Interpretação Semântica de Imagens, Visão Computacional, 
Processamento de Sinal, Estratigrafia de Sequências.





1 INTRODUÇÃO

Este  trabalho  aborda  a  área  da  ciência  da  computação  chamada  “visão 
computacional”, discutida mais amplamente pela primeira vez em (Ballard, D. H. e C. 
M. Brown, 1982), para o estudo da extração de dados de imagens, esses por sua vez 
podendo  ser  processados  posteriormente,  tanto  por  humanos  quanto  máquinas, 
buscando  cumprir  alguma  tarefa.  A interpretação  semântica  de  imagens  é  a  área  da 
Inteligência Artificial derivada da visão computacional, que busca algo mais  além da 
simples extração numérica de conteúdos das imagens sem significados semânticos.Seu 
ideal é dar significado aos dados extraídos das imagens, muitas vezes tentando simular 
o que seria o comportamento humano.

Este trabalho visa o estudo das abordagens de interpretação semântica de imagens, 
aplicada  a  interpretação  de  sequências  deposicionais.  A Estratigrafia  de  Sequências, 
apresentada inicialmente por Vail et al. (1977), posteriormente refinada por Posamentier 
et al. (1988) e Van Wagoner et al. (1990), como apontado por Catuneanu (2006), é uma 
área de estudos recentes da Geologia responsável pelo estudo da formação dos estratos 
do subsolo pela variação do nível do mar e deposição de matéria orgânica. Sua correta 
interpretação  permite  uma  boa  predição  da  formação  dos  sistemas  deposicionais  que 
orienta a  exploração de petróleo. 

1.1 Motivação  
Relativamente nova, a área da visão computacional ainda tem muito a ser explorada, 

considerando  que  nem  mesmo  possui  uma  formalização  padrão,  mas  sim  diversos 
estudos aplicados a problemas distintos. Essa também é uma área muito promissora pela 
grande  ajuda  que  pode  nos  dar  ao  resolver  problemas  tanto  de  altos  graus  de 
dificuldades, como, por exemplo, diagnósticos médicos e outros tipos de interpretação, 
ou  mesmo  problemas  que  exigiriam  alta  demanda  de  trabalho,  como,  por  exemplo, 
catalogar todos os gols que um jogador fez ao longo da carreira.

A área  de  estratigrafia  de  sequências,  também  relativamente  nova,  oferece  fortes 
ferramentas para a análise estratigráfica cujo estilo vem sendo tomado como o preferido 
pelos geólogos ao longo dos últimos anos (CATUNEANU, O., 2006). Unindo-a com a 
área  da  visão  computacional  e  interpretação  semântica  de  imagens  é  possível  criar 
ferramentas muito efetivas e úteis no momento em que nosso país torna-se um dos mais 
fortes na exploração de petróleo, contando com pesado investimento, sendo mais de 70 
bilhões de reais investidos em 2009 no aumento da capacidade de produção de petróleo 
e gás natural, dos quais mais de 30 bilhões de reais em exploração e produção e 2,8 
bilhões de dólares investidos para o período até 2013, segundo (PETR).



12

Com  diversos  trabalhos  na  área  de  interpretação  semântica  de  imagens,  tendo 
algumas boas abordagens, apresentadas no segundo capítulo, poucos trabalhos buscam a 
área de estratigrafia de sequências, deixando o caminho livre para inovações, como o 
framework apresentado  por  Fiorini  (2009),  ou  os  resultados  conseguidos  pela 
abordagem semelhante de Xia (2009).

Criado a partir das linguagens OWL e Java, o framework S-Chart tem como foco a 
interpretação  semântica  de  gráficos  através  da  combinação  de  algoritmos  de 
processamento de sinais com algoritmos e modelos de raciocínio simbólico. Divide-se 
em  3  níveis:  semântico,  visual  e  analógico,  sendo  os  dois  primeiros  destinados  às 
interpretações  e  o  último  ao  processamento  de  imagens.  Sua  aplicação,  o  sistema 
Intelistrata,  busca  a  utilização  de  suas  ferramentas  para  inferências  no  âmbito  da 
estratigrafia  de  sequências,  como  delimitação  de  sequências  deposicionais  e 
parassequências. 

1.2 Objetivos
O objetivo deste trabalho é propor um novo algoritmo de processamento de sinal 

para o sistema Intelistrata, desenvolvido por Fiorini (2009), buscando maior precisão do 
algoritmo  de  identificação  dos  limites  de  sequências  deposicionais  em  depósitos 
sedimentares  siliciclásticos  em bacias sedimentares  do tipo Margem Passiva. Para tal 
será utilizada uma nova abordagem para o algoritmo, utilizando-se médias móveis, ao 
invés das  wavelets utilizadas no sistema original. Dessa forma espera-se, em trabalhos 
futuros, estender  as funcionalidades do sistema Intelistrata, utilizando-se a base para 
inferências  e  também  uma  arquitetura  já  definidas  e  própria  para  expansões  do 
framework S-Chart.

1.3 Organização dos Capítulos
O  capítulo  2  revisa  conceitos  e  trabalhos  relacionados  à  área  da  visão 

computacional, apresentando algumas das principais abordagens, apontando seus pontos 
fortes e fracos e terminando por compará-las.

O capítulo 3 introduz o  framework S-Chart e sua aplicação, o sistema Intelistrata, 
voltado  para  a  estratigrafia  de  sequências,  sendo  essa  última  abordada  em  maiores 
detalhes ao fim do capítulo.

O  capítulo  4  apresenta  a  proposta  de  um  novo  algoritmo  ao  sistema,  buscando 
melhores resultados.

O  capítulo  5  mostra  a  validação  e  os  resultados  alcançados  pelo  novo  algoritmo 
apresentado no capítulo anterior.

O  sexto  e  último  capítulo  apresenta  as  conclusões  do  trabalho,  comentando  seus 
resultados e possíveis avanços futuros. 



13

2 INTERPRETAÇÃO SEMÂNTICA DE IMAGENS

O  principal  desafio  dos  sistemas  de  visão  computacional  é  interpretar 
corretamente o conteúdo de imagens. Um sistema desse tipo deve ter como 
saída uma descrição, formal ou não, dos objetos presentes em uma imagem, 
bem como a sua classificação e suas propriedades visuais. (FIORINI, S. R., 
2009, p.21)

Um sistema de visão computacional consiste em saber dar o correto significado 
ao  que  vemos,  ou,  no  caso,  ao  que  o  sistema  “vê”.  Assim  foram  criadas  diversas 
tentativas de chegar a uma solução, desde algoritmos simples de extração de feições de 
imagens,  como  retas,  superfícies,  regiões  e  texturas,  até  a  tentativa  de  simulação  do 
conhecimento  de  um  especialista  humano.  A  limitação  é  que  até  hoje  o  processo 
cognitivo humano não é completamente conhecido para que possa ser transformado em 
um algoritmo e então simulado.  Até o momento, a interpretação semântica de imagens 
é um problema que persiste sem uma solução completa. 

Com os diversos estudos na área, chegou-se à conclusão de que o significado de um 
objeto em uma imagem não está no seu formato, nome, ou taxonomia. Só sabemos dar 
um significado, por exemplo, ao termo, ou ao objeto chamado “carro” por vivência e 
por encontrá-lo contextualizado de certa forma em alguma cena, mas esse símbolo por 
si  só  nada  nos  diz  a  respeito  de  seu  significado.  Indo  além,  o  termo  “carro”  é  uma 
palavra da língua portuguesa e fica ainda mais óbvio pelo fato de que ele nada significa 
a  alguém  que  nunca  tenha  tido  contato  com  essa  língua.  Essa  falta  de  significado 
intrínseco ao termo, ou no caso de uma imagem, um objeto nela reconhecido, traz a 
necessidade  de  uma  atribuição  do  valor  semântico  (o  significado)  a  um  objeto  da 
imagem (o símbolo).

A associação de um símbolo com o objeto ao qual ele se refere é referenciado na 
literatura como o problema do ancoramento simbólico (the symbol grounding problem) 
e  visa responder, segundo Harnad, S. (1990, p.1):

Como a interpretação semântica  de um sistema simbólico formal pode 
ser  intrínseca  ao  sistema,  ao  invés  de  apenas  parasítico  como  em  nossas 
mentes?  Como  podem  os  significados  de  símbolos  sem  significado, 
manipulados exclusivamente em função de suas formas (arbitrárias), serem 
ancorados a algo que não outros símbolos sem significado? 

 Esse questionamento vem da tentativa de dar um real significado a cada símbolo ao 
invés  de  simplesmente  tentar  relacioná-lo  a  outros.  Dentre  as  capacidades  humanas, 
aquelas  que  são  procuradas  para  a  solução  do  ancoramento  simbólico  são: 
discriminação,  manipulação,  identificação  e  capacidade  de  produzir  e  responder 
descrições de objetos ou eventos. Os sistemas que delas se utilizam, ancoram os valores 
semânticos  às  feições  encontradas  na  imagem,  referentes  a  um  símbolo.  Esse 
ancoramento pode ter tanto uma abordagem top-down, na qual a partir de um conjunto 



14

de  valores  semânticos  são  procuradas  feições  na  imagem,  quanto  bottom-up,  cujo 
processamento de imagem extrai todas as feições possíveis e tenta conectá-las a valores 
semânticos. Há uma espécie de consenso que considera os valores semânticos como alto 
nível e a imagem e suas feições, ou símbolos, como baixo nível.

Geralmente  os  sistemas  costumam  fazer  uma  abordagem  híbrida  e  iterativa  na 
tentativa de melhores resultados. Como o exemplo de Fiorini, S. R. (2009), caso fosse 
utilizado um sistema de interpretação de imagens de satélite, uma imagem teria regiões 
extraídas na Figura 2.1a. A partir de uma abordagem  bottom-up, essas regiões seriam 
interpretadas  como  sendo  um  rio  e  uma  estrada  (Figura  2.1b).  Considerando  que  o 
modelo simbólico definiria que na sobreposição das entidades “rio” e “estrada” poderia 
haver  uma  ponte,  o  interpretador  passaria  ao  sentido  top-down em  busca  de 
características visuais que confirmasem essa hipótese (Figura 2.1c).

Figura 2.1: Exemplo de interpretação de ancoramento simbólico (FIORINI, S. R., 2009)
Alguns  sistemas  de  visão  computacional  são  divididos  em  partes  chamadas  de 

níveis.  Esses  níveis  são  denominados  para  aumentar  a  modularidade,  diminuir  a 
complexidade  dos  sistemas  e  ainda  melhorar  a  clareza  do  sistema  de  interpretação 
semântica.  Como  dito  anteriormente,  há  um  consenso  de  que  os  valores  semânticos 
atribuídos  à  imagem  são  o  “alto  nível”,  enquanto  a  imagem  bruta  e  suas  possíveis 
feições  são  o  “baixo  nível”.  Os  níveis  podem  ainda  receber  diferentes  nomes,  como 
“nível  semântico” e “nível  da imagem”  ou mesmo contar com níveis  intermediários, 
como  “nível  visual”  (HUDELOT,  C.  et  al.,  2004),  para  diminuir  a  distância  e 
complexidade  dos  problemas  entre  níveis,  dividindo-os  em  sub-problemas,  podendo 
assim conter algumas propriedades da imagem e de cada objeto nela encontrado, mas 
ainda sem a apropriação de seu valor semântico, seu significado.



15

Os  diferentes  níveis  possuem  diferentes  abordagens, focos  e linguagens,  assim,  a 
partir da sua utilização, é também necessário definir uma maneira de fazer comunicação 
entre eles. Essa comunicação pode ser feita de diversas maneiras, como a criação de 
ontologias visando uma linguagem comum, ou simplesmente dados vindos de um nível 
para  posterior  processamento  no  nível  que  os  recebe.  Por  exemplo,  regiões  de  uma 
imagem que de acordo com seu formato e cor podem receber diferentes valores em um 
nível intermediário, a exemplo da Figura 2.5 na seção 2.3.

A seguir  são  apresentadas  algumas  das  principais  abordagens  que  utilizam  esses 
conceitos.

2.1 Agregados
O trabalho de (NEUMANN, B. e R. MÖLLER, 2006) visa analisar a possibilidade 

do  uso  de  Lógica  de  Descrição  (Description  Logics  –  DL)  como  representação  de 
conhecimento  e  sistema  de  raciocínio  para  interpretação  de  alto  nível  de  cenas.  O 
sistema  proposto  pelos  autores  visa  a  análise  de  cenas,  podendo  intuir  o  que  está 
acontecendo.  Foi  voltado,  inicialmente,  à  monitoração  de  tráfego,  já  que  o  sistema 
inclui primitivas de representação de objetos ao longo do tempo.

A abordagem foi proposta tendo em mente os seguintes aspectos:
1.  Representação  de  conhecimento  necessita  uma  forte  base  formal 

quando  o  corpo  de  conhecimento  se  torna  maior  e  diverso.  Muitas  das 
representações de formalismos anteriores como redes semânticas, linguagens 
de frames e sistemas baseados em regras sofreram de falta de uma semântica 
precisa  no  sentido  de  que  o  correto  uso  de  conhecimento  representado  é 
parcialmente  baseado  em  noções  intuitivas,  que  não  necessariamente 
proveem uma base consistente para processamento de conhecimento de larga 
escala.

2. Sistemas de representação de conhecimento podem prover serviços de 
inferência  padronizados  que  podem  ser  utilizados  (e  reutilizados)  para 
desenvolvimento  de  aplicações.  Serviços  de  inferência  típicos  são  de 
checagem de consistência, herança, classificação de instâncias e construção 
de  modelos, mas muitos outros foram propostos e investigados,  como,  por 
exemplo, pattern matching (BAADER, F. e R. KUESTERS, 1999). Serviços 
de  inferência  são  interessantes  para  interpretação  de  cenas  já  que  podem 
prover  importantes  funcionalidades  para  o  processo  de  interpretação  em 
termos de software existente com propriedades bem definidas.

3.  Há  um  crescente  corpo  de  pesquisa  com  respeito  a  conhecimento 
espacial e temporal e sistemas de raciocínio relacionados (VILA, L., 1994) 
(STOCK, O., 1997) (COHN, A. G. e S. M. HAZARIKA, 2001). Espaço e 
tempo têm um papel determinante em cenas e pode-se esperar que serviços 
de raciocínio visual e temporal provenham suporte para interpretação delas. 
Entretanto,  é  notável  que  até  agora  apenas  alguns  poucos  exemplos  dessa 
integração tenham sido feitos em sistemas de visão (vision system) (HAAG, 
M. et al., 1997) (NAGEL, H.-H., 1999) (COHN, A. G.  et al., 2003). Um dos 
problemas  parece  ser  a  incompatibilidade  quantitativa  entre  informações 
espaciais  e  temporais  vindas  de  visualizações  de  baixo-nível  e  a  natureza 
qualitativa dos seus sistemas de raciocínio.

4.  Lógica  de  Descrição  constitui  uma  família  de  formalismos  de 
representação  de  conhecimento  que  tem  recebido  muita  atenção  na  última 
década.  Lógica  de  Descrição  oferece  representação  de  conhecimento 
orientado a objetos similar a linguagens de frames usados em muitos sistemas 
baseados em conhecimento, mas baseado em semântica formal. A Lógica de 



16

Descrição representa um subconjunto do Cálculo de Predicados de Primeira 
Ordem,  que  é  geralmente  escolhido  por  sua  garantia  de  decidibilidade  de 
checagem  de  consistência  e  outros  serviços  de  inferência  chaves.  Além  do 
que,  recentes  desenvolvimentos  de  sofisticadas  técnicas  de  otimização 
levaram a sistemas de Lógica de Descrição que combinam uma expressiva 
representação  de  linguagem  com  serviços  altamente  eficientes.  Em 
(BAADER, F. et al., Eds., 2003) é provido um excelente overview do estado 
da  arte  da  metodologia  da  Lógica  de  Descrição.  (NEUMANN,  B.  e  R. 
MÖLLER, 2006, p.2-3)

Ao longo do trabalho, os autores apresentam os termos interpretação de alto nível 
(high-level interpretation) – que levam a estruturas conceituais que podem ser descritas 
como interpretações – e agregados, o ponto principal da abordagem. O primeiro termo é 
definido como a tarefa de entender uma cena indo além do simples reconhecimento de 
objetos. Para tal é proposto o seguinte framework:

Figura 2.2 – Framework baseado em conhecimento para interpretação de alto nível de 
cenas (NEUMANN, B. e R. MÖLLER, 2006) 

Como  bem  apontado  por  Fiorini,  S.  R.  (2009),  os  autores  não  especificam 
claramente como seria a passagem de dados da interpretação de baixo para alto nível. 
Simplesmente é citado o uso do intermediário GSD (Geometrical Scene Description), 
introduzido  pelo  próprio  autor  em  (NEUMANN,  B.,  1989)  que,  nas  palavras  dele 
mesmo, é um conveniente separador entre processos de alto e baixo nível. Logo após 
ainda é declarado que neste trabalho esses tipos de processos deverão interagir, assim 
não se assume que o GSD seja completo ou correto em qualquer sentido. Também são 
deixadas  de  lado  as  dificuldades  da  interpretação  de  baixo  nível  das  imagens, 
assumindo-se que uma reconstrução geométrica parcial da cena estará disponível.

Ainda  quanto  à  interpretação  de  alto-nível,  são  listadas  algumas  características 
esperadas:

• Envolver diversos objetos e ocorrências.
• Depender das relações temporais e espaciais entre partes de uma cena.
• Descrever cenas em termos qualitativos, omitindo detalhes geométricos.



17

• Explorar informação contextual.
• Incluir fatos inferidos, não observáveis na cena.
• Baseado em conhecimento visual e experiências sobre o mundo. 

O termo “agregados” é descrito como a principal entidade conceitual. Ele consiste 
em um conjunto de partes unidas para formar um conceito que satisfaz certas restrições. 
Como exemplos utilizados pelos autores, um agregado pode ser um conjunto de louças 
e talheres que podem vir a definir se a cena que está sendo vista é de uma mesa de café 
da  manhã,  almoço,  etc.  Segundo  os  autores  a  principal  motivação  para  definir  um 
agregado  é  prover  uma  descrição  coerente  de  entidades  que  ocorrem  em  uma  cena, 
independentemente de estarem ou não, visíveis, podendo haver a inferência de algum 
elemento que não esteja evidente nela, estando de acordo com as características de uma 
interpretação de alto nível citada acima.

Ainda  quanto  às  escolhas  feitas  pelos  autores,  é  defendido  o  uso  de  Lógica  de 
Descrição, usando-se o argumento de que, como já visto em diversos sistemas de frames 
e redes semânticas, não é necessário o uso de uma lógica de primeira ordem, utilizando-
se  apenas  algumas  partes  dela,  tendo  uma  grande  vantagem  sobre  os  provadores  de 
teoremas necessários na lógica completa. Lógica de Descrição também é defendida por 
ter uma semântica formal que evita ambiguidades que geralmente surgem em sistemas 
de conhecimento quando construídos intuitivamente.

No decorrer do trabalho de Neumann e Möller (2006), é apontado o uso do sistema 
RACER (HAARSLEV, V. e R. MÖLLER, 2001), que implementa serviços de inferência 
na Lógica de Descrição ALCQHIR+(D-), também chamada de SHIQ(Dn)-, considerado 
suficiente, já que, segundo os  autores, os  requisitos  do sistema  são satisfeitos  com a 
lógica ALCF(D). Entretanto, o que fica latente é o fato de que não há suporte para a 
escolha  de  qual  agregado  será  construído  primeiro,  algo  que  geraria  backtracking e 
ineficiência  para  a  interpretação  da  cena,  já  que  no  momento  em  que  o  trabalho  foi 
elaborado  esse  tipo  de  suporte  estava  fora  do  escopo  dos  sistemas  de  Lógica  de 
Descrição da época. Esse tipo de problema não resolvido acaba tirando boa parte da 
credibilidade do trabalho, já que ele não resolve grande parte daquilo que se propõe, 
apresentando  simplesmente  uma  solução  teórica  que  apenas  funcionaria  num  mundo 
que não existe, deixando assim pouco proveito prático.

Por  fim,  o  trabalho  não  deixa  explícito  se  utiliza  uma  abordagem  top-down ou 
bottom-up; contudo, no capítulo 5.2 - Supporting the Scene Interpretation Process with  
a  DL  System,  é  apontada  a  necessidade  de  instance  merging,  um  passo  tipicamente 
utilizado quando uma instância top-down hipotética precisa se conectar a uma evidência 
bottom-up. Isso leva a crer uma abordagem híbrida, tendo um processamento bottom-up 
para as imagens no baixo nível e interpretações top-down.

2.1.1 Evoluções da Abordagem dos Agregados
Dentre as evoluções do trabalho de Neumann e Möller (2006) temos os seguintes 

artigos:
Em KREUTZMANN, A. et al., (2009), o trabalho estende os antigos trabalhos de 

Neumann,  utilizando  um  modelo  probabilístico  de  alto  nível.  Nesse  modelo 



18

probabilístico, são utilizadas árvores de decisão e hierarquias de composição bayesianas 
(Bayesian  Compositional  Hierarchies).  O  trabalho  também  visa  a  evolução  da 
classificação dos objetos utilizando o framework SCENIC (HOTZ, L. e B. NEUMANN, 
2005). Os autores alegam que esse método reduz a complexidade e melhora a qualidade 
da  interpretação  para  cenas  temporais,  também  reduzindo  a  incidência  de  falsos 
positivos.

Em (HOTZ, L. et al., 2008) também é utilizado o framework SCENIC. Sua principal 
contribuição é a utilização clara de um nível intermediário para “comunicação” entre o 
alto  e  baixo  nível,  sendo  que,  suas  principais  características  são  o  casamento  entre 
evidências  do  baixo  nível  com  conceitos  do  alto  nível,  confirmação  ou  refutação  de 
hipóteses do alto nível e início de atividades do baixo nível a partir de hipóteses do alto 
nível. Aqui também fica claro o uso da abordagem top-down.

Mesmo sendo duas das mais interessantes evoluções do trabalho, elas não possuem 
um avanço suficiente para serem tratadas como uma nova abordagem.

2.2 Abdução
A abordagem abdutiva de (SHANAHAN, M. e D. A. RANDELL, 2004) é proposta 

para  uso  em  robôs,  tendo  como  motivação  o  fato  de  que,  até  o  momento  de  sua 
publicação, as ações dos robôs eram geradas assumindo-se que a percepção de cenas 
estava em uma caixa-preta que poderia prover dados sobre o mundo em um alto nível, 
sem a preocupação de como os dados brutos do baixo nível seriam transformados em 
dados de alto nível.

Os experimentos no artigo foram realizados com o robô LUDWIG, um humanóide 
composto  por  tronco,  dois  braços,  cada  um  com  3  graus  de  liberdade  e  uma  stereo  
camera em  uma  cabeça  pan-and-tilt (uma  cabeça  que  gira  sobre  o  próprio  eixo, 
simulando a movimentação de uma cabeça humana). A função desse robô é identificar 
objetos interessantes e então mexê-los utilizando servovisão. Ele cumpre a sua tarefa 
com  ajuda  da  extensão  dada  à  abdução  básica  em  (SHANAHAN,  M.,  2002),  um 
framework que permite o fluxo bidirecional entre cognição e a imagem de baixo nível, 
segundo  os  autores,  tendo  o  potencial  de  abranger  cognição,  ação  e  percepção.  Um 
importante  aspecto  também  é  capacidade  de  melhorar  a  representação  de  um  objeto 
através da interação com ele. Dessa forma, é tido como grande contribuição do artigo 
superar as deficiências de tentativas prévias de caracterização lógica da percepção de 
robôs utilizando abdução. O trabalho é feito através de um meta-interpretador escrito 
em prolog com o processamento das imagens no baixo nível feitas em C++, tendo ainda 
a interação com o usuário, para melhorar a percepção que deseja-se dar ao robô.



19

Figura 2.3: Robô LUDWIG (SHANAHAN, M. e D. A. RANDELL, 2004)

A percepção visual dada pela abdução é feita da seguinte forma:
Sendo ? a teoria que captura a relação causal entre objetos de uma cena ou imagem 

e  os  dados  retirados  dessa  imagem  de  baixo  nível,  ?  uma  conjunção  de  fórmulas 
representando  uma coleção  de dados  da imagem no baixo nível, a tarefa é  encontrar 
uma conjunção ? de fórmulas, tal que:

Dessa forma, a idéia é encontrar hipóteses na cena que expliquem os dados visuais 
que o robô recebeu.  Assim, temos  que ?  deve  ser consistente  com  ?  e  deve  conter 
apenas  predicados  considerados  “abdutíveis”,  construindo  assim  diversos  ?  que 
explicam   ?,  devendo-se  utilizar  o  ?  que  contenha  mais  informação  e  ela  deve  ser 
correta.

Temos que:
Sendo ?1 … ?n o conjunto de todas  hipóteses que explicam ?.
Dado que uma e apenas uma dessas hipóteses pode ser a verdadeira explicação, e se 

nenhuma das hipóteses é absorvida por qualquer outra, podemos assumir  ?1 … ?n.
Considerando uma hipótese qualquer ?k e R sendo ?1 … ?k-1 ?k+1 … ?n.
Temos, pelas leis da probabilidade:

Onde P(?k) é a probabilidade prévia de ? e P(R), a de R, temos:



20

Para qualquer hipótese ? na forma ?1 ^ … ^ ?m, temos:

Como exemplo de aplicação é dada a identificação de blocos Lego como pode ser 
visto na Figura 2.4:

Figura 2.4: Blocos Lego e suas arestas (SHANAHAN, M. e D. A. RANDELL, 2004)

A primeira parte da Figura 2.4 representa a visão do robô, a segunda, a detecção de 
arestas Sobel, já a terceira, mostra a identificação de cada aresta pelo algoritmo, ou seja, 
o processamento da imagem no baixo nível. O algoritmo visa primeiramente a abdução 
de áreas trapezoidais a partir da identificação das arestas e, em um segundo momento, a 
abdução  de  cubóides  dentro  dessas  áreas.  Esse  trabalho  é  feito  utilizando  axiomas 
lógicos de primeira ordem, relacionando às primitivas de baixo nível retas e pontos com 
as regiões trapezoidais e cubóides. O núcleo do trabalho, o meta-interpretador, trabalha 
com uma lista de hipóteses ordenadas de acordo com seu poder de explicação de  ?, 
então suas expectativas são confirmadas, ou não, reordenando assim as hipóteses. Ao 
fim desse processo, que ainda pode contar com o ajuste do usuário, temos o resultado 
que  é  a  hipótese  que  fica  melhor  posicionada  e  temos  então  um  trabalho  com  uma 
abordagem híbrida (top-down e bottom-up).

Indo um pouco além da simples abordagem do trabalho há algumas evoluções para 
melhor resposta em termos de interpretação de cenas, como a percepção ativa, cálculo 
de eventos, abdução de eventos visuais para respostas do robô contextualizadas através 
de  sensores  visuais  e  não  apenas  de  proximidade  e  aspect  graphs,  que  representam 
diversas visões de um mesmo objeto, podendo assim facilitar sua identificação.

2.2.1 Evoluções da Abordagem Abdutiva
Dentre  os  trabalhos  encontrados  até  o  momento  da  revisão  bibliográfica  deste 

trabalho  (Junho  de  2010),  o  único  que  pode  ser  encarado  como  uma  evolução  na 
abordagem abdutiva de (SHANAHAN, M. e D. A. RANDELL, 2004) é o encontrado 
em  (RANDELL,  D.  e  M.  WITKOWSKI,  2006).  Sua  principal  contribuição  é  a 
utilização  de  feature  clouds,  uma  estrutura  de  dados  que  codifica  características 
heterogêneas  e  espacialmente  distribuídas,  detectadas  pelo  sensor,  e  podem  ser 
contrastadas com outras representações de aplicações baseadas em percepção visual. 

Mesmo com o uso dessa técnica que utiliza vetores 3D para formação das descrições 
e hipóteses e com a reivindicação dos autores de que seu uso melhora os resultados e 
também sua flexibilidade, a exemplo do que foi visto sobre as evoluções da abordagem 
do capítulo 2.1, esse trabalho demostra apenas uma diferente aplicação de técnicas, não 



21

tendo uma grande mudança em sua essência e não devendo, assim, ser considerada uma 
nova abordagem.

2.3 Orion
A abordagem do grupo Orion pode ser vista em (Hudelot, C. et al. ,2004), (Maillot, 

N. et al. ,2004) e (Hudelot, C., 2005). O grupo traz uma abordagem ao problema do 
ancoramento simbólico, descrito como a dificuldade de relacionar dados numéricos de 
uma imagem com dados semânticos que representam e dão significado ao conteúdo da 
imagem (LORENZATTI, A., 2008), conteúdo esse tratado por um sistema cognitivo que 
introduz uma nova camada entre o nível semântico e o nível da imagem, chamado de 
nível visual.

Dentro do trabalho do grupo Orion para resolução da interpretação do significado de 
uma imagem, são propostos 3 sub-problemas:

• O problema do processamento da imagem, que visa à extração de dados 
numéricos da imagem no baixo nível;

• o problema do ancoramento simbólico, já detalhado anteriormente;
• o problema da interpretação semântica, que consiste na extração de um 

significado da imagem.
Essas 3 áreas são divididas como mostrado na Figura 2.5 a seguir:

Figura 2.5: Os 3 níveis de abstração correspondentes aos sub-problemas representados 
através de uma imagem microscópica da biologia (HUDELOT, C. et al., 2004)

Essa  subdivisão  de  problemas  envolve  ainda  problemas  de  comunicação  entre  as 
camadas,  resolvido  através  de  ontologias  intermediárias  (o  grupo  Orion  utilizou  a 
definição de ontologia encontrada em (GRUBER, T. R., 1995): “especificação formal e 
explícita  de uma  conceitualização compartilhada”,  considerando uma  ontologia como 
sendo  composta  por  um  conjunto  de  conceitos  C,  um  conjunto  de  relações  R  e  um 
conjunto de axiomas). A primeira ontologia, responsável pela comunicação entre o nível 
semântico  e  o  problema  do  ancoramento  simbólico,  ou  simplesmente  o  nível  visual, 



22

chamada “ontologia de conceitos visuais” e a “ontologia de processamento de imagens”, 
responsável pela comunicação entre os níveis visual e de imagem.

A  ontologia  de  conceitos  visuais  tem  como  meta  ser  um  vocabulário  comum 
utilizado por humanos para descrever objetos dentro de uma cena, ou seja, a descrição 
de conceitos semânticos. Ela foi composta por 115 conceitos, dos quais:

• Conceitos  espaciais:  32  conceitos  que  definem  formato,  tamanho  e 
localização  e  32  conceitos  referentes  a  relações  espaciais,  como  topologia, 
distância e orientação;

• conceitos  de  cor:  tendo  em mente  o formato HSL,  é composto  por 28 
termos  voltados  à  matiz  (Hue),  4  à  saturação  (Saturation)  e   5  à  luminância 
(Lightness);

• conceitos de textura: contendo 14 tipos de texturas.
A ontologia de processamento de imagens tem como meta codificar formalmente os 

conceitos,  propriedades  e  relações  do  processamento  de  imagens,  definido  como  “o 
processo de manipulação e análise de imagens com um computador de acordo com um 
objetivo” (HUDELOT, C. et al., 2004). Composta por 183 conceitos, está dividida da 
seguinte forma:

• Conceitos de entidades de imagem: 11 conceitos representando diferentes 
estruturas de dados, como regiões, bordas, etc;

• conceitos de características de imagem: 167 conceitos, como medidas de 
tamanho (área, comprimento, etc.), formato (compacidade, excentricidade,etc.), 
dentre outros;

• conceitos de funcionalidades de processamento de imagens: 5 conceitos 
provenientes  das  intenções  de  dado  processamento  de  imagem,  dentre  eles 
segmentação de imagem. 

Dessa maneira, a ontologia deve funcionar de maneira que o nível superior possa 
requisitar  dados,  guiando  a  forma  como  devem  ser  entregues,  bem  como  os  dados 
entregues  pelo  nível  inferior  devem  ser  de  fácil  compreensão  para  o  nível  superior. 
Assim,  ampliando  o  esquema  da  Figura  2.5,  temos  a  inclusão  das  ontologias  entre 
níveis, como pode ser observado na Figura 2.6:



23

Figura 2.6: Ancoramento simbólico: 3 níveis e ontologias para comunicação 
(HUDELOT, C. et al., 2004)

A abordagem  Orion  sugere  ainda  dois  métodos  de  trabalho  para  a  interpretação 
semântica:  conhecimento  a  priori  e  por  aprendizado.  O  primeiro  consiste  em  ter  a 
ligação entre características  dos dados  da imagem no baixo nível e conceitos  visuais 
construídos explicitamente, já o segundo tem essa ligação aprendida através de diversas 
imagens.  O  método  por  aprendizado  é  composto  por  duas  etapas:  seleção  de 
características e treinamento. 

A seleção das características é feita através da Análise Discriminante Linear (Linear  
Discriminant Analysis – LDA). Já a segunda etapa, o treinamento, é feita de maneira 
supervisionada,  através  de  um  conjunto  de  treinamento  montado  a  partir  de 
características extraídas de regiões de interesse apontadas por um especialista.

Apesar de mais próxima ao método de aprendizagem humano, a abordagem por 
aprendizado  ainda  tem  alguns  problemas,  principalmente  o  fato  de  não  conseguir 
aprender  a  estrutura  espacial  dos  conceitos  semânticos,  assim  não  os  levando  em 
consideração para conseguir os  resultados. Como é de  se esperar, o método  se torna 
mais eficiente à medida em que o conjunto de treinamento cresce.

No método do conhecimento a priori, uma base de conhecimento de ancoramento 
simbólico é previamente construída, como pode ser no exemplo da Figura 2.7 :



24

Figura 2.7: Exemplo de ancoramento simbólico construído a priori (HUDELOT, C. et 
al., 2004)

Como  artefato  ainda  é  utilizada  a  imprecisão  de  conjuntos  fuzzy para  modelar  as 
características de baixo nível entre conceitos visuais e dados da imagem.

Dentro da abordagem Orion ainda é utilizada uma estratégia híbrida (podendo 
ser  usado  tanto  top-down quanto  bottom-up),  ou  ainda  a  ligação  dos  conceitos  para 
formação do ancoramento simbólico pode ser feita de maneira manual.

2.3.1 Evoluções da abordagem Orion
Não parece haver evoluções da abordagem do grupo Orion até o momento, apenas 

algumas aplicações, como encontrado em  (RAICU, D. S., E. et al., 2010).

2.4 Espaços Conceituais
A abordagem encontrada em (CHELLA, A. et al., 1997), (CHELLA, A. et al., 2001) 

e (GÄRDENFORS, P., 2004) – espaços conceituais – tem, nos seus primórdios, a área 
da visão computacional contextualizada na robótica. O termo é definido em (CHELLA, 
A.  et  al.,  1997)  como  um  espaço  métrico  consistindo  em  um  número  de  dimensões 
cognitivas, incluindo cor, tamanho, etc. e trazendo uma

arquitetura cognitiva para um sistema de visão computacional, no qual 
uma  representação  interna  efetiva  do  ambiente  é  construída  através  de 
processos definidos em um nível intermediário adequado que age como um 
intermediário  entre  os  dados  sensoriais  e  o  nível  simbólico.  […] Essa 
arquitetura visa prover um modelo geral de visão para um agente autônomo.

 A abordagem dos espaços conceituais é dividida em 3 diferentes níveis, como pode 
ser visto na Figura 2.8:



25

Figura 2.8: A arquitetura proposta pela abordagem dos  espaços conceituais e seus 3 
diferentes níveis (CHELLA, A. et al., 1997)

• Nível  Subsimbólico  (Subsymbolic  Level):  A informação  é  estritamente 
relacionada aos dados sensoriais, ou seja, à imagem bruta do baixo nível;

• Nível  Conceitual  (Conceptual  Level):  O  nível  intermediário  no  qual  a 
informação é caracterizada em termos  de um espaço métrico definido por um 
número  de  dimensões  cognitivas,  independente  de  qualquer  linguagem.  Em 
resumo: o core da abordagem dos espaços conceituais;

• Nível Linguístico (Linguistic Level): Onde a informação é expressada por 
uma linguagem simbólica.

As transições vistas na Figura 2.8 são realizadas da seguinte forma:

• “A” recebe a imagem de entrada de uma câmera e tem como saída um 
mapeamento chamado 21/2 D;

• “B”  constrói  uma  descrição  da  cena  em  termos  de  combinações  de 
primitivas geométricas 3D;

• “C” implementa o mapeamento entre o nível conceitual e simbólico;



26

• “D” implementa o modo linguístico do mecanismo de foco de atenção;
• “E” implementa o modo associativo do foco de atenção.

No seu nível mais baixo, o subsimbólico, a abordagem trata apenas de dados brutos 
vindos  da  imagem,  sem  a  utilização  de  abstrações.  Ao  passar  ao  próximo  nível,  o 
conceitual, é utilizado o conceito de knoxel, definido como “um ponto genérico em um 
espaço  conceitual  (o  termo  knoxel  é  derivado  por  analogia  de  pixel).  Um  knoxel 
corresponde  a  uma  entidade  epistemologicamente  primitiva  no  considerado  nível  de 
análise.” (CHELLA, A. et al., 2001, p.3), que se traduz como uma região da imagem. A 
seguir, na Figura 2.9, pode ser visto um exemplo da aplicação do conceito, sendo que 
cada ki é um knoxel: 

Figura 2.9: Uma imagem com seus objetos transformados em knoxels (CHELLA, A. et 
al., 1997)

Esses  knoxels  são  formados  através  de  superquadráticas  –  formas  geométricas 
derivadas  de  uma  equação  paramétrica  quadrática  com  funções  trigonométricas 
elevadas a dois expoentes reais – representadas da seguinte forma:

onde -?/2 ? ? ? ?/2 e -? ? ? &amp;lt;?. ax, ay e az são os comprimentos dos eixos e ?1 e ?2, 
os  fatores  de  forma,  atuando,  respectivamente,  em  relação  à  longitude  e  latitude  do 
formato.  Sendo  que  essa  é  a  forma  canônica  de  uma  superquadrática,  temos  que  o 
knoxels são representados, num ambiente 3D, com a adição de 3 coordenadas de centro 
px, py e pz e 3 ângulos de Euler ?, ?, e ?:

Temos a seguir a Figura 2.10 para ilustrar a variação dos fatores de forma:



27

Figura 2.10: Variação dos fatores de forma (CHELLA, A. et al., 2001)

Passando  ao  nível  linguístico,  tendo  em  mente  a  necessidade  de  prover  uma 
descrição concisa da cena em termos de uma linguagem lógica de alto nível, é utilizado 
um  formalismo  de  representação  híbrido,  dividido  em  componente  terminológico  e 
componente  assertivo.  O  primeiro  componente  contém  as  descrições  de  conceitos 
relevantes  para  o  domínio  representado,  um  modelo  conceitual,  já  o  segundo  é 
composto pelas asserções descrevendo a cena. A divisão entre esses dois componentes é 
útil  para  a  distinção  entre  o conhecimento  conceitual  e as  asserções  feitas  para  cada 
cena.  A seguir,  nas  Figuras  2.11 e  2.12,  são  mostrados  exemplos  de  conhecimento  e 
situação  no  componente  terminológico,  respectivamente.  O  nível  linguístico  ainda 
permite o agrupamento de knoxels, permitindo assim a formação de objetos, como no 
caso do martelo na Figura 2.9, formado pelos knoxels k1 e k2.



28

Figura 2.11: Fragmento de  conhecimento no componente terminológico (CHELLA, A. 
et al., 1997)

Figura 2.12: Situação no componente terminológico (CHELLA, A. et al., 1997) 

Dessa forma podemos ter a representação de um martelo em um espaço conceitual, 
semelhante ao da Figura 2.9, como pode ser visto na Figura 2.13:



29

Figura 2.13: Martelo representado por seus knoxels em um espaço conceitual 
(CHELLA, A. et al., 2001)

2.4.1 Evoluções da Abordagem dos Espaços Conceituais
A exemplo  de  outras  abordagens,  não  há  evoluções  tão  significativas  a  ponto  de 

revolucionar  a  abordagem  dos  espaços  conceituais,  apenas  algumas  aplicações  do 
trabalho como pode ser visto em (CHELLA, A. e S. GAGLIO, 2007) e (CHELLA, A. 
et al., 2008), essas mais voltadas à robótica.

2.5 Comparativo Entre as Abordagens
Após  descrição  mais  detalhada  de  cada  abordagem  estudada,  será  feito  um 

comparativo entre elas:
A abordagem  dos  agregados  (NEUMANN,  B.  e  R.  MÖLLER,  2006)  tem  como 

características o uso de Lógica de Descrição (Description Logics – DL), o que torna a 
representação  simples  e  mantém  um  bom  nível  formal.  Os  pontos  fortes  incluem  a 
possibilidade de utilização em cenas  com passagem de tempo, uma grande vantagem 
para sistemas em tempo real e possui também o que é a sua principal característica, a 
utilização  dos  agregados,  procurando  tirar  conclusões  de  acordo  com  o  contexto  da 
cena, o que aproxima a abordagem de um comportamento mais natural. Entretanto, ela 
deixa  de  lado  as  dificuldades  de  interpretação  de  baixo  nível,  não  provendo  muitas 
informações  sobre  o  modo  como  trata  o  problema  do  ancoramento  simbólico, 
assumindo  que  isso  não  causará  problemas,  coisa  que  parece  recorrente  em  alguns 
trabalhos  acadêmicos, quando os autores  parecem fugir do mundo real para criar um 
ambiente  em  que  seus  problemas  não  existirão  e  sua  idéia  poderá  prosseguir  sem 



30

problemas. Outro fato que pode também ser considerado um ponto fraco é a falta de um 
nível intermediário na abordagem entre a imagem bruta e o nível mais alto, o que pode 
aumentar significativamente a complexidade do código para melhores resultados. Além 
disso, a maneira como é feita comunicação entre dados no baixo nível e alto nível não é 
explicitamente mostrada, levando a crer que seria feita através de dados brutos, ou seja, 
a partir do processamento da imagem já deveria haver a formação dos agregados, com a 
utilização do GSD e uma tradução posterior para, no caso, lógica de descrição para que 
o sistema possa ter suas conclusões.

A abordagem  da  abdução  (SHANAHAN,  M.  e  D.  A.  RANDELL,  2004)  possui 
também a possibilidade de se trabalhar com imagens em movimento e conta com um 
forte formalismo: a Lógica de Primeira Ordem. Tem também como ponto forte o fato de 
haver interação com o usuário para melhorar a qualidade da cena que está sendo visto e, 
consequentemente, ter melhores resultados. Como pontos fracos da abordagem pode ser 
citada  a  declaração  dos  próprios  autores  de  que  ela  funciona  bem  com  exemplos 
simples,  como  reconhecimento  de  blocos  de  lego,  mas  não  possui  boa  resposta  com 
cenas  mais  complexas,  algo  que  talvez  pudesse  ser  melhorado  se  a  abordagem  não 
trabalhasse apenas com representações de linhas e regiões, mas sim com outros padrões, 
como  cores  e  texturas.  A exemplo  do  que  é  visto  na  abordagem  dos  agregados,  a 
abordagem não possui uma forma de comunicação explícita entre os diferentes níveis da 
abordagem, apenas a formação de conjuntos de linhas e regiões, retiradas diretamente 
do  processamento  da  imagem,  que  servirão  para  montar  as  teorias  e  fórmulas  para 
conclusões do significado da imagem no alto nível; contudo, a abordagem abdutiva não 
especifica também, com clareza, o que se deve esperar como resultado no alto nível.

A abordagem Orion (HUDELOT, C. et al., 2004), (MAILLOT, N. et al., 2004) e 
[HUDELOT, C., 2005) possui a criação de um nível intermediário entre a imagem bruta 
e  os  dados  semânticos  e tem  como  ponto  forte  a  divisão  muito  clara  entre  seus  três 
níveis, bem como a comunicação entre eles que é feita por ontologias, fazendo com que 
a abordagem possua um bom nível de abstração e clareza. Outra característica a favor 
da abordagem é o fato de ter sido utilizado em aplicações reais e ser um trabalho bem 
completo, o que serve como uma base mais forte para posteriores aplicações. Contudo, 
o  fato  de  ser  um  trabalho  tão  complexo  faz  com  que  ele  possa  se  tornar  inviável, 
dependendo da área a ser aplicado. Também é um trabalho que deixa a desejar pela falta 
de possibilidade utilização de cenas em movimento e o fraco resultado quando se utiliza 
o método por aprendizado e não conhecimento a priori.

Finalmente,  a  abordagem  dos  espaços  conceituais  (CHELLA,  A.  et  al.,  1997), 
[CHELLA,  A.  et  al.,  2001)  e  (GÄRDENFORS,  P.,  2004),  a  exemplo  da  abordagem 
Orion,  possui  a  criação  de  um  nível  intermediário  entre  a  imagem  bruta  e  os  dados 
semânticos, deixando bem clara a divisão entre os  níveis  alto, intermediário e baixo. 
Torna-se uma abordagem interessante pelo fato da introdução do conceito de knoxel, 
possibilitando assim representações a partir de um espaço 3D e composição de objetos 
complexos  a  partir  de  modelagens  simples.  Porém,  a  exemplo  do  que  é  visto  na 
abordagem abdutiva,  só é levada  em consideração  a  forma  dos  objetos, deixando  de 
lado algumas  características importantes.

Assim, temos algumas das principais características evidenciadas na tabela 2.1.



31

Tabela 2.1: Comparação entre abordagens semânticas de reconhecimento de objetos

Abordagens

Agregados Abdução Orion Espaços conceituais

Formalismo de 
Representação

Lógica de 
Descrição 

(Description 
Logics – DL)

Lógica de 
Primeira 
Ordem

Frames

Frames e 
Lógica, mas 

não especifica 
o tipo

Aplicação Básica Interpretação de Cenas

Controle de 
Tráfego e 
Robótica

Interpretação de 
imagens estáticas Robótica

Tipo de 
Ancoramento 

Simbólico

Possivelmente 
híbrido (top-down 

e bottom-up)

Híbrido (top-
down e bottom-

up)

Híbrido (top-down 
e bottom-up) e 

Manual

Híbrido (top-
down ebottom-

up)

Processamento 
de Imagem Utiliza GSD

Detecção de 
arestas e 
regiões

Detecção de 
regiões, ou seleção 

manual

Detecção de 
regiões

Implementação Utiliza sistema RACER
Utiliza C++ e 

Prolog

Em (HUDELOT, 
C., 2005) utilizou 

a plata- forma 
LAMA 

(CRUBÉZY, M. et 
al., 1998)

Menciona uso 
dos sistemas 

TEA-1 
(RIMEY, R. 
D., 1993) e 
BUSTER 

(BIRNBAUM, 
L., 1993)

Número de 
Níveis 2 níveis explícitos

2 níveis 
explícitos 3 níveis explícitos

3 níveis 
explícitos

Níveis Utilizados

Não são 
explicitadas 

nomenclaturas para 
os níveis

Não são 
explicitadas 

nomenclaturas 
para os níveis

Semântico, Visual 
e da Imagem

Subsimbólico, 
Conceitual e 
Linguístico

Comunicação 
Entre Níveis Dados Brutos Dados Brutos Ontologias

Knoxels entre 
níveis 

Coneitual e 
Linguístico.

Com a análise feita ao longo do capítulo e resumida na tabela 2.1 acima, pode-se 
concluir que a abordagem Orion é a melhor formulada dentre as quatro. Contudo, deve-
se manter em mente que cada uma foi proposta com objetivos diferentes e tendem a 
mostrar alguma dificuldade na extensão para outros tipos de abordagem.



32

3 O FRAMEWORK S-CHART E O SISTEMA 
INTELISTRATA

O trabalho de Fiorini, S. R. (2009 e 2010) apresenta duas ferramentas para a análise 
semântica de gráficos: o  framework S-Chart e o sistema Intelistrata. Sendo o primeiro 
um  framework geral para  interpretação  de gráficos  e o segundo uma aplicação  para 
estratigrafia de sequências, que será vista em mais detalhes na seção 3.3.

3.1 Framework S-Chart
Criado a partir das linguagens OWL e Java, o framework S-Chart tem como foco a 

interpretação  semântica  de  gráficos  através  da  combinação  de  algoritmos  de 
processamento  de  sinais  com algoritmos  e  modelos  de  raciocínio  simbólico.  A partir 
disso o framework utiliza os seguintes conceitos:

• Incorporação de ontologias de domínio;
• Primitivas de modelagem independentes de domínio;
• Ancoramento simbólico explícito;
• Modelo processável por computador.
A arquitetura do framework  S-Chart é dada pela  divisão  em três  componentes: o 

componente  de  representação  que,  a  exemplo  dos  trabalhos  de  (HUDELOT,  C.,  N. 
MAILLOT, et al., 2004), (MAILLOT, N., M. THONNAT, et al., 2004) e (HUDELOT, 
C., 2005), é dividido em três níveis (Semântico, Visual e Analógico); o componente de 
mapeamento,  destinado  ao ancoramento  simbólico,  e  o  componente  de  interpretação, 
responsável pela inferência e interpretação das informações visuais, como pode ser visto 
na Figura 3.1 a seguir:



33

Figura 3.1: Arquitetura do framework S-Chart (FIORINI, S. R., 2009)
O  componente  de  representação  é  composto  pelos  níveis  semântico,  visual  e 

analógico.  O  nível  semântico  é  responsável  pelo  modelo  de  conhecimento  e  suas 
ontologias  de  domínio.  O  visual  é  composto  por  feições  visuais  genéricas, 
independentes  de  domínio,  contendo  noções  de  formas  visuais  básicas  como  pontos, 
retas e curvas; e também relações como proximidade, comparações de tamanhos, etc. 
Por fim, o nível analógico é também independente de domínio e diretamente ligado a 
algoritmos de processamento de imagens para extração de elementos necessários para 
reconhecimento no nível visual.

O componente de mapeamento, responsável pelo ancoramento simbólico, associa os 
elementos da imagem ao seu correspondente e é definido de uma maneira que apenas 
possa haver o mapeamento de um nível do componente de representação para o nível 
vizinho.  Assim,  entidades  do  nível  analógico  somente  poderão  ser  mapeadas  para  o 
nível  visual  e  então  essas  entidades  do  nível  visual  para  o  semântico,  não  sendo 
permitido  o  mapeamento  direto  de,  por  exemplo,  um  conjunto  de  pixels  do  nível 
analógico para uma entidade do nível semântico, digamos, um carro.

O componente de interpretação, responsável por processar o sinal em conjunto com 
os  modelos  de  representação  e  ancoramento  simbólico  até  que  seja  inferido  algum 
objeto do domínio presente no sinal é, talvez, o componente mais interessante dentro do 
framework S-Chart  e  possui  sua  arquitetura  interna  contendo  duas  máquinas  de 
interpretação, uma semântica e outra visual. Seu funcionamento se dá a partir de um 
sinal  de  entrada  contendo  a  imagem  a  ser  analisada,  que  será  processada  pela  parte 
responsável pelo processamento de sinal, e uma entidade do domínio, uma hipótese que 
será procurada nesse sinal. 

Desse modo, a máquina de interpretação semântica do componente de interpretação 
“tenta confirmar a presença de conceitos do domínio com base nas suas extensões no 
nível visual, definidos por detectores simbólicos” (FIORINI, S. R., 2009, p.55). Já  a 
máquina de interpretação visual extrai as primitivas visuais do nível analógico através 
do  acionamento  de  algoritmos  de  processamento  de  sinal  e  da  utilização  de  seus 
próprios detectores simbólicos.



34

A arquitetura do componente de interpretação, que possui como saída as instâncias 
de  conceitos  do  domínio  relacionados  à  hipótese  inicial  de  busca  através  de  uma 
abordagem mista  na qual  utiliza raciocínio  top-down e  bottom-up, pode ser visto em 
mais detalhes na Figura 3.2.

Figura 3.2: Arquitetura do Componente de Interpretação (FIORINI, S. R., 2009)

3.2 Sistema Intelistrata
O sistema Intelistrata consiste na aplicação do  framework S-Chart no domínio da 

Estratigrafia  de  Sequências,  uma  sub-área  da  Geologia.  O  sistema,  arquitetado  de 
maneira que pode ser vista na Figura 3.3, sugere interpretações estratigráficas de perfis 
de raios gama.  

Figura 3.3: Arquitetura do sistema Intelistrata (FIORINI, S. R., 2009)



35

Para a criação do sistema Intelistrata foram propostas extensões sobre o framework 
S-Chart. Por exemplo, são incluídas ontologias – todas criadas em OWL – da área de 
estratigrafia de sequências. É importante salientar que não existe uma ontologia própria 
para esta área; uma ontologia foi criada a partir do conhecimento de alguns especialistas 
na área durante o desenvolvimento do trabalho de (FIORINI, S. R., 2009).

Há  também  extensões  no  nível  analógico  e  visual  do  framework S-Chart, 
proporcionando um maior alcance ao tema proposto, a Estratigrafia de Sequências. É 
importante lembrar que o  framework S-Chart foi construído com um propósito geral e 
toda aplicação feita a partir dele pode incluir extensões tornando-o mais completo para 
diversas áreas e seus resultados mais satisfatórios. Isso é o que vemos com o sistema 
Intelistrata.

Essas extensões formam, juntamente com a parte original do  framework S-Chart, o 
componente chamado “Modelos de Representação” na arquitetura do sistema na Figura 
3.3.

Os  componentes  de  infra-estrutura  na  arquitetura  do  sistema  Intelistrata  são  os 
componentes desenvolvidos por terceiros que dão suporte ao seu funcionamento. Sua 
utilização é justificada por Fiorini (2009), no caso do sistema Protege por ser uma das 
mais populares ferramentas de manipulação de OWL no momento do desenvolvimento 
do sistema, sendo que essa linguagem foi considerada suficiente para o proposto e ainda 
a ferramenta possui a disponibilidade de extensão pelo próprio usuário. Já o software 
Jess foi escolhido para execução das regras utilizadas no sistema e por sua facilidade de 
integração com o Protege. A parte de processamento numérico fica a cargo do Matlab 
R2008a, por disponibilizar diversos pacotes de processamento de dados numéricos e de 
sinal.

Por  fim,  o  componente  de  interpretação  da  arquitetura  do  sistema  Intelistrata  é 
composto  por  uma  GUI  (componente  de  interface  gráfica)  simples,  que  permite  a 
seleção do arquivo a ser analisado e a exibição de seus resultados; pelas máquinas de 
interpretação semântica e visual, como mencionado na seção 3.1 e pelo gerenciador de 
processamento de sinal, responsável pela delegação e gerenciamento dos algoritmos de 
processamento de sinais do sistema. 

3.3 Estratigrafia de Sequências
Estratigrafia de sequências é o mais recente paradigma revolucionário no 

campo de geologia sedimentar. Os conceitos incorporados por essa disciplina 
resultaram em uma mudança fundamental na maneira de pensar geologia e, 
em particular, os métodos de fácies e análises estratigráficas. Ao longo dos 
últimos quinze anos essa abordagem tem sido aceita por geocientistas como o 
estilo preferido de análise estratigráfica, que tem servido para fazer a ligação 
entre  diversas  disciplinas.  De  fato,  um  aspecto  chave  da  abordagem  de 
estratigrafia de sequências é encorajar a integração de conjuntos de dados e 
métodos  de  pesquisa.  Unir  conhecimentos  de  diversas  disciplinas 
invariavelmente  leva  a  interpretações  mais  robustas  e,  consequentemente, 
progresso científico. Assim, a abordagem da estratigrafia de sequências tem 
levado a um melhor entendimento de como unidades estratigráficas, tratos de 
sistemas e unidades deposicionais se relacionam em tempo e espaço dentro 
de bacias sedimentares. A aplicação de estratigrafia de sequências tem amplo 
campo  de  aplicações,  desde  exploração  preditiva  de  petróleo,  carvão  e 
delimitação dos depósitos, até melhor entendimento das mudanças geológicas 
locais e globais da Terra. (CATUNEANU, O., 2006, p.1)



36

A Estratigrafia  de  Sequências  é  a  área  da  Geologia  responsável  pelo  estudo  da 
formação dos estratos do subsolo pela variação do mar e deposição de matéria orgânica. 
Sua  correta  interpretação  permite  uma  boa  predição  do  que  pode  ser  encontrado  em 
dado local, o que é de grande ajuda para atividades como a extração de petróleo.

Há diversas maneiras de estudos para predição do material em dada área, como os 
perfis  de poços, que  “representam registros  geofísicos  de propriedades  de rochas  em 
diferentes poços” (CATUNEANU, O., 2006, p.40). Dentre as principais vantagens do 
uso de perfis de poços, que faz medidas indiretas sobre as propriedades de rochas está o 
custo reduzido em relação à extração de rochas. É possível aproximar o perfil da região 
através  do  uso  de  diferentes  tipos  de  perfis  que  possuem,  por  sua  vez,  diferentes 
interpretações  geológicas  e  devem  ser  combinados  para  resultados  mais  precisos.  O 
sistema Intelistrata utiliza o perfil de raios gama, que consiste em medir radioatividade 
natural, por exemplo, o decaimento de Potássio, Tório e Urânio nas rochas, o que reflete 
indiretamente  a  quantidade  de  argilominerais,  indicando  assim,  a  ocorrência  de 
sedimentos finos e grossos. Essa medição gera um perfil, uma curva, a exemplo do que 
pode ser visto na Figura 3.4, a partir da qual um especialista, ou um sistema como o 
Intelistrata,  é  capaz  de  dizer,  pelo  formato  visual  das  curvas  em  quais  trechos  deve 
haver sequências deposicionais, podendo assim identificar intervalos de interesse para 
posterior prospeção de petróleo no local.

Uma  sequência  deposicional,  segundo  as  palavras  de  Catuneanu  (2006),  pode  ser 
considerada  a  parte  fundamental  da  estratigrafia  de  sequências.  Ela  corresponde  aos 
pacotes de rochas depositados durante um ciclo completo de mudanças no nível básico 
do  mar  ou  transições  das  linhas  costeiras  dependendo  do  modelo  de  sequência 
deposicional  que  está  sendo  aplicado.  Elas  são  “uma  sucessão  relativamente 
concordante  de  estratos  geneticamente  relacionados  delimitadas  por  discordâncias  ou 
suas conformidades correlativas”. Essas sequências deposicionais são um histórico do 
que houve com determinada região ao longo dos anos e podem representar o tipo de 
material orgânico que ali se encontra. Uma parassequência, por sua vez, marca ciclos 
menores de oscilação do nível do mar e sua delimitação é sempre intena à seqüência 
deposicional.  Superfícies  de  inundação  máxima  são  os  estratos  que  identificam  a 
inversão do ciclo de subida do nível do mar.

No  capítulo  a  seguir  será  mostrado  um  novo  algoritmo,  com  auxílio  de  médias 
móveis, na tentativa de identificar padrões interessantes do perfil de raios gama, como 
por exemplo quedas abruptas, deixando a cargo do sistema inferir seu significado (no 
caso sabemos  que  será  um limite  de  sequência  deposicional).  A abordagem  proposta 
deve  fornecer  como  saída  objetos  possíveis  interpretação  semântica  pela  arquitetura 
adotada.



37

Figura 3.4: Exemplo de Perfil de Raio Gama. Editado de (FIORINI, S. R., 2009)



38

4 UM NOVO ALGORITMO

Nesta seção será discutida uma nova abordagem para o algoritmo de processamento 
de sinal, que visa tentar melhorar os resultados do sistema Intelistrata, tendo foco no 
nível  analógico  do  sistema.  Ela  deverá  ser  utilizada  em  conjunto  com  os  demais 
componentes do sistema, sem alterações significativas nos mesmos, apenas o suficiente 
para a integração do novo algoritmo com o sistema.

4.1 O novo algoritmo
O  sistema  Intelistrata  tem  como  objetivo  principal  a  busca  de  sequências 

deposicionais,  parassequências  e  superfícies  de  máxima  inundação.  Neste  trabalho 
estamos  interessados  apenas  na  melhora  da  identificação  dos  limites  de  sequências 
deposicionais.  Posteriormente,  melhorias  podem  ser  feitas  na  delimitação  de 
parassequências e identificação de superfícies de máxima inundação.

Segundo  um  geólogo  especialista,  a  identificação  dos  limites  de  sequências 
deposicionais, quando analisado apenas  o perfil de raios  gama, se dá por uma queda 
abrupta no valor do gama. Dessa maneira, fica evidenciado que o problema maior do 
sistema  Intelistrata  está  em  seu  processamento  de  sinal  no  qual  busca,  através  da 
transformada wavelet, encontrar certos padrões na curva, mais precisamente um tipo de 
gaussiana. Isso pode ser feito de uma maneira mais precisa com outros métodos pois ao 
invés de tentar analisar o comportamento de uma curva para identificar tais quedas o 
sistema  busca  por  padrões  que  podem  não  acusar  essa  queda,  já  que  mesmo  que  se 
quisesse prosseguir na tentativa de aproximações de curvas, uma no estilo “dente-de-
serra” talvez fosse mais apropriada.

A transformada wavelet é feita tendo em vista a procura de semelhanças da curva do 
perfil de raio gama com uma curva gaussiana do tipo gaussiana  2, como mostrado na 
Figura 4.1.



39

Figura 4.1: Wavelet Gaussiana 2 (FIORINI, S. R., 2009)
Quando o sistema Intelistrata encontra um dado intervalo do perfil semelhante a uma 

curva  guassiana,  em  certo  nível  pré-definido,  ele  assinala  essa  região  para 
posteriormente ser testado pelo sistema como uma região de sequência deposicional. O 
principal  problema  dessa  abordagem  é  o  fato  de  buscar  semelhanças,  e  não 
comportamentos da  curva  do  perfil  de  raios  gama.  Segundo  o  especialista  da  área, 
dentro desse perfil, os limites de sequências deposicionais são identificados por quedas 
abruptas no gráfico, ou seja, no valor gama do perfil no ponto analisado. Dessa forma, 
qualquer  queda  brusca  que  ocorra  e  não  tenha  certa  semelhança  com  a  wavelet 
gaussiana será ignorada pelo sistema Intelistrata, mesmo curvas a exemplo das dente-
de-serra, como a da Figura 4.2, que podem representar ainda melhor uma queda desse 
tipo.

Figura 4.2: Exemplo de curva dente-de-serra 

Entretanto,  mesmo  que  fosse  utilizada  outra  curva,  o  problema  original 
permaneceria:  a  busca  por  um  padrão  de  curva  ao  invés  da  verificação  do 
comportamento dela.

Especialistas na área costumam, além de buscar tais quedas, enxergar tendências de 
subida  e  descida  dentro  dos  perfis  para  ajudar-lhes  na  marcação  dos  limites  de 
sequências  deposicionais.  Tentou-se  recriar  esses  artefatos  com  utilização  de  médias 
móveis, como será apresentado nas próximas subseções.



40

4.1.1 Curva de Tendências
As curvas de tendências mostram para onde o valor geral do gráfico no perfil de 

raios gama está se deslocando. Ele ajuda a verificar se temos uma tendência de ascensão 
ou queda. Isso serve como ferramenta para que geólogos especialistas na área consigam 
verificar mais facilmente propriedades da curva.

Um tipo de ferramenta que pode ser utilizado para acompanhar a tendência de uma 
curva é a ferramenta de médias móveis, comumente utilizada na análise de tendência do 
valor de ações na bolsa de valores. Uma média móvel é chamada dessa maneira pois ela 
movimenta-se ao longo de uma parte da informação disponível. Por exemplo, se estão 
disponíveis mil pontos e deseja-se calcular a média móvel com uma janela de 50 pontos, 
a média móvel calculará cada um de seus valores  levando-se em conta os  49 pontos 
anteriores  ao  ponto  em  questão  e  ele  próprio.  Assim,  se  quisermos  saber  o  valor  da 
média  móvel  no  ponto  100,  será  feita  a  média  dos  valores  nos  pontos  51  a  100  da 
informação original. Para o ponto 101 serão utilizados os valores de 52 a 101, no ponto 
500, os valores de 451 a 500 e assim sucessivamente. Ainda existem diversos tipos de 
médias  móveis,  dentre  os  principais  as  médias  móveis  simples,  que  fazem  a  média 
aritmética  dos  pontos  dentro  da  janela  e  médias  móveis  ponderadas,  que  distribuem 
diferentes pesos aos pontos dentro da janela. Ainda há uma interessante ferramenta que 
pode  ser  utilizada  juntamente  com  médias  móveis  chamada  regressão  linear.  Essa 
regressão  serve  para  estimar  o  próximo  ponto  levando-se  em  questão  os  pontos 
anteriores aplicados a uma função linear, o que além de originar o nome da ferramenta 
faz  com  que  o  comportamento  traçado  pela  média  seja  mais  suave,  não  sendo  tão 
fortemente alterado por pontos muito distantes à tendencia do gráfico no local.

Para  descobrir-se  a  tendência  da  curva  em  dado  ponto  são  feitos  os  4  seguintes 
passos: (1) calcula-se a média móvel para toda a curva, (2) então é feito o somatório dos 
valores dessa média nos 40 pontos antecessores ao ponto em questão. (3) Ao verificar-se 
esse somatório pode-se inferir que a tendência da curva é de subida caso o resultado seja 
positivo, ou então infere-se que a tendência é de queda caso o resultado seja negativo. 
(4) No caso do somatório resultar zero, considera-se que a tendência continua sendo a 
mesma do ponto anterior. Chegou-se ao valor 40 a partir de testes empíricos, sendo que 
ele foi o que mostrou da melhor maneira o comportamento geral da curva, ignorando 
alterações mais bruscas, que poderiam ser  considerados como um ruído no sinal.

A curva aqui utilizada é do tipo  Lowess, um tipo de média móvel ponderada com 
regressão linear.

Essas  decisões  (tipo  de  curva  e  número  de  pontos  a  serem  verificados)  foram 
tomadas, além de utilizar a experiência do autor deste trabalho e algumas justificativas 
matemáticas como a natureza da curva e o porquê dela apresentar bom comportamento 
no  caso,  a  partir  de  verificação,  junto  com  o  especialista,  do  que  ele  considera  que 
estava próximo ou não do que ele visualiza ao buscar essas tendências.

Um exemplo da curva de tendências pode ser visto na Figura 4.3, levando-se em 
conta que a análise deve ser feita da maior para a menor profundidade, sendo que aqui 
temos outro possível problema no sistema Intelistrata, que faz a verificação no sentido 
oposto.



41

Figura 4.3: Curva de tendências



42

4.1.2 Limites de Sequências Deposicionais
Apesar de manter a mesma filosofia das curvas de tendência (utilização de médias 

móveis e possíveis analogias com investimento em bolsa de valores), o problema aqui 
se torna um pouco mais complicado e exige um maior tratamento pelo seu maior nível 
de detalhes.

Inicialmente se pensou na possibilidade de alterar a wavelet utilizada na tentativa de 
identificar os limites de sequências deposicionais, idéia refutada posteriormente pelas 
razões já citadas neste mesmo capítulo. Após isso foi iniciada a abordagem com ajuda 
das médias móveis, procurando uma maneira de identificar quedas bruscas. A partir de 
então, deu-se uma série de tentativas:

• Verificação  se  a  média  de  quedas  dos  últimos  pontos  do  valor  gama  (aqui 
escolhendo-se uma quantidade de pontos arbitrária) está dentro ou fora do desvio 
padrão das alterações no gráfico, considerando-se que uma queda acima do valor do 
desvio padrão pode identificar uma alteração brusca e possível limite de sequência 
deposicional.  Essa  idéia  a  princípio  parecia  boa  e  como  todas  as  subsequentes 
contribuiu para chegar-se ao algoritmo final, mas  seu grande problema é que não 
permite a detecção de quedas bruscas com a precisão necessária. Isso por que caso 
haja uma queda brusca mas essa tenha sido formada por uma sequência  de quedas 
beirando o desvio padrão, mas ainda dentro dele, não será considerada uma queda 
brusca, pois sua média continua dentro desse desvio padrão. Por exemplo, se são 
escolhidos  5  pontos  para  formar-se  a  média  e  o  desvio  padrão  para  o  gráfico 
analisado tem um valor 4 (aqui a unidade não chega a ser relevante, mas poderíamos 
considerar pés ou metros para o caso de perfis de poços), caso os últimos 5 pontos 
tenham quedas constantes de um valor 3,9 (aqui a mesma unidade utilizada para o 
desvio padrão), sua média será 3,9, ainda dentro do limite estabelecido pelo desvio 
padrão, mas  provavelmente uma sequência de quedas  assim mostraria uma queda 
brusca.  Indo  além,  aqui  o  desvio  padrão  é  considerado  para  todo  o  gráfico,  não 
regiões específicas, como exemplificado pela Figura 4.5.

• Modificação da abordagem anterior, utilizando a média móvel adaptativa 
de  Perry  Kaufman  (KAUFMAN,  P.  J.,  1998),  ao  invés  do  valor  gama  para 
cálculo  do  desvio  padrão.  O  problema  em  regiões  com  sequências  de  quedas 
dentro do desvio padrão foi amenizado, mas não totalmente excluído e ainda não 
havia  a  noção  de  que  o  desvio  padrão  deveria  ser  considerado  para  regiões 
diferentes, ao invés de considerar-se o todo. Adiante será abordado o motivo de 
se fazer o cálculo por regiões.

• Utilização da idéia de que uma queda brusca costuma ser identificada por 
uma “falha” no gráfico, como mostra a Figura 4.4. Para tal é feita a identificação 
de um período no qual o valor do gama permanece abaixo do valor da média, o 
que identifica uma período de queda, o que por si só pode mostrar que ela seja 
possivelmente abrupta, já que a média está demorando a ter um valor próximo ao 
gama.  Identificada  a  queda,  retorna-se  à  tentativa  de  verificar  se  tal  queda 
realmente  se  deve  a  uma  alteração  brusca,  então  é  utilizada  a  verificação  do 
desvio padrão dentro do valor gama. Nesta abordagem retornam os problemas 
das anteriores e ainda há o problema de se definir o intervalo que o valor gama 
deve permanecer abaixo da média para ser considerado uma queda brusca.



43

• Inserção da noção de que a queda brusca é notada visualmente; portanto, 
seu valor absoluto em uma região de pequena amplitude certamente não será o 
mesmo que em uma região de grande amplitude, como exemplificado na Figura 
4.5, na qual temos 3 regiões de amplitudes distintas e nota-se que a amplitude da 
queda  brusca  assinalada  pode  ser  muito  diferente  de  uma  região  para  outra. 
Dessa  forma,  desvios  padrões  e  “falhas”  no  gráfico  devem ser  calculados  em 
uma região relativa ao ponto examinado, não ao gráfico por completo. Aqui os 
problemas  relativos  à  identificação  do  intervalo  necessário  abaixo  da  média 
prosseguem,  mas  nota-se  uma  melhora  na  identificação  de  pontos  em  que  as 
alterações são maiores que o desvio padrão da região.

Figura 4.4: “Falha” devido a uma queda brusca



44

Figura 4.5: Quedas bruscas em regiões com diferentes amplitudes do valor gama



45

Essas  abordagens  sofrem  de  problemas  comuns.  Apresentam  bons  resultados  em 
parte,  mas  ou  apresentam  excesso  de  falsos  positivos,  ou  então  negligenciam  alguns 
resultados que deveriam ser considerados. Além disso é difícil identificar, por exemplo, 
o  que  seria  um  longo  período  para  o  valor  gama  permanecer  abaixo  da  média  para 
considerar que a queda é considerável e isso certamente demandaria uma análise mais 
aprofundada,  o  que está  fora  do  escopo  deste  trabalho.  No entanto,  utilizar  o  desvio 
padrão  para  identificar  uma  queda  brusca  parece  algo  mais  plausível,  já  que 
estatisticamente sabemos que um valor acima do desvio padrão representa algo fora do 
comportamento natural do gráfico e podemos então associar isso a mudanças bruscas.

 A abordagem final se de utiliza duas médias móveis do tipo Lowess criadas a partir 
dos  valores  gama.  Uma  delas  é  a  média  móvel  lenta,  que  serve  para  dar  o 
comportamento  geral  do  gráfico  (mais  lenta  inclusive  que  a  utilizada  na  curva  de 
tendências) e a outra é a média móvel rápida, que é muito mais suscetível a pequenas 
alterações do perfil de raios gama, mas ainda assim se atém à tendência dele servindo 
como um tipo de filtro passa-baixas.

Utilizando duas médias móveis descritas acima, é feita a verificação de quando a 
média móvel rápida cruza a média móvel lenta para baixo, assumindo um valor menor 
(voltando  ao  investimento  na  bolsa  de  valores,  isso  significa  um  possível  ponto  de 
venda, já que a tendência é que o valor continue caindo, já no nosso escopo significa 
apenas um tendência de queda no valor gama), assim temos que verificar se essa queda 
é  ou  não  abrupta.  A partir  de  então  se  faz  a  verificação  de  uma  região  de  tamanho 
predeterminado,  por  exemplo  de  trinta  metros  em  volta  do  ponto  (os  quinze  metros 
anteriores e posteriores ao ponto) computando as diferenças entre os valores da média 
móvel  rápida  e  lenta.  Com  isso  em  mãos,  é  verificado  se  a  distância  entre  as  duas 
médias  naquele  ponto  é  maior  que  o  desvio  padrão  relativo  à  região.  Caso  positivo, 
podemos marcar aquele ponto como um possível limite de sequência deposicional. Esse 
valor de trinta metros é um valor adotado em função dos resultados, mas em futuros 
testes pode-se tentar chegar a um valor melhor, caso ele exista. De modo geral, valores 
maiores que esse tendem a verificar a média geral do gráfico, ignorando alguns pontos 
importantes,  já  valores  menores  tendem  a  utilizar  uma  média  muito  localizada, 
causando número excessivo de falsos positivos.

Levando-se em consideração a natureza um tanto difusa das marcações de limites de 
sequências  deposicionais  nas  quais  é  possível  marcar  diferentes  pontos  sem  que  tais 
diferenças sejam consideradas um erro, optou-se por marcar-se no novo algoritmo, ao 
invés de um ponto apenas, regiões inteiras nas quais seriam aceitáveis delimitações de 
limites de sequências deposicionais.

A seguir é mostrado, em pseudo-código, o algorítmo descrito acima:
Parâmetros de entrada: 

Profundidades // Array contendo profundidades do poço.

Valor Gama // Array com valor gama para cada ponto do array de 
        // profundidades.

Tamanho  médio  de  sequências  deposicionais  //  Tamanho  médio  que  se  
// espera para as sequências deposicionais no poço.

Início do Algoritmo

MédiaMóvelLenta = Média Móvel Lowess com janela igual a 
(Tamanho médio de sequências deposicionais/2)*3;



46

MédiaMóvelRápida = Média Móvel Lowess com janela igual a 
(Tamanho médio de sequências deposicionais/2)/3;

// Laço para percorrer todos os pontos.

Para i=1 até i=Tamanho do Array de Valores Gama

// Se a media movel rápida for menor que a lenta significa 
// que houve uma queda e verificaremos se ela é ou nao  
//  brusca.

Se ( MédiaMóvelRápida &amp;lt;MédiaMóvelLenta)

desvPadrao  = desvio padrão  da  diferença  entre as  
       duas médias móveis na região do ponto i;

diff =  MédiaMóvelLenta[i] -  MédiaMóvelRápida[i];

// Caso a diferença entre as duas médias seja maior 
// que o desvio padrão, significa que houve uma 
// queda brusca.

Se (desvPadrao &amp;lt;diff)

     Insere ponto i na região de quedas bruscas;

Fim-Se

Fim-se

Fim-Para

Marca regiões de quedas bruscas no gráfico;

Final do Algoritmo

No  capítulo  a  seguir,  serão  comentados  alguns  dos  resultados  atingidos  por  esse 
novo algoritmo.



47

5 VALIDAÇÃO DA PROPOSTA

Para a validação da proposta serão utilizados dois perfis de poços os quais possuem 
interpretações  detalhadas  e foram previamente  analisados  pelo sistema  Intelistrata no 
trabalho de Fiorini (2009), retirados do livro de Van Wagoner et al. (1990): 

• Tenneco  Rattlesnake  State  2-12,  localizado  na  região  de  Book  Cliffs, 
Utah, USA, com aproximadamente 340 metros a partir da profundidade de 820 
m.

• Exxon Production Research Co. Sego Canyon nº 2, localizado na mesma 
região  do  poço  acima,  com  aproximadamente  360  metros  a  partir  da 
profundidade de 30m.

Além desses dois perfis de poços ainda serão avaliados resultados em comparação às 
marcações  feitas  pelo  especialista  –  levando-se  em  consideração  apenas  informações 
sobre perfis de raios gama – os perfis de poços CA-53, CA-79 e CA-87, cujos dados 
foram retirados do trabalho de Goldberg (2001).

5.1 Comparativo de resultados: Novo algoritmo x Intelistrata
O sistema Intelistrata apresenta na Figura 5.1 sua interpretação em relação ao perfil 

de poço  Tenneco  Rattlesnake  State 2-12, no qual  as  linhas  tracejadas  representam os 
limites de sequências deposicionais marcados pelo especialista e as regiões verdes, as 
sequências deposicionais inferidas pelo sistema. As demais marcações são referentes a 
outros elementos que não representam interesse para o estudo em questão. A Figura 5.2 
apresenta os resultados alcançados pelo novo algoritmo. As marcações feitas em verde 
são  relativas  aos  limites  de  sequências  deposicionais.  A exemplo  da  Figura  5.1,   as 
linhas  tracejadas  representam  os  limites  de  sequência  deposicionais  marcados  pelo 
especialista. Foram feitas marcações corretas pelo novo algoritmo em todos os pontos 
(860m, 935m e 1042m) e uma marcação sem correspondente pelo especialista (região 
entre 940m e 960m), já o sistema Intelistrata apresenta marcações próximas às ideais 
para  as  regiões  935m-1042m e  1042m-1160m e  ainda  conta  com  três  tentativas  sem 
correspondente pelo especialista de marcações dentro dessas duas mesmas regiões.

A Figura 5.3 representa a interpretação do sistema Intelistrata em relação ao perfil de 
poço  Sego  Canyon  nº  2.  Da  mesma  forma  que  na  Figura  5.1,  as  linhas  tracejadas 
referem-se  às  delimitações  de  sequências  deposicionais  feitas  pelo  especialista, 
enquanto as regiões  verdes  demonstram a inferência de tais  sequências deposicionais 
feitas pelo sistema e as demais demarcações não demonstram interesse para o caso. A 
figura 5.4 apresenta os resultados do novo algoritmo para o mesmo poço. As marcações 
feitas  em  verde  são  relativas  aos  limites  de  sequências  deposicionais.  A exemplo  da 



48

Figura  5.3,  as  linhas  tracejadas  representam  os  limites  de  sequências  deposicionais 
marcados  pelo especialista. Foram feitas  marcações  corretas  pelo  novo algoritmo em 
todos  os  pontos  (80m,  215m  e  345m)  e  uma  marcação  sem  correspondente  pelo 
especialista  (região entre 90m e 110m), já o sistema Intelistrata  apresenta marcações 
próximas às ideais para as regiões  80m-215m e 215m-345m e ainda conta com duas 
marcações  sem correspondente pelo especialista  nas  regiões  de 150m-215m e 230m-
375m.

Como se pode observar, o novo algoritmo apresenta maior quantidade de acertos e 
menor  incidência  de  falsos  positivos  que  o  sistema  Intelistrata  apresentava 
originalmente. Traduzindo em números, o novo algoritmo faz 4 delimitações nos dois 
casos, com acerto em todas as 3 marcações dos dois poços e um falso positivo em cada, 
uma  aproveitamento  de  100%  de  acertos  em  relação  às  marcações  de  limites  de 
sequências deposicionais e acerto de 75% das marcações feitas. Já o sistema Intelistrata 
possui  5  marcações  para  o  poço   Tenneco  Rattlesnake  State  2-12,  acertando 
aproximadamente 2 resultados (interpretações B2 e B4 da Figura 5.1) e desperdiçando 
três. Para o poço Sego Canyon nº 2 são realizadas 4 marcações de limites de sequência 
deposicionais,  podendo-se  considerar  que  há  acerto  nas  interpretações  B1  e  B3  da 
Figura  5.3  e  desperdício  de  2  marcações.  Isso  resulta,  respectivamente,  em 
aproximadamente  66% de  acertos  em relação  às  marcações  de  limites  de  sequências 
deposicionais e acerto de 40% das marcações  feitas para o primeiro poço e 66%  de 
acertos em relação às marcações de limites de sequências deposicionais e acerto de 50% 
das marcações feitas para o segundo poço, dados que dão força ao novo algoritmo aqui 
apresentado.

Na próxima seção serão apresentados poços não utilizados na validação do sistema 
Intelistrata no trabalho de Fiorini (2009).



49

Figura 5.1: Comparação das interpretações do especialista e do sistema Intelistrata para 
o perfil de poço Tenneco Rattlesnake State 2-12 (FIORINI, S. R., 2009)



50

Figura 5.2: Interpretação do perfil de poço Tenneco Rattlesnake State 2-12 pelo novo 
algoritmo.



51

Figura 5.3: Comparação das interpretações do especialista e sistema Intelistrata para o 
perfil de poço Exxon Production Research Co. Sego Canyon nº 2 (FIORINI, S. R., 

2009)



52

Figura 5.4: Interpretação do perfil de poço Exxon Production Research Co. Sego  
Canyon nº 2 pelo novo algoritmo.



53

5.2 Testes em novos perfis de poços
Para os testes realizados com os perfis de poços CA-53, CA-79 e CA-87, retirados 

do trabalho de Goldberg (2001) foram comparados os resultados do novo algoritmo com 
as interpretações contidas na fonte e também foram analisadas opiniões de especialistas. 
Foram utilizados como tamanho médio de sequência deposicional 100m, 200m e 120m 
para os poços CA-53, CA-79 e CA-87, respectivamente. É importante lembrar que este 
trabalho apenas considera perfis de raios gama, enquanto as interpretações contidas no 
trabalho  de  Goldberg  (2001)  estão  repletas  de  outras  informações,  como  curva  de 
resistividade e informações litológicas.

Como pode ser visto nas Figuras 5.5, 5.6 e 5.7, as marcações feitas em verde são 
relativas  às  demarcações  dos  limites  de  sequências  deposicionais  feitas  pelo  novo 
algoritmo.  As  linhas  vermelhas  indicam  os  limites  de  sequências  deposicionais 
apontados  em (GOLDBERG, K., 2001). É possível observar  que algumas  marcações 
feitas pelo novo algoritmo coincidem com as marcações encontradas na fonte e outras 
apresentam uma aproximação muito satisfatória. Para ilustrar tal afirmação, verifica-se 
que  quando  as  marcações  não  coincidem,  mas  apresentam-se  próximas,  a  diferença 
entre elas não ultrapassa 4% do tamanho do poço em questão. Ainda foram apresentadas 
esporádicas marcações que não apresentam representação no novo algoritmo, como por 
exemplo a marcação próxima à profundidade de 200 metros do poço CA-79 na Figura 
5.6, ou mesmo marcações feitas pelo novo algoritmo que não possuem representação no 
trabalho de Goldberg, como as regiões próximas a 100m e 350m do poço CA-87.

É importante frisar que os geólogos especialistas tiveram dificuldade em marcar os 
limites  de sequência deposicionais nesses  perfis  sem o auxilio de outras  informações 
(como  dados  de  testemunho  e,  principalmente,  correlação  entre  poços).  Isso  não 
permitiu que fosse feita uma análise a exemplo da adotada na seção 5.1, adotando-se 
então, como gabarito uma interpretação de (GOLDBERG, K., 2001), cuja interpretação 
levou em conta não somente o perfil gama. Isso aumenta a credibilidade da abordagem 
para o novo algoritmo aqui exibida e afirma seu valor como ferramenta de auxílio aos 
especialistas da área.

A  tabela  5.1  mostra  os  limites  de  sequência  deposicionais  marcados  em 
(GOLDBERG,  K.,  2001)  relacionados  aos  limites  de  sequências  deposicionais  mais 
próximos  marcados  pelo  novo  algoritmo  e  seus  respectivos  erros,  como  pode  ser 
observado nas Figuras 5.5, 5.6 e 5.7.

Tabela 5.1: Resultados do novo algoritmo

CA53 – Aproximadamente 642m

Limite de Sequência 
Deposicional Marcado 

pelo Especialista

Limite de Sequência 
Deposicional Marcado 

pelo  Algoritmo
Erro

136m 114m 3,50%

192m 187m 0,07%

319m 310m 1,50%



54

394m Correto 0,00%

498m 483m 2,30%

547m Correto 0.00%

CA79 – Aproximadamente 900m

Limite de Sequência 
Deposicional Marcado 

pelo Especialista

Limite de Sequência 
Deposicional Marcado 

pelo  Algoritmo
Erro

75m Correto 0,00%

165m Não Possui 100,00%

343m 325m 2.00%

595m 583m 1,30%

720m 716m 0,04%

790m Correto 0,00%

890m Correto 0,00%

CA87 – Aproximadamente 655m

Limite de Sequência 
Deposicional Marcado 

pelo Especialista

Limite de Sequência 
Deposicional Marcado 

pelo  Algoritmo
Erro

116m 132m 0,24%

185m 198m 0,19%

308m 292m 0,24%

442m Correto 0,00%

551m 545m 0,09%

587m 595m 0,12%



55

Figura 5.5: Interpretação do perfil de poço CA-53 pelo novo algoritmo.



56

Figura 5.6: Interpretação do perfil de poço CA-79 pelo novo algoritmo.



57

Figura 5.7: Interpretação do perfil de poço CA-87 pelo novo algoritmo.



58

6 CONCLUSÃO

A tarefa de tentar entender e reproduzir os processos cognitivos  por trás da visão 
humana  proporciona  diversos  desafios  de  pesquisa  há  anos.  Em  particular,  a 
interpretação semântica de imagens oferece grandes desafios. Este trabalho tenta buscar 
complementar a solução de um problema específico de interpretação semântica aplicado 
na área de Geologia.

Ao  longo  deste  trabalho  é  proposto  um  novo  algoritmo  para  o  componente  de 
processamento de sinal do sistema baseado no framework S-Chart, chamado Intelistrata. 
Esse novo algoritmo busca, com sucesso, aprimorar o método de demarcação de limites 
de  sequências  deposicionais  para  posterior  interpretação  semântica  pelos  demais 
componentes do sistema.

O  algoritmo  proposto  neste  trabalho  teve  ganhos  tanto  em  qualidade  quanto 
eficiência nas demarcações de limites de sequência deposicionais, tendo para as duas 
comparações feitas com o componente de processamento de sinal original do sistema 
Intelistrata acerto de 100%, contra 66% e eficiência de marcações de 75% contra 40% e 
50% do sistema original. Ainda teve boa aproximação de marcações em outros perfis de 
poços,  nas  quais  seus  erros  quando  não  houve  marcação  precisa  em  relação  à  do 
gabarito não ultrapassaram 4% do tamanho dos poços.

6.1 Trabalhos Futuros
Para  a  detecção  de  parassequências  e  superfícies  de  máxima  inundação  ainda  é 

possível  seguir  a  mesma  abordagem  proposta  para  o  novo  algoritmo  no  capítulo  4, 
utilizando para parassequências exatamente a lógica oposta à detecção de sequências, 
uma vez que sequências deposicionais são detectadas através de quedas bruscas no valor 
do  gama,  enquanto  parassequências  são  detectadas  por  subidas  bruscas,  segundo  o 
especialista.

Quanto ao sistema  Intelistrata é interessante ampliar os  tipos  de perfis analisados 
para se chegar a um resultado mais próximo do real, uma vez que a simples análise de 
perfis de raios gama sem contar com outros dados pode limitar muito a corretude dos 
resultados.



59

REFERÊNCIAS

Baader, F., D. Calvanese, D. L. Mcguinness, D. Nardi e P. F. Patel-Schneider, Eds. The 
description  logic  handbook:  theory,  implementation,  and  applications:  Cambridge 
University Press, p.545ed. 2003.

Baader, F. e R. Kuesters. Matching in Description Logics with Existential Restrictions. 
1999

Ballard, D. H. e C. M. Brown. Computer vision. Englewood Cliffs, N.J.: Prentice-Hall. 
1982. xx, 523 p., [2] leaves of plates p.

Birnbaum, L., M. Brand e P. Cooper. Looking for trouble: Using causal semantics to 
direct focus of attention. Fourth International Conference on Computer Vision, 1993., 
1993. 49-56 p.

Catuneanu, O. Principles of sequence stratigraphy. Amsterdam ; Boston: Elsevier. 2006. 
ix, 375 p. p.

Chandrasekaran, B., J. R. Josephson e V. R. Benjamins. What Are Ontologies, and Why 
Do We Need Them? IEEE Intelligent systems: 7 p. 1999.

Chella, A., M. Frixione e S. Gaglio. A cognitive architecture for artificial vision. Artif. 
Intell., v.89, n.1-2, p.73-111. 1997.

Chella,  A.,  M.  Frixione  e  S.  Gaglio.  Conceptual  Spaces  for  Computer  Vision 
Representations. Artif. Intell. Rev., v.16, n.2, p.137-152. 2001.

Chella,  A.,  M.  Frixione  e  S.  Gaglio.  A  cognitive  architecture  for  robot  self-
consciousness. Artif. Intell. Med., v.44, n.2, p.147-154. 2008.

Chella,  A.  e  S.  Gaglio.  A  cognitive  approach  to  robot  self-consciousness.  AI  and 
Consciousness: Theoretical Foundations and ... 2007.

Cohn, A. G. e S. M. Hazarika. Qualitative Spatial Representation and Reasoning: An 
Overview. Fundam. Inf., v.46, n.1-2, p.1-29. 2001.

Cohn,  A.  G.,  D.  R.  Magee,  A.  Galata,  D.  C.  Hogg  e  S.  M.  Hazarika.  Towards  an 
Architecture  for  Cognitive  Vision  Using  Qualitative  Spatio-temporal  Representations 
and Abduction In: (Ed.). Spatial Cognition III: Springer Berlin / Heidelberg, v.Volume 
2685/2003,  2003.  Towards  an  Architecture  for  Cognitive  Vision  Using  Qualitative 
Spatio-temporal Representations and Abduction p.1034

Crubézy, M., M. Marcos e S. Moisan.  Experiments in Building Program Supervision 
Engines  from  Reusable  Components.  3th  European  Conference  on  Artificial 
Intelligence  Workshop  on  Applications  of  Ontologies  and  Problem-Solving  Methods, 
1998. p.

Fiorini, S. R. S-Chart: Um Arcabouço para Interpretação Visual de Gráficos. Computer 
Science, Universidade Federal do Rio Grande do Sul, Porto Alegre, 2009.  122 p.



60

Gärdenfors, P. Conceptual Spaces: The Geometry of Thought: MIT Press. 2004. 320 p.

Goldberg,  K.  The  paleoclimatic  evolution  of  the  Permian  in  the  Parana  Basin  in 
southern Brazil. University of Chicago, 2001.  267 p.

Gómez-Pérez,  A.,  M.  Fernández-López  e  O.  Corcho.  Ontological  engineering  :  with 
examples  from  the  areas  of  knowledge  management,  e-commerce  and  the  semantic 
Web. London: Springer. 2004. xii, 403 p.

Gruber,  T.  R.  Toward  principles  for  the  design  of  ontologies  used  for  knowledge 
sharing. Int. J. Hum.-Comput. Stud., v.43, n.5-6, p.907-928. 1995.

Haag,  M.,  W.  Theilmann,  K.  Schäfer  e  H.-H.  Nagel.  Integration  of  Image  Sequence 
Evaluation  and Fuzzy Metric Temporal  Logic Programming.  Proceedings  of the 21st 
Annual  German  Conference  on  Artificial  Intelligence:  Advances  in  Artificial 
Intelligence: Springer-Verlag: 301-312 p. 1997.

Haarslev,  V.  e  R.  Möller.  RACER  System  Description.  Proceedings  of  the  First 
International Joint Conference on Automated Reasoning: Springer-Verlag: 701-706 p. 
2001.

Harnad, S. The symbol grounding problem. Phys. D, v.42, n.1-3, p.335-346. 1990.

Hotz,  L.  e  B.  Neumann.  Scene  Interpretation  as  a  Configuration  Task.  Künstliche 
Intelligenz, v.3, p.56-65. 2005.

Hotz,  L.,  B.  Neumann  e  K.  Terzic.  High-Level  Expectations  for  Low-Level  Image 
Processing.  Proceedings  of  the  31st  annual  German  conference  on  Advances  in 
Artificial Intelligence. Kaiserslautern, Germany: Springer-Verlag: 87-94 p. 2008.

Hudelot,  C.  Towards  a  Cognitve  Vision  Platform  for  Semantic  Image  Interpretation; 
Application to the Recognition of Biological Organisms. Université de Nice - Sophia 
Antipolis UFR Sciences, 2005.  280 p.

Hudelot,  C.,  N.  Maillot  e  M.  Thonnat.  Symbol  Grounding  for  Semantic  Image 
Interpretation: From Image Data to Semantics. Tenth IEEE International Conference on 
Computer Vision, p.8. 2004.

Kaufman, P. J. Trading systems and methods. New York: John Wiley. 1998. xv, 703 p.

Kreutzmann, A., K. Terzi? e B. Neumann. Context-aware classification for incremental 
scene  interpretation.  Proceedings  of  the  Workshop  on  Use  of  Context  in  Vision 
Processing. Boston, Massachusetts: ACM: 1-6 p. 2009.

Lorenzatti, A. Análise de modelos para a representação de conhecimento visual. p.18. 
2008.

Maillot,  N.,  M.  Thonnat  e  C.  Hudelot.  Ontology  Based  Object  Learning  and 
Recognition:  Application  to  Image  Retrieval.  Proceedings  of  the  16th  IEEE 
International Conference on Tools with Artificial Intelligence: IEEE Computer Society: 
620-625 p. 2004.



61

Nagel, H.-H. From Video to Language-A Detour via Logic vs. Jumping to Conclusions. 
Proceedings  of  the  Integration  of  Speech  and  Image  Understanding:  IEEE  Computer 
Society: 79 p. 1999.

Neumann,  B.  Description  of  Time-Varying  Scenes.  Lawrence  Erlbaum,  n.Semantic 
Structures, p.167-206. 1989.

Neumann, B. e R. Möller. On Scene Interpretation with Description Logics In: (Ed.). 
Cognitive Vision Systems: Springer Berlin / Heidelberg, v.Volume 3948/2006, 2006. On 
Scene Interpretation with Description Logics p.247-275

PETR  Disponível  em: &amp;lt;http://www.petrobras.com.br/rs2009/pt/relatorio-de-
sustentabilidade/resultados-e-contribuicoes-para-a-sociedade/resultados-economico-
financeiros/investimentos/&gt; Acesso em nov. 2010.

Posamentier,  H.W.,  Jervey,  M.T.  e  Vail,  P.R.  1988.  Eustatic  controls  on  clastic 
deposition  I  –  conceptual  framework.  In:  WILGUS,  C.K.;  HASTINGS,  B.S.; 
KENDALL, C.G.;  ST. C.; POSAMENTIER, H.W.; ROSS, C.A. &amp;amp; VAN WAGONER, 
J.C.  (Eds.)  1988.  Sea-level  changes:  an  integrated  approach.  Society  of  Economic 
Paleontologists and Mineralogists Special Publication, 42, 407 p.

Raicu,  D.  S.,  E.  Varutbangkul,  J.  D.  Furst  e  S.  G.  A.  Iii.  Modelling  semantics  from 
image data: opportunities from LIDC. International Journal of Biomedical Engineering 
and Technology 2010 v.3, p.83 - 113. 2010.

Randell, D. e M. Witkowski. Abductive Visual Perception with Feature Clouds. 2006.

Reading,  H.  G.  Sedimentary  environments  :  processes,  facies,  and  stratigraphy. 
Cambridge, Mass: Blackwell Science. 1996. xiv, 688 p.

Rimey, R. D. Control of Selective Perception using Bayes Nets and Decision Theory. 
University of Rochester. 1993

Shanahan,  M.  A  Logical  Account   of   Perception  Incorporating  Feedback  and 
Expectation. Knowledge Representation Conference, 2002. 3-13 p.

Shanahan, M. e D. A. Randell. A Logic-Based Formulation of Active Visual Perception. 
Principles  of  Knowledge  Representation  and  Reasoning:  Proceedings  of  the  Ninth 
International Conference (KR2004). Whistler, Canada, June 2-5, 2004, 2004. 64-72 p.

Stock, O. Spatial and Temporal Reasoning: Kluwer Academic Publishers. 1997. 394 p.

Vail,  P.  R.,  Mitchum  JR.,  R.  M.,  Todd,  R.  G.,  Widmier,  J.  M.,  Thompson,  S.,  III, 
Sangree, J. B., Bubb, J. N., Hatlelid, W. G. Seismic stratigraphy and global changes of 
sea level. In: PAYTON, C. E. (Ed.) Seismic stratigraphy - applications to hydrocarbon 
exploration. Tulsa:  American Association of Petroleum Geologists, 1977a. p. 49-212. 
(American Association of Petroleum Geologists. Memoir, 26).

Van  Wagoner,  J.C.;  Mitchum,  R.M.;  Campion,  K.M.  &amp;amp;  Rahmanian,  V.D.  1990. 
Siliciclastic sequence stratigraphy in well logs, cores, and outcrops: concepts for high 
resolution correlation of time and facies. American Association of Petroleum Geologists 
Methods in Exploration Series, No 7.

http://www.petrobras.com.br/rs2009/pt/relatorio-de-sustentabilidade/resultados-e-contribuicoes-para-a-sociedade/resultados-economico-financeiros/investimentos/
http://www.petrobras.com.br/rs2009/pt/relatorio-de-sustentabilidade/resultados-e-contribuicoes-para-a-sociedade/resultados-economico-financeiros/investimentos/
http://www.petrobras.com.br/rs2009/pt/relatorio-de-sustentabilidade/resultados-e-contribuicoes-para-a-sociedade/resultados-economico-financeiros/investimentos/


62

Vila, L. A survey on temporal reasoning in artificial intelligence. AI Commun., v.7, n.1, 
p.4-28. 1994.

Xia,  L.,  F.  Yiren,  D.  Shaogui  e  W.  Tongshan.  Automatic  demarcation  of  sequence 
stratigraphy using the method of well logging multiscale data fusion. Online English 
edition of the Chinese language journal, v.Volume 36, n.Issue 2, April 2009, p.7. 2009.


	LISTA DE ABREVIATURAS E SIGLAS
	LISTA DE FIGURAS
	LISTA DE TABELAS
	RESUMO
	1 INTRODUÇÃO
	1.1 Motivação  
	1.2 Objetivos
	1.3 Organização dos Capítulos

	2 INTERPRETAÇÃO SEMÂNTICA DE IMAGENS
	2.1 Agregados
	2.1.1 Evoluções da Abordagem dos Agregados

	2.2 Abdução
	2.2.1 Evoluções da Abordagem Abdutiva

	2.3 Orion
	2.3.1 Evoluções da abordagem Orion

	2.4 Espaços Conceituais
	2.4.1 Evoluções da Abordagem dos Espaços Conceituais

	2.5 Comparativo Entre as Abordagens

	3 O FRAMEWORK S-CHART E O SISTEMA INTELISTRATA
	3.1 Framework S-Chart
	3.2 Sistema Intelistrata
	3.3 Estratigrafia de Sequências

	4 UM novo algoritmo
	4.1 O novo algoritmo
	4.1.1 Curva de Tendências
	4.1.2 Limites de Sequências Deposicionais


	5 VALIDAÇÃO DA PROPOSTA
	5.1 Comparativo de resultados: Novo algoritmo x Intelistrata
	5.2 Testes em novos perfis de poços

	6 CONCLUSÃO
	6.1 Trabalhos Futuros

	referências

</field>
	</doc>
</add>