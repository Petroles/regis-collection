<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.20255</field>
		<field name="filename">3727_323092.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">
UNIVERSIDADE FEDERAL DE SANTA CATARINA
DEPARTAMENTO DE AUTOMAÇÃO E SISTEMAS

Caio Merlini Giuliani

ESTRATÉGIAS DE OTIMIZAÇÃO NÃO
DIFERENCIÁVEL APLICADAS À MAXIMIZAÇÃO DA

PRODUÇÃO DE CAMPOS DE PETRÓLEO

Florianópolis

2013



Caio Merlini Giuliani

ESTRATÉGIAS DE OTIMIZAÇÃO NÃO
DIFERENCIÁVEL APLICADAS À MAXIMIZAÇÃO DA

PRODUÇÃO DE CAMPOS DE PETRÓLEO

Dissertação submetida ao Programa
de Pós-Graduação em Engenharia de
Automação e Sistemas para a obten-
ção do Grau de Mestre em Engenharia
de Automação e Sistemas.
Orientador: Prof. Eduardo Campo-
nogara, Dr.
Coorientador: Prof. Agustinho Pluce-
nio, Dr.

Florianópolis

2013



Ficha de identificação da obra elaborada pelo autor,
 através do Programa de Geração Automática da Biblioteca Universitária da UFSC.

Giuliani, Caio Merlini
   Estratégias de otimização não diferenciável aplicadas à
maximização da produção de campos de petróleo / Caio Merlini
Giuliani ; orientador, Eduardo Camponogara ; co-
orientador, Agustinho Plucenio. - Florianópolis, SC, 2013.
   98 p.

   Dissertação (mestrado) - Universidade Federal de Santa
Catarina, Centro Tecnológico. Programa de Pós-Graduação em
Engenharia de Automação e Sistemas.

   Inclui referências 

   1. Engenharia de Automação e Sistemas. 2. Otimização sem
derivada. 3. Otimização da produção de petróleo. 4. Região de
confiança. 5. Busca direta. I. Camponogara, Eduardo. II.
Plucenio, Agustinho. III. Universidade Federal de Santa
Catarina. Programa de Pós-Graduação em Engenharia de
Automação e Sistemas. IV. Título.



Caio Merlini Giuliani

ESTRATÉGIAS DE OTIMIZAÇÃO NÃO
DIFERENCIÁVEL APLICADAS À MAXIMIZAÇÃO DA

PRODUÇÃO DE CAMPOS DE PETRÓLEO

Esta Dissertação foi julgada aprovada para a obtenção do Título
de “Mestre em Engenharia de Automação e Sistemas”, e aprovada em
sua forma final pelo Programa de Pós-Graduação em Engenharia de
Automação e Sistemas.

Florianópolis, 10 de Setembro 2013.

Prof. Jomi Fred Hübner, Dr.
Coordenador do Curso

Prof. Eduardo Camponogara, Dr.
Orientador

Prof. Agustinho Plucenio, Dr.
Coorientador

Banca Examinadora:

Prof. Eduardo Camponogara, Dr.
Presidente

Prof. Alexandre Trofino Neto, Dr.





Eng. Alex Furtado Teixeira, M. Sc.

Eng. Bruno da Costa Flach, Dr.

Prof. Daniel Juan Pagano, Dr.





AGRADECIMENTOS

Inicialmente, agradeço à minha amada Família, meu suporte em
toda a vida. Pai, Mãe, Emília, sou profundamente grato por todos vocês.

Agradeço à Elisa, pela companhia, apoio e paciência.
Ao meu orientador, Eduardo Camponogara, e coorientador, Agus-

tinho Plucenio, agradeço pela orientação, por todas as oportunidades e
pela confiança.

Agradeço aos colegas e amigos que me acompanharam durante
o curso.

Agradeço aos membros da banca, pela atenção, pelas críticas e
sugestões.

Agradeço ao Programa de Pós-graduação em Engenharia de Au-
tomação e Sistemas, pela oportunidade.

Agradeço ao Centro de Pesquisas da Petrobras (CENPES), pelo
apoio financeiro com a bolsa.





Saruman believes it is only
great power that can hold
evil in check, but that is
not what I have found. I
found it is the small
everyday deeds of ordinary
folk that keep the darkness
at bay. Small acts of
kindness and love.

Gandalf





RESUMO

Este trabalho apresenta métodos de otimização não-diferenciável
aplicados à produção de petróleo. Na indústria do petróleo e gás, a pro-
dução de reservatórios, poços e sistemas relacionados pode ser predita
com a utilização de simuladores numéricos. Este trabalho estuda técni-
cas de otimização que não fazem uso de derivadas da função objetivo,
sendo adequadas para a utilização direta de ferramentas de simulação.
São apresentadas a “busca direta direcional” e “região de confiança não-
diferenciável”. A primeira não faz qualquer uso de modelos, enquanto
a segunda utiliza modelos que aproximam a função objetivo em uma
região limitada. Ambas são estudadas em suas formas irrestritas e com
restrições lineares nas variáveis. Foi feita uma análise computacional
em que ambos os métodos foram utilizados para a alocação de gás
de injeção a um campo de produção de petróleo, com as produções
dos poços modeladas por funções suaves, que garantiam suas condições
de convergência. Os dois métodos convergiram para os pontos ótimos,
sendo que o de região de confiança apresentou maior eficiência. Uma se-
gunda análise computacional, contemplando apenas o método de região
de confiança foi realizada empregando um simulador fenomenológico de
poços de petróleo. Ambos os algoritmos podem servir de base para a
otimização também com restrições não-lineares. Para tanto, propomos
a utilização do método de Lagrangiano aumentado, que substitui as res-
trições não-lineares por penalizações na função objetivo, transformando
o problema não-linear em uma sequência de problemas com restrições
lineares. É possível implementá-lo sem necessidade de informações sobre
as derivadas. Apresentamos a teoria de como isto pode ser feito, porém
sem uma análise numérica.

Palavras-chave: Otimização sem derivada. Otimização da produção
de petróleo. Região de confiança. Busca direta.





ABSTRACT

This work presented methods of nondifferentiable optimization
applied to the production of petroleum. In the petroleum industry, the
production of reservoirs, wells and related systems can be accurately
predicted using numerical computer simulators. This work presented
techniques of optimization that do not use the derivative of the objective
function, hence better suited to use directly those simulation tools. The
methods of directional direct-search and nondifferentiable trust-region
are presented. The former does not make use of any model, whereas the
latter samples the objective function to build models in a limited region.
Both are studied in their unconstrained form and with linear constraints
on the variables. A computational analysis has been carried out, in which
both methods where employed in order to optimize the lift-gas allocation
in a field of petroleum wells, modeled by smooth functions, so that
their convergence conditions were satisfied. Both methods converged
to the optimum, being the trust-region the more effective. A second
analysis has been conduced, using only the trust-region method and a
phenomenological simulator of petroleum wells. Both algorithms can be
used also in optimization with nonlinear constraints. To that end, we
propose the method of augmented Lagrangian, in which the nonlinear
constraints are substituted by penalizations on the objective function,
rendering the solution of nonlinear problem a sequence of subproblems
with linear constraints. This method can also be used without knowledge
of derivatives. Part of the underlying theory is presented.

Keywords: Derivative free optimization. Petroleum production opti-
mization. Trust region. Direct-search.





SUMÁRIO

1 Introdução 17
1.1 Organização do documento . . . . . . . . . . . . . . . . 18

2 Otimização não-diferenciável irrestrita 21
2.1 Busca direta direcional . . . . . . . . . . . . . . . . . . . 21
2.2 Região de confiança . . . . . . . . . . . . . . . . . . . . 30

2.2.1 Definição do modelo . . . . . . . . . . . . . . . . 31
2.2.2 Polinômios de Lagrange . . . . . . . . . . . . . . 34
2.2.3 Cálculo do passo . . . . . . . . . . . . . . . . . . 37
2.2.4 Aceitação do passo e gerenciamento da região . . 38
2.2.5 Teste de criticidade . . . . . . . . . . . . . . . . . 39
2.2.6 Algoritmo de região de confiança . . . . . . . . . 39

2.3 Alternativas algorítmicas . . . . . . . . . . . . . . . . . . 42
2.4 Sumário . . . . . . . . . . . . . . . . . . . . . . . . . . . 42

3 Otimização não-diferenciável com restrições lineares 45
3.1 Material básico sobre otimização restrita . . . . . . . . . 45
3.2 Busca direta direcional com restrições lineares . . . . . . 47

3.2.1 Alternativas algorítmicas . . . . . . . . . . . . . 52
3.3 Região de confiança . . . . . . . . . . . . . . . . . . . . 54

3.3.1 Passo generalizado de Cauchy . . . . . . . . . . . 54
3.3.2 Algoritmo de região de confiança com restrições

lineares . . . . . . . . . . . . . . . . . . . . . . . 55
3.3.3 Alternativas algorítmicas . . . . . . . . . . . . . 57

3.4 Sumário . . . . . . . . . . . . . . . . . . . . . . . . . . . 57

4 Otimização não-diferenciável com restrições não-lineares 59
4.1 Lagrangiano aumentado . . . . . . . . . . . . . . . . . . 59

4.1.1 Lagrangiano aumentado com resolução aproxi-
mada dos sub-problemas . . . . . . . . . . . . . . 60

4.1.2 Lagrangiano aumentado com restrições de desi-
gualdade . . . . . . . . . . . . . . . . . . . . . . 62

4.1.3 Eliminação parcial das restrições . . . . . . . . . 64
4.2 Um algoritmo de Lagrangiano aumentado . . . . . . . . 65
4.3 Resolvendo os sub-problemas com busca direta direcional 69
4.4 Resolvendo os sub-problemas com região de confiança

não-diferenciável . . . . . . . . . . . . . . . . . . . . . . 69
4.5 Sumário . . . . . . . . . . . . . . . . . . . . . . . . . . . 70

5 Análise computacional 73



5.1 Otimização de função suave . . . . . . . . . . . . . . . . 73
5.1.1 Busca direta direcional . . . . . . . . . . . . . . . 74
5.1.2 Região de confiança . . . . . . . . . . . . . . . . 80

5.2 Otimização baseada no simulador . . . . . . . . . . . . . 83
5.3 Sumário . . . . . . . . . . . . . . . . . . . . . . . . . . . 88

6 Conclusão 91

Referências 93

A Sobre a diferenciabilidade do Lagrangiano aumentado 97



1 INTRODUÇÃO

Este trabalho busca aplicar técnicas de otimização não diferenciá-
vel ao caso da produção de petróleo. Neste capítulo introduziremos este
caso de uso, as técnicas de otimização e nossa motivação em estudar
tal aplicação.

Técnicas de otimização matemática podem ser bem empregadas
nas mais diversas áreas. A indústria do óleo e gás tem algumas particu-
laridades que motivam ainda mais tal aplicação. O petróleo é a principal
fonte de energia do mundo moderno e suas reservas, embora grandes,
são finitas e irão exaurir [1]. Além disso, há uma demanda crescente
por óleo [2], e seu preço, nos últimos 15 anos alcançou valores muito
maiores que os do restante do século passado.

A otimização pode ser aplicada tanto no sentido de sugerir meios
de se extrair de forma lucrativa a maior quantidade de óleo possível,
quanto na própria eficiência dos meios de produção.

Alguns trabalhos procuram encontrar a produção ótima de cam-
pos de produção de petróleo utilizando procedimentos heurísticos [3]
ou programação inteira-mista linear ou não-linear [4–6]. Para tanto,
estes constroem modelos complexos, a fim de caracterizar a produção
do campo de uma forma que pode ser utilizada eficientemente por algo-
ritmos de otimização. Tais modelos, embora não sejam fenomenológicos,
requerem bom conhecimento do problema para ser construídos. Além
disso, nem todos os tipos de modelo são igualmente bem sucedidos na
resolução dos problemas de otimização [1, 7].

Esses modelos de otimização são frequentemente obtidos por
meio de dados de simulação numérica. Simuladores são amplamente
utilizados em processos da produção de petróleo. Modelos de reser-
vatório e ferramentas de simulação de processos de extração de pe-
tróleo são cada vez mais rápidos e exatos [2]. Além disso, por serem
parte importante na previsão e gerenciamento da produção, modelos
de simulação são frequentemente sintonizados de forma a reproduzir de
maneira confiável o comportamento de reservatórios, poços e sistemas
relacionados.

Também é possível tentar otimizar a produção fazendo uso direto
dos simuladores, sem a construção dos modelos de otimização menci-
onados anteriormente. Uma possível dificuldade é que os simuladores
podem fornecer previsões de produção com uma boa exatidão, mas
tipicamente não fornecem derivadas, que são necessárias para se apli-
car técnicas clássicas de otimização. Alguns algoritmos de otimização
buscam justamente calcular as derivadas, seja por diferenças finitas ou
métodos probabilísticos, para utilizar métodos clássicos. De qualquer

17



18 Capítulo 1. Introdução

forma, é importante ter em vista que, embora os simuladores forneçam
resultados com exatidão satisfatória em suas variáveis finais, os valores
calculados frequentemente são o resultado de um processo iterativo, que
é interrompido quando o erro esperado fica suficientemente pequeno.
Esta é uma fonte de ruído, que pode acabar ampliado no cálculo de
derivadas.

Nesta dissertação abordamos outra classe de métodos de otimi-
zação, os não-diferenciáveis. Estes são desenvolvidos exatamente para
o caso em que não se dispõe das derivadas da função objetivo, assim
podem fazer uso dos valores calculados pelas ferramentas de simulação
diretamente. Alguns desses métodos são aplicados em [8, 9], também no
contexto de produção de petróleo. Sob certas condições, específicas de
cada método, é possível garantir que se encontre um ponto ótimo.

Nesta dissertação, apresentaremos duas classes de algoritmos de
otimização sem derivadas: busca direta direcional e região de confiança
não-diferenciável. Os algoritmos serão aplicados a um cenário de pro-
dução de petróleo, com poços operando por gas-lift, processo descrito
a seguir.

Em casos onde a pressão do reservatório é suficiente para fazer
os fluidos irem da formação, através do poço até a superfície, o poço é
dito surgente. Quando isso não ocorre, mecanismos de elevação artificial
são usados. Um importante método de elevação é o gas-lift contínuo,
correspondendo a 70% da produção de petróleo no Brasil [10].

Neste método, gás a alta pressão é injetado na coluna de produ-
ção [11]. Por ser mais leve que o petróleo, tende a subir, mas também
acaba gaseificando o conteúdo do tubing, que também se torna mais
leve [12]. Deste modo, a pressão do reservatório, juntamente com a
injeção de gás, impulsiona os fluidos até a superfície.

1.1 ORGANIZAÇÃO DO DOCUMENTO

Este documento foi organizado da seguinte maneira: no capítulo
2 introduzimos os algoritmos de busca direta direcional e região de
confiança não-diferenciável. Ambos para otimização irrestrita.

No capítulo 3, os dois algoritmos são extendidos a fim de resolver
problemas de otimização com restrições lineares nas variáveis. Em am-
bos os casos, os métodos buscam por descenso na função objetivo apenas
por pontos viáveis, isto é, satisfazendo às restrições. Para a busca direta
direcional, isto é feito gerando-se direções de busca que não saem do
conjunto viável. Para a região de confiança, os sub-problemas de região
de confiança são resolvidos na intersecção entre a região de confiança e



1.1. Organização do documento 19

o conjunto viável.
No capítulo 4 propomos o uso do método de Lagrangiano aumen-

tado, para a resolução de problemas de otimização com restrições não-li-
neares nas variáveis. Tal método substitui as restrições não-lineares por
penalizações na função objetivo, gerando uma sequência de sub-probl-
emas contendo apenas restrições lineares. Como podem ser implementa-
dos sem a necessidade de derivadas da função objetivo, os algoritmos do
capítulo anterior podem ser usados a fim de resolver tais sub-problemas.

No capítulo 5 fazemos uma análise computacional dos métodos
propostos no capítulo 3. Os métodos são aplicados para alocação de
gás de gas-lift em um campo de poços produtores de petróleo. Num
primeiro caso, ambos os métodos resolvem o problema da alocação de
gás considerando as funções de produção dos poços modeladas por fun-
ções suaves. Posteriormente, o método da região de confiança é utilizado
para resolver um problema de alocação de gás utilizando diretamente
um simulador fenomenológico.

Finalmente, no capítulo 6 apresentamos nossas conclusões.





2 OTIMIZAÇÃO NÃO-DIFERENCIÁVEL IRRESTRITA

Na área de produção de petróleo e gás há uma grande variedade
de ferramentas para a simulação de reservatórios, poços, dutos e dos
vários sistemas que integram a produção de petróleo e gás. No entanto,
as derivadas dos valores preditos podem não estar disponíveis. Embora
os simuladores sejam capazes de calcular numericamente suas previsões,
a exatidão com que o fazem pode não ser suficiente para que se proceda
com o cálculo de derivadas. Ou então, o custo de avaliar a função obje-
tivo ? em um número de pontos suficiente para calcular numericamente
sua derivada pode ser muito alto.

Este trabalho busca investigar a utilização de métodos de otimi-
zação que não necessitam das derivadas das funções objetivos, podendo
usar diretamente os valores calculados pelos simuladores. Para isto,
introduziremos neste capítulo métodos de otimização não-diferenciável.

Quando temos uma função ? : R? ? R e desejamos resolver um
problema do tipo

min
??R?

? (?)

e as derivadas ?? e ?2? estão disponíveis, podem ser empregadas
técnicas clássicas, como o método de Newton, para encontrar um ótimo
local. Dizemos que ?* ? R? é ótimo local de primeira ordem (ou ponto
estacionário de primeira ordem), se ?? (?*) = 0.

Quando não dispomos da derivada primeira ?? , podem ser uti-
lizados métodos de otimização não-diferenciável. São métodos que, a
partir de uma solução aproximada, buscam melhorar o valor assumido
pela função objetivo. Sob certas condições, é possível garantir que alguns
desses métodos encontram um ponto ótimo de primeira ordem.

2.1 MÉTODOS DE BUSCA DIRETA DIRECIONAL

Uma primeira classe de métodos que será apresentada é a busca
direta direcional. É composta de algoritmos que amostram a função
objetivo um número finito de vezes a cada iteração e não constroem
qualquer modelo dela. As decisões de evolução do algoritmo são sem-
pre tomadas com base nos próprios valores amostrados. Alguns destes
podem ser usados mesmo em funções que não são numéricas.

São algoritmos simples, podem não ser muito eficientes, mas di-
ante de um problema novo, pode ser mais rápido programar um algo-
ritmo de busca direta direcional para chegar à solução do que construir
um algoritmo novo, de convergência mais rápida, porém mais complexo
de se implementar.

21



22 Capítulo 2. Otimização não-diferenciável irrestrita

Há várias formas de se descrever os algoritmos dessa classe, cada
uma com suas particularidades de terminologia ou pequenas diferenças
algorítmicas, mas sempre preservando uma mesma estrutura, sem a cons-
trução de modelos. Neste trabalho, procuramos expor tais algoritmos
seguindo a descrição e notação de [13].

Para descrever o funcionamento desses algoritmos, utilizaremos
um problema de alocação de gás a 2 poços. Consideraremos que a
produção de cada poço é função do gás injetado, conforme a expressão
[14]:

??(?inj) = ?1 + ?2?inj + ?3(?inj)2 + ?4 ln(?inj + 1).

Consideramos que a vazão total produzida ?? é composta de
vazões de óleo ??, gás ?? e água ??. A proporção entre gás e óleo
produzidos é chamada GOR (Gas-Oil Ratio), enquanto o Water Cut
é a proporção de água na fase líquida produzida (composta de óleo e
água).

Considerando os vários poços (neste caso ? = 2), representamos
as seguintes grandezas:

? ??inj é a taxa de injeção de gás no poço ?.

? ??? é a vazão total produzida no poço ?.

? ??? é a vazão de óleo produzido no poço ?.

? ??? é a vazão de água produzida no poço ?.

? ??? é a vazão de gás produzido no poço ?.

Considerando os preços obtidos com a venda do óleo ??, e do
gás ?? , e os custos do tratamento da água ?? e da injeção de gás ??,
definimos a função de ganho econômico correspondente como

? (?inj) =
? =2??
?=1

(?
???

?
? (?

?
inj) + ?? ?

?
? (?

?
inj) ? ?????(??inj) ? ????inj

)?
.

Desejamos maximizar uma função de ganho econômico, para ? = 2
poços, da forma

max
?inj

? (?inj). (2.1)

Para este caso, consideramos o poço 1 modelado por

? ?1? (?1inj) = ?1080 ? 0,26?1inj + 398 ln(?1inj + 1)

? GOR = 0,286



2.1. Busca direta direcional 23

? Water cut = 12,5 %

? ?1? = 0,7?1?
? ?1? = 0,2?1?
? ?1? = 0,1?1? .

e, para o poço 2,

? ?2? (?2inj) = ?1630 ? 0,37?2inj + 671 ln(?2inj + 1)

? GOR = 0,750

? Water cut = 42,9 %

? ?2? = 0,4?2?
? ?2? = 0,3?2?
? ?2? = 0,3?2? .

A busca direta direcional inicia de uma estimativa de solução
e, a cada iteração, avalia a função objetivo um número finito de vezes
em torno da solução corrente. Na Figura 2.1 ilustramos o domínio da
função ? , com as curvas de nível traçadas. A estrela marca o ponto ótimo,
enquanto a estimativa de solução é o maior dos pontos escuros. A cada
iteração, a função objetivo é avaliada em quatro pontos, localizados
há uma certa distância da solução corrente. Neste caso, tais pontos
foram calculados utilizando a estimativa de solução inicial (?1inj, ?2inj)0
e somando-se, +? e ?? em cada variável, a fim de se obter os quatro
pontos de teste, onde a função objetivo é avaliada. Na figura, estes
pontos ficam nas pontas dos traços pretos. O ponto que apresenta o
melhor valor passa a ser a nova estimativa de solução (neste caso, o
ponto acima).

Este procedimento é repetido, então, em torno da nova solução,
conforme ilustrado na Figura 2.2, que é a continuação da anterior.

Na parte (a) da figura, entre todos os pontos considerados, aquele
à direita apresentou o melhor valor da função objetivo, passando a ser
considerado a nova estimativa de solução, conforme ilustrado em (b).

Em (b) ocorre que nenhum dos pontos de teste apresenta um
valor para a função objetivo melhor que a solução corrente. Nesse caso,
o iterando é mantido no mesmo ponto, e a busca por descenso continua
em uma região mais próxima, reduzindo-se o comprimento do passo ?.
Essa redução é ilustrada no quadro seguinte.



24 Capítulo 2. Otimização não-diferenciável irrestrita

500 1.000 1.500 2.000
500

1.000

1.500

2.000

? (?) = 1.641 ? (?) = 1.669

? (?) = 1.670

? (?) = 1.584

? (?) = 1.581

?1inj (injeção no poço 1)

?
2 in

j
(i

nj
eç

ão
no

po
ço

2)

Figura 2.1: Busca direta direcional: a função objetivo é avaliada em
quatro pontos em torno da estimativa de solução

Em (c), é encontrado um ponto melhor à direita. Em (d), o
melhor ponto é acima. No quadro (e), novamente, nenhum dos pontos
de teste apresenta um valor melhor que a solução corrente, e novamente
o comprimento do passo é reduzido, enquanto mantém-se a mesma
solução (f).

Neste capítulo procuraremos formalizar e generalizar esse método
de solução e discutir sobre suas possibilidades de sucesso.

Para garantir que esses métodos cheguem a um ponto ótimo, os
algoritmos cumprem as seguintes etapas:

1. Buscar uma direção de descenso.

2. Manter uma boa geometria das direções de busca (em um sentido
formal).

3. Garantir que a região de busca diminua tanto quanto desejado.
Isto é, exige-se que as regiões onde se busca por descenso decres-
çam, no limite.



2.1. Busca direta direcional 25

(a) (b)

(c) (d)

(e) (f)

Figura 2.2: Busca direta direcional na otimização da produção em dois
poços.



26 Capítulo 2. Otimização não-diferenciável irrestrita

O primeiro ponto é encontrar uma direção de descenso, isto é,
uma direção na qual a função objetivo ? decresce, a partir da estimativa
de solução corrente ?. Métodos convencionais de otimização escolhem
a direção baseados no gradiente ?? (?). Por exemplo, o método do
máximo descenso emprega ??? (?). No entanto, quando não se tem
acesso à derivada, é necessário fazer outra escolha.

Suponha que a função ? é continuamente diferenciável. Então,
qualquer vetor ? ? R? que forma um ângulo agudo com ??? (?) é uma
direção de descenso para ? a partir de ?. Isto é, se

??? (?)? ? &gt; 0 (2.2)

? é uma direção em que, a partir de ?, ? decresce ao menos por uma
distância (possivelmente curta).

Métodos de busca direta direcional buscam em um conjunto de
direções ? = {?1, ?2, . . .}? R?, em que, para todo vetor ? ? R?, ? ?= 0,
existe um ?? ?? de modo que

?? ?? &gt; 0. (2.3)

Em particular, para ? = ??? (?) ?= 0, existe um ?? que satizfaz (2.2).
Então, uma das direções de ? é direção de descenso, ainda que não se
saiba, de antemão, qual.

Resta mostrar que é possível construir um conjunto ? conforme
mencionado, com um número finito de elementos. Em [15], é demons-
trado o seguinte teorema:

Teorema 1 O conjunto ? = {?1, ?2, . . . , ??} gera R? por meio de
combinações lineares de coeficientes não-negativos se, e somente se,
para todo vetor não-nulo ? ? R?, existe um ? ?? tal que

?? ? &gt; 0.

Pelo fato desses conjuntos gerarem R? por meio de combinações não-
negativas (combinações cônicas), eles também podem ser chamados
geradores positivos de R?. Por isso a classe de algoritmos apresentada
nesta seção é chamada em [13] de “Generating Set Search” (busca [por
meio de] conjuntos geradores [positivos]). Alguns exemplos de conjuntos
geradores positivos estão na Figura 2.3.

Também de [15], o seguinte teorema é apresentado:

Teorema 2 Suponha que ? = {?1, ?2, . . . , ??}, gera R? por meio de
combinações cônicas, então o número de vetores ? ? ? + 1, e é possível
? = ? + 1.



2.1. Busca direta direcional 27

Figura 2.3: Três exemplos de conjuntos de vetores geradores positivos
do R2.

Para construir um tal conjunto, suponha que {?1, ?2, . . . , ??} é
uma base de R?. Então, para quaisquer ?? &gt; 0, definindo

??+1 = ??1?1 ? ?2?2 ? . . . ? ???? (2.4)

o conjunto {?1, ?2, . . . , ??, ??+1} é gerador positivo dos R?. Este con-
junto também é chamado de base positiva mínima.

Outra possibilidade para construir ? a partir de uma base de
R? para combinações lineares {?1, . . . , ??} é unir tais vetores aos seus
negativos:

? = {?1, . . . , ??}?{??1, . . . ,???}. (2.5)
Esta é chamada de base positiva máxima.

Em algoritmos de busca direta direcional, para cada iterando
?? com função objetivo ? (??), é construído um conjunto ?? gerador
positivo de R?, no qual se busca descenso para ? .

Porém, não basta o conjunto ?? ser gerador positivo de R?. É
necessário garantir que todos os conjuntos usados tenham uma boa
geometria, no sentido da seguinte definição:

Definição 1 Definimos a medida cosseno de um conjunto ? ? R?
como

? (?) = min
??R?
? ?=0

max
???

?? ?

??????

Isto é, ? (?) é o cosseno do maior ângulo interno formado entre um vetor
não-nulo ? ? R? e o vetor ? ? ? mais próximo de ?. Nos algoritmos
de busca direta direcional, trata-se de uma medida de quão distante
??? (?) pode estar de ?.

Uma das formas de manter a boa geometria das direções de busca
é impor uma medida cosseno mínima, um ?min &gt; 0 de modo que:

? (??) ? ?min.



28 Capítulo 2. Otimização não-diferenciável irrestrita

Qualquer conjunto gerador positivo ? tem ? (?) &gt; 0, por con-
sequência de (2.3). O conjunto formado pelas direções coordenadas e
seus respectivos opostos

{?1, ?2, . . . , ???1, ??}?{??1,??2, . . . ,????1,???}
é um gerador positivo do R?, com medida cosseno 1/

?
?.

Um exemplo de busca direta direcional é apresentado no Algo-
ritmo 2.1, baseado em [13].

O algoritmo permite que se utilize, a cada iteração, um novo
conjunto ?? de direções de busca, o qual é formado por um conjunto
??, gerador positivo dos R?, e um outro conjunto ??. Este último
contém direções de busca adicionais, permitindo-se a implementação
de outros meios de busca por descenso durante as iterações. Porém, há
limites nos comprimentos das direções:

?min ????? ?max ?? ???, (2.6)
?min ???? ?? ???. (2.7)

Os valores de ?min ? ?max são arbitrários, mas é importante que sejam
fixos durante toda a execução do algoritmo, de modo que o comprimento
final do passo seja determinado por ?? (???min ?????????max).

A iteração ? é dita bem-sucedida (? ??) se existe uma direção
? ? ?? tal que

? (?? + ???) &amp;lt;? (??) ? ?(??)
em que a função forçante ? : R?{0}? R?{0} é não-decrescente e

lim
??0+

?(?)
?

= 0. (2.8)

Pode ser, por exemplo, qualquer função da forma ?(?) = ???, em que
? &gt; 0 e ? &gt; 1, constantes.

Caso não exista uma tal direção, a iteração ? é dita mal-sucedida
(? ??).

O tamanho do passo muda ao longo das iterações. Se não for
encontrado descenso ele é reduzido, caso contrário, é aumentado, de
acordo com as relações:

??+1 =
{?

????, se a iteração ? foi bem-sucedida
????, se a iteração ? foi mal-sucedida

em que o parâmetro de contração do passo ?? é tal que 0 &amp;lt;?? ? ?max&amp;lt;
1 e o de expansão do passo ?? ? 1.

Tendo o algoritmo bem definido, podemos apresentar um primeiro
resultado sobre sua convergência [13]:



2.1. Busca direta direcional 29

Algoritmo 2.1: Um exemplo de busca direta direcional, de [13]
Seja ? : R? ? R dada;
Seja ?0 ? R? um ponto inicial;
Defina

???? &gt; 0 a tolerância de convergência;
?0 &gt; ???? um tamanho de passo inicial;
?max ? 1 um limite superior para o coeficiente de expansão
??;
?0 ? [1, ?max] o valor inicial do coeficiente de expansão do
passo;
?max &amp;lt;1 um limite superior para o parâmetro de contração
??;
?0 ? (0, ?max] o valor inicial do coeficiente de contração do
passo;
?max ? ?min &gt; 0 limites superior e inferior, respectivamente,
para os comprimentos dos vetores de qualquer conjunto
gerador positivo;
?min &gt; 0 um limitante superior para a medida cosseno dos
conjuntos geradores positivos;
? : R+ ? R+ uma função não-decrescente satisfazendo a
equação (2.8);

for ? = 0, 1, . . . do
Defina ?? conjunto gerador positivo para R? satisfazendo
?min ????? ?max, ?? ???, com ? (??) ? ?min;
if Existe ? ??? tal que ? (?? + ???) &amp;lt;? (??) ? ?(??) then

??+1 ? ?? + ???;
??+1 ? ????;

else
??+1 ? ??;
??+1 ? ???? ;
if ??+1 &amp;lt;???? then

Encerrar;

Determine ??+1 ? (0, ?max] e ??+1 ? [1, ?max];



30 Capítulo 2. Otimização não-diferenciável irrestrita

Teorema 3 Seja ? : R? ? R, com ?? Lipschitziana com constante
de Lipschitz M. O Algoritmo 2.1 produz iterandos tais que, para toda
iteração mal-sucedida ? ??

??? (??)??
1

? (??)

[?
? ???max +

?(??)
???min

]?
. (2.9)

Assim, obtemos uma cota superior (ainda que desconhecida) para
??? (??)?, mesmo sem calcularmos tal valor em nenhum momento.
Ainda, como ?min limita os valores de ? (??), o termo 1/? (??) é limi-
tado superiormente ao longo das iterações. Além disso, como os valores
de ? , ?max e ?min são fixos, e considerando (2.8), se o tamanho do
passo for reduzido indefinidamente, isto é, se

lim
??0
???

?? = 0

então
lim
??0
???
??? (??)? = 0.

Já foram abordados a maneira de encontrar uma direção de
descenso (por meio de conjuntos geradores positivos) e o controle da
geometria das direções de busca (por meio da medida cosseno). O
ponto faltante é garantir que a direção de busca decresça. Fazendo-se
lim??? ?? = 0, o Teorema 3 garante convergência para um ponto
estacionário de primeira ordem. Isto é, um ponto ?* em que

?? (?*) = 0.

Isso é enunciado no teorema seguinte:

Teorema 4 Seja ? limitada inferiormente. Suponha a função ? como
dada em (2.8). Então, o Algoritmo 2.1 produz iterações de modo que

lim inf
??+?

?? = 0.

A demonstração pode ser vista em [13].

2.2 MÉTODOS DE REGIÃO DE CONFIANÇA

Métodos de região de confiança partem de uma aproximação
para a solução e utilizam os valores já calculados da função objetivo
para construir modelos. Estes buscam aproximar ? localmente, em uma
vizinhança do ponto atual chamada região de confiança.



2.2. Região de confiança 31

O modelo construído, espera-se, é mais fácil de otimizar que a
função original. Por um lado, porque se dispõe de técnicas clássicas de
otimização com derivadas. Por outro, porque a avaliação do modelo
pode ser muito mais rápida que a função ? original.

Construído um bom modelo, ele é otimizado dentro da região de
confiança, gerando um ponto ?+? , para então se calcular ? (?

+
? ). Assim,

é possível economizar no número de vezes que se avalia ? . O que é uma
vantagem com relação aos métodos de busca direta quando, por exemplo,
cada cálculo de ? é uma simulação que pode durar vários minutos. Por
outro lado, métodos de região de confiança são mais complexos de se
implementar.

Entre os vários métodos de região de confiança, há diferenças
com relação ao tipo de modelo, forma da região de confiança, maneiras
de manter ou melhorar o modelo, aceitação do passo e gerenciamento
da região de confiança.

Nesta seção, apresentamos métodos de região de confiança não-
diferenciáveis, em grande parte, conforme a descrição e nomenclatura
de [16]. Neste livro há várias explicações abrangentes para o uso de
modelos polinomiais de regressão, mínima norma ou modelos não poli-
nomiais. Porém, nesta dissertação, vamos abordar apenas modelos de
interpolação por polinômios de até segunda ordem, da forma

??(?? + ?) = ??(??) + ??? ? +
1
2

?? ???

que aproximam a função objetivo ? na região de confiança dada por
uma bola de tamanho ?? em torno do iterando ??:

?(??, ??) = {? : ?? ? ???? ??}

onde a norma ?·? pode se tratar da norma 2 ou norma infinito, por
exemplo.

Para introduzir os métodos de região de confiança não-diferenci-
áveis, iniciamos com alguns conceitos básicos.

2.2.1 Definição do modelo

Entre os vários algoritmos de otimização que usam região de
confiança, há uma grande diferença com relação ao tipo de modelo
usado. Nesta seção, introduzimos o modelo que usamos no trabalho, de
interpolação com polinômios de segunda ordem.

Para modelos de interpolação, definimos um conjunto de pontos
? = {?0, ?1, . . . , ??} onde o modelo construído coincide com a função



32 Capítulo 2. Otimização não-diferenciável irrestrita

objetivo, isto é,
?(??) = ? (??) ??? ??. (2.10)

É necessário também fixar uma base ? = {?1, . . . , ??} que re-
presente o espaço dos polinômios de segunda ordem no R?. Então, as
combinações lineares dos seus elementos ?1, . . . , ?? geram os polinômios,
e o modelo ? pode ser escrito como:

?(?) =
???

?=1
????(?). (2.11)

em que ?? ? ?.
Então, fixado um conjunto de pontos ?, para se determinar o

modelo polinomial de interpolação, a partir desta última equação, jun-
tamente com as ? + 1 equações (2.10), tem-se o sistema de equações
lineares:

? (?,?)?? = ? (?) (2.12)

em que

? (?,?) =

?
????

?0(?0) ?1(?0) · · · ??(?0)
?0(?1) ?1(?1) · · · ??(?1)

...
...

. . .
...

?0(??) ?1(??) · · · ??(??)

?
????

e

? (?) =

?
????

? (?0)
? (?1)

...
? (??)

?
???? .

Para o modelo ser calculado, basta que a matriz ? (?,?) seja
invertível. Isto depende apenas do conjunto de pontos ?, e não da base.
Quando isso ocorre, dizemos que ?, ou respectivamente o modelo ? nele
baseado é bem posicionado para interpolação. A seguir apresentaremos
um algoritmo para o cálculo deste conjunto, baseado na eliminação
Gaussiana.

Por outro lado, o bom condicionamento do sistema (2.12) depende
de ? e também da base. Este é um ponto que interfere tanto na exatidão
com que se resolve o sistema, como na estimativa dos erros ??(?)?? (?)?
entre o modelo e a função objetivo.



2.2. Região de confiança 33

Neste trabalho, fixamos o uso da base de monômios, que chama-
mos base natural e denotamos ?:

? = {?0, . . . , ??}
=
{?

1, ?1, ?2, . . . , ??,

?21
2

, ?1?2,
?22
2

, ?1?3, ?2?3,
?23
2

, . . . ,
?2?
2

}?
.

Para proceder com o cálculo de um conjunto ? de pontos bem
posicionados para interpolação, apresentamos o Algoritmo 2.2, de [16].
O algoritmo procede de forma semelhante à eliminação gaussiana, a-
plicada à matriz ? (?,?). Inicia com um conjunto de pontos ?, pos-
sivelmente incompleto ou mal-posicionado, e com um conjunto de po-
linômios, chamados polinômios pivô. O laço mais externo consiste em
encontrar, entre os pontos disponíveis, aquele em que o polinômio pivô
corrente assume maior valor absoluto. Na eliminação gaussiana, equivale
a encontrar para cada coluna de ? , o maior valor de elemento pivô. A
diferença é que, quando um pivô é zero, ou quando em ? não há outros
pontos, um novo ponto é calculado, substituindo o primeiro em ?.

O segundo passo do algoritmo consiste em realizar a eliminação
propriamente dita, operando com os polinômios. Para cada um dos
polinômios seguintes, se subtrai o polinômio pivô corrente, multiplicado
pelo fator adequado. O resultado equivalente, na matriz dos polinômios
pivô ? (?,?), é que os elementos abaixo do pivô são zerados.

Ao final deste procedimento, tem-se um conjunto de polinômios
pivô, e uma respectiva matriz ? (?,?) não-singular, o que garante que
o conjunto de pontos ? é bem posicionado (note que, no primeiro
passo, garantimos que todos os elementos-pivô da eliminação gaussiana
fossem não-nulos). Para a construção do modelo, pode-se resolver o
sistema triangular ? (?,?) = ? (?) com retro-substituição, gerando os
coeficientes que multiplicam os polinômios-pivô para construir o modelo.

Porém, não basta que seja possível calcular um modelo de in-
terpolação. É necessário que o sistema resultante ? (?,?) seja bem-
condicionado. A maneira de limitar o número de condicionamento de
? é feita de maneira semelhante ao algoritmo anterior. No entanto, o
critério para descartar (recalcular) um ponto durante a eliminação gaus-
siana em ? é mais forte. Exige-se que todos os elementos-pivô tenham
módulo maior que um valor ?, fixado. O procedimento é ilustrado no
Algoritmo 2.3, de [16].

Com este algoritmo, todos os pivôs da matriz ? são, garantida-
mente, maiores que o limiar ? escolhido. Se necessário, o respectivo ponto
é trocado para que isso ocorra. Para tanto, a otimização que ocorre no



34 Capítulo 2. Otimização não-diferenciável irrestrita

primeiro passo não é estritamente necessária. Basta que se encontre um
ponto ? ? ? que satisfaz |??(?)| ? ?. A maneira de encontrá-lo será
mostrada adiante.

Segundo [16], as estimativas de erros podem ser relacionadas com
o número de condicionamento da matriz ? , aplicada a um conjunto de
pontos modificado para uma região de confiança dada por uma bola de
raio 1 centrada na origem:

? = {0, ?1, . . . , ??}
= {0, (?1 ? ?0)/?(?), . . . , (?? ? ?0)/?(?)}??(0, 1)

em que ?(?) é o fator de escala que faz com que todos os ele-
mentos caibam (exatamente) em uma bola de raio 1:

?(?) = max
1????

??? ? ?0?.

de modo que o uso do conjunto ? limita a norma

1 ????? (? + 1) 32 .

O que motiva o uso do algoritmo neste conjunto ?. Por outro lado,
a decomposição LU feita pelo algoritmo, provê uma cota superior para
?? ?1?. Considere a decomposição dada, com ambas as matrizes L e U
com números 1 na diagonal: ? = LDU (? ?1 = U?1D?1L?1). O limiar
para os pivôs dá uma cota superior para a norma ?D?1??

?
? + 1/?,

de modo que

?? ?1? = ?D?1??L?1??U?1??
?

? + 1?L?1??U?1?
?

.

O valor ?growth = ?L?1??U?1?, chamado fator de crescimento da fato-
ração pode ser muito grande, mas é limitado. A escolha do maior valor
possível para os pivôs pode ajudar a diminuir esse termo.

Assim, o número de condicionamento de cond(? (?,?)) é limi-
tado.

2.2.2 Polinômios de Lagrange

Dado um conjunto de ? + 1 pontos ? = {?0, ?1, . . . , ??}, de-
finimos os polinômios de Lagrange correspondentes como polinômios
?? : R? ? R, em que ? = 1, . . . , ?, e

?? (??) =
{?

1 se ? = ?
0 se ? ?= ? (2.13)



2.2. Região de confiança 35

Algoritmo 2.2: Completando o conjunto de pontos de interpola-
ção

Escolha uma aproximação inicial para os polinômios-pivô ??,
possivelmente usando a base: ??(?) = ??(?). Considere o conjunto
inicial ? = {?0, ?1, . . . , ?????}, com ???? + 1 pontos;
for ? = 0, 1, . . . do

Encontre ?? = argmax???????? |??(?
? )|. Se |??(??? )| &gt; 0 e

? ? ????, troque os pontos ?? e ??? no conjunto ?. Senão,
calcule (ou recalcule, caso ? ? ????) como

?? ? argmax
???

|??(?)|

for ? = ? + 1, . . . , ? do

?? (?) ? ?? (?) ?
?? (??)
??(??)

??(?)

Algoritmo 2.3: Melhorando o modelo e o conjunto de pontos
Escolha uma aproximação inicial para os polinômios-pivô ??,
possivelmente usando a base: ??(?) = ??(?) para ? = 0, . . . , ?.
Escolha um limiar ? &gt; 0 para a seleção de elementos-pivô.
Considere o conjunto inicial ? bem-posicionado com ? + 1
pontos;
for ? = 0, 1, . . . , ? do

Encontre se possível, ?? ?{?, . . . , ?} tal que |??(??? )| ? ?. Se
tal ?? for encontrado, troque os pontos ?? e ??? de lugar em ?.
Caso contrário, recalcule ?? como

?? ? argmax
???

|??(?)|.

interrompa caso |??(??)| &amp;lt;? (O limiar ? é muito grande).
for ? = ? + 1, . . . , ? do

?? (?) ? ?? (?) ?
?? (??)
??(??)

??(?)



36 Capítulo 2. Otimização não-diferenciável irrestrita

Isto é, para todo índice ?, ?? é um polinômio que se anula em todos os
pontos de ?, exceto por ?? , com ?? (?? ) = 1. Além disso, tal polinômio é
único, e independente de base, contanto que a matriz ? de interpolação
seja não-singular.

Assim, o modelo de interpolação para a função objetivo ? é:

?(?) =
???

?=0
??(?)? (??) (2.14)

Para que os ? + 1 polinômios de Lagrange estejam bem definidos,
é necessário que os pontos sejam bem posicionados; em caso contrário,
não é possível determinar ? + 1 polinômios satisfazendo (2.13).

Para chegar ao erro de interpolação, introduzimos a seguinte
definição [16]:

Definição 2 Seja ? &gt; 0 e um conjunto ? ? R? dado. Um conjunto
bem posicionado ? = {?0, ?1, . . . , ??} é dito ?-posicionado em ? se, e
somente se, para a base de polinômios de Lagrange associados com ?,
tem-se que

? ? max
?=0,...,?

max
???
|??(?)|

Esta medida também estabelece cotas superiores para os erros de
predição tanto do modelo ?? ? ?? como de sua derivada ??? ????
[17]:

Teorema 5 Dada uma bola ?(?, ?) e um conjunto de pontos de inter-
polação ? ? ?(?, ?) bem posicionado, e seus polinômios de Lagrange
correspondentes {??(?)}??=0, existem constantes ??? &gt; 0 e ??? &gt; 0 tais
que, para todo polinômio da forma (2.14) de grau maior que um e todo
ponto ? ??(?, ?),

?? (?) ? ?(?)?? ???
???

?=0
??? ? ??2 |??(?)| (2.15)

e
??? (?) ???(?)?? ??? ??. (2.16)

Dessa forma, mantendo-se ? limitado, o erro de interpolação cai com
o raio da região ?. Estes resultados motivam a buscar modelos de
interpolação polinomial construídos sobre pontos ?-posicionados, para
um ? mantido constante.

Alguns algoritmos constroem modelos ?-posicionados fazendo
uso explícito do valor de ?. Não é o caso do Algoritmo 2.3, que cons-
trói modelos ?-posicionados com um valor de ? desconhecido, porém



2.2. Região de confiança 37

limitado e que depende do parâmetro ?. Optamos por este algoritmo
por ser mais fácil de adaptar ao caso restrito.

2.2.3 Cálculo do passo

Para o cálculo do passo, uma possibilidade é tentar encontrar o
ótimo global na região de confiança, resolvendo o problema

min
???(?? ,?? )

??(?)

Isto pode ser feito em casos particulares. Se a região de confi-
ança for dada por uma bola na norma-? do tipo ?(??, ??) = {? :
?? ? ????}, trata-se de um problema de otimização com restrições
lineares. Se o modelo ?? for linear, trata-se de um problema de progra-
mação linear:

min ??(?) = ??? ?
? ? ?? ? ??
? ? ?? ????.

O mesmo poderia ser dito de bolas na norma-1.
De modo semelhante, se o modelo for quadrático, e a bola for

dada na norma-2 o problema de minimização

min ??(? + ?) = ??(??) + ??? ? +
1
2

?? ???

sujeito a ??? &amp;lt;??
pode ser resolvido eficientemente (em tempo polinomial), utilizando o
algoritmo de Moré-Sorensen, o que torna o uso da norma-2 vantajoso.
Tal algoritmo não será apresentado neste trabalho porque estamos in-
teressados no caso de restrições lineares, que não podem ser tratadas,
embora haja algumas heurísticas [18].

A otimização de um modelo quadrático em uma bola dada por
restrições lineares torna-se um problema NP-difícil se a derivada se-
gunda ? tiver ao menos um auto-valor negativo [19]. E segundo [20],
nesse caso é difícil até mesmo decidir se um determinado ponto é mínimo
local.

De qualquer forma, não é necessário chegar ao ótimo global na
região. Alguns algoritmos exigem que a minimização encontre ao menos
uma fração do decréscimo obtido pela otimização global. Uma alterna-
tiva ainda menos exigente é por meio do passo de Cauchy. Defina:

??? = argmin
??0

?? ???? ??(?? ,?? )

??(?? ? ???)



38 Capítulo 2. Otimização não-diferenciável irrestrita

o passo de Cauchy é dado por

??? = ???? ??.

Então, o novo ponto é dado por ?+? = ?? + ?
?
? . Os algoritmos que

apresentaremos exigem que se encontre, a cada iteração, uma fração do
passo de Cauchy.

De acordo com [20], verifica-se experimentalmente uma conver-
gência linear do algoritmo quando, repetidamente, se encontra o passo
de Cauchy a cada iteração. Em tal livro a otimização do modelo na
região de confiança é tratada com grande riqueza de detalhes, seja para
se encontrar um bom ponto de teste ou para encontrar o ótimo global.

2.2.4 Aceitação do passo e gerenciamento da região

Da otimização aproximada do problema na região de confiança,
o valor do decréscimo encontrado com o modelo ??(??)???(?+? ) será
sempre positivo. Algumas decisões do algoritmo são dadas com base no
grau de concordância entre o decréscimo real obtido e o esperado:

?? =
? (??) ? ? (?+? )

??(??) ? ??(?+? )
. (2.17)

Se este valor for alto (?? ? ?1, ?1 &gt; 0 fixo), o passo é aceito, o
iterando é atualizado (??+1 ? ?+? ), e a região de confiança é deslocada
de acordo, ficando em torno de ??+1.

Ainda, [16] sugere que se aceite o passo em casos mais modestos
para o descenso encontrado. Então, o passo também é aceito se ?? ? ?0,
com ?0 fixado, contanto que o modelo que produziu tal passo seja
suficientemente preciso (?-posicionado). Além disso, ?1 ? ?0 ? 0, e o
uso de ?0 = 0 é encorajado por tais autores, possibilitando que se aceite
descenso simples, na esperança de se aproveitar todas as avaliações da
função objetivo, que podem ser custosas.

O outro uso para o coeficiente de concordância ?? é para o ge-
renciamento da região de confiança. Caso seja alto, ?? ? ?1, o raio da
região pode ser aumentado, por exemplo, ??+1 ? min{?inc??, ?max},
?inc &gt; 1, sendo ?max o valor máximo para o raio da região.

Caso contrário, a falha em prever adequadamente o decréscimo
da função pode se dever a dois motivos: ou o modelo não é bom, ou o
modelo é bom, mas numa vizinhança menor do iterando, enquanto o
raio da região de confiança está muito grande. Assim, caso o modelo já
seja ?-posicionado, o erro deve-se a um raio muito grande, então este é
reduzido de um fator ?: ??+1 ? ???.



2.2. Região de confiança 39

Por outro lado, caso o modelo ainda não seja ?-posicionado, não
podemos concluir que o raio foi grande demais. Neste caso, o modelo
deve ser melhorado (por exemplo, com o Algoritmo 2.3). O raio é man-
tido (??+1 ? ??), já que uma redução indevida afetaria, no mínimo, a
taxa de convergência do algoritmo (e as provas de convergência também
dependem deste ponto).

2.2.5 Teste de criticidade

Quando se detectar que os iterandos estão se aproximando de
um ponto estacionário, o raio da região de confiança é reduzido, e novos
modelos ?-posicionados são calculados, de modo a se ter menores erros
entre o modelo e a função objetivo.

Por outro lado, essa redução do raio não pode ser excessiva, de
modo a não prejudicar o avanço do algoritmo. Para garantir a conver-
gência, é necessário fazer o raio da região próximo de alguma medida
de estacionariedade, como a norma da derivada do modelo ????. Isso
também motiva ter o raio da região de confiança como o critério de
parada usual dos algoritmos de região de confiança: o raio da região
converge para zero, ou fica limitado acima de zero junto com a medida
(????), que está relacionada a ??? (??)?.

Se, ao início de uma iteração, ???? for pequeno o suficiente
(???? &amp;lt;??, para um valor fixo ??), executa-se o teste de criticidade,
de modo a obter um modelo ?-posicionado em uma região com um raio
de, no máximo ?????, para um valor fixo ?.

Isto é feito iterativamente, já que o valor de ?? depende do modelo
??, que por sua vez depende da região de confiança, cujo raio será (no
final) limitado por ?????. Para tanto, o raio da região é repetidamente
reduzido e novos modelos ?-posicionados são criados, até que se encontre
uma região com o raio ??? que não excede ?????.

Também, para que esta redução do raio não seja excessiva, este
valor ??? do raio é usado, contanto que seja maior que ? ????. Caso con-
trário, utiliza-se o valor min(? ???? , ??). O procedimento encontra-se
formalizado no Algoritmo 2.4.

2.2.6 Algoritmo de região de confiança

O Algoritmo 2.5 é um exemplo de método de região de confiança
segundo [16].

Agora apresentamos as condições suficientes para que o Algo-
ritmo 2.5 convirja para um ponto ótimo de primeira ordem.



40 Capítulo 2. Otimização não-diferenciável irrestrita

Algoritmo 2.4: Teste de criticidade
? = 0;
?0? = ??;
for ? = 0, 1, . . . do

Incremente ? em 1;
??? = ???1??;
Utilize o modelo anterior ?(??1)? , para calcular um novo
modelo ?(?)? , ?-posicionado em ?(??, ???);
if ??? ? ????? then

Retorne ??? e ???? = ?
(?)
? .

Vamos fazer algumas suposições sobre a função objetivo ? . Como
os iterandos do algoritmo sempre apresentam descenso com relação ao
ponto anterior, todos os eles pertencem ao conjunto de nível (inferior)
definido com relação ao primeiro iterando:

?(?0) = {? ? R?| ? (?) ? ? (?0)}

Para a construção dos modelos são usados pontos nas regiões de
confiança, definidas por bolas em torno dos iterandos. Então, ? não é
avaliada apenas em ?(?0), mas no conjunto maior

????(?0) =
??

???(?0)
?(?, ?max).

Hipótese 1 Sejam ?0 e ?max dados. A função ? é diferenciável e tem
gradiente Lipschitz contínuo em um domínio aberto contendo ????(?0).

Hipótese 2 A função ? é limitada inferiormente em ?(?0), isto é, que
existe uma constante ? * tal que para todo ? ? ?(?0), ? (?) ? ? *.

E introduzimos, ainda, uma hipótese sobre o modelo

Hipótese 3 Suponha que existe uma constante ???? tal que para todo
iterando ??, a derivada segunda do modelo ?? satisfaz

????? ????.

E uma hipótese sobre o passo escolhido durante o algoritmo:



2.2. Região de confiança 41

Algoritmo 2.5: Um método de região de confiança
Seja ? : R? ? R dada;
Seja ?0 ? R? um ponto inicial;
Seja ?0 : R? ? R? um modelo inicial;
Seja ?(?0, ?0) a região de confiança inicial;
Defina 0 ? ?0 ? ?1 &amp;lt;1 e ?1 ?= 0;
Defina os fatores de redução e aumento da região de confiança
0 &amp;lt;? &amp;lt;1 &amp;lt;????;
Defina o raio máximo ?max da região de confiança;
for ? = 0, 1, . . . do

Construa o modelo ??(??) que interpola ? em ??. Calcule o
gradiente ?? = ???(??);
if ????? ?? e ?? não é ?-posicionado em ?(??, ?????) then

Refine o modelo até que ?? seja ?-posicionado em
?(??, ??), ?? ? (0, ?????).

Calcule o ponto ?+? = ?? + ?? que garanta descenso para o
modelo ?? em ?;
Calcule o grau de concordância entre a predição de ?? e o
valor de ? :

?? =
? (??) ? ? (?+? )

??(??) ? ??(?+? )
; (2.18)

Atualize o iterando:

??+1 =
{?

?+? se ?? ? ?1 ou ?? ? ?0 e ?? ?-posicionado
?? caso contrário

Atualize o tamanho da região de confiança:

??+1 =

??
?

min(??????, ?max), se ?? ? ?1
???, se ?? &amp;lt;?1 e ?? é ?-posicionado
??, se ?? &amp;lt;?1 e ?? não é ?-posicionado

Atualize o modelo ??+1;



42 Capítulo 2. Otimização não-diferenciável irrestrita

Hipótese 4 Para toda iteração ?, o passo ?? escolhido satisfazendo ao
menos uma fração ?? ?? do decréscimo referente ao passo de Cauchy:

??(??) ? ??(?? + ??) ? ?? ??
[?
??(??) ? ??(?? + ??? )

]?
para uma constante ?? ?? ? (0, 1).

Com base nessas hipóteses, [16] apresenta o seguinte teorema:

Teorema 6 Suponha as hipóteses 1, 2, 3 e 4. Então

lim
??+?

??? (??)? = 0

2.3 ALTERNATIVAS ALGORÍTMICAS

Em [17] é apresentado um algoritmo para a manutenção do mo-
delo de interpolação polinomial mais simples que aquele apresentado
neste capítulo. Os resultados preliminares são interessantes, podendo-se
economizar no número de avaliações da função objetivo.

Tal abordagem procura utilizar ao máximo os pontos em que já
se conhece a função objetivo. Não a apresentamos nesta dissertação
porque não nos parece claro como estendê-la ao caso com restrições
lineares, do qual trataremos no próximo capítulo.

2.4 SUMÁRIO

Neste capítulo introduzimos os métodos de otimização não-dife-
renciável. Trata-se de métodos de otimização que não necessitam de
informação sobre as derivadas da função objetivo. Assim, podem ser
usados em situações inacessíveis aos métodos clássicos de otimização,
baseados em derivadas. Podem ser usados, por exemplo, na otimização
de funções calculadas por simuladores ou por experimentos físicos.

Apresentamos dois métodos de otimização não-diferenciável: bus-
ca direta direcional e região de confiança não-diferenciável. O primeiro,
amostra a função objetivo um número finito de vezes por iteração e
utiliza tais valores para decidir sobre o andamento do algoritmo. Não
constrói qualquer modelo da função objetivo.

O método da região de confiança, ao contrário, primeiro amostra a
função objetivo a fim de construir um modelo que a aproxime localmente.
Este modelo é utilizado para decidir onde se buscará por descenso.

Como estes métodos não fazem uso da informação das derivadas,
é de se esperar que sua convergência não seja tão eficiente quanto a



2.4. Sumário 43

dos métodos que as utilizam. Portanto, se derivadas estão disponíveis,
é recomendado que se utilize um método que faça uso delas [16].





3 OTIMIZAÇÃO NÃO-DIFERENCIÁVEL COM
RESTRIÇÕES LINEARES

No capítulo anterior apresentamos algoritmos de otimização não-
diferenciável, porém não foram consideradas quaisquer restrições. Nes-
te capítulo estenderemos os métodos de otimização já tratados para
problemas sujeitos a restrições lineares nas variáveis, da forma seguinte:

min ? (?)
sujeito a ? ? ? = {? : ?? ? ?}.

Os métodos deste capítulo buscam por descenso apenas nos pon-
tos do conjunto viável. Assim, todos os iterandos são sucessivas aproxi-
mações para o ponto ótimo.

3.1 MATERIAL BÁSICO SOBRE OTIMIZAÇÃO RESTRITA

O conjunto viável ? contém os pontos que satisfazem às restrições
do problema.

Definimos o cone polar de um conjunto ? ? R?, denotado ? ?
como

? ? = {? : ?? ? ? 0, ?? ? ?};

como o nome sugere, o cone polar é um cone, e é convexo. Alguns
exemplos de cones polares estão na Figura 3.1.

Definimos o cone normal ao conjunto viável ? no ponto ? como
o conjunto

??(?) = {? ? R? : ?? (? ? ?) ? 0, ?? ? ?}

Figura 3.1: Conjuntos e seus polares. Para conjuntos cônicos convexos,
o cone polar do cone polar é o próprio conjunto (? = (? ?)?).

45



46 Capítulo 3. Otimização não-diferenciável com restrições lineares

?

?

??(?)

??(?)

?

?

??(?) ??(?)

Figura 3.2: Cone normal e cone tangente a ? em dois diferentes pontos
da fronteira do conjunto viável.

?

??? (?)

?

Figura 3.3: Ponto ? ? ? ótimo sob restrições: ??? (?) ???(?)

e o cone tangente a ? em ? como o polar do cone normal no mesmo
ponto, isto é,

??(?) = ??(?)? = {? | ?? ? ? 0, ?? ???(?)}.

Informalmente, o cone normal ??(?), contém as direções que
“apontam para fora” de ?. Enquanto o cone tangente ??(?) contém
vetores ?, em que, a partir de ?, se pode andar na direção ? alguma
distância sem sair de ?. Para um ponto interno a ?, ??(?) = R? e
??(?) = {0}. Uma ilustração se encontra na Figura 3.2.

Para definir ponto ótimo restrito, dizemos que ?* é ótimo de
primeira ordem sob restrições se, e somente se

??? (?*)? ? ? 0, ?? ???(?*). (3.1)

Uma ilustração de ponto ótimo restrito encontra-se na Figura 3.3.
Definimos a projeção de um vetor ? ? R? em um conjunto ?, e



3.2. Busca direta direcional com restrições lineares 47

? ?

?

??? (?)
?

Figura 3.4: O vetor ? que resolve a equação (3.3) na definição de ?(?, ?).

denotamos ?? [?] como o mínimo para o problema

min
???
?? ? ??2

A chamada decomposição de Moreau do ponto ? ? R? relativa a
? ? ? é dada por

? = ???(?) [?] + ???(?) [?] . (3.2)

Como no caso restrito não podemos usar, por exemplo, ????
para detectar um ponto estacionário, definimos a medida

?(?, ?) = | min
?+???
?????

?? ? ?|. (3.3)

Esta medida é ilustrada na Figura 3.4: ? é a direção mais próxima de
??? (?) que, a partir de ?, se pode percorrer a distância ? sem sair do
conjunto viável.

De acordo com [20], temos o seguinte teorema, que mostra que
? pode ser usada como medida de criticidade:

Teorema 7 Suponha que ? tem derivada segunda contínua e que o
conjunto viável ? é não-vazio, fechado e convexo. Então

?(?) = ?(?, 1), ? ? ? (3.4)

é contínua, não-negativa e ?(?) = 0 se, e somente se ? é ponto ótimo.

Isto é, ?(?) pode ser vista como uma indicação da criticidade
da função ? associada. Se ?(?) ? 0, consequentemente ??? (?)? ? ? 0
?? ? ?(?).

3.2 BUSCA DIRETA DIRECIONAL COM RESTRIÇÕES LINEARES

Uma ilustração das dificuldades introduzidas por restrições está
na Figura 3.5. Pelo Teorema 1, sabemos que ao considerar um conjunto



48 Capítulo 3. Otimização não-diferenciável com restrições lineares

?

??? (?)

?
(a)

?

??? (?)

?
(b)

Figura 3.5: Conjunto viável ? hachurado, abaixo da restrição (horizon-
tal); direções de descenso viáveis sombreadas. Em um primeiro caso, a
direção de busca próxima a ??? (?) não é viável. Usando-se direções
de busca paralelas às faces, é possível encontrar descenso viável.

de direções de busca gerador positivo, é possível garantir que há uma das
direções formando ângulo agudo com a direção de máximo descenso. No
entanto, pode ocorrer que justamente tal direção se torne inviável (Fig.
3.5), levando para fora do conjunto viável, não importa quão pequeno
seja o comprimento do passo. E no exemplo da figura, o iterando atual
?? não é ótimo restrito. Ao mesmo tempo, desejamos prosseguir com a
busca sempre dentro do conjunto viável, de modo que todos os iterandos
sejam sucessivas aproximações do ótimo do problema e a busca possa
ser interrompida quando se obtiver uma exatidão suficiente na resposta.
Dessa maneira, é necessário construir conjuntos de direções de busca
mais abrangentes para o caso restrito. Para o caso da figura, alterando-
se o conjunto das direções de busca de modo a incluir direções paralelas
às faces do conjunto ? já é possível encontrar descenso viável.

Ao utilizarmos a busca direta direcional, é necessário definir quais
as faces do conjunto viável que estão excessivamente próximas do ite-
rando ??. E proceder a busca paralelamente a elas, evitando-se pontos
inviáveis.

Considere que o conjunto viável é dado por restrições lineares,
da forma ? = {? : ?? ? ?}.

Cada restrição linear, respectivamente cada linha da matriz ?,
define uma face do conjunto viável, da forma{?

? : ??? ? = ??
}?

,



3.2. Busca direta direcional com restrições lineares 49

? ?1

? ?(?, ?1)

?(?, ?1)

? ?2

? ?(?, ?2)

?(?, ?2)

Figura 3.6: Os cones ?(?, ?) e seus polares. A partir de ?? é possível
andar ?? em qualquer direção de ? ?(??, ??).

em que ??? é a linha ? da matriz ? e ?? é a componente ? do vetor ?.
Além disso, ??? é o vetor ortogonal à respectiva face.

Para ? ? ?, definimos o conjunto das restrições ativas por

?(?) =
{?

? ?{1, . . . , ?} : ??? ? = ??
}?

e, dado ? &gt; 0, o conjunto das restrições ?-ativas por

?(?, ?) =
{?

? ?{1, . . . , ?} : ??? ? ? ?? ???
}?

.

Assim, ?(?, ?) contém justamente os índices das restrições que estão a
uma distância ? de serem violadas. Isto é, todos os ? tais que ? + ??? /? ?.

Definimos também o cone

?(?, ?) =

??
?? ? R? | ? = ??

???(?,?)
????, ?? &gt; 0

??
? .

Em termos gerais, trata-se do cone gerado pelas direções ?? que apontam
para fora do conjunto viável. O polar correspondente, ? ?(?, ?), aproxima
localmente a geometria do conjunto viável ?. Assim, é posssível partir
de ? e percorrer ao menos uma distância ? em qualquer direção de
? ?(?, ?), permanecendo-se em ?, conforme ilustrado na Figura 3.6 e
formalizado na proposição seguinte:

Proposição 1 Se ? ? ? e ? ? ? ?(?, ?), ???? ?, então ? + ? ? ?.

Dessa maneira, o tratamento de restrições que apresentaremos
utiliza conjuntos geradores positivos que satisfazem uma das seguintes
condições:



50 Capítulo 3. Otimização não-diferenciável com restrições lineares

Condição 1 Para ?? &gt; 0, ?? gera positivamente ? ?(??, ??).

Condição 2 ?? inclui geradores positivos para todos os cones ? ?(?, ?),
0 ? ? ? ?* para algum ?* &gt; 0 independente da iteração ?.

O teorema seguinte aponta uma maneira de se gerar as direções
de busca para satisfazer tais condições [21, 22].

Teorema 8 Suponha que um cone ?(?, ?0) ? R? é gerado positiva-
mente pelos vetores que compõem as colunas de uma matriz ? . Suponha
que tal matriz tem posto-coluna completo (os vetores são linearmente
independentes).

? Sejam ?1, . . . , ?? os vetores que geram positivamente o núcleo
(espaço-nulo) de ? ? .

? Sejam ?1, . . . , ?? os vetores das colunas da matriz ? (? ? ? )?1.

Então,

1. O conjunto de direções ? = {??}1???? ?{???}1???? satisfaz a
condição 1 (isto é, gera o cone polar ? ?(?, ?0)).

2. O conjunto de direções ? = {??}1???? ?{???, ??}1???? satisfaz
a condição 2, (gera o cone polar ? ?(?, ?) para todo 0 &amp;lt;? &amp;lt;?0).

Outra informação dada pelo teorema é a quantidade de direções
necessárias para conduzir a busca no R?. Note que o número ? das
colunas de ? (? ? ? )?1 é o posto de ? . Se ? tem posto completo (? =
?), o número de direções necessárias para atender à condição 2 é 2?.
Caso ? &amp;lt;?, o núcleo de ? ? tem dimensão ? ? ?, podendo ser gerado
positivamente por ? = ??? + 1 vetores. Nesse caso, o número de vetores
do conjunto ? das direções de busca é (? ? ? + 1) + ? + 2 &amp;lt;2?.

Lembrando que ?(?), definida conforme o Teorema 7, é uma
medida de estacionariedade, a seguinte proposição ilustra como um ?
suficientemente pequeno induz uma cota superior para essa medida.

Proposição 2 Considere ? &gt; 0. Existe ? &gt; 0 dependendo apenas de ?
e da matriz de restrições ?, tal que vale o seguinte: suponha que ? ? ?,
??? (?)? &amp;lt;? e ?(?) &gt; 0. Dado ? ? 0, seja ? o conjunto de geradores
de ? ?(?, ?). Então existe um número ?????? (?) &gt; 0, dependendo apenas
de ? tal que se ? &amp;lt;?, para algum vetor ? ??,

??????(?)?(?)??????? (?)? ?. (3.5)



3.2. Busca direta direcional com restrições lineares 51

? ?1

?

? ?(?, ?1)

?(?, ?1)

??? (?)

(a) ?1 não é pequeno o suficiente

? ?2
?

? ?(?, ?2)

?(?, ?2)
??? (?)

(b) ?2 adequado

Figura 3.7: Para se encontrar uma direção de descenso viável em
? ?(?, ?), ? precisa ser pequeno.

A condição ? &amp;lt;? do teorema é ilustrada com a Figura 3.7.
Para um valor ?1 muito grande, a direção de máximo descenso ??? (?)
não tem projeção em ? ?(?, ?1), enquanto para um ?2 suficientemente
pequeno, sim.

Isto é, ?????? tem um papel análogo ao feito pela medida cosseno
no caso irrestrito. De modo semelhante, também é necessário garantir
uma boa geometria das direções de busca. Para tanto, introduzimos a
seguinte condição

Condição 3 Existe um ?min &gt; 0 tal que para todo ? e todo conjunto
??, que gera o cone ? ?(??, ?), a relação (3.5) é satisfeita com

?????? &gt; ?min. (3.6)

De acordo com [13], tal condição só precisa ser levada em con-
sideração explicitamente quando ? ?(??, ?) contém um sub-espaço. Ao
mesmo tempo, conjuntos de direções dados pelo Teorema 8 ainda admi-
tem liberdade na escolha dos vetores que geram positivamente o núcleo
de ? ? .

Uma opção é partir de uma base ortogonal e completá-la com os
negativos de todas as suas direções, ou conforme a equação (2.4).

Alguns teoremas de [13] mostram a convergência do método
apresentado:

Teorema 9 Suponha que ?? é lipchitziana com constante ? . Suponha
que os iterandos {??} do Algoritmo 3.1 pertencem a um conjunto limi-
tado, e que ??? (?)?? ? em tal conjunto. Então, existem constantes ?



52 Capítulo 3. Otimização não-diferenciável com restrições lineares

e ? independentes da iteração ?, tais que

?(??) ? ?
[?
? ???max +

?(??)
???min

]?
se a condição 2 for utilizada e

?(??) ? ?
[?
? ???max +

?(??)
???min

+ ?
?

?min
??

]?
se a condição 1 for utilizada.

Concluímos os resultados de convergência do método com o teo-
rema de [13]:

Teorema 10 Se a condição 1 for utilizada,

lim inf
??+?

?(??) = 0,

se a condição 2 for utilizada,

lim
??+?

?(??) = 0.

3.2.1 Alternativas algorítmicas

Um algoritmo semelhante à busca direta direcional, com fortes
características de convergência e capaz de tratar restrições ainda mais
gerais, bastando que o conjunto seja conexo, está em [23]. É um algo-
ritmo capaz de tratar até mesmo restrições do tipo caixa-preta, isto é,
que não se conhece de antemão. Por outro lado, tal algoritmo não faz uso
das restrições conhecidas, como o que apresentamos nesta dissertação.



3.2. Busca direta direcional com restrições lineares 53

Algoritmo 3.1: Um algoritmo de busca direta direcional para
restrições lineares

Seja ? : R? ? R dada;
Seja ?0 ? ? um ponto inicial viável;
Seja ???? &gt; 0 a tolerância de convergência;
Seja ?0 &gt; ???? um tamanho de passo inicial;
Seja ?max ? 1 um limite superior para o coeficiente de expansão
??;
Seja ?max &amp;lt;1 um limite superior para o parâmetro de contração
??;
Sejam ?max ? ?min &gt; 0 limites superior e inferior,
respectivamente, para os comprimentos dos vetores de qualquer
conjunto gerador positivo;
Seja ?min &gt; 0 um limitante superior para a medida cosseno dos
conjuntos geradores positivos;
Seja ? : R+ ? R+ uma função não-decrescente satisfazendo a
equação (2.8);
Se for utilizada a condição 1, seja ?0 a tolerância inicial para as
restrições localmente ativas e 0 &amp;lt;?? &amp;lt;1 o fator de redução de ??;
Se for utilizada a condição 2, defina ? &gt; 0 para a tolerância das
restrições localmente ativas;
for ? = 1, 2, . . . do

Defina ?? conjunto gerador positivo satisfazendo a condição 3
e 2 ou 1 e ?min ????? ?max, ?? ???, com ? (??) ? ?min;
for ? ??? do

Defina ??(?) como o maior valor tal que
(?? + ??(?)?) ? ?;
Defina ??? = min(??, ??(?));
if Existe ? ??? tal que ? (?? + ????) &amp;lt;? (??) ? ?(??)
then

??+1 ? ?? + ????;
??+1 ? ????, em que 1 ? ?? ? ?max;

else
??+1 ? ??;
??+1 ? ????, 0 &amp;lt;?? ? ?max;
Se está sendo usada a condição 1, ??+1 ? ????;
if ??+1 &amp;lt;???? then

Encerrar;



54 Capítulo 3. Otimização não-diferenciável com restrições lineares

3.3 MÉTODOS DE REGIÃO DE CONFIANÇA COM RESTRIÇÕES LI-
NEARES

Métodos de região de confiança podem ser estendidos a problemas
com restrições lineares de forma mais intuitiva que os de busca direta
direcional. Em princípio, pode-se pensar em restringir os algoritmos
apresentados ao conjunto viável. No entanto, se ? for amostrada somente
em pontos viáveis, pode não ser possível obter bons modelos (isto é,
modelos ?-posicionados), que são essenciais nas provas de convergência
daqueles algoritmos.

Nesta seção mostraremos que, com pequenas alterações, o Algo-
ritmo 2.5 já apresentado funciona para o caso com restrições lineares
nas variáveis. Utilizaremos a abordagem que [20] apresenta ao abordar
o caso diferenciável com restrições convexas.

Idealmente, a função objetivo seria avaliada apenas em pontos
viáveis, candidatos à solução do problema. Mas o formato do conjunto
viável ? pode não permitir que se consiga um modelo de interpolação
adequado. Para manter um modelo ?-posicionado não faremos tal res-
trição. Os pontos usados na construção do modelo na região ?(??, ??)
serão tomados sem levar em consideração se são viáveis ou não.

Para tanto, propomos utilizar os Algoritmos 2.2 e 2.3 sem qual-
quer alteração. Resta comentar sobre o cálculo do passo.

3.3.1 Passo generalizado de Cauchy

Como no capítulo anterior, a cada iteração precisamos encontrar
um ponto candidato à solução que satisfaça uma condição mínima de
descenso para o modelo.

Como no caso irrestrito, se o modelo usado for linear, em uma
bola na norma ? · ??, o acréscimo de (outras) restrições lineares não
introduz maiores dificuldades. Ainda é possível chegar ao ótimo global
utilizando programação linear. No entanto, para modelos quadráticos,
encontrar o ótimo global pode ser um problema NP-difícil se o problema
for não-convexo. Nesta seção introduziremos o passo generalizado de
Cauchy conforme [20], que define um descenso suficiente para garantir a
convergência do algoritmo e pode ser encontrado em todas as iterações.

Como no caso anterior, o passo de Cauchy envolve a busca por
descenso utilizando a parte linear do modelo, isto é, a direção ??, par-
tindo do ponto ??, mas agora sujeito a ?? + ? ? ?.

Para tanto, defina o caminho do gradiente projetado (projected
gradient path de [20]) como

?(?, ?) = ?? [? ? ??? (?)] , ? ? 0.



3.3. Região de confiança 55

Isto é, a projeção em ? de um ponto da reta que passa por ? e tem
direção ??? (?). Uma generalização do passo de Cauchy é encontrar o
mínimo do modelo sobre o caminho do gradiente projetado.

3.3.2 Algoritmo de região de confiança com restrições lineares

Agora estamos em condições de definir o método de região de
confiança para o caso com restrições lineares (Algoritmo 3.2). Difere,
com relação ao anterior, apenas no fato de manter todos os seus ite-
randos (isto é, os pontos ?? onde são centradas as regiões), viáveis. A
construção e manutenção de modelos é feita da mesma forma.

Parte-se de um ponto viável ?0 ? ?. E para o cálculo do passo
?+? = ?? + ??, se busca por descenso para ?? em ?(??, ??) ? ?, de
forma a não sair do conjunto viável.



56 Capítulo 3. Otimização não-diferenciável com restrições lineares

Algoritmo 3.2: Um método de região de confiança
Seja ? : R? ? R dada;
Seja ?0 ? R? um ponto inicial;
Seja ?0 : R? ? R? um modelo inicial;
Seja ?(?0, ?0) a região de confiança inicial;
Defina 0 ? ?0 ? ?1 &amp;lt;1 e ?1 ?= 0;
Defina os fatores de redução e aumento da região de confiança
0 &amp;lt;? &amp;lt;1 &amp;lt;????;
Defina o raio máximo ?? da região de confiança;
for ? = 0, 1, . . . do

Construa o modelo ??(??) que interpola ? em ??. Calcule o
gradiente ?? = ???(??);
if ????? ?? e ?? não é ?-posicionado em ?(??, ?????) then

Refine o modelo até que ?? seja ?-posicionado em
?(??, ??), ?? ? (0, ?????).

Calcule o ponto ?+? = ?? + ?? que garanta descenso para o
modelo ?? em ?? ?;
Calcule o grau de concordância entre a predição de ??(?+? ) e
o valor de ? (?+? ):

?? =
? (??) ? ? (?+? )

??(??) ? ??(?+? )
; (3.7)

Atualize o iterando:

??+1 =
{?

?+? se ?? ? ?1 ou ?? ? ?0 e ?? ?-posicionado
?? caso contrário

Atualize o tamanho da região de confiança:

??+1 =

??
?

min(??????, ?max), se ?? ? ?1
???, se ?? &amp;lt;?1 e ?? é ?-posicionado
??, se ?? &amp;lt;?1 e ?? não é ?-posicionado

Atualize o modelo ??+1;



3.4. Sumário 57

3.3.3 Alternativas algorítmicas

Em [18], é apresentado um algoritmo eficiente para o caso de
limites superiores e inferiores nas variáveis, estendendo o apresentado em
[17]. Quando uma variável chega a um limite, ela é fixada e o problema
segue, otimizando-se apenas as variáveis restantes. Dessa maneira, os
modelos são construídos apenas com variáveis irrestritas, evitando o
problema descrito no parágrafo acima. Uma grande vantagem dessa
abordagem é que os modelos ficam mais simples conforme as variáveis
chegam aos seus limites, diminuindo o esforço de manutenção do modelo.
O algoritmo procura economizar nos passos de melhora de modelo e
nas avaliações da função objetivo ? .

Por outro lado, tal algoritmo não é extensível para outras res-
trições além de limites superiores e inferiores. A autora avalia a pos-
sibilidade de tratar demais restrições usando métodos como SQP e la-
grangiano aumentado. A abordagem apresentada neste capítulo, trata
diretamente problemas que não são resolvidos por [18]. Ao custo de
um maior esforço na manutenção dos modelos e provável maior nú-
mero de avaliações da função objetivo ? , por incluir pontos inviáveis na
construção do modelo ?.

3.4 SUMÁRIO

Neste capítulo apresentamos alguns conceitos de otimização res-
trita e estendemos os algoritmos de busca direta direcional e de região
de confiança. Em ambos os casos, os algoritmos buscam por descenso
sem deixar o conjunto viável.

A busca direta direcional pode ser estendida ao caso com restri-
ções lineares por meio de conjuntos de direções de busca que reprodu-
zam, de certa maneira, a geometria local do conjunto viável, possibili-
tando a busca por descenso em direções viáveis.

A extensão do algoritmo de região de confiança é mais simples.
Basta resolver o sub-problema da região de confiança respeitando tam-
bém as restrições lineares. É importante lembrar, porém, que para a
construção do modelo pode ser necessário incluir-se também pontos
inviáveis.

O próximo capítulo apresenta um algoritmo de Lagrangiano au-
mentado para a resolução de problemas também com restrições não-
lineares. Tal abordagem acaba gerando sub-problemas com restrições
lineares, que podem ser resolvidos com os algoritmos do presente capí-
tulo.





4 OTIMIZAÇÃO NÃO-DIFERENCIÁVEL COM
RESTRIÇÕES NÃO-LINEARES

Nos capítulos anteriores apresentamos algoritmos capazes de re-
solver o problema de otimização com restrições lineares. Na produção
de petróleo, no entanto, se forem considerados itens como limites da
produção de gás ou de algum contaminante, os problemas resultantes
terão restrições não-lineares. Assim, não podem ser resolvidos com os
métodos vistos. A abordagem utilizada neste trabalho para resolver tais
problemas foi a de usar um método de Lagrangiano aumentado.

É um método que consiste em substituir as restrições do problema
de otimização por uma sequência de sub-problemas de otimização. Estes
são irrestritos, ou com restrições mais simples. As restrições não-lineares
originais são substituídas por termos de penalização na função objetivo.
Assim, os métodos dos capítulos anteriores podem ser empregados na
resolução dos sub-problemas.

4.1 LAGRANGIANO AUMENTADO

A fim de resolver o problema na função objetivo ? : R? ? R,
com restrições não-lineares ? : R? ? R?:

min ? (?)
sujeito a ?(?) = 0.

O método consiste em resolver uma sequência de sub-problemas,
derivados deste, porém com as restrições de igualdade ? transformadas
em penalizações, incluídas na função objetivo, em vez de serem tratadas
explicitamente. Ao contrário do capítulo anterior, admitimos que a
busca ocorra também por pontos inviáveis.

Para tanto, introduzimos a função Lagrangiano aumentado asso-
ciada a ? , dada por

?(?, ?, c) = ? (?) +
???

?=1
????(?) +

1
2

???
?=1

c?2?(?)

= ? (?) + ?? ?(?) +
c
2
??(?)?2.

Para pontos viáveis (? ? ?), ?(?) = 0 e ?(?, ?, c) = ? (?). O
parâmetro de penalização c determina o quanto as violações das res-
trições ? são penalizadas, enquanto ? consiste de estimativas para os
multiplicadores de Lagrange do problema original.

59



60 Capítulo 4. Otimização não-diferenciável com restrições não-lineares

Os problemas a serem resolvidos, então, são dados por

min
??R?

?(?, ?, c)

Quanto maior o valor de c, maior a penalização imposta aos
pontos inviáveis ? /? ?. Assim, se c for alto, a minimização de ?(?, ?, c)
tenderá a produzir pontos onde ?(?) ? 0. Nesse caso, ?(?, ?, c) ? ? (?),
já que o ponto ? quase é viável, assim a minimização de ?(?, ?, c)
aproxima a de ? (?). [24].

Se ? é uma boa estimativa para os multiplicadores de Lagrange
exatos ?* (correspondentes ao ponto ótimo ?*), a minimização de
?(?, ?, c) provê um ponto ? próximo de ?*, contanto que c seja su-
ficientemente alto para que se possa realizar tal minimização [24].

4.1.1 Lagrangiano aumentado com resolução aproximada dos sub-
problemas

Porém, não é necessário encontrar com exatidão o ponto ótimo
em cada um dos sub-problemas. Estamos particularmente interessados
em métodos iterativos nos quais, em vez de buscar por um ponto ??
em que

????(?, ?, c)? = 0,
o usual é que o método pare quando satisfeito um critério da forma

????(?, ?, c)?? ??,

isto é, com a norma do gradiente (ou critério semelhante) baixa, ainda
que não-nula.

A convergência de um algoritmo feito pela resolução de tais sub-
problemas é esclarecida, em parte, com a seguinte proposição, de [24]:

Proposição 3 Sejam ? e ? continuamente diferenciáveis. Para a ite-
ração ? = 0, 1, . . ., considere que ?? satisfaz

???(??, ??, c ?)?? ??,

em que a sequência {??} é limitada, bem como {??} e {c ?} satisfazem

0 &amp;lt;c ? &amp;lt;c ?+1, ??, c ? ??,

0 ? ??, ??, ?? ? 0



4.1. Lagrangiano aumentado 61

Considere que a subsequência {??}? converge para um vetor ?*
tal que ??(?*) tem posto ?. Então

{?? + c ??(??)}? ? ?*,

em que ?* satisfaz, juntamente com ?*, as condições de otimalidade de
primeira ordem para o problema original (com restrição de igualdade):

?? (?*) + ??(?*)?* = 0, ?(?*) = 0.

As hipóteses da proposição podem não ser satisfeitas, como comentários
a seguir [24].

Em primeiro lugar, pode não ser possível encontrar um {??}
satisfazendo ???(??, ??, c ?)?? ??. A causa disso, normalmente, é que
o Lagrangiano aumentado ?(·, ??, c ?) não é limitado inferiormente.

Uma segunda possibilidade é que, ou a sequência {??} não con-
verge, ou converge para um ponto ?* em que ??(?*) tenha colunas
linearmente dependentes. Isto normalmente ocorre quando o Lagrangi-
ano aumentado é limitado inferiormente, porém o problema original não
tem uma solução viável. Neste caso, quando se aumenta a penalização
c, o termo quadrático c2??(?)?

2 domina e a solução do sub-problema é
justamente um ponto estacionário desta função, de modo que

c
2
???(?*)?2 = 0.

Um terceiro caso, que raramente ocorre na prática, é que {??}
converge para um ponto {?*} ao qual não há multiplicadores de La-
grange associados. Neste caso, a sequência {?? + c ??(??)} também
diverge.

Apontados esses casos, patológicos, [24] comenta que o normal
é que o algoritmo chegue a um par (?*, ?*) satisfazendo as condições
de otimalidade. Ainda, a grande experiência prática consolida que o
método, de modo geral, é confiável e normalmente converge para um
ponto que é, pelo menos, mínimo local do problema original. As falhas,
usualmente se devem ao fato de que minimizar ?(·, ??, c ?) torna-se mais
difícil conforme c ? ??.

Existe, ainda, outro motivo que torna ineficiente a busca pela
solução exata dos sub-problemas: os multiplicadores de Lagrange não
são exatos. A solução do problema interno pode se afastar da solução do
problema original justamente por isso. Assim, alguns métodos chegam a
iterar de maneira ainda mais intensa entre a resolução de sub-problemas
e a atualização dos multiplicadores de Lagrange [24].



62 Capítulo 4. Otimização não-diferenciável com restrições não-lineares

4.1.2 Lagrangiano aumentado com restrições de desigualdade

Tendo apresentado o caso do método do Lagrangiano sujeito a
restrições de igualdade, seguimos com o problema com desigualdades

min ?
sujeito a ?(?) = 0

?(?) ? 0.

em que ? : R? ? R? , e como antes, ? : R? ? R, ? : R? ? R?.
Este pode ser facilmente colocado na forma anterior, introduzin-

do-se as variáveis de folga ?1, . . . , ?? [25]:

min ? (?)
sujeito a ?(?) = 0

?(?) + ?2 = 0,

em que ?2 representa o vetor (?21 , . . . , ?2? ).
Então, podemos usar o mesmo método, usando nos sub-problemas

a função Lagrangiano aumentado, a seguir reescrita com as variáveis
adicionais:

?(?, ?, ?, ?, c) = ? (?) + ?? ?(?) + c
2
??(?)?2+

???
?=1

{?
??(??(?) + ?2? ) +

c
2
|??(?) + ?2? |2

}?
,

em que ??(?) é a componente ? de ?(?). Os sub-problemas consistem
em

min
?,?

?(?, ?, ?, ?, c). (4.1)

A fim de encontrar ? e ? que resolvam (4.1), é possível, para cada
?, minimizar em ? o Lagrangiano aumentado ?(?, ·, ?, ?, c). Para tanto,
basta minimizar cada termo dependente de ?, problema este reescrito
na variável ?? = ?2? :

min
???0
{??[??(?) + ??] +

1
2

c|??(?) + ??|2}. (4.2)

Nos pontos de mínimo irrestrito ?? de cada uma destas funções, a
derivada vale zero:

?? + c[??(?) + ????] = 0,



4.1. Lagrangiano aumentado 63

consequentemente,
???? = ?[(??/c) + ??(?)].

Se, por outro lado, este valor ???? for negativo, o mínimo restrito de (4.2)
é ?*? = 0 (A expressão de (4.2) é convexa em ??).

Então:
?*? = max{0,?[(??/c) + ??(?)]},

e
??(?) + ?*? = max{??(?),?(??/c)}.

Assim, denotando

?+(?, ?, c) =

?
?? max{?1(?),?(?1/?)}...

max{?? (?),?(?? /?)}

?
?? ,

a função Lagrangiano aumentado, já minimizada em ? é:

min
?
?(?, ?, ?, ?, c) = ? (?) + ?? ?(?) + 1

2
c??(?)?2+

+ ?? ?+(?, ?, c) +
1
2

c??+(?, ?, c)?2.

Isto motiva a definição do Lagrangiano aumentado para proble-
mas com restrições de desigualdades

?(?, ?, ?, c) = ? (?) + ?? ?(?) + ?? ?+(?, ?, c)+

+
1
2

c{??(?)?2 + ??+(?, ?, c)?2} (4.3)

que pode ser reescrito [25] como:

?(?, ?, ?, c) = ? (?) + ?? ?(?) + 1
2

c??(?)?2+

+
1
2c

???
?=1

{?
max[0, ?? + c??(?)]2 ? ?2?

}?
. (4.4)

A equivalência entre (4.3) e (4.4) pode ser verificada coordenada por
coordenada. Note que se ??(?) ??(??/c), então ?+? (?, ?, c) = ??(?), mas
por outro lado,

1
2?
{?

max[0, ?? + c??(?)]2 ? ?2?
}?

= ????(?) +
1
2

???(?)2

= ???+? (?, ?, c) +
1
2

??+? (?, ?, c)
2.



64 Capítulo 4. Otimização não-diferenciável com restrições não-lineares

Caso contrário, ??(?) ??(??/c), então ?+? (?, ?, c) = ?(??/c), enquanto
1
2?
{?

max[0, ?? + c??(?)]2 ? ?2?
}?

=
1
2c

(??2? )

= ??
(?
???

c

)?
+

1
2

c
(???

c

)?2
= ???+? (?, ?, c) +

1
2

c?+? (?, ?, c)
2.

Então, os sub-problemas devem ser resolvidos utilizando o La-
grangiano aumentado dado por (4.3) ou (4.4), sem a necessidade de
usar nenhuma das variáveis adicionais ??. O problema continua com ?
variáveis.

No Apêndice A mostramos ainda, que se as funções ? , ? e ? são
continuamente diferenciáveis, então o Lagrangiano (4.4) também o é.

A atualização dos multiplicadores de Lagrange pode ser feita de
forma semelhante ao caso irrestrito. Considerando que a minimização
de ?(·, ??, ??, c) resulta em um ponto ??,

??+1 =?? + c ??(??) (4.5a)
??+1 =?? + c ??+(??, ??, ??). (4.5b)

Ainda, (4.5b) pode ser reescrito, coordenada por coordenada:

??+1? = max{0, ?
?
? + c

???(?)}. (4.6)

4.1.3 Eliminação parcial das restrições

Nos casos anteriores, todas as restrições eram transformadas em
penalizações da função objetivo, e os sub-problemas consistiam em um
problema de minimização irrestrita do Lagrangiano aumentado. Porém,
não é necessário fazer esta substituição em todas as restrições. É pos-
sível incluir no Lagrangiano aumentado apenas algumas, mantendo as
restantes nos sub-problemas, que então as tratam de maneira explícita.

Em problemas com restrições lineares e não-lineares, é possível
por exemplo, incluir as não-lineares como penalizações, mas seguir tra-
tando as lineares explicitamente. Isto permitirá utilizar os métodos do
capítulo anterior na resolução dos sub-problemas.

Para o problema

min ? (?)
sujeito a ?(?) = 0

?(?) ? 0,



4.2. Um algoritmo de Lagrangiano aumentado 65

se incluirmos no Lagrangiano aumentado apenas as restrições referentes
à igualdade ?(?) = 0, chegamos ao sub-problema seguinte:

min
??R?

?(?, ?, c) = ? (?) + ?? ?(?) + c
2
??(?)?2

sujeito a ?(?) ? 0.

Isto não interfere na estratégia de atualização dos multiplicadores de
Lagrange, que pode ser mantida a mesma.

De modo geral, as restrições não incluídas no Lagrangiano aumen-
tado são mantidas nos sub-problemas. Não há necessidade de manter as
restrições de desigualdades, incluindo no Lagrangiano as de igualdade.
Qualquer mistura das duas pode ser penalizada ou mantida [24].

Neste trabalho, é de interesse o caso em que as restrições mantidas
são dadas por inequações lineares, da forma ?? ? ? = ?(?) ? 0.

4.2 UM ALGORITMO DE LAGRANGIANO AUMENTADO

Havendo exposto a teoria sobre o método de lagrangiano aumen-
tado, apresentaremos a seguir um algoritmo completo (Algoritmo 4.1),
baseado em [26].

O problema que queremos resolver contém restrições não-linea-
res (a serem incluídas no Lagrangiano aumentado) e restrições lineares
(mantidas explicitamente). O problema é dado por:

min ?
sujeito a ?(?) ? 0

?? ? ?.

em que ? : R? ? R, ? : R? ? R?, ? ? R?×?, ? ? R?.
Este algoritmo permite utilizar mais de um parâmetro de pe-

nalização c, permitindo que diferentes restrições tenham penalizações
distintas. Para tanto, as ? restrições não-lineares são divididas em ?
grupos, denotados ?? , possivelmente segundo o tipo de não-linearidade.
A cada grupo ?? , é associada a penalização c? .

A função Lagrangiano aumentado correspondente é semelhante
à (4.4), com as restrições divididas nos grupos ?, cada um com um
parâmetro de penalização próprio:

?(?, ?, c) =? (?) +
???

?=1

1
2c?

??
????

(?{?
max[0, ?? + c? ??(?)]2 ? ?2?

}?)?
.



66 Capítulo 4. Otimização não-diferenciável com restrições não-lineares

O sub-problema a ser resolvido envolve as restrições lineares, que
não foram incluídas no Lagrangiano aumentado:

min
??R?

?(?, ?, c) (4.7a)

sujeito a ?? ? ?. (4.7b)

A cada iteração ?, o iterando ?? é calculado, resolvendo-se o
sub-problema aproximadamente, utilizando-se como critério de parada
a norma da projeção do gradiente da função no cone tangente ao espaço
viável

????(?,?? ) [???(?, ?, c)]?? ??, (4.8)

em que ?? determina a exatidão com que se resolve o problema.
Os multiplicadores de Lagrange e os parâmetros de penalização

são atualizados de forma alternada. Caso as restrições incluídas no
Lagrangiano aumentado estejam suficientemente satisfeitas, isto é

?max{?(?)[?? ], 0}?? ??, (4.9)

em que ?? &gt; 0 e o sub-índice [?? ] denota uma partição do vetor associ-
ada ao grupo de restrições [?? ], o parâmetro de penalização do grupo
correspondente é mantido o mesmo,

c ?+1? = c
?
? ,

e os multiplicadores de Lagrange são atualizados, de forma semelhante
à (4.6):

??+1[?? ] = max{0, ?
?
[?? ] + c

?
? ?[?? ](?

?)}, ? = 1, . . . , ?.

Caso as restrições não sejam satisfeitas conforme (4.9), os multi-
plicadores de Lagrange são mantidos

??+1[?? ] = ?
?
[?? ]

e os parâmetros de penalização correspondentes são atualizados con-
forme a fórmula

c ?+1? = ?
?
? c

?
?

em que

? ?? =
{?

? se c ?? = ??
max(?, ??) caso contrário



4.2. Um algoritmo de Lagrangiano aumentado 67

e ?? é o menor dos parâmetros de penalização ao início da iteração:

?? = min(c ?1 , . . . , c
?
? ).

Dessa maneira, caso os sub-problemas não cheguem a satisfazer suficien-
temente as restrições, os parâmetros de penalização c correspondentes
são progressivamente aumentados. No limite, c ? ?, que é uma das
formas de garantir a convergência do método.

Ainda, resta garantir que os ?? e ?? convirjam para zero, de modo
que, no limite, as restrições sejam satisfeitas e o ponto encontrado seja
ótimo para a função original ? .



68 Capítulo 4. Otimização não-diferenciável com restrições não-lineares

Algoritmo 4.1: Método de Lagrangiano Aumentado, baseado
em [26]

Inicialização: defina as constantes positivas: ?* ? 1, ?* ? 1,
? &gt; 1, ?? &amp;lt;1 e ?? &amp;lt;1. Seja ? = 0, ?0 = min?=1,...,? c 0? , ?0 = ?0,
?0 = (??)?? ;
for k = 1, 2, . . . do

Resolva o sub-problema (4.7) de modo a encontrar um ponto
?? satisfazendo

????(?,?? ) [???(?, ?, c)]?? ??

Caso ????(?,?? ) [???(?, ?, c)]?? ?*| e
?max{?(?)[?? ], 0}?? ?*, encerre.
for ? = 1, . . . , ? do

if ?max{?(?)[?? ], 0}?? ?? then
Atualize os multiplicadores de Lagrange

c ?+1? = c
?
? ,

??+1[?? ] = max{0, ?
?
[?? ] + c

?
? ?[?? ](?

?)}, ? = 1, . . . , ?.

else
Aumente as penalizações

??+1[?? ] = ?
?
[?? ]

c ?+1? = ?
?
? c

?
?

??+1 = min
?=1,...,?

c ?+1?

if ??+1 &gt; ?? then

??+1 =
1

??+1
,

??+1 =
1

(??+1)??
.

else

??+1 = ??
1

??+1
,

??+1 = ??
1

(??+1)??
.



4.3. Resolvendo os sub-problemas com busca direta direcional 69

4.3 RESOLVENDO OS SUB-PROBLEMAS COM BUSCA DIRETA DI-
RECIONAL

O algoritmo apresentado na seção anterior é bastante prático, no
sentido de exigir, na resolução dos sub-problemas, critérios de parada
que são usuais em algoritmos de otimização. Isto permitiu a [27] adaptá-
lo para utilizar a busca direta direcional na resolução dos sub-problemas.

Em primeiro lugar, é necessário resolver os sub-problemas com a
exatidão desejada. Um resultado análogo ao Teorema 9 fornece uma cota
superior para ????(?? ,?? )

[?
??? (??)

]?
? em função do tamanho do passo

??. Dessa maneira, como critério de parada para os sub-problemas,
podemos utilizar

?? ? ??

em que ?? faz o papel de ??.
O mesmo pode ser feito com o critério de parada do algoritmo

de Lagrangiano aumentado que passa a ser:

?? ? ?* e ?max(?(?), 0)?? ?*.

Resta definir a forma de atualizar as tolerâncias ?? dos sub-pro-
blemas que seja equivalente à do algoritmo da seção anterior.

Para tanto, considere ???? ? 1, e defina a função

?(?, c) = max
{?

1,
(?

1 + ??? +
???

?=1
c?

)?
/????

}?
.

Em que ?max limita superiormente os comprimentos das direções
de busca ???? ? ?max. Considere que a tolerância ?0 utilizada para
a detecção de restrições quase-ativas, e consequentemente ?(?, ?) e
? ?(?, ?), é dada por ?0 = min{?max, ?max?}.

Então a tolerância para os sub-problemas é atualizada conforme
a regra [27]:

??+1 = ??+1/(?max?(??+1, c ?+1)).

4.4 RESOLVENDO OS SUB-PROBLEMAS COM REGIÃO DE CONFI-
ANÇA NÃO-DIFERENCIÁVEL

Para o uso do algoritmo de Lagrangiano aumentado proposto, o
Algoritmo 3.2, de região de confiança com restrições lineares pode ser
utilizado sem grandes alterações.

O critério de parada usual do algoritmo é o raio da região de
confiança, mas vamos propor uma alternativa próxima ao proposto na



70 Capítulo 4. Otimização não-diferenciável com restrições não-lineares

seção 4.2. Considere ???? ? ??. Vamos mostrar que, sob certas condições,
podemos considerar um critério de parada baseado no modelo ?:

????(?,?? ) [???(?)]?? ????.
Resta mostrar que este novo critério provê a exatidão necessária

para a convergência do algoritmo. Se o modelo for ?-posicionado, de
(2.16), temos:

??? ?? ????(?, ?, c) ???(?)?? (4.10)
?????(?,?? ) [??(?, ?, c)] ? ???(?,?? ) [??(?)]?? (4.11)
?????(?,?? ) [??(?, ?, c)]??????(?,?? ) [??(?)]?? (4.12)
?????(?,?? ) [??(?, ?, c)]?? ?? (4.13)

em que utilizamos o fato de que projeções em conjuntos convexos en-
curtam distâncias [28] e uma desigualdade triangular. Então, o modelo
? pode ser utilizado no critério de parada, já que:

????(?,?? ) [??(?, ?, c)]?? ???? + ??? ??.

Então, se for escolhido ???? de modo que

?? ? ???? + ??? ?? (4.14)
a cota 4.8 é satisfeita. O valor de ? pode não ser conhecido, mas é finito.
Já o valor de ??? depende do condicionamento da função ?(·, ?, c), que
depende da penalização c. Se os multiplicadores ? estiverem convergindo
para seus valores corretos, os parâmetros de penalização c permanecerão
limitados. Nesse caso, com um ? suficientemente pequeno (ou decres-
cente, a fim de que ??? ?? ? 0) este critério de parada alternativo é
válido.

Caso isto não ocorra, e c crescer indefinidamente, este critério
não pode ser usado. Nesta situação, porém, a dificuldade está em fazer
que os modelos ? sejam boas aproximações da função Lagrangiano
aumentado ?(·, ?, c). Então, o algoritmo todo terá dificuldade em con-
vergir e mesmo o critério de parada usual (baseado apenas no raio da
região) pode apresentar problemas.

4.5 SUMÁRIO

Neste capítulo apresentamos o método do Lagrangiano aumen-
tado para a resolução de problemas de otimização com restrições não-
lineares. O método substitui restrições do problema original em penali-
zações para a função objetivo.



4.5. Sumário 71

A função lagrangiano aumentado inclui penalizações para as vio-
lações de restrições e estimativas para os multiplicadores de Lagrange
do problema original. O método consiste em resolver uma sequência de
subproblemas de otimização do Lagrangiano aumentado, atualizando-
se as estimativas dos multiplicadores de Lagrange e, eventualmente
aumentando as penalizações associadas às restrições.

O método, inicialmente para tratar problemas com restrições de
igualdades, já foi estendido para o tratamento de desigualdades, neste
capítulo apresentamos o caso unilateral, mas também é possível tratar
desigualdades como ? ? ?? ? ? sem a necessidade de introdução de
mais multiplicadores.

Por fim, apresentamos um algoritmo desta classe em que as restri-
ções lineares não são incluídas como penalizações, podendo ser tratadas
explicitamente na otimização do Lagrangiano aumentado. Mostramos
como os sub-problemas podem ser resolvidos utilizando os algoritmos
não-diferenciáveis do capítulo anterior.





5 ANÁLISE COMPUTACIONAL

Neste capítulo fazemos uma análise do desempenho dos algorit-
mos de busca direta direcional e região de confiança não-diferenciável
para a resolução de problemas com restrições lineares nas variáveis. Es-
pecificamente, problemas envolvendo a alocação de gás, sujeitos a uma
disponibilidade limitada de gás para gas-lift.

Primeiramente, apresentamos um conjunto de problemas que foi
resolvido empregando-se os dois métodos, com os dados de [29]. Em
seguida, apresentamos a resolução de um problema em que o método de
região de confiança empregou diretamente o simulador para a avaliação
da função objetivo.

5.1 OTIMIZAÇÃO DE FUNÇÃO SUAVE

O problema resolvido na presente seção consiste em alocar gás
de gas-lift para um conjunto de poços, com restrições lineares

max ? (?inj)
sujeito a ??inj ? ?

em que ?inj = (?1inj, . . . , ??inj) é o vetor de vazões alocadas de gás de
elevação,

? =

?
? ?????

e1×?

?
?

? = (?1, . . . , ?? ,??1, . . . ,??? , ?max), ?? é a matriz identidade de ordem
? , e ?1×? é um vetor linha com todos os elementos iguais a 1. Os valores
das restrições foram ?1 = · · · = ?? = 4000 Mscf/d e ?1 = · · · = ?? =
80 Mscf/d. Foram resolvidos 10 casos diferentes do problema, com a
disponibilidade total de gás do campo variada logaritmicamente de um
valor muito restrito ?max = 2.800 Mscf/d, até ?max = 28.000 Mscf/d,
em que o ótimo irrestrito se torna viável. Desta maneira obtivemos dez
diferentes versões do problema. Ainda, para cada versão, resolvemos o
problema partindo de 10 diferentes pontos iniciais.

A função ? , como já apresentado, é da forma

? =
???

?=1

(?
???

?
? (?

?
inj) + ?? ?

?
? (?

?
inj) ? ?????(??inj)

)?
?

???
?=1

?inj?
?
inj

neste caso, porém, utilizamos a aproximação de [14] para modelar a
produção total de cada poço:

??? (?
?
inj) = ?

?
1 + ?

?
2 ?

?
inj + ?

?
3 (?

?
inj)

2 + ??4 ln(?
?
inj + 1).

73



74 Capítulo 5. Análise computacional

Os parâmetros ?1, . . . , ?4, foram identificados de um problema [3], adap-
tado em [2], utilizando mínimos quadrados lineares, e estão listados na
Tabela 5.1. Os valores das vazões de óleo ??? , gás ??? e água ??? produ-
zidas foram calulados, para cada poço, utilizando os valores de GOR
(relação gás-óleo) e Water cut (proporção de água na fase líquida) fixos,
conforme a Tabela 5.2.

Para cada um dos cenários propostos, a disponibilidade total
de gás para gas-lift e o valor ótimo da função objetivo são dados na
Tabela 5.3. O ponto ótimo foi calculado numericamente, utilizando-se
um algoritmo baseado em derivadas.

Desta maneira, podemos testar o desempenho dos algoritmos para
funções suaves (em que há garantia teórica de convergência) mantendo
a estrutura do problema de interesse.

5.1.1 Busca direta direcional

No algoritmo de busca direta direcional, na iteração ?, o conjunto
de direções de busca ?? gera ? ?(?, ?) para 0 &amp;lt;? &amp;lt;??, com ?0 = 0,5.
Para tanto, utilizamos o procedimento do Teorema 8, colocando os
geradores dos cones ?(?, ?) como as colunas de uma matriz ? . Para o
cálculo dos vetores ?? mencionados no Teorema utilizamos uma base
ortogonal que gera o espaço nulo de ? ? por combinações lineares e
a completamos com os negativos de todas as direções, como em (2.5),
de modo a ter uma base positiva. A estes vetores acrescentamos os
??, colunas de ? (? ? ? )?1, com seus negativos ???, de modo a ter um
conjunto ?? satisfazendo a Condição 2 (p. 50).

Como função forçante, que determina o descenso mínimo para a
aceitação do passo, foi utilizada ?(?) = 14 ?

2. O parâmetro de controle
do tamanho do passo foi iniciado em ?0 = 1. O critério de parada da
busca direta direcional é dado pelo tamanho deste parâmetro, enquanto
que o critério usado pelo método de região de confiança sem derivadas é
o raio da região. Para obtermos critérios de parada equivalentes, ambos
os métodos foram aplicados ao problema com um critério de parada
exigente, de modo a satisfazer com folga à exatidão desejada, de erro
menor que 1 em cada coordenada. A partir daí, foram derivados os
critérios de parada de um e de outro algoritmo. Para o de busca direta
direcional,

?? &amp;lt;???? = 0,0038.
Na Tabela 5.4 apresentamos um sumário das resoluções dos pro-

blemas, considerando, para cada cenário, as médias dos tempos e dos
números de avaliações das funções objetivos. Na segunda parte da ta-
bela, tendo em vista que o valor ótimo ?*inj é conhecido (Tabela 5.3),



5.1. Otimização de função suave 75

Tabela 5.1: Parâmetros do problema resolvido. ??? (??inj) = ??1 + ??2 ??inj +
??3 (??inj)2 + ??4 log(??inj + 1).

Poço ?1 ?2 ?3 ?4
1 ?1081 ?0,2559 1,400 × 10?5 398,6
2 ?1132 ?0,2092 ?8,202 × 10?6 471,5
3 ?1357 ?0,3079 6,750 × 10?7 559,5
4 ?1191 ?0,2580 2,236 × 10?6 476,7
5 ?1297 ?0,3074 1,687 × 10?5 478,4
6 ?1357 ?0,2505 ?9,927 × 10?6 565,5
7 ?1629 ?0,3698 9,045 × 10?7 671,5
8 ?1282 ?0,2908 6,551 × 10?6 504,7
9 ?1791 ?0,4068 9,881 × 10?7 738,5
10 ?594,0 ?0,1285 9,991 × 10?7 238,1
11 ?1084 ?0,2482 6,276 × 10?6 425,4
12 ?1433 ?0,3254 7,900 × 10?7 590,8
13 ?1151 ?0,2798 1,952 × 10?5 413,3
14 ?1058 ?0,0749 ?3,558 × 10?5 443,7
15 ?1059 ?0,1566 ?1,931 × 10?5 494,3
16 ?1266 ?0,2569 2,363 × 10?6 489,8
17 ?1293 ?0,3010 1,745 × 10?5 474,9
18 ?1121 ?0,1566 ?2,101 × 10?5 517,7
19 ?1182 ?0,1893 ?2,440 × 10?5 534,5
20 ?1019 ?0,1601 ?1,402 × 10?5 445,2
21 ?1725 ?0,3515 ?1,706 × 10?5 724,5
22 ?478,7 ?0,0871 ?3,015 × 10?6 214,3
23 ?843,3 ?0,1463 ?1,170 × 10?5 377,5
24 ?1072 ?0,1564 ?2,598 × 10?5 517,6
25 ?1121 ?0,1566 ?2,101 × 10?5 517,7
26 ?1058 ?0,0749 ?3,558 × 10?5 443,7
27 ?1059 ?0,1566 ?1,931 × 10?5 494,3
28 ?1266 ?0,2569 2,363 × 10?6 489,8
29 ?1191 ?0,2580 2,236 × 10?6 476,7
30 ?1297 ?0,3074 1,687 × 10?5 478,4
31 ?1357 ?0,2505 ?9,927 × 10?6 565,5
32 ?1629 ?0,3698 9,045 × 10?7 671,5



76 Capítulo 5. Análise computacional

Tabela 5.2: Valores de GOR e Water cut dos poços considerados
Poço GOR Water cut (%)

1 0.286 12,5
2 0.227 9,6
3 0.385 13,3
4 0.308 18,7
5 0.500 14,3
6 0.150 9,1
7 0.462 7,1
8 0.212 3,6
9 0.417 20,0
10 0.329 9,1
11 0.385 13,3
12 0.267 6,3
13 0.282 11,9
14 0.208 8,6
15 0.232 4,5
16 0.235 12,3
17 0.269 5,6
18 0.317 6,4
19 0.278 12,7
20 0.333 6,1
21 0.161 10,2
22 0.137 11,8
23 0.194 15,0
24 0.262 5,6
25 0.431 9,7
26 0.276 31,0
27 0.281 22,0
28 0.088 1,1
29 1.429 30,0
30 1.000 33,3
31 0.167 33,3
32 0.750 42,9



5.1. Otimização de função suave 77

Tabela 5.3: Cenários propostos, com valores das soluções.
Cenário ?max ? (?*inj)

1 2,80 × 103 4,36 × 105
2 3,62 × 103 4,87 × 105
3 4,67 × 103 5,35 × 105
4 6,03 × 103 5,79 × 105
5 7,79 × 103 6,21 × 105
6 1,01 × 104 6,57 × 105
7 1,30 × 104 6,89 × 105
8 1,68 × 104 7,13 × 105
9 2,17 × 104 7,28 × 105
10 2,80 × 104 7,31 × 105

apresentamos o erro médio entre os valores produzidos ao final do al-
goritmo com este, tanto no valor da função objetivo (? (?*inj) ? ? (?inj)),
quanto na distância entre as soluções (??*inj ? ?inj??). Os erros são bai-
xos, tendo-se em consideração os valores ótimos conhecidos na Tabela
5.3.

De modo geral, o caso mais restrito teve uma convergência mais
rápida, necessitou de menos avaliações da função objetivo, e induziu
erros menores. Provavelmente devido à proximidade entre o ponto inicial
e o ponto ótimo.

Na Figura 5.1 mostramos o valor assumido pela função objetivo
no iterando corrente durante uma das execuções do algoritmo em três
dos cenários apresentados. Os valores da função objetivo foram nor-
malizados, considerando-se 0 o ponto inicial e 1 o ponto ótimo. Como
o ponto inicial é variável, a normalização é diferente para cada curva.
Percebemos que a evolução do valor é irregular, e fica mais lenta nas
proximidades do ponto ótimo.

Para um dos casos, apresentamos a distância Euclidiana ao ponto
ótimo, na Figura 5.2, em que verificamos o mesmo comportamento, mais
lento próximo ao ponto ótimo.



78 Capítulo 5. Análise computacional

10?2 10?1 100 101 102 103
0

0,2

0,4

0,6

0,8

1

Tempo [s]

?
(?

)

Cenário 1
Cenário 6
Cenário 10

Figura 5.1: Valor da função objetivo durante a busca direta direcional,
normalizado de 0 a 1.

10?1 100 101 102 103
0

100

200

300

400

Tempo [s]

e

Distância euclidiana ao ponto ótimo

Figura 5.2: Distância Euclidiana entre o ponto ótimo e o iterando
corrente da busca direta direcional.



5.1. Otimização de função suave 79

Tabela 5.4: Resolução de todos os cenários usando busca direta direcio-
nal. Média dos casos em cada cenário.

Cenário Tempo Avaliações ? ? (?*inj) ? ? (?inj) ??*inj ? ?inj??
1 7s 8.183 4.58 × 10?5 4.40 × 10?3
2 14s 22.087 8.66 × 10?5 6.36 × 10?3
3 24s 40.629 8.93 × 10?5 8.77 × 10?3
4 42s 70.664 1.43 × 10?4 1.18 × 10?2
5 67s 116.602 2.79 × 10?4 2.27 × 10?2
6 114s 196.331 3.18 × 10?4 4.37 × 10?2
7 199s 339.503 5.04 × 10?4 9.27 × 10?2
8 306s 517.005 1.05 × 10?3 1.36 × 10?1
9 484s 819.350 3.08 × 10?3 2.98 × 10?1
10 598s 1.100.179 4.30 × 10?3 1.88 × 10?1



80 Capítulo 5. Análise computacional

5.1.2 Região de confiança

Nesta aplicação, foram consideradas regiões de confiança dadas
por bolas na norma ?? em torno do iterando:

??(??, ??) = {? : ?? ? ???? ? ??}.

Os modelos usados foram polinomiais de segunda ordem, com
matriz Hessiana diagonal ??:

?(?? + ?) = ?(??) +
1
2

?? ??? + ??? ?, ? ???(??, ??).

O raio inicial foi ?0 = 1 e para a aceitação do passo foram usados
os coeficientes ?1 = 0,4 e ?0 = 0, de modo que, mesmo descenso simples
é aceito, contanto que o modelo seja ?-posicionado.

O raio foi aumentado e diminuído utilizando-se os parâmetros
?inc = 2 e ? = 0,5, respectivamente, que foram mantidos constantes
ao longo do algoritmo. O teste de criticidade foi executado com ??&amp;lt;
?0 = 32, usando ? = 10 e ? = 9. Os passos de teste foram calculados
resolvendo-se o sub-problema da região de confiança utilizando a parte
linear dos modelos.

Como no caso anterior, o critério de parada foi calculado para
equivaler em exatidão ao resultado alcançado pela busca direta direcio-
nal, na seção anterior. Chegamos ao critério

?? &amp;lt;???? = 0,0156.

Apresentamos um sumário da resolução dos problemas na Tabela
5.5. Para cada cenário é apresentada a média entre todos os pontos
iniciais. Tanto o tempo como o número de avaliações da função objetivo
foram pouco sensíveis à restrição de disponibilidade de gás para gas-lift.

Na Figura 5.3 apresentamos a evolução do valor corrente da fun-
ção objetivo, normalizado de 0 a 1. É mostrado apenas o caso mediano
de três dos cenários. Dos três, o caso mais restrito foi o mais rápido de
ser resolvido, seguido do menos restrito. O caso intermediário acabou
levando mais tempo. Nesta figura, ainda, para o Cenário 1, é possível
notar um período em que a função objetivo fica num mesmo valor. Pode-
mos especular que em tal momento foram necessárias várias execuções
do algoritmo de melhora de modelo, ou do passo de criticidade, que
podem ser custosos e, em si, não trazem melhora na função objetivo.

A distância euclidiana ao ponto ótimo durante as iterações de um
dos casos é mostrada na Figura 5.4, em um gráfico linear. O algoritmo
chega rapidamente na proximidade do ponto ótimo, onde é gasta a
maior parte do tempo.



5.1. Otimização de função suave 81

10?2 10?1 100 101 102 103
0

0,2

0,4

0,6

0,8

1

Tempo [s]

?
(?

)

Cenário 1
Cenário 6
Cenário 10

Figura 5.3: Valor da função objetivo durante a execução do algoritmo
de região de confiança, normalizado de 0 a 1.

Tabela 5.5: Resolução de todos os cenários usando região de confiança.
Média dos casos em cada cenário.

Cenário Tempo Avaliações ? ? (?*inj) ? ? (?inj) ??*inj ? ?inj??
1 4s 755 2.33 × 10?3 3.37 × 10?2
2 17s 4.602 2.10 × 10?2 2.73 × 10?1
3 19s 5.327 9.39 × 10?3 2.12 × 10?1
4 27s 7.712 7.66 × 10?3 2.58 × 10?1
5 28s 7.725 4.67 × 10?3 2.68 × 10?1
6 23s 6.447 2.20 × 10?3 2.31 × 10?1
7 19s 5.287 9.62 × 10?4 1.93 × 10?1
8 18s 4.995 6.25 × 10?4 2.19 × 10?1
9 17s 4.636 3.34 × 10?4 1.95 × 10?1
10 16s 4.567 3.79 × 10?4 2.40 × 10?1

Comparando com a busca direta direcional, há uma grande redu-
ção no tempo de execução e, principalmente, no número de avaliações da
função objetivo. Essa redução ficará mais relevante quando tais funções
forem obtidas como resultado de um cálculo de simulador.



82 Capítulo 5. Análise computacional

0 5 10 15
0

100

200

300

400

Tempo [s]

e

Distância euclidiana ao ponto ótimo

Figura 5.4: Distância Euclidiana entre o valor ótimo encontrado e o
valor do iterando corrente durante a execução do algoritmo de região
de confiança.



5.2. Otimização baseada no simulador 83

5.2 OTIMIZAÇÃO BASEADA NO SIMULADOR

Na seção anterior aplicamos os métodos de otimização estudados
para a otimização em um campo de petróleo em que a produção era
modelada por funções suaves. Naquele caso, a teoria relacionada aos
métodos era capaz de garantir a convergência.

Na presente seção faremos a otimização da alocação de gás em um
campo de produção de petróleo utilizando diretamente um simulador
para os poços e sistemas relacionados. Não apenas o modelo é mais
completo, mas também há presença de ruído, proveniente do cálculo das
simulações, realizado iterativamente. Como a utilização do simulador
torna a resolução mais lenta, optamos por realizar os experimentos
apenas com o método de região de confiança.

Consideramos o cenário de [7], com a diferença que sua abor-
dagem envolvia sofisticados modelos linearizados por partes, enquanto
nossa será com um simulador numérico.

O campo de produção consiste de 16 poços (Figura 5.5), com a
produção direcionada para dois manifolds, e cada manifold direciona
sua produção a um separador. Os poços numerados de 1 a 8 localizam-
se a 1 km do manifold 1, e 10 km do manifold 2, enquanto os poços de
9 a 16, estão a 1 km do manifold 2 e 10 km do manifold 1.

Figura 5.5: O gás para gas-lift deve ser alocado a 16 poços, cuja produção
é distribuída entre 2 manifolds [7].

Como nosso estudo não é capaz de otimizar o roteamento entre
poços e manifolds, mantivemos este constante, conforme a Tabela 5.6.

A tubulação ligando o manifold 1 ao seu separador tem 100 m,
enquanto a tubulação entre o manifold 2 e seu separador tem 50 m, com
diâmetro interno de 4,5 in e rugosidade absoluta de ? = 0,001 in.

Os poços têm tubos de produção (tubings) de diâmetro interno
de 3 in, comprimento total de perfuração de 3,7 km, profundidade de
2,7 km e ponto de injeção a 2,7 km.



84 Capítulo 5. Análise computacional

Tabela 5.6: Alinhamento entre poços e manifolds
Poço Manifold

1 1
2 2
3 1
4 1
5 2
6 1
7 1
8 2
9 2
10 2
11 2
12 2
13 1
14 1
15 2
16 2

Apresentamos na Tabela 5.7 algumas características dos poços
produtores. Também estão indicados a pressão estática do reservatório
?? e o índice de produtividade ?? (productivity index). O modelo deste
campo foi simulado utilizando o software PIPESIM.

O modelo deste campo foi simulado utilizando um simulador
fenomenológico. Sempre que a função objetivo precisava ser avaliada,
era feita uma simulação numérica da produção do campo.

O problema resolvido foi o seguinte:

max ? =
???

?=1
(????? + ?? ?

?
? ? ????) ?

???
?=1

?inj?
?
inj

sujeito a ? ? ??inj ? ?
???

?=1
??inj ? ?maxinj ,

em que as vazões de óleo ??, gás ?? e água ?? de cada poço são calculadas
pelo simulador, e a vazão de gás para gas-lift ?inj está limitada, em cada
poço de ? = 0 até ? = 226.534 Nm3/d e ? = 16. A disponibilidade total
de gás do campo utilizada foi ?maxinj = 8×? = 1.812.278 Nm3/d. Utiliza-
mos os preços de óleo ?? = 20, e gás ?? = 2. O custo do tratamento da



5.2. Otimização baseada no simulador 85

Tabela 5.7: Características dos poços
Poço GOR (Nm3/Nm3) Water cut (%) ?? (psi a) ?? (STB/d/psi)

1 200 0 2100 15
2 200 20 2300 2
3 300 10 1950 12
4 300 40 2050 15
5 400 0 1750 4
6 400 20 1700 9
7 500 10 1700 11
8 500 40 2100 10
9 200 10 1900 5
10 200 40 2200 9
11 300 0 1850 11
12 300 20 2300 6
13 400 10 1825 14
14 400 40 2200 7
15 500 0 1600 8
16 500 20 1800 5

água foi ?? = 1 e o custo da injeção de gás foi ???? = 5.
Para a resolução, implementamos o algoritmo de região de confi-

ança em Matlab, que foi usado para gerar código binário, que faz uso
do simulador.

Como na seção anterior, utilizamos uma região de confiança dada
por uma bola na norma ?? em torno do iterando:

??(??, ??) = {? : ?? ? ???? ? ??}.

Os modelos usados foram de interpolação, polinomiais lineares:

?(?? + ?) = ?(??) + ??? ?, ? ???(??, ??).

O raio inicial foi ?0 = 1, o raio máximo foi ?max = 16.384 e o
critério de parada, ? &amp;lt;10?3.

Para a aceitação do passo usamos os coeficientes ?1 = 0,1 e ?0 = 0.
Os parâmetros de aumento e contração do raio foram os mesmos em
todas as iterações: ?inc = 2 e ? = 0,5. O limiar para a substituição de
pivôs durante o algoritmo de melhora de modelo foi ? = 116 .

Desta vez, para o cálculo do passo, resolvemos o problema de
otimização dentro da região de confiança, utilizando a função linprog,
do Matlab, com o algoritmo active-set.



86 Capítulo 5. Análise computacional

Tabela 5.8: Sumário da resolução do problema: A maior parte do tempo
foi gasta nas simulações

Pto. inicial n.o simulações Tempo simulação Tempo algoritmo
1 1383 2 h 18 min 22 s
2 1294 2 h 22 min 22 s
3 1166 2 h 5 min 21 s
4 1190 2 h 6 min 22 s
5 1242 2 h 12 min 21 s
6 1253 2 h 15 min 21 s
7 1418 2 h 38 min 16 s
8 1132 1 h 60 min 15 s
9 1110 2 h 4 min 16 s
10 1075 1 h 57 min 18 s
11 1002 1 h 48 min 13 s
12 1080 1 h 58 min 15 s

Resolvemos o problema a partir de 15 diferentes pontos inici-
ais, escolhidos aleatoriamente. Em 12 dos casos, o algoritmo convergiu,
aproximadamente, para um mesmo ponto, sendo ??? a média deles, com
valor ? (???) = 2.136.131 para a função objetivo. Com relação à média
???, o desvio padrão da distância dos pontos finais a ela ?? ? ????2 foi
19,2 Nm3/d, enquanto que ?????2 = 1.258 Nm3/d. Considerando todos os
valores encontrados para a função objetivo, o desvio padrão foi de 0,69.

Considerando estes 12 pontos iniciais, apresentamos alguns de-
talhes da resolução na Tabela 5.8: número de simulações feitas, tempo
gasto com simulações e tempo gasto no restante do algoritmo. A maior
parte do tempo foi gasta com as simulações, que foram executadas se-
quencialmente. O tempo gasto pelo restante do algoritmo, em si, foi de
22 s, no pior caso.

Na tabela 5.9 fazemos um sumário da exatidão das soluções
encontradas. Para tanto, consideramos ??? o melhor ponto encontrado
entre todos os cenários. Na tabela estão os desvios absolutos, com
relação a tal ponto, e relativos, comparando-se com a norma deste
ponto ou com a distância entre o melhor ponto ??? e o ponto inicial de
cada caso.

Na Figura 5.6 mostramos o valor corrente da função objetivo
durante a execução do algoritmo, para dois pontos iniciais diferentes,
em função do número de simulações feitas.

No entanto, em 3 dos 15 pontos, o algoritmo não foi capaz de se
afastar muito do ponto original. As previsões dos modelos não foram



5.2. Otimização baseada no simulador 87

Tabela 5.9: Sumário da resolução do problema: exatidão das soluções
encontradas.

Pto. inicial ?? ? ???? ????????????
???????
??????0? ? (???) ? ? (?)

? (???)?? (?)
? (???)

1 0 0 0 0 0
2 3.87 0.304 × 10?2 0.171 × 10?4 0.182 0.085 × 10?6
3 3.87 0.304 × 10?2 0.462 × 10?4 0.182 0.085 × 10?6
4 3.87 0.304 × 10?2 0.249 × 10?4 0.182 0.085 × 10?6
5 3.87 0.304 × 10?2 0.259 × 10?4 0.182 0.085 × 10?6
6 3.87 0.304 × 10?2 0.206 × 10?4 0.182 0.085 × 10?6
7 21.77 1.711 × 10?2 1.179 × 10?4 0.720 0.337 × 10?6
8 31.12 2.445 × 10?2 1.626 × 10?4 1.016 0.476 × 10?6
9 32.05 2.519 × 10?2 1.639 × 10?4 1.017 0.476 × 10?6
10 26.48 2.081 × 10?2 1.480 × 10?4 1.272 0.596 × 10?6
11 33.67 2.646 × 10?2 1.607 × 10?4 1.276 0.597 × 10?6
12 51.71 4.064 × 10?2 4.262 × 10?4 2.315 1.084 × 10?6

0 200 400 600 800 1.000 1.200 1.400
?4

?2

0

2

·106

Número de simulações

f(
x)

Valor da função objetivo

Ponto inicial 1
Ponto inicial 12

Figura 5.6: Valor da função objetivo ao longo da execução da otimização



88 Capítulo 5. Análise computacional

boas o suficiente para o raio da região crescer muito e foi feito pouco
progresso.

Notamos que o custo atribuído à injeção de gás acabou sendo
muito elevado. Isto fez com que vários dos pontos iniciais acabassem,
ao longo da resolução, a quase zerar a injeção de gás para depois voltar
a aumentá-la.

Também comparamos a solução obtida com a de [7], que uti-
liza um modelo linear por partes do simulador. Esta última encontrou
um valor de 2.234.150 para a função objetivo. Ao aplicar a solução
no simulador, o valor realmente obtido foi 2.155.338. No entanto, esta
abordagem também encontrou um alinhamento ótimo entre poços e
manifolds, que foi diferente daquele que utilizamos durante nossa resolu-
ção. Se aplicarmos o resultado que encontramos (de injeção de gás) com
o alinhamento de [7], nosso valor para o ganho econômico é um pouco
maior: 2.203.409. O tempo de resolução também foi muito diferente: a
resolução de [7] durou apenas 55 s, porém com o modelo de otimização
construído previamente.

Estas diferenças entre as duas abordagens mostram a relevância
do tratamento para os alinhamentos entre poço e manifold. Além disso,
a estratégia que utiliza modelos lineares por partes pode apresentar
imprecisões, seja em função das escolhas as variáveis modeladas, seja
no número de pontos utilizados para a construção do modelo.

Uma possibilidade de corrigir essas distâncias entre o resultado
obtido pela programação inteira e o resultado obtido com o simulador
é utilizar métodos sem derivada como meio de melhorar a solução do
resultado da programação inteira.

5.3 SUMÁRIO

Neste capítulo mostramos aplicações dos algoritmos de busca
direta direcional e o de região de confiança não-diferenciável. Em um
primeiro estudo de caso, ambos foram aplicados na maximização de
um ganho econômico, no problema da alocação de gás em um campo
produtor de petróleo.

As curvas de produção dos poços eram modeladas por funções
suaves e ambos os algoritmos foram capazes de encontrar o valor ótimo
para as injeções, sendo que a busca direta direcional necessitou de muito
mais avaliações da função objetivo.

No segundo caso, analisamos a otimização diretamente com um
simulador de poços de petróleo e sistemas relacionados. Essa possibili-
dade de usar diretamente os simuladores é um grande motivador para o



5.3. Sumário 89

uso de métodos não-diferenciáveis. Neste caso, as funções de produção
dos poços não eram suaves, tendo em vista o ruído causado pelo simula-
dor numérico. Além disso, há interação entre as produções de diversos
poços, tendo em vista que produzem em manifolds comuns. Para este
caso, foi aplicado apenas o algoritmo de região de confiança. Das 15
tentativas de solução, 12 foram bem-sucedidas e convergiram para a
vizinhança de um mesmo ponto.

Comparamos a solução encontrada com a obtida por terceiros
com outra abordagem, baseada em programação inteira, que também
otimiza o alinhamento entre poços e manifolds. A abordagem com
programação inteira faz uso de um modelo específico para otimização,
construído previamente, tendo um tempo para solução bastante inferior
à nossa, que utiliza diretamente o simulador.

Os métodos que estudamos não resolvem a questão do roteamento
da produção, enquanto que a abordagem que utiliza modelos lineares
por partes pode ter erros de modelação. Uma possibilidade é utilizar
os métodos não-diferenciáveis como uma alternativa para melhorar o
resultado obtido com programação inteira.





6 CONCLUSÃO

Na indústria do petróleo há várias ferramentas de simulação nu-
mérica dos processos de produção. No entanto, os simuladores normal-
mente não fornecem derivadas das variáveis calculadas, o que impede
seu uso para otimização com algoritmos clássicos. Neste trabalho apre-
sentamos dois métodos de otimização que não fazem uso de derivadas:
busca direta direcional e região de confiança não-diferenciável. Eles fo-
ram expostos em sua forma irrestrita e com restrições lineares. Ambos
foram utilizados em um estudo numérico em que se otimizou a produção
de um campo que produz petróleo por gas-lift. Para o tratamento de
restrições não-lineares, propomos o método do Lagrangiano aumentado,
que pode fazer uso dos métodos anteriores para resolver a sequência de
sub-problemas resultante. Neste método, as restrições não-lineares são
substituídas por penalizações na função objetivo, restando apenas as
restrições lineares.

Os algoritmos de busca direta direcional são de implementação
mais simples, enquanto os de região de confiança demandam mais tra-
balho. Ambos têm garantia de convergência, dependendo da suavidade
da função que se está otimizando. Os algoritmos também podem fazer
uso de ferramentas de simulação numérica diretamente, embora neste
caso não se seja possível verificar a suavidade da função.

Nos estudos numéricos que realizamos, o algoritmo de otimização
por região de confiança não-diferenciável foi mais eficiente que o de
busca direta direcional, chegando ao ponto ótimo em menos tempo e
com menos avaliações da função objetivo. Também fizemos um estudo
com o algoritmo de região de confiança e um simulador de redes de
petróleo. A maioria do tempo de solução foi gasta no cálculo da função
objetivo (simulações), e não no algoritmo em si.

Em nossos estudos, para ambos os algoritmos as avaliações de
função objetivo foram feitas sequencialmente. O desempenho pode ser
melhorado se várias avaliações forem feitas em paralelo. Isto é particular-
mente marcante para o algoritmo de busca direta direcional, que utiliza
várias avaliações por iteração. Em particular, a abordagem de busca
direta direcional tem um algoritmo que pode ser utilizado de forma
distribuída [30], permitindo a execução paralela e com certo balanço de
carga.

No caso de alocação de gás para gas-lift, se o usuário dispuser de
uma boa estimativa para a solução, proveniente seja de conhecimentos
de operação, seja do resultado de uma otimização aproximada prévia,
o uso de algoritmos não-diferenciáveis pode dar suporte para melhorar
tal estimativa.

91



92 Capítulo 6. Conclusão

Os algoritmos apresentados convergem para ótimos locais. Se a
otimalidade global for necessária, devem ser utilizados outros métodos.
Para o caso em que as restrições são limites superiores e inferiores,
existem os algoritmos DIRECT (DIviding RECTangles) [31] e MCS
(Multilevel Coordinate Search) [32]. Outra alternativa é recorrer a mé-
todos auxiliares que indiquem um bom ponto inicial para a solução.

Os algoritmos apresentados não resolvem problemas com vari-
áveis inteiras. No contexto de campos de produção de petróleo, estas
ocorrem, inevitavelmente, nas decisões sobre o roteamento da produção.
Além disso, o problema da alocação de gás utilizando outras estratégias
como programação inteira mista pode ser mais eficiente em encontrar o
ótimo. Se o número de otimizações a ser feito for alto, ou se o custo de
manutenção de um modelo de otimização preciso for baixo, é a melhor
abordagem.

O presente estudo apresentou métodos que buscassem fazer uso
do conhecimento das restrições lineares. Há métodos semelhantes que
tratam apenas limites superiores e inferiores. Neste caso, outras restri-
ções devem ser tratadas com métodos de penalização, como Lagrangiano
aumentado. Um estudo comparando tal alternativa com nossa escolha
(tratamento explícito de restrições lineares), ainda pode ser feito.

Em trabalhos futuros faremos um estudo numérico do método do
Lagrangiano aumentado para o tratamento das restrições não-lineares.
No caso específico de alocação de gás para gas-lift, tais restrições ocor-
rem nas produções admissíveis de gás ou contaminantes, mas também
na modelação da capacidade de compressão de gás do campo.

Ainda em trabalhos futuros, podemos utilizar os métodos abor-
dados para problemas que não estão sendo resolvidos com programação
inteira-mista. Entre esses, incluem-se otimização em reservatórios de
petróleo e escoamentos com mudança de fase (flashing).



REFERÊNCIAS

[1] SILVA, T. L. Formulações inteiras mistas para modelos lineares por
partes multidimencionais. Dissertação (Mestrado) — Programa de
Pós-graduação em Engenharia de Automação e Sistemas, Universi-
dade Federal de Santa Catarina, Florianópolis, 2012.

[2] CODAS, A. Otimização da produção de poços de petróleo com injeção
contínua de gás e alinhamento poço-separador: modelos lineares por
partes e algoritmos. Dissertação (Mestrado) — Programa de Pós-
graduação em Engenharia de Automação e Sistemas, Universidade
Federal de Santa Catarina, Florianópolis, 2012.

[3] BUITRAGO, S.; RODRÍGUEZ, E.; ESPIN, D. Global optimiza-
tion techniques in gas allocation for continuous flow gas lift systems.
In: Proceedings of the Gas Technology Conference. [S.l.]: Society of
Petroleum Engineers, 1996.

[4] CODAS, A. et al. Integrated production optimization of oil fields
with pressure and routing constraints: the Urucu field. Computers &amp;amp;
Chemical Engineering, v. 46, p. 178–189, 2012. ISSN 0098-1354.

[5] KOSMIDIS, V. D.; PERKINS, J. D.; PISTIKOPOULOS, E. N.
Optimization of well oil rate allocations in petroleum fields. Industrial
&amp;amp; Engineering Chemistry Research, v. 43, n. 14, p. 3513–3527, 2004.

[6] MISENER, R.; GOUNARIS, C. E.; FLOUDAS, C. A. Global opti-
mization of gas lifting operations: A comparative study of piecewise
linear formulations. Industrial &amp;amp; Engineering Chemistry Research,
v. 48, n. 13, p. 6098–6104, 2009.

[7] SILVA, T. L.; CODAS, A.; CAMPONOGARA, E. A computational
analysis of convex combination models for multidimensional piecewise-
linear approximation in oil production optimization. In: Proceedings
of the 2012 IFAC Workshop on Automatic Control in Offshore Oil
and Gas Production. Trondheim: [s.n.], 2012. v. 1, p. 292–298.

[8] GUNNERUD, V.; CONN, A.; FOSS, B. Embedding structural in-
formation in simulation-based optimization. Computers &amp;amp; Chemical
Engineering, v. 53, p. 35 – 43, 2013. ISSN 0098-1354.

[9] CIAURRI, D. E.; ISEBOR, O. J.; DURLOFSKY, L. J. Application
of derivative-free methodologies to generally constrained oil produc-
tion optimisation problems. International Journal of Mathematical
Modelling and Numerical Optimisation, v. 2, n. 2, p. 134–161, 2011.

93



94 Referências

[10] GANZAROLI, C. A. Modelagem, simulação e controle da dinâmica
de poços operando com gas-lift contínuo. Dissertação (Mestrado) —
Programa de Pós-graduação em Engenharia de Automação e Sis-
temas, Universidade Federal de Santa Catarina, Florianópolis, 2011.

[11] THOMAS, J. E. (Ed.). Fundamentos de engenharia de petróleo. 2.
ed. Rio de Janeiro, RJ: Editora Interciência, 2001.

[12] PLUCENIO, A. Automação da produção de poços de petróleo ope-
rando com elevação artificial por injeção contínua de gás. Dissertação
(Mestrado) — Programa de Pós-graduação em engenharia elétrica,
Universidade Federal de Santa Catarina, Florianópolis, 2003.

[13] KOLDA, T. G.; LEWIS, R. M.; TORCZON, V. Optimization by di-
rect search: New perspectives on some classical and modern methods.
SIAM Review, v. 45, n. 3, p. 385–482, August 2003.

[14] ALARCÓN, G. A.; TORRES, C. F.; GÓMEZ, L. E. Global opti-
mization of gas allocation to a group of wells in artificial lift using
nonlinear constrained programming. ASME Journal of Energy Re-
sources Technology, v. 124, n. 4, p. 262–268, 2002.

[15] DAVIS, C. Theory of positive linear dependence. American Journal
of Mathematics, The Johns Hopkins University Press, v. 76, n. 4, p.
733–746, 1954. ISSN 00029327.

[16] CONN, A. R.; SCHEINBERG, K.; VICENTE, L. N. Introduction
to Derivative-Free Optimization. 1. ed. Philadelphia, PA: Society for
Industrial and Applied Mathematics, 2009.

[17] SCHEINBERG, K.; TOINT, P. L. Self-correcting geometry in
model-based algorithms for derivative-free unconstrained optimiza-
tion. SIAM Journal on Optimization, SIAM Publications, Philadel-
phia, PA, v. 20, n. 6, p. 3512–3532, 2010. ISSN 1052-6234.

[18] TRÖLTZSCH, A. Active sets in bound-constrained optimization
without derivatives. Saarbrücken: Lambert Academic Publishing,
2012.

[19] PARDALOS, P. M.; VAVASIS, S. A. Quadratic programming with
one negative eigenvalue is NP-Hard. Journal of Global Optimization,
Kluwer Academic Publishers, v. 1, p. 15–22, 1991. ISSN 0925-5001.

[20] CONN, A. R.; GOULD, N. I. M.; TOINT, P. L. Trust Region
Methods. Philadelphia, PA: Society for Industrial and Applied Math-
ematics, 2000.



Referências 95

[21] LEWIS, R. M.; TORCZON, V. Pattern search methods for linearly
constrained minimization. SIAM Journal on Optimization, v. 10, n. 3,
p. 917–941, 2000.

[22] LUCIDI, S.; SCIANDRONE, M.; TSENG, P. Objective-derivative-
free methods for constrained optimization. Mathematical Program-
ming, Springer Berlin / Heidelberg, v. 92, p. 37–59, 2002. ISSN 0025-
5610.

[23] ABRAMSON, M. A. et al. OrthoMADS: A deterministic MADS
instance with orthogonal directions. SIAM Journal on Optimization,
v. 20, n. 2, p. 948–966, 2009. ISSN 10526234.

[24] BERTSEKAS, D. P. Nonlinear Programming. 2. ed. Belmont, MA:
Athena Scientific, 1999.

[25] BERTSEKAS, D. P. Constrained optimization and Lagrange mul-
tiplier methods. Belmont, MA: Athena Scientific, 1996.

[26] CONN, A. R. et al. Convergence properties of an augmented la-
grangian algorithm for optimization with a combination of general
equality and linear constraints. SIAM Journal on Optimization, v. 6,
n. 3, p. 674–703, August 1996.

[27] KOLDA, T. G.; LEWIS, R. M.; TORCZON, V. A generating
set direct search augmented Lagrangian algorithm for optimization
with a combination of general and linear constraints. Albuquerque,
NM, 2006. Disponível em:&amp;lt;http://www.prod.sandia.gov/cgi-
bin/techlib/access-control.pl/2006/065315.pdf&gt;.

[28] PHELPS, R. R. Convex sets and nearest points. Proceedings of
the American Mathematical Society, American Mathematical Society,
v. 8, n. 4, p. pp. 790–797, 1957. ISSN 00029939.

[29] GIULIANI, C. M.; CAMPONOGARA, E.; PLUCENIO, A. A com-
putational analysis of nondifferentiable optimization: Applications to
production maximization in gas-lifted oil fields. In: Proceedings of
the 9th IEEE International Conference on Automation Science and
Engineering (CASE). Madison, WI: [s.n.], 2013. p. 292–297.

[30] HOUGH, P. D.; KOLDA, T. G.; TORCZON, V. J. Asynchronous
parallel pattern search for nonlinear optimization. SIAM Journal on
Scientific Computing, v. 23, n. 1, p. 134–156, June 2001.



96 Referências

[31] JONES, D. R.; PERTTUNEN, C. D.; STUCKMAN, B. E. Lips-
chitzian optimization without the lipschitz constant. Journal of Opti-
mization Theory and Applications, v. 79, n. 1, p. 157–181, 1993. ISSN
00223239.

[32] HUYER, W.; NEUMAIER, A. Global optimization by multilevel
coordinate search. Journal of Global Optimization, v. 14, n. 4, p. 331–
355, 1999. ISSN 09255001.

[33] SPIVAK, M. Significance of the derivative. In: . Calculus. 3.
ed. Houston, TX: Publish or Perish, 1994. cap. 11.



A SOBRE A DIFERENCIABILIDADE DO LAGRANGIANO
AUMENTADO

Na seção 4.1.2, apresentamos uma maneira de tratar restrições
de desigualdades no problema do Lagrangiano aumentado sem a neces-
sidade de variáveis adicionais.

Para tanto, os sub-problemas resultantes envolviam uma função
Lagrangiano aumentado já otimizada nas variáveis de folga, da seguinte
maneira:

?(?, ?, ?, c) = ? (?) + ?? ?(?) + 1
2

c??(?)?2+

+
1
2c

???
?=1

{?
max[0, ?? + c??(?)]2 ? ?2?

}?
. (4.4)

Na discussão subsequente, tal expressão foi presumida suave.
Neste apêndice vamos provar que, de fato, (4.4) é continuamente di-
ferenciável.

Para tanto, a suposição que fazemos é que as funções ? , ? e
? são continuamente diferenciáveis. Diante dessa hipótese, é imediato
que os primeiros termos de ?(·, ?, ?, c) são continuamente diferenciáveis.
Trataremos de modo separado a parcela que envolve a função “max”.

Para provar sua diferenciabilidade, introduzimos um teorema
de [33]:

Teorema 11 Suponha que a função ? : R ? R é contínua no ponto
?, e que ? ?(?) existe para todo ? em um intervalo contendo ?, exceto,
possivelmente para ? = ?. Suponha, ainda, que lim??? ? ?(?) existe.
Então ? ?(?) existe, e

? ?(?) = lim
???

? ?(?).

Vamos usar o teorema para mostrar a suavidade da função ?(?) =
max[0, ?(?)]2, com ? : R ? R continuamente diferenciável. Em (4.4)
ocorre um caso particular em que ?(?) = ?? + c??(?).

A função ? também pode ser escrita como

?(?) =
{?

0, se ?(?) ? 0
?(?)2, se ?(?) ? 0.

Claramente ? é continuamente diferenciável em todos os pontos
em que ?(?) &amp;lt;0 ou ?(?) &gt; 0.

Agora suponha que existe um ponto ? ? R tal que ?(?) = 0. Se,
na vizinhança de ? não ocorre troca de sinal, por exemplo, ?(?) ? 0,

97



98 Apêndice A. Sobre a diferenciabilidade do Lagrangiano aumentado

também é imediato que ? é continuamente diferenciável. Resta a dúvida
com relação àqueles pontos em que há troca de sinal.

Suponha que ?(?) = 0 e ?(?) &gt; 0 para ? &gt; ? e ?(?) &amp;lt;0 se ? &amp;lt;?,
na vizinhança de ?. Então, o limite, por um lado é

lim
???+

??(?) = lim
???+

?(?)2 =

= lim
???+

2?(?)??(?) =

= 2
(?

lim
???+

?(?)
)?(?

lim
???+

??(?)
)?

=

= 2 × 0 × ??(?) =
= 0.

Enquanto, pelo outro lado, o limite é

lim
????

??(?) = lim
????

0 =

= 0.

Consequentemente,
lim
???

??(?) = 0. (A.1)

Como ? é contínua, e sua derivada tem limite no ponto ? (A.1),
pelo Teorema 11, ? é continuamente diferenciável em ?, com ??(?) = 0.
O caso recíproco (?(?) &gt; 0 se ? &gt; ? e ?(?) &amp;lt;0 se ? &amp;lt;?) pode ser
resolvido de forma análoga.

Assim, o Lagrangiano aumentado proposto (4.4) é composto por
uma soma na qual todas as parcelas são continuamente diferenciáveis,
e portanto, continuamente diferenciável.


	Resumo
	Abstract
	Sumário
	Introdução
	Organização do documento

	Otimização não-diferenciável irrestrita
	Busca direta direcional
	Região de confiança
	Definição do modelo
	Polinômios de Lagrange
	Cálculo do passo
	Aceitação do passo e gerenciamento da região
	Teste de criticidade
	Algoritmo de região de confiança

	Alternativas algorítmicas
	Sumário

	Otimização não-diferenciável com restrições lineares
	Material básico sobre otimização restrita
	Busca direta direcional com restrições lineares
	Alternativas algorítmicas

	Região de confiança
	Passo generalizado de Cauchy
	Algoritmo de região de confiança com restrições lineares
	Alternativas algorítmicas

	Sumário

	Otimização não-diferenciável com restrições não-lineares
	Lagrangiano aumentado
	Lagrangiano aumentado com resolução aproximada dos sub-problemas
	Lagrangiano aumentado com restrições de desigualdade
	Eliminação parcial das restrições

	Um algoritmo de Lagrangiano aumentado
	Resolvendo os sub-problemas com busca direta direcional
	Resolvendo os sub-problemas com região de confiança não-diferenciável
	Sumário

	Análise computacional
	Otimização de função suave
	Busca direta direcional
	Região de confiança

	Otimização baseada no simulador
	Sumário

	Conclusão
	Referências
	Sobre a diferenciabilidade do Lagrangiano aumentado

</field>
	</doc>
</add>