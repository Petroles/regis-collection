<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.08684</field>
		<field name="filename">13555_MarcosAntoniodeMatosLaia_DO_corrigida.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">
 

 

UNIVERSIDADE DE SÃO PAULO  
INSTITUTO DE FÍSICA DE SÃO CARLOS 

EMBRAPA INSTRUMENTAÇÃO 
 
 
 
 
 
 
 
 
 
 
 

MARCOS ANTONIO DE MATOS LAIA 
 
 
 
 
 

Filtragem de Kalman não linear com redes neurais  

embarcada em uma arquitetura reconfigurável para uso na   

tomografia  de Raios-X  para amostras da física de solos 

 

 
 
 
 
 
 
 
 
 
 
 
 
 
 

 
São Carlos 

2013 



  

 
 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 



 

 

MARCOS ANTONIO DE MATOS LAIA 

  
 
 
 
 
 
 
 
 
 
 
 
 
 

Filtragem de Kalman não linear com redes neurais  

embarcada em uma arquitetura reconfigurável para uso na   

tomografia  de Raios-X para amostras da física de solos 

 
 
 

Tese apresentada ao Programa de Pós-
Graduação em Física do Instituto de 
Física de São Carlos da Universidade de 
São Paulo, para obtenção do título de 
Doutor em Ciências. 
 
Área de concentração: Física Aplicada 
Opção: Física Computacional 
Orientador: Prof. Dr. Paulo E. Cruvinel 
 
 

 

 

 

 

 

Versão Corrigida 

(Versão original disponível na Unidade que aloja o Programa) 

 

São Carlos 
2013 

   



 

 

  

 

 

 
  



 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Aos meus pais, por todo apoio e carinho  que  foram fundamentais   

para a elaboração deste trabalho 

 

   



 

 

  

 

  



 

 

AGRADECIMENTOS 

 

 

Ao Prof. Dr. Paulo E. Cruvinel, pelos ensinamentos nos anos de convivência, atenção, 

apoio e orientação. 

Aos colegas Francisco de Assis Scannavino Júnior e Cristiane Gataz, pelas discussões  

e amizade, bem como pelos bons momentos no laboratório de pesquisa. 

Ao Instituto de Física de São Carlos, pela oportunidade de realização desse 

doutoramento. 

Ao Conselho Nacional de Desenvolvimento Científico e Tecnológico e Instituto 

Nacional de Ciência e Tecnologia em Sistemas Embarcados, pela concessão da bolsa de 

doutorado e pelo apoio financeiro para a realização desta pesquisa. 

A Embrapa Instrumentação Agropecuária, por colocar à disposição a área 

experimental e os laboratórios.  

  

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 



 

 

  

 

 

 

  



 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

“Não creio que haja alguma emoção mais intensa para um inventor que ver alguma de 

suas criações funcionando. Essa emoção faz que se esqueça de comer, de dormir, de tudo." 

Nikola Tesla 

 
  



 

 

  

  



 

 

RESUMO 

 

LAIA, M. A. M. Filtragem de Kalman não linear com redes neurais embarcada 

em uma arquitetura reconfigurável para uso na tomografia  de Raios-X para 

amostras da física de solos. 2013. 156 p. Tese (Doutorado em Ciências) -  Instituto 

de Física de São Carlos, Universidade de São Paulo, São Carlos, 2013. 

 

Estudar as propriedades físicas do solo envolve conhecer a umidade, o transporte 

de água e solutos, a densidade, a identificação da porosidade, o que é essencial 

para o crescimento de raízes das plantas. Para esses estudos, a tomografia de raios 

X tem se mostrado uma técnica útil. As imagens tomográficas são obtidas através de 

projeções (sinais) que são reconstruídos com algoritmos adequados. No processo 

de aquisição dessas projeções, podem surgir ruídos provenientes de diferentes 

fontes. O sinal tomográfico apresenta ruídos que possuem uma distribuição de 

Poisson gerada pela contagem de fótons, bem como o detector de fótons é 

influenciado por uma presença de ruído eletrônico com uma distribuição Gaussiana. 

Essas diferentes distribuições podem ser mapeadas com transformadas não lineares 

específicas que alteram uma distribuição Gaussiana para outros tipos de 

distribuições, como a de transformada de Anscombe (Poisson) ou transformada de 

Box-Muller (Uniforme), mas são aproximações que apresentam erros acumulativos. 

As transformadas podem ser então mapeadas por um sistema de redes neurais, o 

que garante um melhor resultado com o filtro de Kalman não linear em que os pesos 

da rede e as medidas das projeções são estimados em conjunto. Este trabalho 

apresenta uma nova solução com filtragem de Kalman descentralizada utilizando 

redes neurais artificiais embarcada em uma arquitetura reconfigurável com o intuito 

de obter se um valor ótimo de melhoria na relação Sinal/Ruído de projeções 

tomográficas e consequentemente nas imagens reconstruídas proporcionando  

melhorias para os métodos de análise dos físicos de solos agrícolas. 

 

Palavras-chave: Física computacional. Computação reconfigurável. Filtro de Kalman.  

  



 

 

  

  



 

 

ABSTRACT 

 

LAIA, M. A. M. Nonlinear Kalman filtering with neural network embedded in a 

reconfigurable architecture for use in X-ray tomography for samples of soil 

physics. 2013. 156 p. Tese (Doutorado em Ciências) -  Instituto de Física de São 

Carlos, Universidade de São Paulo, São Carlos, 2013. 

 

To study the physical properties of soil moisture involves knowing the transport of 

water and solutes, density, porosity identification, which is essential for the growth of 

plant roots. For these studies, X-ray tomography has been shown to be a useful 

technique. The tomographic images are obtained through projections (signals) that 

are reconstructed with appropriate algorithms. In the process of acquiring these 

projections, noise can arise from different sources. The tomographic signal is noisy 

which have a Poisson distribution generated by photon counting, and the photon 

detector is influenced by a presence of electronic noise with a Gaussian distribution. 

These different distributions can be mapped to specific nonlinear transformed altering 

a Gaussian distribution for other types of distributions, such as the Anscombe 

transform (Poisson) or Box-Muller transform (Uniform), but are approximations that 

have cumulative errors. Transforms can then be mapped by a neural network 

system, which ensures a better result with nonlinear Kalman filter in which the 

network weights and measures of the projections are estimated together. This work 

presents a new solution to the unscented Kalman filtering using artificial neural 

networks embedded in a reconfigurable architecture in order to obtain an optimum 

value of improvement in S/N ratio of tomographic projections and consequently the 

images reconstructed by providing improvements for the methods of physical 

parameters of the agricultural soils. 

 

Keywords: Computational physics. Reconfigurable computing. Kalman filter.  

  



 

 

  

  



 

 

SUMÁRIO 

1 INTRODUÇÃO ........................................................................................................... 15 

1.1 TOMOGRAFIA COMPUTADORIZADA APLICADA A SOLOS ....................................... 16 

1.2 HISTÓRICO DA TOMOGRAFIA COMPUTADORIZADA .............................................. 22 

1.3 INCERTEZAS EM MEDIDAS TOMOGRÁFICAS .......................................................... 23 

1.4 TRABALHOS RELACIONADOS ................................................................................ 26 

2 COMPUTAÇÃO RECONFIGURÁVEL BASEADA EM FPGA .......................... 29 

2.1 DISPOSITIVOS RECONFIGURÁVEIS ......................................................................... 32 

2.2 FPGAS .................................................................................................................. 34 

3 DESENVOLVIMENTO METODOLÓGICO E MATERIAIS ............................. 43 

3.1 PROCESSAMENTO DIGITAL EM SISTEMAS EMBARCADOS ...................................... 43 

3.2 FILTRO DE KALMAN .............................................................................................. 47 

3.2.1 FILTRO DE KALMAN DISCRETO ..................................................................................... 47 

3.2.2 FILTRO DE KALMAN ESTENDIDO ................................................................................... 49 

3.2.3 FILTRO DE KALMAN COM REDES NEURAIS ARTIFICIAIS (RNAS) ................................... 50 

3.2.4 FILTRO DE KALMAN DESCENTRALIZADO ...................................................................... 52 

3.3 MÉTODO DE RECONSTRUÇÃO TOMOGRÁFICA DE RAIOS X .................................... 59 

3.4 MODELAGEM DO SISTEMA DE FILTRAGEM A SER EMBARCADO ............................. 63 

3.5 CORDIC ................................................................................................................ 70 

3.6 PONTO FIXO ......................................................................................................... 76 

3.6.1 FATOR DE ESCALA ......................................................................................................... 76 

3.6.2 ARITMÉTICA DE PONTO FIXO ........................................................................................ 77 

3.6.3 NOTAÇÕES NUMÉRICAS ............................................................................................... 78 

3.7 GERAÇÃO DE CÓDIGO EM HDL .............................................................................. 81 

4 RESULTADOS ........................................................................................................... 87 

4.1 ALGORITMO EMBARCADO .................................................................................. 104 

4.2 ANÁLISE DE RESULTADOS NA CONFIGURAÇÃO DE FILTRO EMBARCADO .............. 106 

4.2.1 RESULTADOS OBTIDOS COM OS PHANTOMS DE CALIBRAÇÃO ................................. 107 

4.2.2 RESULTADOS OBTIDOS COM AMOSTRAS DE SOLOS AGRÍCOLAS .............................. 127 

5 CONCLUSÃO ........................................................................................................... 145 

5.1 TRABALHOS FUTUROS ........................................................................................ 148 

 



 

 

  

  



15 

 

1 INTRODUÇÃO 
 

 

Tomografia de solos tem como objetivo investigar propriedades como 

transporte de água e solutos, porosidade e densidade, bem como a interação solo-

planta com base na análise de imagens reconstruídas a partir das projeções (sinais) 

obtidas de amostras. As primeiras aplicações de tomografia da ciência do solo foram 

discutidas no início da década de 1980, por físicos e engenheiros
1-3

.  

O desenvolvimento sistematizado da tomografia computadorizada aplicada à 

física de solos no Brasil originou-se de parceria e colaboração entre o Centro 

Nacional de Pesquisa e Desenvolvimento de Instrumentação Agropecuária 

(CNPDIA), do Instituto de Física de São Carlos (IFSC), da Universidade de 

Campinas (Unicamp), da Universidade de São Paulo (USP) e do Departamento de 

Computação da Universidade Federal de São Carlos (UFSCar)
4-12

. Além destas 

instituições, projetos neste segmento tem contado  com a parceria de Universidades 

Italianas e Americanas, o que vem promovendo a elaboração de contribuições 

pioneiras
3,13-15

. 

Este trabalho de pesquisa baseado em arquiteturas reconfiguráveis e 

tomografia aplicada à ciência dos solos vêm sendo desenvolvido junto ao Programa 

de Pós-Graduação em Física Computacional do IFSC e o INCT-SEC
a
, que é 

coordenado pelo Instituto de Ciências Matemáticas e de Computação (ICMC) com o 

CNPDIA.  O Programa de Pós-Graduação em Física Computacional investe em 

inovação tecnológica através de pesquisas científicas ligadas à modelagem 

computacional de problemas físicos que visam analisar e desenvolver teorias, 

criando modelos capazes de explicar tais fenômenos físicos.  

 Neste contexto, é apresentado o desenvolvimento de  uma nova abordagem 

para o uso do filtro de Kalman com redes neurais artificiais embarcado para filtragem  

de projeções tomográficas da ciência do solo que viabiliza a minimização das 

incertezas do processo aleatório da contagem de fótons
16

. Esta pesquisa é pioneira, 

uma vez que o filtro de Kalman estruturado em uma arquitetura reconfigurável obtém 

aprendizado em tempo real, sem necessidade de treinamento prévio, sendo assim 

um novo modelo baseado na física do processo de obter-se projeções com maior 

                                            
a
 INCT-SEC – Instituto Nacional de Ciência e Tecnologia em Sistemas Embarcados Críticos  



16 

 

  

qualidade que levam em conta a interação de fótons com a matéria em dada energia 

para auxílio à análise que envolve processos dinâmicos da ciência do solo. 

Este texto está organizado em cinco capítulos sendo o primeiro uma 

introdução à tomografia computadorizada aplicada à ciência do solo, o segundo 

aborda sobre computação reconfigurável, o terceiro sobre os materiais e métodos 

para o desenvolvimento de um filtro de Kalman embarcado para tomografia 

computadorizada aplicada à física dos solos, o quarto sobre os resultados obtidos 

até o presente momento e o quinto sobre as considerações finais, conclusão e 

trabalhos futuros.  

 

 

1.1  TOMOGRAFIA COMPUTADORIZADA APLICADA A SOLOS 
 

 

O uso do solo para a agricultura tem se tornado cada vez mais o foco das 

discussões no cenário mundial. Isso se deve às preocupações com as mudanças do 

clima e as consequências na produção de alimentos para um mundo cada vez mais 

populoso. O uso eficiente do solo objetiva suprir as necessidades de uma produção 

que tende a tornar-se cada vez mais escassa. A agricultura é a atividade que mais 

afeta o meio ambiente, seja pela grande quantidade de água usada ou pela imensa 

quantidade de insumos agrícolas que são aplicados sobre o solo
18

. O uso desses 

recursos acaba por degradar os recursos hídricos. Estima-se que cerca de 75% do 

consumo de água pelo homem é utilizado para a agricultura
19

.  

A atividade agrícola ocupa extensas áreas com monoculturas ou com uma 

pequena variedade de espécies, fazendo com que haja uma proliferação 

descontrolada de insetos e pragas microbianas, provocadas principalmente pela 

quebra da cadeia alimentar de um ecossistema equilibrado.  

Para combater os problemas de pragas, são aplicados milhões de toneladas 

de pesticidas sobre as culturas de todo o mundo. Esse tipo de ação faz com que a 

saúde humana esteja em risco devido à presença de tais pesticidas na água e no ar.  

A contaminação das águas pelos pesticidas ocorre de duas maneiras: 

escorrimento superficial para os rios e corpos de d’água e percolação
b
 profunda no 

solo até atingir as águas subterrâneas. Através do conhecimento dos mecanismos 

                                            
b
 Percolação se refere ao movimento e filtragem de fluídos por materiais porosos. 



17 

 

de transporte do soluto na região não-saturada do solo pode-se otimizar a aplicação 

dos insumos agrícolas para a minimização dos efeitos prejudiciais ao reservatórios 

hídricos naturais
17

.  

A movimentação de água e solutos no solo depende diretamente da 

característica do mesmo. As características são ligadas à capacidade de absorção 

do solo, presença de macroporos, da quantidade de matéria orgânica presente no 

solo, solubilidade das substâncias presentes e permeabilidade do solo. Em regiões 

onde o solo é arenoso e permeável, a infiltração da água no solo é mais intensa do 

que o escorrimento superficial
20

. 

Os poros grandes presentes no solo contribuem para a penetração de raízes, 

trocas gasosas e presença da água no volume do solo. Quanto maior a densidade 

de macroporos, mais as raízes podem se espalhar pelo solo e quanto mais 

contínuos os macroporos, mais livremente os gases podem realizar trocas com a 

atmosfera. Macroporos também permitem que haja uma infiltração direta de água e 

transporte de solutos nos poros. O tamanho da abertura dos macroporos está ligado 

diretamente ao crescimento da planta, tendo um papel mais importante que a própria 

porosidade
20

. 

O manejo do solo também exerce um papel importante na física de transporte 

de água do solo. O plantio direto é usado para minimizar perdas de solo e água pela 

ação do escorrimento superficial. Ele visa diminuir o impacto da agricultura e das 

máquinas agrícolas sobre o mesmo. 

No plantio direto, a palha e os demais restos vegetais de outras culturas são 

mantidos na superfície do solo, garantindo cobertura e proteção do mesmo contra 

processos danosos, tais como a erosão. O solo só é manipulado no momento do 

plantio, quando é aberto um sulco onde são depositadas sementes e fertilizantes. 

Não existe, além do supracitado, nenhum método de preparo do solo. O mais 

importante controle que se dá nesse modo de cultivo é o das plantas daninhas, 

através do manejo integrado de pragas, doenças em geral e plantas infestantes. 

Também é muito importante para o sucesso do sistema que seja utilizada a rotação 

de culturas. 

O plantio direto também garante a presença de macroporos devido à matéria 

orgânica incorporada, maior presença de minhocas e atividades biológicas mais 

intensas. Já no plantio convencional, a maior exposição do solo ao impacto direto da 

chuva causa o selamento superficial do solo, provocando escorrimento superficial e 



18 

 

  

erosão. Outros fatores são o uso de máquinas agrícolas de grande porte que 

promovem a compactação do solo, eliminando os macroporos.  

A ciência tem razoável domínio sobre os estudos de solos saturados
c
 e na 

região não saturada, que é um horizonte agricultável na maioria das culturas. Nesta 

região ocorrem processos biológicos, reações químicas e concentração variável de 

massa e umidade. Antes, a preocupação era resolver problemas específicos para 

aumentar a produtividade. Hoje já se busca encontrar um equilíbrio entre agricultura 

e manejo sustentável do ecossistema
19

. 

Pesquisadores da ciência do solo têm colaborado com pesquisadores de 

outras áreas do conhecimento com objetivo de melhor caracterizar as propriedades 

do solo. Os resultados dessas colaborações têm provido uma melhor qualidade de 

vida. O uso desses resultados na agricultura vem sendo aplicado através de 

diversas atividades que direcionam a uma melhor base para o uso dos recursos 

naturais que podem ser utilizados de forma sustentável
20

.  

Neste contexto, técnicas avançadas têm sido utilizadas para encontrar 

respostas a variados mecanismos físicos e químicos que ocorrem nos solos. Entre 

elas incluem o uso de sonda de nêutrons, gravimetria, transmissão diretas de raios 

X, microscopia e intrusão de mercúrio, tomografia de raios X, ressonância magnética 

nuclear, entre outras
21,22

. O uso da Tomografia Computadorizada (TC) de raios X e 

gama, bem como da ressonância magnética nuclear, pode permitir a análise não 

invasiva o que é desejável para a obtenção de medidas sem perturbação do 

ambiente. Estas técnicas fornecem como resultados imagens digitais as quais 

podem auxiliar na recomendação de diagnósticos e prognósticos para o ambiente 

físico observado.  

A TC é utilizada para estudar a influência da estrutura física do solo nos 

mecanismos de transporte de água no solo
20

. Perret e colaboradores estudaram 

uma estrutura do solo como uma rede de poros em 3 dimensões e utilizaram a TC 

para estudo de fluxo preferencial em solos.  

Os primeiros resultados de análise de TC no Brasil foram obtidos com 

tomógrafos médicos, contudo o preço e as dificuldades envolvidas com a calibração 

de tais equipamentos fizeram o seu uso inviável para pesquisa aplicada em física de 

                                            
c
 O grau de saturação de uma amostra de solo é definido pela razão entre volume de água e 

volume vazio. O volume vazio, por sua vez é definido pela diferença entre o volume sólido e 

volume total. 



19 

 

solos. Uma solução para esse problema foi o desenvolvimento de tomógrafos mais 

baratos de primeira geração, projetados exclusivamente para uso de pesquisas em 

agricultura. Cruvinel, um engenheiro e cientista da Embrapa/CNPDIA situada em 

São Carlos, São Paulo, construiu pela primeira vez um tomógrafo para aplicações 

em ciência do solo.  É importante mencionar que esta contribuição pioneira usando 

TC de raios X e gama na ciência do solo foram consequências do uso de radiação 

gama na medida de densidades de torrão de solo e conteúdo de água em amostras 

de solo. 

A TC tem como desafio melhorar a qualidade das imagens, o que é um dos 

principais requisitos para sua análise, sendo desejável que as mesmas estejam bem 

próximas da representação das amostras que foram ensaiadas. Neste contexto, o 

uso de algoritmos desenvolvidos para outras áreas do conhecimento humano tem 

crescido consideravelmente e as técnicas de processamento de imagens têm 

auxiliado significantemente na melhoria da informação visual utilizada na análise e 

interpretação ou percepção automática realizada com o auxilio dos computadores. 

Tais aspectos envolvem: 

? O modelamento do funcionamento do olho humano;  

? Estudo de transformadas de imagens, como a Transformada de Fourier, 

wavelets e espectro de potência. 

? A aplicação de filtros que visem recuperar informações e conhecimento 

presente em imagem buscando ampliar as oportunidades do uso das técnicas 

do processamento de imagens. 

?  Compressão de imagens e formulação de novas bases cognitivas.  

? Segmentação de imagens, para detecção de bordas, de primitivas, de linhas 

e descontinuidade para sua análise;  

? Reconhecimento e interpretação de imagens, como técnicas de análise 

baseada em redes neurais, com o propósito de reconhecer padrões e suas 

características.  

Uma imagem de boa qualidade permite observar dados que podem ser 

fundamentais para a aplicação de algum processamento digital
23

. Dentro desse 

princípio, parte essencial desse trabalho tem como objetivo a melhoria da qualidade 

de imagens tomográficas de raios X filtrando os sinais obtidos antes da sua 

reconstrução. 



20 

 

  

Na Embrapa Instrumentação foram projetados e construídos tomógrafos 

dedicados à aplicação agrícola, tal como se pode observar na Figura 1
12,17,24-25

. 

 

 

Figura 1 - Tomógrafos desenvolvidos na Embrapa Instrumentação: (a) 
Minitomógrafo desenvolvido para aplicações agrícolas

12
. (b) 

Tomógrafo portátil de transmissão direta de raios X para uso em 
campo

17
. (c) Tomógrafo com micro precisão

24
. (d) Tomógrafo de 

espalhamento Compton
25

. 

A qualidade das imagens tomográficas influencia na classificação de 

primitivas morfológicas presentes no solo e que impacta na análise da porosidade, 

da densidade e de índices de compactação. Tais primitivas afetam o aumento da 

produção agrícola e a preservação do solo. A classificação possibilita  o uso de 

ferramentas de processamento de imagens para caracterização dos fenômenos 

físicos, tais como o movimento de solutos e água, formação de poros, texturas e 

distribuição de raízes
3
. Aliada ao desenvolvimento de técnicas de análise,  modelos 

foram desenvolvidos visando à melhoria e a precisão das imagens, nos resultados 

de algoritmos de reconstrução, além do desenvolvimento de ferramentas 

computacionais para ajudar os usuários na extração de informações
5-11

. 

Com base na intensidade de fótons emitida por uma fonte de raios X e gama, 

bem como na intensidade captada por um detector na outra extremidade da reta de 

propagação, pode-se determinar o peso da atenuação devido ao objeto que se faz 

presente entre a fonte e o detector. O peso da atenuação é um dado crucial para o 



21 

 

processo de reconstrução, o qual possibilita obter um mapa de coeficientes de 

atenuação linear da secção transversal do objeto, como pode ser visto na Figura 2. 

 

Figura 2 - Processo de estabelecimento de uma projeção tomográfica. 

Um tomografia computadorizado 2D gera uma imagem reconstruída das 

projeções obtidas numa série de emissões de raios X, em diferentes ângulos, que 

consiste numa seção transversal (uma “fatia”) do objeto em estudo
11

. 

A imagem resultante proporciona um mapa de coeficientes de atenuação 

linear de raios X, os quais são representados através de pixels cujos valores são 

dados em números CT – Computerized Tomography. Esses números são 

normalizados em função do coeficiente de atenuação da água     , sendo definidos 

como: 

 

           
           

    
          (1) 

 

onde µ(x,y) representa o coeficiente de atenuação linear de raios X no pixel do corpo 

sob estudo. 

Largamente utilizada nas áreas médicas, a tomografia computadorizada teve 

seu uso em ciência do solo introduzido por Petrovic, Hainsworth e Aylmore e por 



22 

 

  

Crestana
1-3

. Petrovic demonstrou a possibilidade de usar um tomógrafo 

computadorizado de raios X para medir a densidade de volumes de solos, já 

Hainsworth e Aylmore verificaram a distribuição espacial de água no solo, enquanto 

Crestana demonstrou que a TC pode solucionar problemas de estudos da física da 

água no solo, através das medidas do potencial mátrico da água no solo realizadas 

através dos tensiômetros instalados em várias profundidades e da curva de retenção 

de água no solo foi possível medir os respectivos valores de umidade. Utilizando 

curvas de calibração do tomógrafo para o solo estudado foi possível medir os 

valores de densidade global do solo considerando conhecidos os valores de 

umidade. 

  

 

1.2  HISTÓRICO DA TOMOGRAFIA COMPUTADORIZADA 
 

 

Em 1917, o matemático austríaco Radon foi o primeiro a apresentar uma 

solução matemática das equações de reconstrução de corpos a partir de projeções, 

determinando a função distribuição de densidade da região estudada através delas, 

no campo da gravitação
26

. 

Bracewell, em 1946, utilizou a reconstrução tomográfica para construir um 

mapa das regiões solares emissoras de micro-ondas, pois naquela época as 

antenas de micro-ondas existentes permitiam focalizar apenas pequenas faixas da 

superfície solar
27

.  

O embrião da tomografia reconstrutiva de raios X pode ser encontrado nos 

trabalhos de Takahashi em 1957, onde uma fonte de raios X e um filme foram 

colocados em um mesmo plano
28

.  

Em 1963, Cormack, professor de Física da University of Cape Town, 

desenvolveu a técnica matemática para reconstruir imagens utilizando o método da 

retroprojeção
29

. Ele havia sido solicitado para supervisionar o uso de isótopos 

radioativos no Groote Schuur Hospital devido à demissão do físico do hospital. 

Durante algumas semanas o pesquisador trabalhou com os isótopos radioativos e 

acompanhou tratamentos de radioterapia. Com base em experimentos e 

observações, ele formulou uma matriz de coeficientes de atenuação linear de raios X 

para cortes seccionais que poderia ser obtida pela medida da transmissão de raios X 



23 

 

em vários ângulos através de um corpo com a obtenção de imagens de seções 

transversais. Seu estudo foi decisivo para a reconstrução das seções a partir de um 

número finito de projeções estudadas.  

Em aplicações médicas, o primeiro tomógrafo computadorizado de raios X de 

caráter comercial foi apresentado em 1973, pela EMI Ltda., tendo sido desenvolvido 

pelo engenheiro Hounsfield, causando um grande impacto para os diagnósticos 

médicos
30

.  

 

 

1.3  INCERTEZAS EM MEDIDAS TOMOGRÁFICAS 
 

 

Basicamente, uma TC indica a quantidade de radiação absorvida por cada 

porção da seção analisada e traduz essas variações numa escala de tons de cinza 

em uma imagem. Como a capacidade de absorção de raios X de um material está 

intimamente relacionada com a sua densidade, diferentes medidas são 

apresentadas. Deste modo, cada valor do sinal corresponde à média da absorção 

dos materiais nessa zona, expresso em Unidades de Hounsfield. A principal 

vantagem da TC é permitir o estudo de secções transversais de materiais de forma 

não invasiva. 

Para TCs, devido à faixa de energia utilizada, há três principais efeitos de 

interação da radiação com a matéria que podem ser considerados. São eles o efeito 

fotoelétrico, o efeito Compton e o efeito de produção de pares
15

. Além das questões 

relacionadas aos efeitos mencionados, há outras questões que influenciam a 

medição em tomografia computadorizada. Dentre elas, encontram-se a estatística da 

contagem de fótons (efeito de Poisson) e os ruídos devidos aos equipamentos 

mecânicos e eletrônicos utilizados.  

A probabilidade de detecção de fótons em um intervalo de tempo de 

exposição t pode ser estimada pela função de distribuição de probabilidade de 

Poisson
31

, dada por
     

 

         
     

     
      (2) 

 



24 

 

  

onde   é o número de fótons e    é a medida de fotoelétrons emitidos no intervalo de 

tempo t, dados por: 

                   (3) 

 

onde M é a razão média de fótons (fótons/segundo) e ? é a eficiência quântica do 

detector. A incerteza (ou ruído) é dada pelo desvio padrão 

 

          .      (4) 

 

Logo a relação sinal-ruído, SNR, apresentada pelo sinal incidente pode ser 

dada por: 

 

    
   

    
 

  

 
         .      (5) 

 

Desta relação é avaliado que para um número pequeno de fótons, o ruído 

pode ser considerável, porém com o seu aumento, o ruído pode vir a ser 

desprezível. Para uma fotomultiplicadora, por exemplo, a emissão de elétrons 

termiônicos no fotocátodo causa um aumento nesse tipo de ruído. Considerando que 

o fotocátodo emite elétrons aleatoriamente em razão da corrente de cátodo 

incrementado de:  

 

                  (6) 

 

pode-se estabelecer uma nova relação sinal-ruído que é dada pela expressão por: 

 

    
    

     
.                (7) 

 

Em geral, a visualização de uma imagem tomográfica é acompanhada pela 

presença de granulosidade, que é significante para visualização de objetos de baixo 

contraste. O termo ruído em imagens tomográficas refere-se à variação dos 

coeficientes de atenuação linear sobre o valor médio quando uma imagem é obtida 



25 

 

de um objeto uniforme. O ruído na imagem pode ser baseado no cálculo do desvio 

padrão e também no espectro de potência de Wiener, o qual é visualizado como 

uma função da frequência espacial que permite observar a intensidade e o tipo de 

ruído envolvendo o sistema tomográfico como um todo. 

O ruído presente nas imagens TC inclui: (a) erros de arredondamento que 

ocorrem no algoritmo de reconstrução, (b) ruído eletrônico e (c) ruído causado pelo 

sistema de visualização. Entretanto, a principal fonte de ruído em imagens TC ocorre 

devido à variação quântica (quantus mottle), causado pela variação estatística 

espacial e temporal no número de fótons de raios X emitidos pela fonte. O ruído 

decorrente do algoritmo computacional depende do tamanho do pixel do dispositivo 

de visualização e também influencia o ruído da imagem, assim, maiores pixels levam 

a uma redução do ruído na imagem, porém com perda na resolução. Algoritmos de 

reconstrução normalmente utilizam filtros de suavização que minimizam o efeito 

visual do ruído, acompanhado de alguma perda na resolução espacial. O ruído 

eletrônico pode ter origem em dispositivos eletrônicos não ideais, tais como 

resistores e capacitores não puros, terminais de contatos não ideais, corrente de 

fuga de transistores, efeito Joule, podendo ser também independente do sinal, como 

interferência externa (elétrica ou até mesmo mecânica)
32

. 

Fazer medidas discretas dos dados obtidos em diferentes sensores, que 

podem ser encontrados em dispositivos embarcados se torna uma tarefa que requer 

cuidados devido à necessidade de minimizar imprecisões das medidas. 

Arredondamentos e truncamentos computacionais são os mais difíceis de serem 

gerenciados devido aos finitos recursos dos processadores.  

Dispositivos embarcados apresentam uma notação numérica adequada, 

ainda que imperfeita, devido à aproximação de números que devem ser 

representados como no caso de números irracionais. As aproximações podem ser 

aceitas em casos normais de operação, mas para sistemas críticos não podem ser 

suficientemente precisas.  

As incertezas podem transformar os dados desejados de bons para ruidosos, 

eliminando a precisão necessária para alguma operação crítica. Além dos ruídos, as 

imagens de TC estão sujeitas a diversos artefatos e distorções como fontes com 

energias policromáticas, atribuídos pelos efeitos conhecidos como endurecimento do 

feixe (beam hardening), diferentes materiais em um mesmo voxel (volume parcial), 



26 

 

  

bem como devido ao deslocamento mecânico indesejável da amostra ou do 

equipamento de posicionamento
33-35

. 

 

 

1.4  TRABALHOS RELACIONADOS 
 

 

A base da filtragem de dados provenientes de TC foi desenvolvida a partir da 

construção do minitomógrafo com  a colaboração de Cruvinel, em 1987
12

. Vários 

outros trabalhos com o objetivo de melhorar a qualidade da imagens obtidas tem 

sido orientados no grupo de instrumentação da Embrapa em parceria com a 

Universidade Federal de São Carlos e Instituto de Física de São Carlos 

(Universidade de São Paulo). 

Em 1989, Vaz, orientado pelo Dr. Silvio Crestana da Embrapa Instrumentação, 

usou a técnicas de TC aplicadas à compactação de solo em sua dissertação de 

mestrado
20

.  

Furuie, em 1990, abordou em seu trabalho de doutorado a reconstrução 

tomográfica de imagens com ruído Poisson, fazendo estimativas das projeções
36

.  

No ano seguinte, Portal fez um refinamento dos métodos de estimação das 

projeções para a recontrução das imagens afetadas pelo ruído Poisson
37

.  

Em 1994, Ribeiro abordou em sua dissertação de mestrado sobre o 

desenvolvimento algoritmos de reconstrução em 3D das projeções tomográficas
5
. 

Também em 1994, Cássaro fez um estudo  sobre o uso da tomografia de dupla 

energia para caracterizar a deformação de meio porosos sob diferentes graus de 

hidratação
38

.  

Naime, no mesmo ano, projetou e construiu um tomógrafo portátil para o 

estudo de plantas e solos
17

.  

Em 1995, Venturini apresentou e desenvolveu técnicas para análise da 

qualidade das imagens tomográficas com o uso do espectro de Wiener
6
.  

Biassusi fez um estudo da expansão e contração de um vertissolo com o uso 

de tomografia computadorizada em 1996
39

. 

Em 1997, Macedo construiu um tomógrafo com resolução microscópica para os 

estudos em ciências do solo
21

. 



27 

 

Minatel por sua vez, usou técnicas de filtros frequenciais e wavelets para a 

reconstrução das imagens tomográficas, em 1997
7
.  

Granato, em 1998,  trabalhou com filtros adaptativos para a melhoria das 

imagens após a reconstrução
8
. 

Guerra também estudou a restauração de imagens do minitomógrafo de 

análise de solos por técnicas de regularização enquanto Homem fez um estudo 

sobre técnicas de reconhecimento de padrões aplicadas a imagens tomográficas 

adquiridas em múltiplas energias. Ambos os trabalhos foram concluídos em 1998 

sob a orientação do professor Dr. Nelson Mascarenhas
40,41

. 

Em 2001, Salina fez um estudo sobre a reconstrução tomográfica de imagens 

técnicas POCS sequenciais e paralelas
42

.  

Pereira, em 2002, desenvolveu um algoritmo paralelo para a reconstrução das 

projeções e em 2007 abordou o uso de filtragem nas imagens tanto quanto nas 

projeções antes da etapa de reconstrução com o uso do filtro de Wiener e propôs o 

uso desses algoritmos implementados em DSPs (Processadores Digitais de Sinais) 

usando uma arquitetura paralela
9,43

.  

No mesmo ano, Laia desenvolveu para uso em desktop um filtro de Kalman e 

suas extensões mais comuns para filtragem de projeções tomográficas
10

.  

Botega, em 2008, desenvolveu um ambiente virtual para análise das imagens 

em 3D reconstruídas e utilizou filtros espaciais convencionais
11

.  

Em 2009, Laia publicou um capítulo de livro sobre o uso de filtro de Kalman 

para projeções tomográficas da ciência do solo com um modelo físico mais próximo 

do real, comparando a eficiência do filtro sua versão não linear com o uso de redes 

neurais
16

.  

Ribeiro, em 2010, elaborou novas propostas em filtragem de projeções 

tomográficas sob ruído Poisson
44

. 

Laia, em 2011, fez uma validação sobre o algoritmo do filtro de Kalman não 

linear com redes neurais para ser embarcado e aplicado em amostras da ciência dos 

solos
45

.  

Em 2012, Laia elaborou um estudo sobre um projeto para ser embarcado em 

FPGA (Field-Programmable Gate Array – Arranjo de Portas Programáveis em 

Campo) através de um código HDL gerado pelo Matlab
®46

. 



28 

 

  

  



29 

 

2 COMPUTAÇÃO RECONFIGURÁVEL BASEADA EM FPGA 
 

 

Atualmente, computadores são usados em uma ampla gama de aplicações e 

cada vez mais têm se tornado essencial em todas as áreas de conhecimentos. A 

vantagem do uso de aplicações em computadores de uso geral é a flexibilidade para 

alterar-se algoritmos cujas modificações são facilmente incorporadas ao código que 

deverá ser executado. Um microprocessador, após sua fabricação como um Circuito 

Integrado (CI), pode resolver tarefas computacionais que podem ser executadas em  

tempos distintos, podendo inclusive extrapolar o uso previamente definido pelo seu 

projetista.  

Áreas específicas das engenharias e ciências exatas possuem diferentes 

problemas e complexidade que exigem grande demanda de recursos 

computacionais, os quais incluem o armazenamento, a recuperação, a transmissão 

e o processamento de informações. Muitos desses problemas necessitam que as 

soluções sejam obtidas em um pequeno intervalo de tempo ou até mesmo em tempo 

real
48

. Von Neumann
d
 demonstrou que sistemas com um único processador faz com 

que o maior tempo gasto seja na leitura e na escrita de dados na memória do que no 

uso de instruções para processamento, que na maioria das vezes, dependem de 

resultados anteriores que ainda não foram atualizados na memória.  

A evolução da microeletrônica permitiu o surgimento de dispositivos 

eletrônicos cada vez mais velozes, com maior capacidade de armazenamento de 

informações, menor consumo de energia e menores custos de fabricação. O desafio 

para o projetista de arquitetura de computadores está em manter um padrão de 

velocidade para as operações de novos sistemas mantendo suas generalidades
49

. 

Projetar processadores que atendam uma demanda de uso geral, com várias 

instruções e amplos recursos de memória, ainda se constitui em um desafio a ser 

vencido. 

                                            
d
 A arquitetura de Von Neumann trata de estrutura computacional proposta pelo matemático 

em 1945. Ela descreve um computador com subdivisões de uma unidade de processamentos 
que contém unidade de lógica aritmética, registradores de processamento, unidade de 
controle contendo registradores de instrução e contador de programa, memória externa e 
mecanismos de entrada e saída

47
. 



30 

 

  

 Novas soluções ainda são desenvolvidas para melhorar o tempo de resposta 

e o desempenho através de novas arquiteturas computacionais. Dentre elas se 

destacam: 

? Software paralelo e arquiteturas paralelas de propósito geral50
-54: 

O uso de software paralelo permite que aplicativos possam 

trabalhar como de forma concorrente em arquiteturas paralelas. A 

vantagem sobre sistemas sequenciais é a capacidade de dividir um 

problema em pequenas partes, processar essas partes ao mesmo 

tempo para chegar a uma solução em menor tempo do que se o 

problema viesse a ser resolvido de forma sequencial. 

? Software distribuído  e arquiteturas de propósito geral55
,56: 

Sistemas distribuídos permitem que cada processador na 

arquitetura (presente em uma máquina ou em várias máquinas 

dispostas como um cluster, por exemplo) receba uma parte da tarefa.  

? Software sequencial ou paralelo e arquiteturas dedicadas57
,58: 

Arquiteturas dedicadas são caracterizadas por terem um 

processamento limitado, somente trabalhando de forma efetiva com a 

função para a qual ela  foi construída, não possuindo flexibilidade a 

favor da robustez do sistema. O software é usado para o uso 

otimizado, podendo tanto ser sequencial quanto paralelo sendo 

bastante utilizado em sistemas embarcados
e
. 

? Hardware dedicado e fixo para aplicações específicas59: 

Hardware dedicado e fixo também é utilizado em sistemas 

embarcados, principalmente em sistemas cujo custo em energia e 

resposta em tempo real são fundamentais. Esse tipo de sistema é 

construído com uma finalidade específica, podendo tornar-se obsoleto 

por não permitir atualizações de projeto após a fabricação. 

? Computação e arquiteturas reconfiguráveis60
-62: 

A computação reconfigurável baseia-se na utilização de um software 

que decompõe o problema em tarefas menores e que torna a processar tais 

                                            
e
 Um sistema embarcado é um sistema computacional projetado para funções de controle 

específicas que pode ser parte de um sistema maior, trabalhando em  funções que 
demandam processamento em tempo real

63,64
.  



31 

 

tarefas em paralelo, objetivando atingir resultados significativos em relação 

ao tempo de processamento.  

No projeto de equipamentos dedicados para aplicações específicas, 

arquiteturas reconfiguráveis podem ser utilizadas para validar um design, podendo 

trabalhar, em campo, com otimizações no uso de energia e componentes, por 

exemplo.  

Hardwares dedicados diferem da evolução das arquiteturas RISC
f
, CISC

g
 e 

dos modelos híbridos
h
 que foram projetados para atenderem uma demanda de uso 

geral. Circuitos com hardware personalizado ou circuitos integrados com aplicações 

específicas são desenvolvidos para executarem tarefas específicas, o que possibilita 

o desenvolvimento de sistemas computacionais inteiros e de menor porte, com 

menor consumo de energia e mais rápidos. Esses sistemas, chamados de ASIC 

(Application Specific Integrated Circuit) são limitados ao custo de desenvolvimento e 

à incapacidade de serem modificados após serem fabricados, sendo arriscado para 

uso em projetos comerciais. Uma arquitetura ASIC pode ser usada também para 

contornar o problema da fabricação de circuitos integrados específicos com o 

controle fixo e as unidades funcionais e personalizadas, otimizados para uma dada 

aplicação65. 

Uma configuração em arquitetura ASIC também pode ser um sistema 

embarcado, pois se trata de um sistema microprocessado onde o computador é 

completamente encapsulado e dedicado a um dispositivo ou sistema controlado. Ele 

pode ser provido de um microcontrolador (que inclui uma unidade de processamento 

integrada, quantidade de memória RAM
i
 limitada e uma memória ROM

j
 onde 

instruções do programa são gravadas).  

Algumas ASICs passaram a possuir uma parte reprogramável ou permitir que 

uma parte do código pode ser modificada/apagada fisicamente atráves do uso de luz 

                                            
f
 Reduced Instruction Set Computer – Computador com um Conjunto Reduzido de Instruções, 
este tipo de sistema foi viabilizado pelo uso de compiladores que poderiam aperfeiçoar o uso 
dos ciclos de instruções. 
g
 Complex Instruction Set Computer – Computador com um Conjunto Complexo de 

Instruções, este tipo de sistema foi utilizado quando programas eram feitos em linguagem de 
máquina, permitindo que uma linha de comando executasse uma tarefa específica, sendo 
substituído parcialmente pelo uso de compiladores. 
h
 Híbridos são computadores que possuem características RISC e CISC, sendo comum aos 

computadores com arquitetura x86 e computadores modernos que utilizam instruções 
específicas para melhoria na execução de instruções.  
i
 Random Access Memory – Memória de Acesso Aleatório. Memória volátil de rápido acesso 
usada para escrita e leitura de dados.  
j
 Read-Only Memory – Memória com acesso apenas para leitura. 



32 

 

  

ultravioleta (EPROM
k
) ou eletronicamente (EEPROM

l
) com sistemas modernos 

usando. Dentro dessa categoria de ASICs com partes reprogramáveis, podem haver 

arranjos integrados de portas lógicas que permitem a criação de uma nova estrutura 

em hardware, como novos caminhos de interconexão em sistemas multicores 

(barramentos), compartilhamento de memória ou novas unidades de controle e 

processamento.  

Na realidade, o software ainda tem que obedecer as especificações do 

sistema para garantir os resultados. O gargalo desse tipo de configuração acaba 

sendo a comunicação entre os diferentes  processadores.  

A computação reconfigurável também possui as características 

organizacionais de um computador de uso geral. Entretanto, o modo de executar as 

funções é diferente, ou seja, ao invés de trabalhar uma função sequencialmente 

através de um conjunto de instruções de tempo (como um processador 

convencional), as arquiteturas reconfiguráveis geralmente computam a função 

através de unidades funcionais configuradas no espaço (unidades em diferentes 

blocos dentro dos dispositivos). O que difere os dois tipos de computação é que um 

modelo é temporal/sequencial enquanto o outro é espacial/paralelo. 

 

 

2.1 DISPOSITIVOS RECONFIGURÁVEIS 
 

 

A computação reconfigurável por ser uma área relativamente recente tem 

recebido várias definições. O conceito dado por Compton e Hauck
66

 a define como a  

habilidade de se trabalhar em hardware com a flexibilidade de uma solução em 

software, com o objetivo de aumentar o desempenho total do sistema 

computacional, sendo uma arquititetura com um processador ou multi-processada. O 

diagrama apresentado na Figura 3 exibe as características da computação 

configurável que reúne as vantagens da computação reconfigurável. 

 

                                            
k
 Erasable Programmable Read-Only Memory – Memória Programável de Leitura Apagável 

l
 Electrically-Erasable Programmable Read-Only Memory – Memória Programável de Leitura 
Eletronicamente Apagável. 



33 

 

 

Figura 3 - Diagrama esquemático que ilustra as vantagens da computação 
reconfigurável, que combina as vantagens das outras modalidades 
de arquiteturas. 

A computação reconfigurável pode ser vista como solução intermediária entre 

hardware e software, ou seja, o uso da programação de software paralelo em 

hardware especializados. O objetivo, as metas e as motivações passam a se 

relacionar com a melhoria do desempenho, flexibilidade, generalidade, eficiência e 

custos
48

. Recentemente, esses sistemas têm sido entendidos como fundamentais 

para sistemas embarcados críticos, atribuindo novas oportunidades como trabalhar 

em tempo-real, maior segurança, robustez, baixo consumo de energia e menores 

dimensões. 

A computação reconfigurável é baseada em dispositivos lógicos programáveis 

(PLD – Programmable Logic Devices) que fornecem uma programação flexível no 

nível de portas lógicas e podem atingir um desempenho elevado de acordo com a 

estruturação do projeto e sua aplicação
68

.  

Os PLDs podem ser definidos como sendo um Circuito Integrado com  arranjo 

de portas lógicas, que por sua vez pode ser usado para a implementação de 

circuitos digitais através do uso de softwares específicos desenvolvidos pelos 

fabricantes. Esses dispositivos também podem realizar quaisquer tarefas 

computacionais, podendo inclusive possuir uma unidade de processamento já 

embutida.  



34 

 

  

As interconexões das portas lógicas são feitas por transistores comandados 

por células SRAM
m

, transistores, EEPROM, fusíveis, multiplexadores, entre outros
67

. 

 

 

2.2 FPGAS 
 

 

A FPGA (Field-Programmable Gate Array – Arranjo de Portas Programáveis 

em Campo) é um dipositivo da família dos PLDs e por isso caracteriza-se como um 

dispositivo semicondutor que contém componentes de lógica (blocos lógicos) e 

conexões internas programáveis.  

Esses blocos lógicos podem ser programados para trabalhar como portas 

lógicas (AND
n
, XOR

o
) ou funções complexas que podem ser combinadas como 

decoders/encoders, multiplexadores ou funções matemáticas. A primeira FPGA 

comercial foi criada em 1985 pela Xilinx Inc. como dispositivo programável de acordo 

com as aplicações do usuário (programador ou projetista), lembrando que outros 

PLDs já possuíam a capacidade de programar em blocos lógicos, mas eram apenas 

uma pequena parte, muitas vezes usados para fazer ponte de conexão em 

diferentes processadores de um mesmo sistema.  

Uma FPGA é composta de três tipos de componentes: CLB (Configuration 

Logical Blocks - Blocos de Configuração Lógica), IOB (Input/Output Block – Blocos 

de entrada e saída) e PSM (Programmable Switch Matrix - Matriz de interconexão 

Programável).  

CLBs são circuitos idênticos, construídos pela reunião de flip-flops do tipo D e 

estão localizados no centro do chip enquanto os IOBs estão presentes nas 

periferias, como pode ser visto na Figura 4.  

A interconexão é necessária para implementar projetos na FPGA. A 

configuração distribuída controla o comportamento dos CLBs e IOBs através de um 

programa armazenado.  

 

                                            
m
Static Random Access Memory – Memória Estática de Acesso Aleatório. Ela tem a 

capacidade de manter a memorização dos dados, não necessitando sua atualização de 
tempos em tempos (Refreshing) 
n
 Porta lógica “e” cuja saída é sempre falsa se uma das entradas for falsa. 

o
 Porta lógica “ou exclusiva” cuja saída é sempre verdadeira se as entradas forem diferentes. 



35 

 

 

Figura 4 - Arquitetura interna de uma FPGA, onde são visualizados a 
localização dos CLBs, PSMs e IOBs

48,68
. 

Na Figura 5 é apresentado um diagrama de um CLB simplificado  usado para 

programar uma lógica combinacional ou sequencial. Ele é composto por uma LUT 

(Lookup Table – Tabela de Consulta) controlada por 4 entradas, para programar 

uma lógica combinacional e um flip-flop do tipo D para a lógica sequencial.  

 

 

Figura 5 - Diagrama simplificado de um CLB. 

Um multiplexador (MUX
p
) é usado para selecionar diretamente a saída da 

lógica combinacional através da saída do flip-flop. Um CLB é programado por 

carregar a tabela verdade da função lógica para a LUT (16 bits) e o bit de controle 

                                            
p
 Multiplexadores: São sistemas digitais que podem ser usados como conversores 

paralelo/serial selecionando sinais de entrada, através de sinais de controle. 



36 

 

  

do MUX (1 bit). Utilizando os CLBs, o usuário pode calcular elementos lógicos 

específicos. 

IOBs são circuitos responsáveis pelo interfaceamento das saídas 

provenientes das saídas das combinações de CLBs. São basicamente buffers, que 

funcionarão como um pino bidirecional entrada e saída da FPGA permitindo conexão 

com outros elementos da aplicação. Cada IOB pode ser usado como entrada ou 

saída dependendo do estado do OE (Output Enable). O bit OE pode ser programado 

estaticamente ou como um conjunto para a saída de um CLB. IOBs contêm flip-flops 

do tipo D para atraso (Latching) dos sinais de entrada e saída. As travas podem ser 

eliminadas por MUXs programados apropriadamente. Na Figura 6, um diagrama 

simplificado de um IOB é apresentado com dois flip-flops do tipo D. 

 

 

Figura 6 - Diagrama simplificado de um IOB. 

PSMs são trilhas utilizadas para conectar os CLBs e IOBs. Os recursos de 

interconexões possuem trilhas para conectar as entradas e saídas dos CLBs e IOBs 

para as redes apropriadas. Geralmente, a configuração é estabelecida por 

programação interna das células de memória estática, que determinam funções 

lógicas e conexões internas implementadas na FPGA entre os CLBs e os IOBs. O 

processo de escolha das interconexões é chamado de roteamento. Apesar de 

deixarem a FPGA mais versátil, PSMs causam atrasos nos sinais. No diagrama da 

Figura 7 são apresentadas duas PSMs interligando três unidades de CLBs. 

O roteamento é a forma pela qual os barramentos e as PSMs são 

posicionados para permitir a interconexão entre as células lógicas. Essa arquitetura 



37 

 

permite que se obtenha um roteamento completo e, ao mesmo tempo, uma alta 

densidade de portas lógicas.  

 

 

Figura 7 - Diagrama simplificado de uma PSM. As PSMs são utilizadas para 
interligar CLBs e IOBs através de trilhas tornando a configuração 
da FPGA mais flexível. 

A granularidade é uma característica das FPGAs e, a fim de classificá-las 

quanto ao bloco lógico, foram divididas em 3 categorias: grande granularidade: onde 

as FPGAs dessa categoria podem possuir como grãos unidades lógicas e 

aritméticas, pequenos microprocessadores e memórias; granularidade média: onde 

FPGAs de grão médio frequentemente contêm duas ou mais LUTs e dois ou mais 

flip-flops. A maioria das arquiteturas de FPGAs implementa a lógica em LUTs de 

quatro entradas; pequena granularidade: onde as FPGAs de pequeno grão contêm 

um grande número de blocos lógicos simples. Os blocos lógicos normalmente 

contêm uma função lógica de duas entradas ou um multiplexador 4x1 e um flip-flop. 

Por serem voláteis, as células de armazenamento dos LUTs acabam por 

perderem o conteúdo armazenado quando não há mais fornecimento de energia. 

Assim, a FPGA deve ser programada toda vez que for energizada. Geralmente 

utiliza-se uma pequena memória FLASH EEPROM cuja função é carregar 

automaticamente as células de armazenamento, toda vez que a FPGA for 

energizada. 



38 

 

  

As PSMs apresentam algumas propriedades, tais como tamanho, resistência, 

capacitância e tecnologia de fabricação, que afetam principalmente a velocidade e o 

tempo de propagação dos sinais e definem características como volatilidade bem 

como capacidade de reprogramação. Na escolha de um dispositivo reconfigurável, 

esses fatores devem ser avaliados. Basicamente existem três tipos de tecnologia de 

programação das chaves de roteamento:  

? SRAM, que por serem voláteis utilizam uma EEPROM para armazenar 

a programação e ocupam muito espaço físico, apesar de serem 

rapidamente programáveis;  

? Antifuse, essa tecnologia baseia-se num dispositivo de dois terminais, 

que no estado não programado apresenta uma alta impedância 

(circuito aberto);  

? Gate flutuante, cuja tecnologia baseia-se no uso de transistores MOS 

(Metal Oxide Semiconductor), especialmente construídos com dois 

gates flutuantes semelhantes aos usados nas memórias EPROM e 

EEPROM. O diferencial dessa tecnologia é a sua capacidade de 

programação e retenção de dados. Além disso, da mesma forma que 

uma memória EEPROM, os dados podem ser programados com o 

circuito integrado instalado em placa, característica denominada ISP 

(In System Programmability).  

Na Figura 8 é apresentada uma placa com FPGA fabricada pela Altera. 

 

 

Figura 8 -  Placa com um chip reprogramável desenvolvido pela Altera. No 
detalhe, o maior chip é a FPGA. 



39 

 

Para projetar se uma arquitetura usando uma FPGA, é preciso configurá-la 

(ou programá-la), escolhendo como o chip irá operar com um diagrama de circuito 

lógico ou código fonte. As técnicas para programação variam de HDL (Hardware 

Description Language) à linguagens de alto nível.  

A HDL é uma linguagem utilizada para uma descrição formal e construção de 

circuitos eletrônicos de lógica digital. Ela pode ser descrita como uma operação, 

projeto, organização de circuitos e testes são usados para verificar sua operação por 

meio de simulação69.  

A HDL facilita o trabalho de configuração, viabilizando a manipulação de 

grandes estruturas, sendo possível especificá-las numericamente sem a 

necessidade de desenhá-las à mão. Por outro lado, a entrada esquematizada 

permite uma especificação mais próxima da aplicação que deve ser atendida. 

HDL se caracteriza por expressões baseadas em textos tanto da estrutura 

espacial quanto da estrutura temporal e comportamento de sistemas eletrônicos. 

Como as estruturas da programação concorrente utilizada pela computação 

paralela, a síntese e a semântica da linguagem incluem uma noção explícita do 

tempo, que é um atributo primário de hardware.  

As duas linguagens HDL mais utilizadas, tanto no meio acadêmico como 

comercialmente, são a VHDL (VHSIC-HDL – Very High Speed Integrated Circuits – 

Circuitos Integrados com Velocidade Muito Alta) e Verilog. Smith
70

 faz uma 

comparação entre as duas linguagens dando ênfase nas suas similaridades e 

contrastando suas diferenças. 

As duas linguagens permitem que uma estrutura de hardware seja modelada 

efetivamente. Mas quando se modela um hardware abstrato, a capacidade da VHDL 

só pode ser atingida pelo Verilog quando se usa PLI (Program Language Interface – 

Interface para Linguagem de programação). 

A linguagem VHDL pode ter múltiplas unidades de projeto (pares de 

entidade/arquitetura) que ao estarem presentes no mesmo arquivo de sistema, 

podem ser compilados separadamente. O Verilog atua como linguagem de 

interpretação, assim a compilação pode melhorar o desempenho, mas não mudará a 

natureza da linguagem. Resultados podem ser obtidos pela mudança da ordem da 

compilação de arquivos separados. 

Vários tipos de dados definidos pelo usuário ou pela linguagem podem ser 

utilizados no VHDL. Dependendo da arquitetura a ser projetada, algumas funções 



40 

 

  

dedicadas são necessárias para converter um objeto de um tipo para outro. A 

escolha do tipo usado deve ser considerada, especialmente para os tipos de dados 

enumerados (abstratos). Isso poderá fazer os modelos serem mais fáceis de serem 

escritos, mais claros para serem lidos, e evitando funções de conversão 

desnecessárias que podem deixar o código obscuro. Comparado com VHDL, os 

tipos de dados do Verilog são mais simples, mais fáceis de utilizar e mais 

direcionados a modelagem de uma estrutura de hardware típica do que uma 

abstrata. Todos os tipos de dados são definidos pela linguagem utilizada e não pelo 

usuário.  

Em VHDL, procedimentos e funções podem ser colocados em pacotes e 

serem disponíveis para qualquer unidade de projeto que desejem utilizá-las. Em 

Verilog, por não existir esse conceito de pacotes, funções usadas dentro do modelo 

devem ser definidas nos módulos. 

VHDL permite usar construtos e modelagem de alto nível, bibliotecas para 

guardar entidades compiladas, arquiteturas, pacotes e configurações. Também, 

através dessas estruturas, é possível, gerenciar projetos maiores. Outras 

características relevantes incluem chamadas de procedimentos concorrentes e 

permite o uso de atributos chamados foreign, onde arquiteturas e subprogramas 

podem ser modelados em outras linguagens. A leitura e o entendimento do código 

em Verilog são mais simples, em parte pelo código ser similar à linguagem C
q
 (cerca 

de 50%) enquanto VHDL é baseado em linguagem Ada
r
. 

Verilog é uma linguagem mais fácil de familiarizar com desenvolvimento de 

arquiteturas em FPGA, mas suas limitações tornam VHDL mais interessante para 

um programador com maior experiência e que trabalhe com uma abstração maior
70

. 

Uma vez organizado um projeto, os arquivos fontes podem ser gravados em 

uma FPGA através de um framework desenvolvido pelo fabricante onde através de 

diferentes passos se produz um arquivo que traduz a programação desejada a qual 

é transferida para a FPGA via interface serial ou por um dispositivo de memória 

externa como uma EEPROM. 

                                            
q
 É uma linguagem de programação que desenvolvida para ser utilizado inicialmente no 

sistema operacional Unix. É a linguagem mais utilizada, influente e suportada pela maioria 
das arquiteturas. 
r
 É uma linguagem vista como extensão do Pascal, orientada a objetos e fortemente 
direcionada para programação concorrente. 



41 

 

As aplicações para FPGAs incluem o uso em processamento de sinais 

digitais, sistemas aeroespacial e de defesa, prototipagem para ASIC, imagens 

médicas, visão computacional, reconhecimento de voz, criptografia, bioinformática, 

emulação de hardware de computadores entre outras áreas. Algoritmos que podem 

ser utilizados para uso de paralelismo. FPGAs são também utilizadas em aplicações 

convencionais de computação de alto desempenho onde os núcleos computacionais 

com FFT e convolução são por eles calculados ao invés de se usar 

microprocessadores
71

.  



42 

 

  

  



43 

 

3 DESENVOLVIMENTO METODOLÓGICO E MATERIAIS  
 

Neste trabalho, é feito o uso de filtragem de Kalman
72

 utilizando uma estrutura 

de redes neurais artificiais (RNA) embarcada em uma FPGA. O principal objetivo é 

de filtrar a priori projeções de tomografia de amostras de solo e obter uma melhor 

relação sinal/ruído, o que impacta a imagem a ser posteriormente reconstruída. O 

filtro é projetado como um conjunto de portas lógicas como uma nova arquitetura 

específica diferentemente dos sistemas baseados em DSP onde os mesmos são 

programados como um software e gravados na memória do sistema para então 

serem processados em um núcleo dedicado. 

Os filtros de Kalman com RNA são vistos como extensões de filtros não 

lineares e as modificações são feitas diretamente nas equações para medição e 

correção dos parâmetros dos mesmos.  

O filtro de Kalman foi primeiramente utilizado para calcular posições precisas 

do sistema de navegação da nave Apolo em sua incursão até a Lua, garantindo que 

a trajetória para a chegada ao satélite natural e a volta a Terra
73

. Sem o filtro, os 

erros nos cálculos devido à incerteza da posição poderiam acumular o que levaria a 

nave a se chocar contra o corpo celeste. Desenvolvido na década anterior e aplicado 

como primeiro sistema embarcado crítico, o sistema inaugurou a era digital e o uso 

para a portabilidade de computadores, como também o florescimento da estatística 

aplicada em problemas reais com o processamento computacional.  

 

 

3.1 PROCESSAMENTO DIGITAL EM SISTEMAS EMBARCADOS 
 

 

O primeiro filtro de Kalman embarcado foi implementado como um ASIC, 

sendo um dos primeiros circuitos integrados, algo novo para uma época em que 

computadores e instrumentos eram, em grande parte, exclusivamente baseado em 

eletrônica analógica e limitados a grandes centros de pesquisas e universidades.  O 

ENIAC, por exemplo, apresentado em 1946, era do tamanho de uma sala de 

escritório. Hoje é possível ver que a evolução tecnológica de cinco décadas colocou 

milhões de ENIACS na palma da mão, com um custo de produção menor e mais 

atrativo. O que poucos sabem é que essa miniaturização de computadores, sem 



44 

 

  

perder o poder de processamento, remonta a construção do AGC (Apollo Guidance 

Computer – Computador de Navegação da Apollo)
74,75

.  

A Gemini foi a primeira a ter um sistema computacional completamente 

integrado no sistema de navegação sendo pioneira em uma nova geração de naves 

espaciais. Ela criou a necessidade de computadores de bordo e processamento em 

tempo real. O computador deveria processar um fluxo contínuo de dados de 

navegação e de radar e apresentar as soluções para a tripulação. Isso permitiu que 

a nave operasse de forma independente. O projeto da sua interface era orientado a 

tarefas. A interface de usuário consistia em um teclado com sistema numérico para 

entrada dos dados e um display mecânico (um display eletroluminescente verde de 

alta voltagem acionados por relês) com o endereço e conteúdo de uma simples 

palavra de memória. Sua principal função era fornecer dados para direcionar a 

localização no painel de instrumentos da tripulação. 

O AGC foi construído como um DSP (Digital Signal Processing), ou seja, 

partia do principio de um Hardware fixo que tinha uma programação gravada na 

memória para fazer o controle dos dados de entrada do sistema para retornar uma 

saída. DSP são utilizados essencialmente para processamento de sinais digitais, o 

que pode ser definido como a manipulação matemática de um sinal para modificá-lo 

ou melhorá-lo de alguma maneira.  

Esse processamento pode ser caracterizado pela representação do sinal em 

tempo, frequência ou outros domínios discretos, como por exemplo, uma sequência 

de números. O início do desenvolvimento comercial dos DSPs deu-se nos anos das 

décadas de 1960 e 1970 quando os computadores estavam tornando-se mais 

acessíveis, mas ainda eram caros e limitados a poucas aplicações críticas
76

.  

Dentre seus usos principais encontram-se: medir, filtrar e comprimir sinais 

analógicos em tempo real. Sua operação envolve como primeiro passo converter o 

sinal analógico para digital por amostragem, digitalizando-o com um conversor 

Analógico-Digital (ADC – Analog-to-Digital Converter), o que torna o sinal digital em 

um fluxo de números. Contudo, algumas vezes, a saída requerida do sinal é em sua 

forma analógica, o que requer um conversor Digital-Analógico (DAC – Digital-to-

Analogic Converter). Mesmo que o uso de DSP represente um processo mais 

complexo do que um processamento analógico, o seu poder computacional permite 

várias vantagens como detecção e correção de erros na transmissão de sinais, entre 

outros. Na Figura 9 é ilustrado o processo de discretização e reconstrução de um 



45 

 

sinal, o que ocorre respeitando-se o teorema da amostragem
s
. O sinal analógico é 

convoluído por um trem de impulsos, onde é feita a amostragem em pontos. A 

reconstrução do sinal é feita com base nas amostras, o que depende diretamente da 

qualidade amostral. f(x) corresponde a uma função representando o sinal analógico, 

s(x) um trem de pulsos, (f*s)(x) um sinal discretizado, l(x) uma função contínua e 

(f*s*l)(x) o sinal contínuo reconstruído. 

 

Figura 9 -  Processos de amostragem e reconstrução de sinais. 

A amostragem corresponde em discretizar o sinal espacialmente ou por 

tempo, ou seja, selecionar um limitado número de pontos para representá-lo. 

Denomina-se quantização o processo de discretizar os valores que representam a 

intensidade no ponto
77

.  

                                            
s
  Qualquer sinal no qual frequências maiores que f sejam nulas pode ser perfeitamente 

reconstruído se amostrado em uma frequência igual ou superior a 2f. A frequência limite 
para amostragem é também conhecida como Limite de Nyquist. 



46 

 

  

Algoritmos de DSP têm sido executados em computadores, em 

processadores especializados chamados processadores digitais de sinais 

construídos diretamente no equipamento, como as arquiteturas ASIC. Hoje existem 

tecnologias adicionais usadas para processamento digital de sinais que incluem 

microprocessadores, FPGAs, controladores de sinais digitais e processadores de 

fluxo. Dependendo da aplicação, os DSPs podem ser aplicados em sistemas 

embarcados que pode incluir ou não microprocessadores especializados
78

.  

Quando o processamento requerido não necessita ser em tempo real, ele é 

feito com computadores de uso geral por ser economicamente viável. O sinal passa 

a existir em arquivos de dados. Não há uma diferença maior do que outros tipos de 

dados, exceto no uso de técnicas matemáticas, cujo conjunto de dados deve ser 

usado, como na Transformada de Fourier, por exemplo. Quando o processamento 

requer ser de tempo real, DSP é sempre implementado usando microprocessadores 

especializados. Em geral, usa-se a aritmética de ponto fixo, mas existem versões 

mais potentes que se utilizam de unidades aritméticas de pontos flutuantes. Para 

aplicações que exigem tempo de resposta menor, essas unidades podem ser 

utilizadas.  

Atualmente, os sistemas embarcados fazem parte das atividades do dia a dia das 

pessoas devido ao baixo custo de seus desenvolvimentos e têm presença em 

praticamente todos os setores da sociedade. Eles são largamente utilizados em 

telefones celulares, eletrodomésticos, câmeras fotográficas, em automóveis e 

aviões
79

.  

Entretanto, o projeto de um sistema embarcado torna-se complexo devido a 

conceitos como o uso limitado de energia, portabilidade, memória limitada, 

segurança, confiabilidade e comunicação mantendo um processamento em nível 

adequado à aplicação que se projeta. Já um sistema embarcado crítico possui uma 

maior complexidade de desenvolvimento pela necessidade de ter uma maior 

confiabilidade e segurança com atividades com respostas em tempo real
80

. 

As possibilidades de se trabalhar com sistemas embarcados apresentam-se 

de forma vasta devido aos grandes desafios ligados aos projetos de arquitetura de 

computadores. 

Em um sistema mais complexo pode ocorrer à presença de componentes 

programáveis, com um software de aplicação composto por múltiplos processos, 

distribuídos em diferentes processadores e comunicando-se através de mecanismos 



47 

 

variados. A hierarquia de conexões programáveis permite que os blocos lógicos 

sejam interconectados quando desejado pelo projetista do sistema, comportando-se 

como um sistema de um único chip programável.  

Vários trabalhos sobre a implementação de filtros em FPGA, seja para 

aumentar o desempenho ou apenas para satisfazer uma solução em sistemas 

embarcados, são oferecidos na literatura
80-82

. 

 

 

3.2 FILTRO DE KALMAN 
 

 

3.2.1 FILTRO DE KALMAN DISCRETO 
 

 

O filtro de Kalman foi criado para ser um filtro de correção on-the-fly, que se 

caracteriza por obter um valor preciso das medidas através das observações de 

amostras. O filtro em sua versão básica é considerado um ótimo estimador linear, 

mas possui outras restrições
83

.  

As equações abaixo apresentam o conjunto de funções lineares necessárias 

para a aplicação do filtro:  

 

 
           
         

      (8) 

 

onde xk é o estado atual que possui uma média    com uma matriz de erro com 

covariância Pk, que determina a confiabilidade da medida, qk  é o ruído do processo 

que é assumido ter uma média zero com uma distribuição normal multivariada e uma 

covariância Qk. rk é ruído de observação que é assumido como um ruído Gaussiano 

branco com média zero, com uma covariância Rk. A e H são matrizes de 

transferências que permitem fazer a dinâmica entre os estados.  zk é  vetor de 

estados observados. 

As restrições mais comuns estão no conhecimento profundo do problema, 

como valores iniciais para as medidas, as equações do sistema para o processo 

(que é alimentado com o valor anterior) e de observação (que depende dos valores 



48 

 

  

da equação do processo) e as covariâncias que determinam o processo e a 

incerteza da observação: 

 

 

           

          

          

      (9) 

 

Essa função linear é constituída de um vetor coluna, que por sua vez é 

multiplicado por uma matriz de transferência e somada a outro vetor coluna. Esses 

vetores colunas podem ser escalares, sendo que a matriz de transferência (que 

acompanha as dimensões do vetor coluna) também será escalar. 

A principal característica da filtragem linear é a sua habilidade de fazer uma 

predição dada uma função linear conhecida. O filtro de Kalman Discreto se 

caracteriza por um conjunto de equações: 

 

 
 
 

 
 

   
       

   
        

   

      
       

      

       
            

  

              
 

     (10) 

 

onde xk-1 representa um vetor de estados conhecidos a priori que através de uma 

matriz de transferência é estimado o vetor de estado futuro     
 

. Pk-1 representa a 

matriz de covariância do vetor de estados xk-1.    
 

 representa a covariância estimada 

usando a covariância Pk-1 e Kk  representa o ganho de Kalman, usado para corrigir 

os estados quando multiplicado com o erro de observação dado por         
  . O 

par           são os estados e a covariância estimados pelo filtro.  

A covariância do ruído na observação pode ser facilmente medida, mas o 

comportamento do sinal caracterizado na equação do processo pode variar 

dependendo da aplicação. O próprio filtro tem a capacidade de estimar estados 

ocultos à observação e criar um modelo linear onde os estados ocultos influenciem a 

estimação do próximo estado: 

 



49 

 

 
 
 

 
  

  
 

  
 

 

  
   
   
   

  

  
 

  
 

   

  
   
   
   

  

  
 

  
 

 

         

  
 

  
 

 

   

    (11) 

 

Esta é uma solução ótima quando o problema é linear, mas quando o 

problema passa a ter um comportamento não linear, a aproximação não é tão 

precisa e há uma demora na resposta de convergência e pode apresentar perda na 

precisão dos dados.  

 

 

3.2.2 FILTRO DE KALMAN ESTENDIDO 
 

 

Um sistema não linear pode ser representado como funções não lineares do 

processo e observação: 

 

 
             
           

      (12) 

 

O filtro de Kalman Discreto pode ser modificado para aceitar funções 

conhecidas que variam no tempo. Quando se conhece a função, mas não se 

conhece as matrizes lineares, elas podem ser obtidas no tempo, através de cálculos 

envolvendo gradiente da função a ser linearizada
84

, ou seja: 

 

     
  

  
      (13) 

   
  

  
      (14) 

 

 Assim, o algoritmo do filtro de Kalman Discreto pode ser reescrito como: 

  



50 

 

  

 
  
 

  
 

   
         

   
              

   

   
   

   

    
     

       
             

   

               
 

     (15) 

 

O problema da linearização é que envolve cálculos de matrizes jacobianas
t
 e 

hessianas
u
, que nem sempre são eficientes e precisos e depende do conhecimento 

das funções. Como nem sempre a função de processo é conhecida, pode-se usar 

uma RNA para fazer um mapeamento e a partir da entrada e dos pesos da rede 

estabelecer um cálculo mais preciso da matriz de linearização. Assim o filtro teria a 

capacidade de resolver de forma mais precisa um problema linear anteriormente 

trabalhado de acordo com as entradas e as saídas observadas. 

 

 

3.2.3 FILTRO DE KALMAN COM REDES NEURAIS ARTIFICIAIS 
(RNAS) 

 

 

Como o filtro também tem a capacidade de estimar estados ocultos, o filtro de 

Kalman pode treinar uma RNA a partir de observações, modificando os valores de 

pesos de acordo com a saída observada, como um treinamento supervisionado. 

Os pesos treinados podem ser utilizados como parâmetros em outro  filtro 

para a estimação de novos estados. Ainda há a possibilidade de interligar os dois 

filtros para trabalharem de forma conjunta, com estimação de parâmetros e estados 

em tempo-real. Neste caso específico, um filtro treina a RNA de acordo com a saída 

do outro filtro de forma dinâmica.  

 

O processo de treinamento das RNAs pode ser feito utilizando filtros de 

Kalman. Assim, ele pode ser realizado utilizando-se um filtro dedicado para o 

treinamento e outro filtro, que auxilia no estabelecimento dos pesos da rede neural, 

                                            
t
 Matrizes formadas pelas derivadas parciais de primeira ordem de uma função vetorial. 

u
 Matrizes formadas pelas derivadas parciais de segunda ordem de uma função vetorial. 



51 

 

isto é, com base na estimativa dos estados/pesos da RNA para mapear a função de 

transferência da equação de processo.  

Desta forma, as equações do sistema passam a ser descritas como: 

 

 
             

 
            

              (16) 

                 

A estimativa de parâmetros envolve a determinação de um mapeamento não 

linear, dado por 

 

                    (17) 

 

onde xk é a entrada, W representa os pesos e yk é a saída. O mapeamento não 

linear g é parametrizado pelo vetor W. O mapeamento não linear é assim feito pela 

RNA, onde W é conjunto de pesos. O aprendizado corresponde à estimação dos 

parâmetros de W. O treinamento pode ser feito com pares de amostras, envolvendo 

uma entrada conhecida e saída desejada (xk,dk). O erro é definido pela equação 18. 

O objetivo do aprendizado envolve a minimização do erro quadrático esperado, isto 

é: 

 

                  (18) 

 

Para se estimar os parâmetros, escreve-se um novo conjunto de equações 

para a representação estado-espacial, na forma: 

 

 
          

              
 
               (19) 

 

onde os parâmetros Wk correspondem a um processo estacionário com uma matriz 

identidade de transição de estado, governado por um ruído processual vk (a escolha 

da variância determina o desempenho da filtragem). A saída yk corresponde a uma 

observação não linear em Wk. O filtro de Kalman Descentralizado pode ser aplicado 

diretamente como uma eficiente técnica de terceira ordem para correção dos 

parâmetros. 



52 

 

  

Como o problema de estimação consiste em trabalhar sobre uma entrada xk 

não observada e requer uma união entre a estimação dos estados e parâmetros, o 

mesmo deve ser considerado um problema de estimação conjunta com pesos e 

estados, considerando uma dinâmica discreto-temporal de um sistema não linear, o 

qual pode ser escrito na forma: 

 

 
 
    
  

   
           

  
 

           

      (20) 

 

onde ambos os estados do sistema dado por    e o conjunto dos parâmetros W para 

o sistema dinâmico devem ser estimados através de uma observação do estado 

observado (ruidoso)   . 

As técnicas utilizadas em Inteligência Artificial (Computacional) e em 

estimação com o filtro de Kalman são usadas para aumentar a eficiência de filtragem 

e resolver problemas de ordens mais elevadas. Só que o filtro de Kalman ainda 

precisa de uma matriz de transferência conhecida na equação de processo para 

uma estimação ótima. Logo viu-se a necessidade de arranjar um novo método para 

que o filtro de Kalman suporte funções não lineares sem perder a precisão ou que 

haja um controle maior na mesma. 

A maior precisão e mapeamento de funções não lineares são feitos através 

de transformada descentralizada. O controle da precisão passa a ser feito por novos 

parâmetros, o que aumenta o grau de complexidade do filtro, mas permite que os 

novos valores fossem reais e não aproximados. Esse tipo de filtro é chamado 

usualmente de Filtro de Kalman Descentralizado (Unscented Kalman Filter), que 

será apresentado na próxima seção. 

 

 

3.2.4 FILTRO DE KALMAN DESCENTRALIZADO 
 

 

O filtro de Kalman Descentralizado é similar à versão extendida
85

. A 

distribuição de estados é representada por uma variável aleatória Gaussiana, 



53 

 

especificada pelo uso de um conjunto mínimo de pontos de amostragem 

cuidadosamente escolhidos.  

Os pontos amostrados capturam as verdadeiras médias e covariâncias de 

uma variável aleatória e quando ela é propagada através de uma função não linear, 

promovendo, de forma precisa, uma estimação de terceira ordem para qualquer não 

linearidade. Todo esse processo é feito através do uso de um processamento 

descentralizado como pode ser ver na Figura 10. 

 

 

Figura 10 - Processo o qual o filtro de Kalman Descentralizado faz uma 
estimação da média e covariância de uma variável aleatória. 

Considere um espalhamento da variável aleatória x (com dimensão L) através 

de uma função não linear y=g(x), assumindo que ela possui uma média     e 

covariância Px para calcular y. Isso pode ser feito para formar uma matriz X de 2L+1 

vetores sigmas (com correspondência aos pesos Wi), de acordo com: 

 



54 

 

  

 
 
 
 

 
 
 

    

                              

                                 

  
   

        

  
   

                 

 
 
   

  
 
   

                           

    (21) 

 

onde  = 
2
(L+k)-L é um parâmetro escalar. A variável   determina o ponto de 

espalhamento sigma em volta da média    e é sempre um mínimo positivo. k é um 

parâmetro escalar secundário definido como 0.   é usado para incorporar o 

conhecimento a priori da distribuição de x (para distribuições Gaussianas,  =2 é 

assumido como um valor ótimo).             é a i-ésima linha da matriz da raiz 

quadrada. (c) denota os pesos da covariância e (m) os pesos da média. 

A transformação descentralizada é um método usado para calcular as 

estatísticas de uma variável aleatória através de uma transformação não linear, 

como pode ser vista na Figura 11.  

 

Figura 11 - Esquemático para uma transformação descentralizada da 
covariância. 

 Os vetores sigmas são propagados através da função não linear: 

 

                            (22) 

 

A média e a covariância    são aproximadas pelo uso da média e covariância 

da amostra nos pontos sigmas, isto é: 



55 

 

 

  
    

 
   

  
  
   

      
   

            
   

   

    (23) 

. 

Este método se difere dos métodos gerais de amostragem (como os métodos 

de Monte-Carlo e os filtros de partículas), que requerem ordens de magnitudes 

ampliadas com um maior número de pontos amostrados numa tentativa de definir e 

propagar as distribuições dos estados (possivelmente distribuições não Gaussianas) 

86-88
. A descentralização aborda os resultados de uma forma mais precisa para as 

entradas, que envolvem distribuições Gaussianas de terceira ordem para todas as 

não linearidades. 

O filtro de Kalman descentralizado é uma extensão direta da transformação 

descentralizada para a equação de estimação recursiva 

 

       
            

      (24) 

 

onde o estado das variáveis aleatórias é redefinido com a concatenação dos estados 

originais e do ruído: 

 

   
     

   
   

   .      (25) 

 

A seleção dos pontos sigmas é aplicada para um novo estado da variável 

aleatória para selecionar e calcular a matriz sigma correspondente    
 
.  

Com o uso das funções do modelo e a transição de estados feita pela 

contribuição de propagação de pontos sigmas, elimina-se a necessidade de se 

calcular matrizes jacobianas ou hessianas. O número de cálculos total é o mesmo 

do filtro em sua forma estendida relacionado ao controle não linear que requer uma 

retroalimentação dos estados. Nestas aplicações, o modelo dinâmico é um modelo 

paramétrico que é assumido como conhecido. 

Devido à instabilidade numérica do ruído e do uso da fatoração de Cholesky
v
 

para determinar a raiz quadrada da matriz de probabilidade, van der Merwe e Wan 

                                            
v 
É o método que permite que uma matriz simétrica e positiva definida possa ser decomposta em uma 

matriz triangular inferior e sua transposta. A fatoração de Cholesky é muito útil na resolução de 



56 

 

  

desenvolveram o Filtro de Kalman Descentralizado de Raiz Quadrada, o que permite 

um melhor controle dos valores da matriz de variância que devido ao problema da 

matriz vir a ser negativa ou indefinida
88

. Como o Filtro de Kalman Descentralizado 

original, o filtro de Kalman Descentralizado de Raiz Quadrada é inicializado 

calculando-se a raiz quadrada da matriz de covariância dos estados pela fatoração 

de Cholesky, isto é: 

 

                          
            (26) 

 

O filtro de Kalman Descentralizado com o uso de raiz quadrada é formado 

pelas equações 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38 e 39: 

 

a) Cálculo dos pontos sigmas: 

 

   
        

      
            

     (27) 

 

onde X é o conjunto de pontos onde a transformada descentralizada é baseada na 

média e na covariância a priori.  

 

b) Equações de Predição: 

 

   
    

 
     

                 (28) 

 

onde W
(m)

 representa o conjunto de pesos dos pontos sigmas usados para a 

reconstrução da média verdadeira. 

 

  
         

   
            

     
             (29) 

 

onde W
(c)

 representa o conjunto de pesos dos pontos sigmas usados para a 

reconstrução da covariância verdadeira. 

                                                                                                                                        
problemas de ortoganalização de sinais. A decomposição de Cholesky se dá da forma A=LD(L’) onde 
L é matriz triangular inferior(com 1 na diagonal principal) e D é matriz diagonal. 



57 

 

Uma subsequente atualização de Cholesky (ou regressão) na equação abaixo 

é necessária desde que o peso W0 talvez seja negativo: 

 

  
               

      
     

    
   

    (30) 

      
        

      
       (31) 

 

onde F é a função da propagação das transições dos estados dos pontos sigmas. 

 

c) Equações de Correção:  

 

             
      

       (32) 

 

onde   é a função do sistema para a geração dos pontos sigmas para os estados 

observados  . 

 

   
    

 
     

           
 

     (33) 

 

onde y é o estado observado estimado, reconstruído pelos pontos sigmas. 

 

     
         

   
            

             (34) 

     
                 

          
    

   
 .   (35) 

 

Diferente da maneira que o ganho de Kalman é calculado no filtro de Kalman 

Descentralizado padrão, aqui o ganho é calculado usando-se duas inversões: 

 

           
               (36) 

 

onde as equações que representam a correção da média a priori: 

 

       
          

        (37) 

 



58 

 

  

Uma vez que a matriz de covariância é quadrada e triangular, uma troca 

eficiente pode ser usada para resolvê-la diretamente, sem que se tenha que inverter 

a matriz. Finalmente a fatoração de Cholesky atualiza a variância do estado, a qual é 

calculada aplicando uma sequência de regressões de Cholesky, ou seja:  

 

                
           (38) 

 

Logo, o vetor para a regressão é representado pela coluna da equação na forma: 

 

               (39) 

 

Tendo o conhecimento a priori da função do processo e utilizando um filtro de 

Kalman que suporte funções não lineares, é possível obter-se uma melhoria 

significativa na relação sinal/ruído considerada.  

Quando não se conhece a função do processo ou até mesmo a distribuição 

da variável não é considerada uma distribuição Gaussiana, o uso de uma rede 

neural pode ajudar a promover uma melhor função de mapeamento do processo 

para a redução do ruído. Para isso, uma estimação dos pesos faz-se necessário. 

Neste contexto, utilizando o princípio da não linearidade do filtro de Kalman 

Descentralizado para o uso de função não linear e a experiência de se estimar 

estados ocultos Markovianos
w
, podendo fazer uma estimação conjunta envolvendo 

os pesos e os estados.  

Para se determinar o comportamento de uma função, pode-se utilizar o 

próprio filtro para predição linear ou fazer uma predição não linear usando as redes 

neurais.  

Trabalhos anteriores focaram o uso de filtro de Kalman em filtragem de 

projeções tomográficas e apresentaram as eficiências dos resultados considerando 

a estimação linear ou a estimação feita com o uso de redes neurais, bem como os 

primeiros passos para seu uso em um sistema embarcado usando FPGA
16,45,46,89-93

.   

                                            
w
 Cadeia de Markov é um caso particular de processo estocástico com estados discretos onde os 

estados anteriores são irrelevantes para a predição dos estados seguintes, desde que o estado atual 
seja conhecido. Um modelo oculto de Markov é um modelo estatístico em que o sistema modelado é 
assumido como um processo de Markov com parâmetros desconhecidos, e o desafio é determinar os 
estados ocultos a partir dos estados observáveis.  



59 

 

O uso de RNA permite que relações entre variáveis sejam entendidas como 

funções a serem mapeadas. Num sistema real, todas as variáveis são aleatórias, ou 

seja, trabalham dentro de um determinado campo de valores com uma média e 

variância conhecidas ou aproximadas. Em se tratando de precisão, o valor em 

determinado tempo pode se apresentar diferentemente de outros valores passados 

e valores que ainda serão aferidos.   

 

 

3.3 MÉTODO DE RECONSTRUÇÃO TOMOGRÁFICA DE RAIOS X 
 

 

As maiores contribuições para o desenvolvimento da tomografia 

computadorizada derivam-se dos trabalhos de Radon (1917), Cormack (1963)
 
e 

Hounsfield (1973)
26,29,30

. Radon foi o primeiro a apresentar soluções matemáticas 

para a reconstrução de corpos a partir de projeções, enquanto Cormack 

desenvolveu técnicas para reconstruir imagens utilizando o método de retroprojeção, 

desconhecendo o trabalho de Radon. Já Hounsfield desenvolveu o primeiro 

tomógrafo computadorizado de raios X. 

A tomografia computadorizada, de raios X e gama de 1ª geração, utiliza um 

feixe colimado de radiação, o qual define planos tão finos quanto o próprio feixe e, 

através de vários feixes colimados paralelos, podem-se definir vários planos. Assim, 

obtêm-se valores que formam projeções a partir de cada reta de propagação dos 

feixes que partem da fonte para o detector. 

Na Figura 12, observa-se uma linha tracejada que representa a radiação que 

parte da fonte para o detector. Ela atravessa o objeto e, à medida que o conjunto 

caminha através dos eixos L’ e L, que formam com o eixo x o ângulo ?, as projeções 

vão sendo obtidas.  

As varreduras devem ser realizadas para n valores de   dentro do intervalo de 

0&amp;lt;&lt;180
o
. Assim, obtém-se a varredura completa da transformada de Radon do 

objeto. 

 

 



60 

 

  

 

Figura 12 - Ilustração da tomografia de transmissão de um tomógrafo de 1ª 
geração onde são feitas varreduras da amostra utilizando-se de 
movimentos de translação e rotação

43
. 

A partir das projeções amostradas é possível usar a transformada inversa de 

Radon ou de métodos derivados desta transformada para a reconstrução da fatia, 

como pode ser visto na Figura 13.  

 

Figura 13 -  Projeção paralela de f(x,y) para a Transformada de Radon
43

. 

 



61 

 

A qualidade da imagem reconstruída dependerá diretamente da qualidade da 

amostragem das projeções e do método usado para a reconstrução. 

O raio        no plano onde z = 0 pode ser expresso matematicamente por: 

 

                  (40) 

 

onde t é a distância perpendicular da origem até a linha.  

Com o uso desta equação do raio, a integral do raio P?(t) é dada por: 

 

                                            
 

          
.  (41) 

 

 Com P?(t) sendo uma função de t representando a projeção paralela com 

ângulo ? contínuo, a função P?(t) é a transformada de Randon de f(x,y). As 

projeções dadas foram obtidas paralelamente à rotação no eixo x nomeada por t. 

  Um dos principais algoritmos para a reconstrução de imagens tomográficas é 

o algoritmo de retroprojeção filtrada, por fornecer rapidez, precisão e facilidade em 

sua implementação
5
. O princípio é que o coeficiente de atenuação é estimado pela 

soma total dos coeficientes que atravessam o ponto.  

Ele pode ser visto como uma derivação dos teoremas das secções de Fourier 

adotando o uso de coordenadas polares no lugar dos sistemas de coordenadas 

retangulares: 

 

                     
                  

 

 

  

 

               
                  

 

 

 

 

                    
                                

 

 

 

 

 (42) 

 

Usando                     na equação 42 pode-se escrever 

       como a ajuda do teorema das secções de Fourier e a expressão   em termos 

de   e   como definidos pela transformada inversa de Fourier:  

 

                            
 

  
   

 

 

              
       

 

  
   

 

 

   (43) 



62 

 

  

 

A forma filtrada retroprojetada da equação 43 é construída a partir da 

equação em duas operações diferentes. A primeira é a filtragem dos dados de 

projeção para cada ângulo  , como se segue: 

 

                
       

 

  
   (44) 

 

A segunda equação baseia-se na retroprojeção das projeções filtradas para 

se obter a função objeto: 

 

                            
 

 
    (45) 

 

Para cada pixel(x,y) no plano da imagem, existirá um valor de          

       para cada projeção filtrada Q?, obtida no ângulo ?. Cada uma destas 

projeções filtradas contribuirá para a reconstrução do ponto (x,y) com seu valor em t. 

Conforme pode ser observado na Figura 14 todos os pontos sobre a linha LM 

receberão a mesma contribuição de     para o ângulo ?i
94

. 

 

Figura 14 - Retroprojeção dos pontos sobre a linha LM a partir do dado  
  
    

da projeção filtrada  
  

9. 

  



63 

 

3.4 MODELAGEM DO SISTEMA DE FILTRAGEM A SER 
EMBARCADO 

 

 

O modelo físico da contagem de fótons é definido pela equação: 

 

      
          (46) 

 

onde I0  é o número de fótons que sai da fonte de raios X e gama, ? é o coeficiente 

de atenuação linear de raios X, d é a distância entre a fonte e o detector e Ii é a 

contagem de fótons que passam através do material e chega ao detector. A 

contagem de fótons é afetada por um ruído do tipo Poisson.  

Para uma modelagem mais próxima ao modelo físico, primeiro trabalhou-se 

cada projeção de forma individual, como se fossem posições variantes no tempo. 

Essa abordagem clássica permitiu desenvolver uma dinâmica para a estimação das 

projeções livre de ruídos, ou seja: 

 

 
               

           
              (47) 

 

Onde Pk é uma projeção livre de ruídos e Ik, uma projeção perturbada por ruídos. As 

variáveis qk-1 e rk são ruídos brancos, isto é, possuem distribuição qk-1~N(0,Q) e 

rk~N(0,R), isto é, distribuição Gaussiana normal com médias iguais a 0 e variâncias 

Q e R, respectivamente.  

A função f pode ser utilizada como um mapeamento de redes neurais ou uma 

matriz de transferência de estados. A função h é uma função que oculta os estados 

não observados, também podendo ser representada por uma matriz. Ela também 

pode ser ajustada ao ruído Poisson utilizando a transformada de Anscombe
95

.  

O que se propõe nesse trabalho é utilizar um novo modelo baseado no 

modelo físico, determinando as variáveis do processo e como é feita a observação. 

A equação de processo define um estado anterior xk-1 através de uma 

transformação feita pela função f e influência de um ruído branco qk-1, se chega ao 

um novo estado xk. Estes estados podem ser ocultos à saída do sistema. Assim, é 



64 

 

  

possível definir uma nova função g que permite transformar essa variável de acordo 

com o que é observado. 

O sistema de incerteza do processo de estimação do valor real possui um 

intervalo de confiança que é definido pela contagem de fótons e que é dado pelo 

ruído Poisson. Essa incerteza pode ser filtrada com a estimação de outras medidas 

na equação que são independentes desse intervalo de confiança. Logo, o que acaba 

sendo filtrado são os ruídos provenientes do detector, ou seja, ruídos mecânicos e 

eletrônicos. 

Uma forma de aumentar a confiança no valor esperado é mudar o foco sobre 

o que deve ser estimado para se obter um valor mais confiável de uma medida 

esperada.  

Como a variação do ruído de Poisson tem uma distribuição média e variância 

de valores iguais ao número de fótons, podemos definir um novo sistema baseado 

numa equação de processo em que o raio-soma µk é a variável utilizada no processo 

que permite a observação da projeção, conforme ela se apresenta na matriz de 

projeções: 

 

 
             

        
        

      (48) 

 

A função h é relacionada à transformada de Anscombe que faz com que a 

variância do ruído branco seja uma aproximação ao ruído Poisson. Para promover 

uma melhor estimação da transição dos estados do processo, pode-se usar uma 

RNA, ou seja:  

 

 
 
  
  

   
            

       
 

        
         

     (49) 

 

Agora, focando-se na equação de observação, pode-se tratar a variância do 

ruído da observação com a transformada de Anscombe através do uso combinado 

com sua inversa, 

 

    
        

             (50) 



65 

 

 

onde A representa a transformada e A
-1

 sua inversa. Isso permite trabalhar com um 

ruído Gaussiano com a distribuição rk~N(0,1).  

Pode-se desenvolver uma equação baseada na equação 4 que determina que 

o ruído Poisson possa ser determinado como  

 

     .      (51) 

 

Assim, podemos escrever a equação de observação como: 

 

      
         

       .     (52) 

 

onde rk por ter uma distribuição Gaussiana, assumindo, também, valores negativos 

ou nulos. Essa alternativa permite se desviar do uso da transformada de Anscombe 

que é apenas uma aproximação. 

Outro modelo para a equação de forma simplificada pode ser definido por: 

 

      
              (53) 

 

onde rk passa a ter uma variância dada pela relação sinal/ruído igual a 

 

   
  

   
.      (54) 

 

Esse tipo de abordagem permite fazer a inclusão de outros ruídos presentes 

no sistema de contagem de fótons através da propagação de erros.  

Para definir a covariância do ruído de observação R, o ruído a ser tratado leva  

em conta n medidas de grandezas primárias feitas a partir da observação das 

variáveis do sistema {Io,µ,d}. O cálculo de I é feito a partir da relação entre essas 

variáveis. Em linguagem formal, pode-se escrever: 

 

           .     (55) 

 



66 

 

  

Se os erros com que as grandezas Io, µ e d medidas forem dados por ?I0, ?µ 

e ?d,  o erro ?I da contagem de fótons será dada pela expressão 

 

    
  

   
      

  

  
     

  

  
   .   (56) 

 

Os valores de        e    são dados pelo desvio padrão da média ou por seu 

estimador conforme se tem muita ou pouca medidas das grandezas Io, µ e d. 

Pode-se determinar o erro estatístico das variáveis físicas independentes e 

tornar dependente a variância da variável física para o cálculo do erro estatístico das 

variáveis físicas independentes, bem como tornar a variância da variável física 

dependente para o cálculo do erro estatístico, isto é: 

 

  
   

  

   
 

 

   
   

  

  
 

 

  
    

  

  
 

 

  
 
.   (57) 

 

Além da incerteza das variáveis do sistema, tem-se um ruído característico do 

detector. Essa variação do ruído é conhecida quando se fecha o detector, mas 

mesmo assim contagens são observadas.  

Contagens observadas estão associadas diretamente a um ruído aditivo, 

podendo ser acrescentado na equação como um erro ligado à variável I: 

 

  
   

  

   
 

 

   
   

  

  
 

 

  
   

  

  
 

 

  
   

  

  
 

 

  
 .    (58) 

 

Logo,   
  passa a definir a covariância do ruído de observação de entrada do 

filtro dada por R. 

Na literatura são definidos modos de inferir a covariância do ruído do 

processo dado por Q. Desde que o sinal é observado, pode-se usar a covariância do 

sinal ruidoso para definir a covariância Q
84

.  

Como a covariância do processo é diretamente associada ao vetor ?, a 

equação de Beer-Lambert pode ser escrita como: 

 

      
  

 
        (59) 



67 

 

 

Para este vetor, a covariância Q necessária para entrada do filtro, pode ser 

obtida como: 

 

           
      (60) 

 

Mas, para uma estimação mais precisa, é necessária uma covariância de 

processo livre de ruídos ou aproximada. Inferindo que S seja a covariância do sinal 

ruidoso, Q a covariância do ruído do processo e R a covariância do ruído da 

observação, tem-se a seguinte relação: 

 

           (61) 

 

Como R pode ser medido no sistema e se pode obter um Q que seja afetado 

pelo ruído com variância R  pode-se chegar a   

 

           (62) 

 

Isso pode ser feito usando a técnica de propagação de erros para se obter 

uma covariância   na grandeza dos processos Q e S. 

Outro passo importante é a definição das constantes de controle  ,   e ?. 

Como a magnitude da variável do processo µ difere da variável da observação I,  =1 

foi escolhido. No caso deste valor ser maior ou menor do que o ideal não há 

possibilidade de filtragem, podendo causar, ainda, instabilidades numéricas no filtro. 

Como sugerido na literatura, para um parâmetro ou uma estimação conjunta, a 

variável   se mantém como  =2, enquanto o valor de ? passa a ser igual a 3-n, onde 

n está relacionado ao número de neurônios. 

Neste trabalho, os equipamentos utilizados envolveram um minitomógrafo de 

raios X e gama de primeira geração e um microtomógrafo
24

 para medidas 

micrométricas, ambos desenvolvidos na Embrapa Instrumentação
12

, um computador 

desktop (equipado com um processador Quad-core) e um kit de desenvolvimento de 

FPGAs Cyclone III (EP3C120F780), fabricado pela Altera, conforme ilustrado na 

Figura 15.  



68 

 

  

 

Figura 15 - Kit de desenvolvimento em FPGA fabricado pela Altera que será 
utilizado para o embarque do filtro de Kalman. 

 

O Kit de desenvolvimento de FPGA utilizado para o embarque do filtro  

apresenta as seguintes configurações: 

? Circuito USB-Blaster™ que inclui um CPLD Altera MAX
®
 II que permite 

carregar os arquivos de configuração da FPGA via cartão de memória 

flash ou por um computador. 

? Memória principal de 256 MB DDR2 SDRAM com canal duplo com 

correção de erros. 

? Memória SRAM de 8 MB, que permite fazer uma ponte entre 

processador e acesso à memória principal. Quanto maior a sua 

capacidade, menor será o acesso à memória principal, poupando ciclos 

de processamento enquanto é feita a busca. 

? Memória flash de 64MB que permite que uma grande quantidade de 

dados seja armazenada sem precisar descartá-los. Um arquivo de 

projeção não passa de 100 kB. 

? Portas de comunicação variadas como saída para rede, Ethernet 

10/100/1000, e USB 2.0 permitindo conectar praticamente qualquer 

equipamento desenvolvido no mercado com arquitetura IP ou conexão 



69 

 

universal. Essas conexões vão permitir a gravação da FPGA, bem 

como que a comunicação entre a FPGA e o computador seja mais 

rápida. 

? Dois osciladores on-board de 50 MHz e 125MHz não havendo 

necessidade de se usar nenhum outro circuito externo para esta 

finalidade. 

? Dois conectores para entrada e saída analógica e um HSMC, bem 

como conversores digitais-analógicos que permitem acessar 

diretamente dados dos módulos do minitomógrafo que possuem saídas 

analógicas e digitais. 

? Vários botões, interruptores e indicadores que podem ser programados 

de acordo com um projeto a ser desenvolvido. 

? Duas telas: uma de gráficos com resolução de 128x64 pixels e outra 

com 2 linhas X 16 caracteres (ambas com tecnologia LCD). 

Para o trabalho desenvolvido, em um ambiente de simulação o desempenho 

do filtro de Kalman mostrou-se equivalente ao código gerado em Matlab
®
. O 

algoritmo ainda apresenta alguns gargalos que deverão ser otimizados com a 

introdução de códigos em HDL e estruturas específicas fornecidas no software da 

fabricante da FPGA, como o DSP Builder
®
, um toolkit integrado com o Simulink

®
 do 

Matlab
®
. Apesar disso, os códigos para algumas funções complexas como a 

fatoração de Cholesky e multiplicação de matrizes já foram otimizados com o uso do 

Matlab
®
.  

Algumas funções foram transformadas em C e depois em HDL, o que 

necessitou de novos ajustes, mas devido a sua complexidade pode não foi viável ou 

eficiente escrevê-las diretamente em HDL.  

Neste contexto, uma ferramenta gráfica também está sendo desenvolvida 

para permitir o acesso às projeções, tanto diretamente do minitomógrafo quanto da 

FPGA, além de permitir uma comunicação da FPGA para filtrar dados que já estejam 

no computador. Isso permite uma flexibilidade além de utilizar a FPGA como um 

dispositivo externo de alto desempenho.  O diagrama apresentado na Figura 16 

ilustra esta parte do trabalho em desenvolvido. 

Utilizando o bloco embedded Matlab function presente no Simulink
®
 é 

possível gerar um código em HDL do algoritmo escrito como uma função do Matlab
®
, 



70 

 

  

permitindo uma implementação mais simples e precisa do que refazer cada função 

com blocos e conexões. 

 As limitações se baseiam no uso da memória dinâmica e de funções não 

suportadas pelo codificador HDL ou pelo uso de aritmética em ponto fixo que não 

possui uma função relacionada em C como sqrt (raiz quadrada), pow ou ^ (potência), 

exp (exponencial), chol (fatoração de Cholesky), cholupdate (atualização de 

Cholesky), entre outras. Algumas funções como a cholupdate podem ser 

substituídas por implementações próprias de usuários. Outras funções são 

suportadas pelo DSP Builder
®
 como sqrt e pow, mas seu uso na forma algébrica 

pode demandar trabalho adicional. 

 

Figura 16 - Diagrama esquemático do sistema de filtragem de projeções a 
priori e a posteriori do processo de reconstrução de imagens. 

 

 

3.5 CORDIC 
 

 

Como algumas funções não são suportadas pelo codificador HDL ou não 

suportam a aritmética de ponto fixo, a solução foi construí-las usando técnicas que 

garantam a precisão e sejam otimizadas para chegar ao resultado ótimo em menor 



71 

 

tempo com o mínimo de recursos. A precisão em funções não lineares demandam 

um tempo maior no processamento devido ao uso de séries temporais cujo tamanho 

define a convergência dos valores processados. Para se obter uma melhor precisão 

em um menor tempo de processamento. 

Uma calculadora é um tipo de sistema embarcado que não possui muita 

memória e tem capacidade de processamento limitada quando se compara com um 

computador de uso geral, mas é eficiente com respostas em milisegundos para 

cálculos de raízes quadradas de grandes números com precisão de 10 a 20 dígitos, 

enquanto uma função programada pelo usuário usando séries temporais através de 

laços e recursividades pode durar segundos e nem sempre atingir a precisão 

necessária. A solução encontrada e aplicada neste trabalho desenvolvido foi o uso 

do CORDIC – Coordinate Rotation Digital Computer, conhecido por método de dígito 

a dígito. CORDIC é um algoritmo simples e eficiente usado para computar funções 

trigonométricas que requerem adição, subtração, deslocamento de bit (bit shift) e 

tabela de pesquisa (lookup table), quando não há um multiplicador implementado no 

sistema ou com pouca quantidade, como no caso da maioria das FPGAs.  

Descrito em 1959 por Jack E. Volder
96

 para navegação de bombardeiros, o 

CORDIC é similar as técnicas matemáticas conhecidas desde 1624. A Hewlett-

Packard (HP) alterou o algoritmo para permitir que ele calculasse funções 

hiperbólicas, logarítmicas, exponenciais, multiplicações, divisões e raizes 

quadradas
97-99

.  

Os códigos utilizados foram desenvolvidos por John Burkardt e adaptados 

para serem aceitos no codificador HDL do Matlab
®99

. Nos quadros 1, 2 e 3 são 

apresentados os algoritmos em linguagem do Matlab
®
. 

 

 

 



72 

 

  

 
Quadro 1 - Algoritmo da função raiz quadrada em CORDIC modificado para 

trabalhar com o HDL Code Generation. 

 

Neste trabalho, foi utilizada uma variação do CORDIC com limite de 20 

iterações dentro dos laços. Se o número convergir para um menor valor de 

iterações, o algoritmo prontamente termina o laço em execução. Esses laços 

provocam roubos de ciclos e não são previsíveis para o uso de recursos, ou seja, 

quando eles são usados dinamicamente com estruturas como laços condicionais (a 

estrutura while), ou quando o limite é caracterizado por uma função que possui 

valores diferentes, ou ainda, quando a função é chamada (ao usar o valor final do 

controle de iterações como variável).  

 

 

function y = sqrt_cordic (x,n ) 
  if ( x == 0.0 ) 
   y = 0; 
   return 
 end 
  if ( x == 1.0 ) 
  y = 1; 
   return 
  end 
  poweroftwo = 1.0; 
 if ( x &amp;lt;1.0 ) 
  for i=1:20 
       if (x)&amp;lt;= (poweroftwo * poweroftwo ) 
           poweroftwo = poweroftwo / 2.0; 
       else 
          break; 
       end 
   end 
   y = poweroftwo; 
  elseif ( 1.0 &amp;lt;x )  
for i=1:20 
        if ( poweroftwo * poweroftwo &amp;lt;= x) 
           poweroftwo = poweroftwo * 2.0; 
        else 
           break; 
        end 
     end 
      y = poweroftwo / 2.0; 
   end 
  for i = 1 : n 
  poweroftwo = poweroftwo / 2.0; 
     if (  (y + poweroftwo ) * ( y + poweroftwo )&amp;lt;=  x ) 
        y = y + poweroftwo; 
     end 
  end 
return 

end 



73 

 

 

 

Quadro 2 - Algoritmo da função logaritmo em CORDIC modificado para 
trabalhar com o HDL Code Generation. 

 

Os  laços devem ser modificados para atender um limite máximo de iterações 

dentro dos recursos já alocados. Por exemplo, uma modificação no laço dinâmico 

function fx = ln_cordic ( x, n,a ) 
a_length = 25; 
k =0; 
for i=1:20 

if e&lt;=x 
      k = k + 1; 
      x = x/e; 
    else 
      break; 
    end 
  end 
  for i=1:20 
    if x&lt;1.0 
      k = k - 1; 
      x = x*e; 
    else 
      break; 
    end 
  end 
 w=zeros(1,n);  
 ai=0; 
 for i = 1 : n 
      w(i) = 0.0; 
    if ( i&amp;lt;= a_length ) 
        ai = a(i); 
     else 
        ai = 1.0 + (ai - 1.0) / 2.0; 
     end 
     if ( ai &amp;lt;x ) 
        w(i) = 1.0; 
        x = x / ai; 
     end 
  end 
  x =x - 1.0; 
  x2=(1-x/2); 
  x3=(1+x/3); 
  x4=(1-x/4); 
  x = x*x2*x3*x4; 
  poweroftwo = 0.5; 
  for i = 1 : n 
   wt=  w(i) * poweroftwo;   
       x = x + wt; 
     poweroftwo = poweroftwo / 2.0; 
  end 
  fx = k + x; 
  return  

end 



74 

 

  

para calcular a precisão de um valor é aceitável pelo codificador HDL pode ser feito 

da seguinte maneira: 

 

 

Quadro 3 - Algoritmo da função exponencial em CORDIC modificado para 
trabalhar com o HDL Code Generation. 

function fx = exp_cordic ( x, n, a ) 
a_length = 25; 
e = 2.718281828459045; 
x_int = floor(x);  
poweroftwo = 0.5; 
z = x - x_int; 
w = zeros(1,n); 
for i = 1 : n 

if ( poweroftwo &amp;lt;z ) 
        w(i) = 1.0; 
       z = z - poweroftwo; 
     end 
     poweroftwo = poweroftwo/2.0; 
end 
fx = 1.0; 
for i = 1 : n 

ai=0; 
    if ( i&amp;lt;= a_length ) 
      ai = a(i); 
    else 
      ai = 1.0 + ( ai - 1.0 )/2.0; 
     end 
     if ( 0.0 &amp;lt;w(i) ) 
        fx =fx * ai; 
     end 
end 
 z1=(1.0 + z ); 
 z2=(1.0 + z / 2.0); 
 z3=(1.0 + z / 3.0); 
 z4=(1.0 + z / 4.0); 
 fx=fx*z1*z2*z3*z4;  
  
 if ( x_int &amp;lt;0 ) 
   for i = 1 : 20 
     if i&lt;=-x_int 
       fx = fx / e; 
     else 
       break; 
     end 
   end 
else 

for i=1:20 
    if i&lt;=x_int 
        fx = fx * e; 
    else 
       break; 
    end 
  end 
 end 
return 

end 



75 

 

 
 

a) Código original 
 
while (y &amp;lt;x) 
 

{código} 
 
end_while 

 

b) Código modificado 
 
for i=1:20 
 

if (y&lt;x) 
 

break; 
 
    else 
 

{código} 
 

end_if 
 
end_for 

 
Esse tipo de modificação garante um máximo de iterações para uma precisão 

aceitável e permite que se a condição for aceita antes do fim das iterações, haja 

uma interrupção instantânea. Essa modificação existe nas três principais funções 

matemáticas do algoritmo do filtro especializado em projeções tomográficas: raiz 

quadrada, logarítmica e exponencial.  

A função de raiz quadrada é a função mais importante do algoritmo, pois o 

valor aproximado deve ter precisão suficiente para que não haja problemas na 

estabilidade do filtro. Ela é utilizada amplamente pelas funções qr, chol e cholupdate, 

usadas no processamento de pontos sigmas do filtro.  

Um erro na precisão faz com que o algoritmo fique instável ou ineficiente 

devido às projeções da média e da variância que dependem da fatoração de 

Cholesky para computar funções não lineares baseadas em exponencial, logaritmo e 

RNA.  

O código da função de raiz quadrada em CORDIC dispensa o uso de uma 

tabela de pesquisa, sendo seu cálculo feito usando recursões baseadas em uma 

série temporal e usando laços para determinar a precisão. As funções exponencial  

e logaritmo utilizam pesos calculados através do residual entre a parte inteira e a 

fracionária, usando as mesmas técnicas estabelecidas no cálculo de raíz quadrada. 



76 

 

  

Além dessas técnicas, fazem o uso de uma tabela de pesquisa previamente gerada 

com 25 posições pela função: 

 

    
 
 

 
 
 

  com              (73) 

 

 

3.6 PONTO FIXO 
 

 

O código HDL gerado pelo Matlab
®
 é gerado com variáveis do tipo double 

(ponto flutuante), o que não é suportado pelo sistema de FPGA. Para que o código 

seja embarcado corretamente, todos os dados devem ser trabalhados como ponto 

fixo, tornando a tarefa mais complexa devido às diferentes classes numéricas 

presentes. 

Um número com ponto fixo é representado como um tipo de dado real para 

um número que tem dígitos fixos depois da vírgula (depois da vírgula na notação 

brasileira enquanto na notação americana usa-se o ponto). 

Pontos fixos são úteis para representação valores fracionários (usualmente na 

base 2 ou base 10) quando a execução do processador não tem uma unidade em 

ponto flutuante.  

FPGAs e a maioria dos microprocessadores e microcontroladores não 

possuem uma unidade de ponto flutuante (FPU – Floating Point Unity), mas em 

alguns sistemas o uso de ponto fixo provê melhor desempenho ou uma melhor 

precisão para uma determinada aplicação. 

 

 

3.6.1 FATOR DE ESCALA 
 

 

Um valor de um tipo de dados ponto fixo é um inteiro que é dimensionado  por 

um fator específico determinado pelo tipo. Por exemplo, o valor 1,48 pode ser 

representado por 1480 em um tipo de dados de ponto fixo de um fator de escala 

1/1000 e o valor 1480000 pode ser representado como 1480 com um fator de escala 



77 

 

1000. Diferente dos tipos de dados de ponto flutuante, o fator de escala é o mesmo 

para todos os valores do mesmo tipo e não muda durante os cálculos. 

O fator de escala é usualmente uma potência de 10 ou uma potência de 2. 

Contudo, outro fator de escala pode ser usado com um valor de tempo em horas que 

pode ser representado como um tipo de ponto fixo com um fator de escala de 1/3600 

para se obter valores com uma precisão de segundos. 

O valor máximo de um tipo de ponto fixo é simplesmente o maior valor que 

pode ser representado dentro do tipo inteiro, multiplicado pelo fator de escala e pode 

ser feito o mesmo processo para o valor mínino.  

 

 

3.6.2 ARITMÉTICA DE PONTO FIXO 
 

 

Para adicionar ou subtrair dois valores do mesmo tipo de ponto fixo, é 

necessário adicionar ou subtrair inteiros subjacentes, mantendo o seu fator de 

escala comum. O resultado pode ser apresentado pelo mesmo tipo, desde que 

nenhum estouro (overflow) ocorra. Se os  números têm diferentes pontos fixos com 

diferentes fatores de escala, então um deles deve ser convertido para o outro antes 

da soma.  

Para se multiplicar dois números do tipo ponto fixo, basta multiplicar os dois 

inteiros subjacentes e assumir que o fator de escala do resultado é o produto dos 

fatores de escalas. Esta operação não envolve arrendondamentos. Por exemplo, 

multiplicando o número 123/1000 (0,123) e o número 25/10 (2,5), resulta o inteiro 

123*25=3075 dimensionado por (1/1000)*(1/10) = 1/10000, que é 3075/10000 = 

0.3075.  

Se os dois operandos pertencem ao mesmo tipo de ponto fixo, o resultado 

também será representado neste tipo. Então, o produto dos dois inteiros deve ser 

explicitamente multiplicado pelo fator de escala comum. Neste caso o resultado deve 

ser arredondado havendo a possibilidade do estouro ocorrer.  

Se o fator de escala comum é 1/100, multiplicando 1,23 por 0,25 implica 

multiplicar 123 por 25 para resultar 3075/10000.  Ao ser convertido ao fator de 

escala original 1/100 e dependendo do método de arredondamento usado, resultará 

31 (0,31) ou 30 (0,30).  



78 

 

  

Para dividir dois números de pontos fixos, um toma o inteiro quociente de 

seus inteiros subjacentes e assume que o fator de escala é o quociente do seu fator 

de escala.  

 

 

3.6.3 NOTAÇÕES NUMÉRICAS 
 

 

Existem várias notações numéricas usadas para representar o tamanho da 

palavra e o ponto raiz em um número de ponto fixo. Para as representações 

padronizadas, usa-se f para representar o número fracionário de bits, m é o número 

da magnitude ou de bits inteiros, s é o número de bits assinalados e b é o número 

total de bits: 

? Qf: O prefixo Q. Q15 representa um número de 15 bits fracionários. 

Esta notação é ambígua desde que não especifíca o tamanho da 

palavra, contudo é usualmente assumido que é 16 ou 32 bits 

dependendo do processador em foco a ser usado
100

.  

? Qm.f: A forma clara da notação Q. Desde que a palavra inteira é um 

inteiro complemento de 2, um bit sinalizador é implícito. Por exemplo, 

Q1,30 descreve um número com 1 bit inteiro e 30 bits fracionários 

guardados como um complemento inteiro de 2 em 32 bits
100-101

. 

? fxm.b: O prefixo fx é similar ao de cima, mas usa o tamanho da palavra 

como um segundo ítem no par pontuado. Por exemplo, fx1,16 descreve 

um número com magnitude de 1 bit e 15 bits fracionários em uma 

palavra de 16 bits
102

. 

? s:m:f: outras notações incluem um bit de sinal. Também se difere no 

modo convensional usando dois pontos. Por exemplo, 0:8:0 

corresponde a um byte inteiro não assinalado.  

Operações com pontos fixos podem produzir resultados que tenham mais bits 

que os operandos, existindo a possibilidade de perda de informação. Por exemplo, o 

resultado de uma multiplicação de pontos fixos poderia potencialmente ter muito 

mais bits com a soma de dois operandos.  

Com a finalidade de adequar o resultado para o mesmo número de bits do 

operando, a resposta deve ser arredondada ou truncada. Se for este o caso, a 



79 

 

escolha de quais bits devem ser mantidos é muito importante. Quando se multiplica 

dois números de ponto fixo com o mesmo formato como, por exemplo, I bits inteiros 

ou Q bits fracionários, a resposta sempre será 2I bits inteiros ou 2Q bits fracionários.  

Muitos procedimentos usam multiplicações de pontos fixos com o mesmo 

formato de resultado como os operandos. Isso tem o efeito de manter os bits 

médios: o número I do menos significante de bits inteiros e o número Q do mais 

significante de bits fracionários. Bits fracionários perdidos abaixo deste valor 

representa uma perda de precisão que é comum em multiplicação fracionária. Se 

quaisquer bits inteiros são perdidos os valores serão radicalmente imprecisos.  

Alguns modelos baseados em pacotes de pontos fixos permitem especificar 

um formato resultado diferente dos formatos de entrada. Isso permite maximizar a 

precisão e evitar o estouro. Operações como divisão sempre têm uma limitação de 

resultados embutida de modo que qualquer estouro positivo resulta no maior número 

possível que pode ser apresentado pelo formato atual. Diferentemente, o estouro 

negativo resulta em um número grande negativo representado pelo atual formato. 

Este tipo de construção em limitações é sempre referido como saturação.  

Alguns processadores suportam um estouro implementado em hardware que 

pode gerar uma exceção na ocorrência de um estouro, mas isto é usualmente muito 

tardio para salvar o resultado apropriado neste ponto. Ciclos de desenvolvimentos 

modernos incluem uma fase de prototipagem que examina o potencial da perda de 

precisão e estouro de projetos usando cálculos de pontos fixos antes de continuar 

com prototipagem física.  

Os dados das iterações anteriores são guardados em variáveis persistentes 

(que mantém o último valor guardado, como se fossem variáveis globais).   

Algoritmos complexos com diferentes grandezas númericas entre as variáveis 

e cálculos de precisão fazem com o que o código não seja bem implementado ou 

seja incompatível com a FPGA.  

A solução encontrada é especificar os pontos fixos manualmente e realizar as 

operações aritméticas com diferentes versões das funções implementadas para 

cada tipo de ponto fixo. No Quadro 4 é apresentada a função principal do algoritmo 

desenvolvido em transformado em ponto fixo.  

A função usada para a conversão dos dados é a fi(s,i,f,m), onde s pode ter o 

valor de 1 se o valor possui sinal ou 0 se não possuir, i é o tamanho da palavra em 

bits, f a quantidade de bits para a parte fracionária e m o modelo usado onde pode 



80 

 

  

ser configurados o máximo de bits para a aritmética de ponto flutuante, tipos de 

arredondamento, saturação, entre outros. 

No  Quadro 4, o padrão de bits usados pelo sistema foi de 14 bits 

considerando o modelo padrão do Matlab
®
 para geração de código em HDL.  

 

 

Quadro 4 - Código gerado pelo HDL Code Generation para a transformação 
de dados do tipo ponto flutuante para ponto fixo. 

É nesta função, também, que são calculadas as covariâncias do filtro, onde é 

feita a chamada da função do filtro de Kalman Descentralizado usando os 

parâmetros persistentes, como o vetor de estados anteriores e a matriz de 

function I = KalmanARNfpgao2_FixPt(y) 
    fm = hdlfimath; 
    persistent reg 
    if isempty( reg ) 
        reg = fi( (zeros( 2, 1 )), 1, 14, 14, fm ); 
    end 
    persistent P 
    if isempty( P ) 
        P = fi( (diag( [ 0.03; 0.1*ones( 26, 1 ) ] )),1, 14, 16, fm ); 
    end 
    persistent x 
    if isempty( x ) 
        x = fi( ([ 0; 0.1*ones( 26, 1 ) ]), 1, 14, 13, fm ); 
    end 
    persistent Io 
    if isempty( Io ) 
        Io = fi( (y), 0, 14, -2, fm ); 
    end 
    Io = fi( (max( [ y, Io ] )), 0, 14, -2, fm ); 
    mi = fi( (f23_log( (Io) ./ (y) )), 0, 14, 15, fm ); 
    R1 = fi( (f25_sqrt( Io )), 0, 14, 6, fm ); 
    R2 = fi( (0.0001), 0, 14, 27, fm ); 
    temp1 = fi( (f29_exp( mi )), 0, 14, 13, fm ); 
    temp2 = fi((1./temp1)^2*(R1)^2+(fi_uminus((Io(1)))./ temp1)^2 .* 

(R2)^2, 0, 14, -2, fm ); 
    R = fi( f25_sqrt( temp2 ), 0, 14, 6, fm ); 
    saida = fi( 1, 0, 14, 13, fm ); 
    c_oculta = fi( 5, 0, 14, 11, fm ); 
    estados = fi( 1, 0, 14, 13, fm ); 
    regressao = fi( 2, 0, 14, 12, fm ); 
    entrada = fi( estados + regressao, 0, 14, 12, fm ); 
    pesos = fi( saida*(c_oculta + fi( 1, 0, 1, 0 )) + c_oculta*(entrada 

+ fi( 1, 0, 1, 0 )), 0, 14, 9, fm ); 
    no = fi( c_oculta, 0, 3, 0, fm ); 
    tipo = fi( 1, 0, 14, 13, fm ); 
    Q = fi( f59_anealing( P ), 1, 14, 18, fm ); 
    [fmo_1,fmo_2] = f240_UKF( y, x, P, Q, R, 1, Io,no, reg, estados ); 
    x = fi( fmo_1, 1, 14, 13, fm ); 
    P = fi( fmo_2, 1, 14, 16, fm ); 
    reg = fi( [ x( 1 ); reg( 1 ) ], 1, 14, 14, fm ); 
    I = fi( Io( 1 )*f29_exp( fi_uminus( x( 1, 1 ) )), 0, 14, -2, fm ); 

end 

 



81 

 

covariância do processo, bem como os dados atuais como covariância de erro e o 

estado observado atual. 

 

 

3.7 GERAÇÃO DE CÓDIGO EM HDL 
 

 

Gerar código em HDL através do Matlab
®
 é tido como uma tarefa simples, 

podendo ser automatizada, quando feito através dos blocos pré-definidos da 

ferramenta Simulink
®
 através do HDL Workflow Advisor ou usando a toolbox do HDL 

Coder. O Matlab
®
 em sua versão mais nova, a R2012a possui uma ferramenta de 

análise e geração de pontos fixos integrada ao HDL Code Generation, como pode 

ser vista na Figura 17.  

 

 

Figura 17 - Ferramenta HDL Code Generation usada para criar pontos fixos, 
geração de código em HDL e gravação de um código do Matlab

®
 

na FPGA.  

 



82 

 

  

O filtro, em arquitetura reconfigurável utilizando FPGA, foi implementado 

usando a linguagem de script do Matlab
®
 com bloco de funções definido pelo 

usuário, como o bloco Embedded Matlab
®
 Function. Esse bloco permite a integração 

do código feito pelo usuário, como também sua otimização na tradução para a 

linguagem C, que apresenta um desempenho maior por ser um código compilado.  

Um modo de contornar o uso dessas funções é a declaração da política %eml 

que permite fazer uma chamada da função do sistema e enviar o valor ao 

computador que processa e envia de volta o resultado ao bloco. Na prática, o 

sistema vem a ser dependente, mas pode ser utilizado na opção de sistemas 

hardware-in-loop. 

O tempo de processamento pode vir a ser alto devido ao grande número de 

chamada de funções a serem realizadas causando um aumento de tráfego entre os 

dados durante a comunicação.  Para diminuir o tráfego, deve-se implementar e 

embarcar o filtro de Kalman totalmente na FPGA e reescrever as funções 

necessárias para seu funcionamento.  

Outra característica presente no Matlab
®
 é que o gerador de HDL não permite 

o uso de vetores e matrizes dinâmicas. Assim, o tamanho do vetor ou da matriz deve 

ser definido previamente. Outro problema pode se extender ao tempo de 

processamento para gerar matrizes que diminui a eficiência do código. Laços têm 

um grande problema em relação ao tempo para otimizar o código, mas as 

ferramentas de projeto tem diferentes soluções para esses laços que são 

minimizados dentro de pipelines automaticamente. A função de embarque do 

Matlab
®
 é apresentada na Figura 18. Essa função permite que um código da 

linguagem do Matlab
®
, o M-code, possa ser utilizado no Simulink

®
.  

 
Figura 18 - Bloco de embarque de função do Matlab

®
 do Simulink

®
. Esse 

bloco permite editar uma função em M-code para ser usada como 
um bloco. 

O M-code gerado apresenta algumas restrições quanto ao seu uso padrão 

como linguagem de script. Ele deve ser usado como uma função que tenha ao 

menos uma saída. É possível escrever no próprio arquivo outras funções 



83 

 

necessárias para o código, não necessitando realizar chamadas externas de outras 

funções.  

O código em HDL pode ser gerado a partir de uma ferramenta integrada ao 

Simulink
®
, a HDL Workflow Advisor,  apresentada na Figura 19. 

 

 

Figura 19 - A ferramenta HDL Workflow Advisor usada para gerar um código 
em HDL em conjunto com outros softwares da fabricante da 
FPGA, permitindo a síntese e análise do código. 

A ferramenta permite gerar um código HDL de subsistemas ou funções 

embarcadas e, em versões mais novas do Matlab
®
, escolher novas formas de 

interação entre o Desktop e a FPGA, como FPGA-in-loop, onde ela pode ser 

integrada no sistema comunicando-se de forma implícita. O HDL Workflow Advisor 

permite gerar tanto códigos em HDL quanto projetos do Quartus. Neste trabalho, o 

foco está em usar essa ferramenta para gerar o código em HDL. 

A ferramenta pode gerar o código HDL em duas linguagens Verilog e VHDL. 

Há a opção de gerar o código com ponto flutuante (variáveis do tipo double) que 

podem ser embarcadas quando se tem uma unidade de cálculo de ponto flutuante 

embarcado no código, como na maioria dos DSPs.  

Nesse trabalho, o uso de um co-processador de ponto flutuante foi 

dispensado pois os dados numéricos são transformados em pontos fixos. 

O uso de ponto fixo torna a tarefa de criar um código em HDL mais complexa, 

mas permite uma arquitetura única e específica. 



84 

 

  

O DSP Builder
®
 é o software desenvolvido pela Altera que permite montar um 

modelo usando diagramas em blocos no Simulink
®
 e gravar na FPGA. Sua limitação 

é que apenas os blocos do toolbox são compilados e validados, pois o seu objetivo é 

analisar os resultados do modelo implementando no Simulink
®
 antes do embarque.  

O DSP Builder
®
, apresentado na Figura 20, é usado para gerar um projeto 

para o Quartus através de um bloco implementado no Simulink
®
. 

 

Figura 20 - Ferramenta DSP Builder
®
 fornecida pela Altera que permite 

compilar e gravar o código na FPGA, usada também para a 
verificação de modelos compatíveis com a FPGA. 

O DSP Builder
®
 é chamado pelo bloco Signal Compiler, presente no toolbox 

da Altera e pode ser associado ao modelo da FPGA a ser gravado sem que haja a 

necessidade de configurações por parte do usuário. Esse bloco é apresentado na 

Figura 21. 



85 

 

 
Figura 21 - O bloco Signal Compiler é usado para gerar, validar e embarcar 

funções do DSP Builder
®
 na FPGA.  

Uma forma de usá-lo para rodar um projeto do Matlab
®
 é a de utilizar os 

blocos HIL e HDL Import. Esses blocos são apresentados na Figura 22.  

 

Figura 22 - Blocos utilizados para implementar modelos gerados pelo 
Simulink

®
 na FPGA: HIL (Hardware-in-loop) utilizado para 

embarcar um arquivo de projeto do Quartus, enquanto o HDL 
Import é utilizado para embarcar um código válido em HDL. 

O diagrama da Figura 23 mostra os possíveis caminhos para a gravação dos 

dados na FPGA, tal como a geração de códigos em HDL ou projetos do Quartus. 

O bloco HIL aceita somente códigos gerados como projetos (qpf – Quartus 

Project File) enquanto o HDL Import já aceita códigos em HDL (em VHDL ou 

Verilog). Esses dois blocos são necessários para se criar um caminho para a 

gravação do código na FPGA e integração com o sistema. A importância destes 

blocos dá-se pela capacidade de controlar o fluxo de dados do mini-tomógrafo e da 

FPGA, organizando-os e gerando arquivos contendo os dados coletados e filtrados. 

 O caminho escolhido para o embarque do algoritmo é descrito nos passos 

abaixo:  

1. Reescrever as funções não suportadas pelo gerador de código HDL do 

Matlab
®
. 

2. Aplicar, manualmente, os limites para os pontos fixos para cada variável e 

operação presente no código. 

3. Utilizar o HDL Coder do Matlab
®
, pois o HDL Coder do Simulink

®
 não trata 

o algoritmo dentro do bloco Matlab
®
 Function, não fazendo otimizações 

necessárias como desenrolar laços e otimização do uso de unidades de 

multiplicação. 

4. Verificar a consistência do código usando o bloco HDL Import. 



86 

 

  

5. Criar um projeto no Quartus II
®
 e verificar se há erros no código ao ser 

compilado. 

6. Importar o código para o bloco HIL (Hardware-in-loop). 

 

 

 

Figura 23 - Diagrama esquemático apresentando os possíveis caminhos para 
a geração de códigos em HDL, projeto do Quartus II

®
 e gravação 

direta na FPGA. 

  



87 

 

4 RESULTADOS 
 

 

O trabalho desenvolvido inclui a criação de uma ferramenta que provê uma 

interface para a análise dos sinais filtrados fazendo a comunicação entre o 

computador e a FPGA, tal como a visualização das imagens reconstruídas. A 

implementação do filtro na FPGA é feita usando Matlab
®
 e ferramentas da Altera. 

A ferramenta desenvolvida, como se pode ver na Figura 24, permite um 

acesso de maneira simples e intuitivo a esses recursos através de botões. É 

possível visualizar a imagem reconstruída de uma amostra de grãos de areia, 

originalmente ruidosa e na outra imagem, a mesma amostra de areia após a etapa 

de filtragem das projeções. No gráfico é feita a comparação entre o sinal filtrado (em 

azul) e o ruidoso (em vermelho).  

 

 

Figura 24 - Ferramenta desenvolvida para armazenamento de dados, 
filtragem das projeções e visualização imagens tomográficas 
reconstruídas.  

Assim, esta ferramenta permite abrir dois tipos de arquivos de projeções com 

cabeçalho simplificado ou com cabeçalho específico, além de permitir visualizar o 

processo de filtragem, os dados originais e filtrados, além de fornecer uma 



88 

 

  

comparação entre eles. Outras funcionalidades são a filtragem dos dados feita pelo 

computador ou pela FPGA, bem como uma camada interna onde foi programado um 

algoritmo de reconstrução tomográfica de projeções para auxiliar a análise de 

resultados.  

A implementação do filtro em FPGA segue os passos apresentados na Figura 

25, onde em algumas etapas já desenvolvidas foram realizados testes da qualidade 

de filtragem e precisão de dados. 

 

 

Figura 25 - Diagrama de blocos mostrando as etapas para o embarque do 
código do filtro de Kalman na FPGA. 

Para gerar os resultados com imagens, utilizou-se a filtragem de um vetor de 

projeções retirados da matriz. Cada vetor é filtrado de forma independente e depois 

é incluído numa matriz final com todas as projeções filtradas. Para uma melhor 

visualização do processo final, as matrizes de projeções foram reconstruídas com o 



89 

 

algoritmo de retroprojeção filtrada. O filtro foi validado com a  ferramenta Simulink
®
 

do Matlab
®
, como pode ser visto na Figura 26.  

 

 

Figura 26 - Módulo desenvolvido no Simulink
®
 usando o bloco de embarque 

de função do Matlab
®
. Esse módulo permite ler um dado que 

esteja disponível em uma variável dentro do Matlab
®
 juntamente 

com os parâmetros do filtro. 

Usando o método de quantificação na melhoria na relação sinal-ruído (ISNR – 

Improvemment in Signal to Noise Ratio), foram medidas as melhorias das  projeções 

e as imagens reconstruídas. Este método permite calcular a relação entre o ruído 

anterior e posterior à filtragem. O ISNR pode ser calculado através da equação: 

 

                 
              

              
    (74) 

 

Para a filtragem com estimação com RNA, uma MLP com o esquema de 

neurônios foi definido como 6-10-1. A camada de entrada possui a mesma 

quantidade de entradas, ou seja, 6 entradas (5 estados para a regressão e o estado 

anterior que recebem a retroalimentação), enquanto a camada intermediária é 

definida pela média geométrica entre a entrada e a saída.  



90 

 

  

Para haver a validação, algumas modificações foram necessárias, como 

transformar o filtro em uma versão on-line onde cada uma das projeções é enviada à 

FPGA, analisada pelo filtro de acordo com o ruído medido pelas equações de 

propagação de erro e finalmente filtrada. 

Para validar e ajustar os parâmetros do filtro foi utilizado um phantom 

homogêneo (construído a partir de um tubo de Nylon com 60 mm de diâmetro) 

usado para calibrações e adicionados ruídos Poisson e branco obtendo um sinal 

ruidoso com valor de -50 dB. O ISNR foi aplicado nas projeções individuais, na 

matriz de projeções e na imagem reconstruída. A definição dos parâmetros do filtro 

foi baseada naqueles que apresentaram o maior valor médio de ISNR.  

Os parâmetros usados foram variância dos pesos da rede de 0,01, coeficiente 

de atenuação inicial esperado de 0,1, o grau de espalhamento dos pontos sigmas no 

valor de 0,1, variância de incerteza da medida de 0,01 e grau de convergência da 

RNA de 0,995.  

Na Figura 27 são apresentados os resultados da filtragem através das 

matrizes de projeções obtidas pelo minitomógrafo de raios X e gama, suas 

respectivas imagens reconstruídas e com a comparação dos sinais. O ISNR médio 

da matriz de projeções foi de 2,34 dB enquanto da imagem foi de 4,84 dB.  

Na Figura 28 são apresentados os resultados usando projeções de um tubo 

contendo grãos de areia obtidas através do microtomógrafo. As projeções foram 

reconstruídas para a visualização do efeito da filtragem nas imagens tomográficas. 

Os parâmetros para o filtro foram os mesmo aplicados no phantom homogêneo.  

O ISNR para as projeções obteve a melhoria média  de 0,01 dB enquanto 

para a imagem reconstruída, o ISRN foi de 1,51 dB.  

No conjunto de figuras abaixo (Figura 29, Figura 30, Figura 31, Figura 32, 

Figura 33, Figura 34 e Figura 35) é possível notar o comportamento diferenciado da 

filtragem em cada tipo de amostra. As projeções que foram filtradas possuem 

resolução micrométrica e são provenientes do microtomógrafo de raios X e gama. 

Na comparação entre os sinais foi utilizada a primeira posição obtida no ângulo 0, ou 

seja, a primeira linha da matriz de projeções. 



91 

 

 

Figura 27 - Phantom homogêneo usado para calibrar o filtro. Foram 
adicionados ruídos Poisson e branco para verificar a taxa de 
melhoria da relação sinal-ruído após a filtragem. Em (a) é 
apresentada a comparação dos sinais, em (b) a matriz de 
projeções original, a sua respectiva reconstrução feita pelo 
algoritmo de retroprojeção filtrada em (c). Em (d), a matriz de 
projeções ruidosa e em (e) sua imagem reconstruída. Em (f) a 
matriz de projeções filtradas com a apresentação da imagem 
reconstruída em (g). 



92 

 

  

 
Figura 28 - Projeções de uma amostra de areia usadas para validar o filtro. 

Foram adicionados ruídos Poisson e branco para verificar a taxa 
de melhoria da relação sinal-ruído após a filtragem. Em (a) é 
apresentada a comparação dos sinais, em (b) a matriz de 
projeções original, a sua respectiva reconstrução feita pelo 
algoritmo de retroprojeção filtrada em (c). Em (d), a matriz de 
projeções ruidosa e em (e) sua imagem reconstruída. Em (f) a 
matriz de projeções filtradas com a apresentação da imagem 
reconstruída em (g). 



93 

 

 

 

 

 

Figura 29 -  Phantom homogêneo (phantomp.dat) usado para calibração. (a) 
Comparação entre as projeções, (b) matriz de projeções original, 
(c) imagem reconstruída das projeções originais, (d) matriz de 
projeções filtradas e (e) imagem reconstruída da projeção filtrada. 

  



94 

 

  

 

 

 

Figura 30 - Amostra com grãos de areia (areia2.dat). (a) Comparação entre as 
projeções, (b) matriz de projeções original, (c) imagem 
reconstruída das projeções originais, (d) matriz de projeções 
filtradas e (e) imagem reconstruída da projeção filtrada. 

  



95 

 

 

 

 

Figura 31 - Amostra de solo (torrao.dat). (a) Comparação entre as projeções, 
(b) matriz de projeções original, (c) imagem reconstruída das 
projeções originais, (d) matriz de projeções filtradas e (e) imagem 
reconstruída da projeção filtrada. 

 

 

 

 



96 

 

  

 

 

 

Figura 32 - Amostra de solo (cimen2.dat). (a) Comparação entre as projeções, 
(b) matriz de projeções original, (c) imagem reconstruída das 
projeções originais, (d) matriz de projeções filtradas e (e) imagem 
reconstruída da projeção filtrada. 

 

 

 

 



97 

 

 

 

 

Figura 33 - Amostra de solo (degri30.dat). (a) Comparação entre as projeções, 
(b) matriz de projeções original, (c) imagem reconstruída das 
projeções originais, (d) matriz de projeções filtradas e (e) imagem 
reconstruída da projeção filtrada. 

 

 

 

 



98 

 

  

 

 

 

Figura 34 - Amostra de solo (adub30.dat). (a) Comparação entre as projeções, 
(b) matriz de projeções original, (c) imagem reconstruída das 
projeções originais, (d) matriz de projeções filtradas e (e) imagem 
reconstruída da projeção filtrada. 

 



99 

 

 

 

 

Figura 35 - Amostra de solo (mb1t1.dat). (a) Comparação entre as projeções, 
(b) matriz de projeções original, (c) imagem reconstruída das 
projeções originais, (d) matriz de projeções filtradas e (e) imagem 
reconstruída da projeção filtrada. 

 

 

 



100 

 

  

Na Figura 29 é possível perceber que o filtro suavizou o sinal, acompanhando 

a curva da projeção, evitando os picos relacionados aos ruídos. Na imagem 

reconstruída temos a parte do corpo da amostra mais clara com a presença de 

ruídos. Esses ruídos também são formados pela presença de artefatos na 

reconstrução da imagem, sendo só possível atenuá-los numa filtragem após a 

reconstrução.  

Na filtragem das projeções apresentada na Figura 30 é possível perceber que 

o sinal filtrado descarta alguns detalhes, classificando-os como ruídos. Se esses 

detalhes forem importantes como características da amostra, a imagem reconstruída 

irá apresentar suavizações. 

O resultado apresentado na Figura 31 apresenta uma filtragem onde o sinal 

filtrado acompanha bem o sinal original. A maioria dos detalhes é mantida, enquanto 

na parte com maior atenuação, há uma filtragem mais discreta.   

O mesmo comportamento ocorre na filtragem de outras amostras de solo 

(Figura 32, Figura 33, Figura 34 e Figura 35), onde as amostras apresentam 

microporos maiores do que na amostra anterior. Alguns detalhes nas imagens foram 

preservados, mas a diferença nos contrastes provocaram perdas de detalhes, como 

os microporos. Isso ocorre devido à presença de granularidade da imagem que pode 

ser interpretada como falsos elementos ou poros. Uma filtragem excessiva pode 

provocar essa perda de detalhes como bordas da imagem reconstruída. 

 O filtro pode ser reajustado para suavizar ou manter mais detalhes da 

imagem, mas isso vai impactar na qualidade final do sinal de saída do sistema, 

afetando diretamente a imagem resultante, sendo, portanto, necessário um cuidado 

na realização destes ajustes, o que é obtido com o ensaio de phantoms. 

Para comparar a eficiência do filtro e configurá-lo para obter uma qualidade 

de sinal desejável, foram aplicados dois tipos de filtros:  

Um com funções nativas do Matlab
®
 e outro funções contendo algoritmos 

baseados em CORDIC.  

Com o objetivo de analisar como o filtro se comporta com diferentes projeções 

e frente à impossibilidade de medir o ISNR apenas com dados ruidosos e filtrados, 

foi feito uma medição de SNR (Signal to Noise Ratio – Relação Sinal/Ruído) em 

cada projeção e  imagem reconstruída. O SNR pode ser dado por: 

 



101 

 

                
 

 
      (75) 

 

A partir dessas medidas, pode-se calcular o ganho da filtragem.  

 

Na Tabela 1 são apresentados os SNRs para as matrizes de projeções e 

imagens reconstruídas.  

 

Tabela 1 - Resultados obtidos com a análise de SNR das projeções e 
imagens reconstruídas.  

Arquivos 
das 

Projeções 

Relação Sinal/Ruído (em dB) 

Projeção Imagem 

Original Filtrada Ganho Original Filtrada Ganho 

phantomp.dat 14,52 16,44 1,92 2,34 2,47 0,13 

areia2.dat 24,51 24,84 0,33 -1,36 -0,98 0,38 

torrao.dat 14,72 14,85 0,13 -1,29 -1,15 0,14 

cimen2.dat 18,08 18,31 0,23 -2,62 -2,22 0,40 

degri30.dat 18,90 19,07 0,17 -4,77 -4,51 0,26 

adub30.dat 16,67 16,86 0,19 -3,00 -2,81 0,19 

mb1t1.dat 19,11 19,25 0,14 -1,71 -1,31 0,40 

 

Após obter os SNRs, foi calculado o ganho baseado na diferença entre o SNR 

das amostras filtradas e o SNR das amostras originais. Algumas amostras possuíam 

SNR negativos significando que o ruído tinha potência maior que o sinal. 

Valores negativos no ganho de SNR tem o mesmo significado do que no uso 

do ISNR, significa que detalhes foram perdidos, havendo perdas na qualidade do 

sinal.  

Na prática, o ganho obtido na filtragem de projeções pode ser diferente para o 

ganho medido nas imagens reconstruídas. O motivo principal é que o algoritmo de 

reconstrução atua como um filtro passa-altas. 



102 

 

  

Os filtros passa-alta permitem a passagem de altas frequências em uma 

imagem, destacando os detalhes. Os ruídos presentes em projeções tomográficas 

também fazem parte da frequência alta e são potencializados juntos com os 

detalhes.  

O uso do ganho do SNR usando a relação entre a média e o desvio padrão é 

uma medida menos precisa do que o ISNR feito com o cálculo da relação entre ruído 

dos dados originais e o ruído dos dados filtrados, mas permite quantificar e qualificar 

os resultados de dados que não são conhecidos a priori.  

Os filtros foram aplicados em um phantom na amostra de areia e em uma 

amostra de solo. Para o cálculo do ISNR foi adicionado um ruído de -50 dB de 

potência.  

Na Figura 36 são apresentados os resultados obtidos com a filtragem das 

amostras de areia e de solo natural. É possível, que visualmente, as filtragens 

apresentem resultados similares. 

Nas tabelas 2 e 3 são apresentados os resultados do tempo de 

processamento e dos valores de ISNR pra a filtragem usando funções do Matlab
®
 e 

métodos de CORDIC. Apesar dos resultados apresentarem-se visualmente 

melhores, houve uma grande diferença no grau de filtragem, que pode ser visto na 

discrepância entre os valores de ISNR nos dois filtros. 

Os filtros de Kalman apresentados nesse trabalho não foram otimizados para 

filtragem de ruídos Gaussianos adicionados em projeções. O objetivo principal é  

comparar o efeito de filtragem entre os dois filtros e prover uma melhor visão para a 

precisão dos dados conforme as etapas de implementação do filtro no sistema 

embarcado. 

Foi observado que o filtro de Kalman, mesmo usando as funções de CORDIC 

adaptadas, com ou sem otimização de multiplicação de matriz pelo Matlab
®
, o tempo 

de processamento foi 38% menor do que o filtro de Kalman usando as funções 

nativas do Matlab
®
. A precisão estava dentro do padrão esperado, oferecendo até 

mesmo um valor maior de ISNR na filtragem, mostrando a capacidade do filtro de se 

adaptar às imprecisões mesmo dentro do próprio sistema. 

O tempo de processamento do filtro foi menor com o uso do algoritmo 

CORDIC deve-se a ele ser mais ágil e menos preciso do que o algoritmo 

implementado nativamente no Matlab
®
. A causa da perda de precisão e o menor 

tempo de processamento está ligado ao limite de iterações dos algoritmos (limitando 



103 

 

o tamanho das séries temporais), o uso de tabelas de alocação, e operações de bit 

shift presente no CORDIC.  

 

 

Figura 36 - Projeções tomográficas afetadas por ruídos Gaussianos (a) 
composta de grãos de areia e (b) uma amostra de solo natural. 

 

 

 

 

 



104 

 

  

Tabela 2 - Comparação de desempenho das funções do Matlab
®
 e métodos 

de CORDIC para projeções tomográficas de grãos de areia. 

Funções Matlab
®
 CORDIC 

Tempo 55,74 s 28,99 s 

ISRN Máximo 23,30 dB 31,99 dB 

ISRN Mínimo -45,91 dB -48,73 dB 

ISRN Médio -1,76 dB -1,83 dB 

Variância ISNR 165,20 177,64 

 

Tabela 3 - Comparação de desempenho das funções do Matlab
®
 e métodos 

de CORDIC para projeções tomográficas de solo natural. 

Funções Matlab
®
 CORDIC 

Tempo 45,58 s 24,03 s 

ISRN Máximo 42,82 dB 45,56 dB 

ISRN Mínimo -30,98 dB -32,58 dB 

ISRN Médio 1,27 dB 1,22 dB 

Variância ISNR 138,36 138,87 

 

Os valores de ISNR usando CORDIC também apresentaram-se com picos de 

ganhos e perdas maiores do que usando o Matlab
®
, o que demonstra uma perda de 

estabilidade também confirmada pelo pouca diferença entre os valores médios e 

uma variação maior do ISNR nos algoritmos implementados com CORDIC.  

Comparando os resultados de filtragem com os sinais originais, nota-se que a 

diferença é muito pequena, que valida o filtro para ser aplicado a uma FPGA para 

prover uma melhor relação sinal/ruído. 

 

 

4.1 ALGORITMO EMBARCADO 
 

 

O processo de embarque do filtro torna-se complexo por depender de fatores 

ligados aos recursos disponíveis na FPGA e o computador utilizado para compilar os 

arquivos para a gravação dos dados devido aos recursos necessários para a tarefa.  

O primeiro passo, após a escolha dos valores de ponto-fixo, foi gerar o código 

em HDL. Como o algoritmo inicialmente era bem complexo, a tarefa de gerar o 

código não era suportada pelo computador utilizado para o projeto, pois o suporte de 



105 

 

memória era apenas de 4 Gigabytes de memória RAM. Com a aquisição de um novo 

equipamento com 16 Gigabytes de memória RAM, o problema persistiu. Após uma 

análise da localização do erro no processo e no algoritmo, descobriu-se que o erro 

estava na função de Loop Unroll (desenrolar de laços) feito pelo Matlab
®
, de forma 

automática, ou, numa etapa posterior, no próprio Quartus II
®
. Os gargalos foram 

encontrados, principalmente, em três funções: mapeamento da rede neural, 

decomposição QR e fatoração de Cholesky. Essa situação foi contornada ao se 

utilizar uma diretiva do Matlab
®
, a coder.unroll, que permite que o código, antes de 

ser compilado, desenrole os laços, usando menos memória, mas aumentando o 

tempo de compilação. Nessa etapa, levou da ordem de vinte horas para se gerar o 

código HDL. Adicionalmente, o código a ser embarcado possuía um número de 

recursos que era maior que a capacidade suportada pela FPGA.  

Para diminuir o tempo de geração do código bem como adequá-lo para ser 

embarcado, a rede neural foi otimizada retirando as funções de regressão e 

diminuindo o número de neurônios na camada oculta. Assim, a rede neural passou a 

ter quatro neurônios  e o desenrolamento dos laços foi mais rápido e não utilizou-se 

de muita memória do sistema para gerar o código. 

Para diminuir o tempo e analisar o código, foi realizado um teste sem o uso de 

redes neurais para o embarque na FPGA. Após uma análise profunda no código, 

descobriu-se que a função de decomposição QR era a responsável pela ocupação 

de grande espaço (cerca de 5 vezes a capacidade da FPGA), devido à matriz 22x5, 

com vários cálculos de raiz quadrada. Assim, a primeira opção foi adaptar uma 

função de decomposição QR em CORDIC presente no Matlab
®
. Outra solução, mais 

viável, foi a de diminuir o cálculo da matriz 50%, ou seja, trabalhar uma matriz 11x5, 

levando em conta que a matriz de covariância de pontos sigmas gerados pelo 

Matlab
®
 apresenta um espelhamento com valores positivos nas primeiras onze 

linhas e os mesmos valores, negativos, nas últimas linhas. Com um cálculo matricial, 

o número de operações diminuiu consideravelmente, mas ainda era alto para o 

sistema compilar. 

Outro aspecto importante foi o de diminuir o uso de unidades lógicas, onde o 

sinal anteriormente aplicado necessitava de uma palavra de 40 bits. Após uma 

modificação no sinal e sua normalização com valor máximo de 1, o tamanho do 

ponto fixo passou a ser de 21 bits, destes, 15 bits reservados para valores 

fracionários. Com essa adaptação, o uso de recursos de hardware necessário caiu 



106 

 

  

quase 50%. As funções de análise do sinal e geração da variância do ruído também 

foram excluídas. O filtro passou a ser alimentado com o sinal e a variância do ruído 

já calculada. O filtro faz o próprio armazenamento das variáveis internas usando a 

diretiva de variável persistente presente no Matlab
®
, o que aumenta a complexidade 

em tratamento de sinais de controle para a gravação, limpeza de memória e uso 

efetivo de funções que dependem desses sinais de controle. Outras funções em 

CORDIC, como raiz quadrada e exponencial, foram limitadas a 6 iterações, 

perdendo parte da precisão, mas disponibilizando mais recursos. 

Analisando o algoritmo do filtro de Kalman, surgiu a ideia de separá-lo em 

duas partes utilizando a técnica de Filtro de Kalman Dual, que diminuiria alguns 

recursos como eliminar o cálculo pesado para a estimação do sinal. Assim, a matriz 

de covariância dos estados do sinal passou a ser de 6x3 e, com o uso da função de 

multiplicação matricial para diminuir o cálculo de função QR, a matriz efetiva utilizada 

passa a ser 3x3.  

O filtro em sua configuração final ocupa 33% da capacidade da FPGA, 

gerando o código e  embarcando-o em um tempo menor do que 32 minutos, 

podendo o mesmo ser utilizado em equipamentos de 32 bits com memória de 4 

Gigabytes.  

 

 

4.2 ANÁLISE DE RESULTADOS NA CONFIGURAÇÃO DE FILTRO 
EMBARCADO 

 

 

Para validar o filtro embarcado, foram utilizados dois Phantoms para 

calibração, um homogêneo e outro heterogêneo. O homogêneo é formado por um 

corpo sólido de Nylon e o heterogêneo contém quatro materiais diferentes (alumínio, 

água, cálcio e fósforo), feito de plexiglas. Aos dois Phantoms foram adicionados  

diferentes ruídos. Foram introduzidos ruídos tais como multiplicativo, Gaussiano e de 

Poisson. Também foram utilizados amostras de solos agrícolas. 

O cálculo para adicionar o ruído multiplicativo é dado por: 

 

                    (76) 

 



107 

 

onde   é a projeção,   é o ruído Gaussiano e       , a projeção perturbada por um 

ruído multiplicativo. 

Já o cálculo para adicionar o ruído Gaussiano é dado por: 

 

                      (77) 

 

onde       , a projeção perturbada por um ruído Gaussiano.  

E, finalmente, o cálculo para adicionar o ruído Poisson é dado por:  

 

                   .     (78) 
 
 

onde         , a projeção ruidosa perturbada por um ruído do tipo Poisson. 

O ruído Poisson foi acrescido de uma multiplicação por 10 para que o ruído se 

apresentasse de maneira mais forte na imagem.  

Os ruídos foram aplicados nos dois Phantoms de calibração. Após a análise 

dos resultados da filtragem obtidos, o filtro foi aplicado novamente nos Phantoms  e 

nas amostras de solo.  

 

 

4.2.1 RESULTADOS OBTIDOS COM OS PHANTOMS DE 
CALIBRAÇÃO 

 

 

Nas Figura 37, Figura 39 e Figura 41 são apresentados os Phantoms de 

calibração homogêneos com os diferentes tipos de ruídos e nas Figura 38, Figura 40 

e Figura 42, os seus respectivos espectros de Fourier do sinal e das imagens 

reconstruídas. Também nas  Figura 43, Figura 45, Figura 47 são apresentados os 

resultados de filtragem do phantom de calibração heterogêneo com os diferentes 

tipos de ruídos e nas Figura 44, Figura 46 e Figura 48, os seus respectivos 

espectros de Fourier do sinal e das imagens reconstruídas. As projeções foram 

filtradas com o filtro de Kalman com redes neurais embarcado em FPGA. 

Os diferentes tipos de ruídos foram escolhidos com o critério de afetar o sinal 

de forma diferenciada: Enquanto o ruído multiplicativo afeta, principalmente, as 



108 

 

  

maiores contagens de fótons, o ruído Poisson afeta as menores contagens e o ruído 

Gaussiano afeta o sinal por inteiro, tanto em baixas quanto nas altas contagens.   

Outra análise importante é quanto ao uso do espectro de Fourier, gerado a 

partir da transformada de Fourier bidimensional em uma imagem. A análise com o 

espectro de Fourier é importante para se decidir qual tipo de filtragem será mais bem 

utilizada.  

O filtro ao ser aplicado em uma imagem pode realçar ou reter os coeficientes 

dos componentes de determinadas frequências, o que pode ser visualizado no 

espectro de Fourier com alteração nos valores das componentes do sinal em 

determinada faixa de frequência.  

 



109 

 

 

Figura 37 –  Phantom de calibração homogêneo com ruído multiplicativo. (a) 
Comparação entre os sinais da primeira linha da matriz de 
projeções. (b) Matriz de projeções do Phantom original. (c) Matriz 
de projeções com ruído. (d) Matriz de projeções filtrada. (e) 
Imagem do Phantom reconstruído. (f) Imagem do Phantom ruidoso 
reconstruído. (g) Imagem do Phantom filtrado reconstruído. 

Na Figura 37, é possível notar que o ruído afeta todo o sinal, principalmente 

nas bordas, ligado à alta contagem. Ao se verificar a imagem reconstruída, é notada 

uma granularidade alta, onde o Phantom não é visível. Com a filtragem é possível 

perceber a restauração do Phantom. 



110 

 

  

 

 

 

 

 

Figura 38 -  Espectro de Fourier das projeções afetadas do Phantom 
homogêneo afetadas pelo ruído multiplicativo. (a) Espectro de 
Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais  (c) 
afetadas pelo ruído e (d) filtradas. 

 

Na Figura 38, é possível ver a comparação dos espectros do sinal. O ruído 

multiplicativo afeta todas as frequências do sinal. O filtro atenua os valores das 

componentes com tentativas de restaurar o sinal. Nos espectros das imagens 

reconstruídas é possível perceber a restauração de parte do sinal, principalmente 

nas baixas e altas frequências.  

 



111 

 

 

Figura 39 - Phantom de calibração homogêneo com ruído Gaussiano. (a) 
Comparação entre os sinais da primeira linha da matriz de 
projeções. (b) Matriz de projeções do Phantom original. (c) Matriz 
de projeções com ruído. (d) Matriz de projeções filtrada. (e) 
Imagem do Phantom reconstruído. (f) Imagem do Phantom ruidoso 
reconstruído. (g) Imagem do Phantom filtrado reconstruído. 

Na Figura 39, foi aplicado o ruído Gaussiano. Ele afeta todo o sinal 

igualmente, ou seja, tanto nas regiões de alta e baixa contagem. O filtro promove 

uma atenuação dos valores dos ruídos se aproximando do sinal na original. Nas 

imagens reconstruídas é possível notar a restauração do corpo do Phantom e 

diminuição da granulação.  



112 

 

  

 

 

 

Figura 40 - Espectro de Fourier das projeções afetadas do Phantom 
homogêneo afetadas pelo ruído Gaussiano. (a) Espectro de 
Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais  (c) 
afetadas pelo ruído e (d) filtradas. 

 

Na Figura 40, nota-se uma filtragem mais precisa. O ruído afeta as 

frequências mais altas do sinal. Algumas componentes foram atenuadas, como a 

faixa de frequência próxima de 35%, 47% 75% e 85%. Em compensação, algumas 

faixas de frequências foram restauradas, como as faixas de 21%, 42% e 95%. Por 

ser um filtro adaptativo, o comportamento não fica preso ao à um só intervalo de 

faixa. 

 



113 

 

 

Figura 41- Phantom de calibração homogêneo com ruído de Poisson. (a)  
Comparação entre os sinais da primeira linha da matriz de 
projeções. (b) Matriz de projeções do Phantom original. (c) Matriz 
de projeções com ruído. (d) Matriz de projeções filtrada. (e) 
Imagem do Phantom reconstruído. (f) Imagem do Phantom ruidoso 
reconstruído. (g) Imagem do Phantom filtrado reconstruído. 

Na Figura 41, foram adicionados ruídos do tipo Poisson. Esse tipo de ruído é 

característico por afetar principalmente as baixas contagens de fótons. É possível 

perceber como o sinal é mais afetado no centro do sinal do que nas extremidades. O 

filtro atua direcionado pela medição do ruído. Ou seja, altas contagens geram 

valores maiores de ruídos, enquanto baixas contagens geram valores menores. Mas 



114 

 

  

ao reconstruir as imagens, o contraste é essencial para que sejam observados 

valores de baixo contraste, ou seja, a relação sinal ruído é maior nas baixas 

contagens. O filtro se adapta e acaba por realizar uma filtragem consistente do sinal, 

o que pode ser observado na reconstrução da imagem filtrada.  

 

  

 

Figura 42- Espectro de Fourier das projeções afetadas do Phantom 
homogêneo afetadas pelo ruído de Poisson. (a) Espectro de 
Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais  (c) 
afetadas pelo ruído e (d) filtradas. 

Na Figura 42, é possível notar que o ruído afeta algumas faixas de frequência, 

atenuando suas componentes.  As frequências mais altas, da faixa de 90 a 100% 

são mantidas, enquanto frequências intermediárias sofrem com a atenuação. O filtro 

tenta restaurar essas componentes, atenuando quando é preciso, como a faixa de 

35%. 



115 

 

 

 

Figura 43- Phantom de calibração heterogêneo com ruído de multiplicativo. 
(a) Comparação entre os sinais da primeira linha da matriz de 
projeções. (b) Matriz de projeções do Phantom original. (c) Matriz 
de projeções com ruído. (d) Matriz de projeções filtrada. (e) 
Imagem do Phantom reconstruído. (f) Imagem do Phantom ruidoso 
reconstruído. (g) Imagem do Phantom filtrado reconstruído. 

Na Figura 43, pelo Phantom heterogêneo ter uma contagem de fótons maior 

que o Phantom homogêneo, há uma maior distorção no interior do sinal do que nas 

bordas. Esse tipo de ruído distorce o sinal completamente, deixando os detalhes da 

tomografia quase imperceptíveis ao reconstruir  a imagem. Após a aplicação do 

filtro, os elementos (os diferentes tipos de materiais do phantom) podem ser 



116 

 

  

visualizados. Isso porque o filtro atenuou o ruído presente nas contagem mais altas 

do que nas contagem mais baixas. 

 

 

 

Figura 44 - Espectro de Fourier das projeções afetadas do Phantom 
heterogêneo afetadas pelo ruído multiplicativo. (a) Espectro de 
Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais  (c) 
afetadas pelo ruído e (d) filtradas. 

 

Na Figura 44, é perceptível que o ruído afeta principalmente as componentes 

intermediárias e mais altas. O filtro acaba por atenuar as amplitudes em todo o 

espectro, o que causou uma restauração das frequências médias e atenuação das 

frequências altas. Como pode se notar na comparação entre os sinais, o ruído 

alterou principalmente as frequências mais altas. 



117 

 

 

 

 

Figura 45 - Phantom de calibração heterogêneo com ruído de Gaussiano. (a) 
Comparação entre os sinais da primeira linha da matriz de 
projeções. (b) Matriz de projeções do Phantom original. (c) Matriz 
de projeções com ruído. (d) Matriz de projeções filtrada. (e) 
Imagem do Phantom reconstruído. (f) Imagem do Phantom ruidoso 
reconstruído. (g) Imagem do Phantom filtrado reconstruído. 

Na Figura 45, é apresentado o Phantom com ruído aditivo Gaussiano. Como 

houve uma distorção do sinal pouco agressiva, a filtragem se apresentou de forma 

optimizada. Os elementos da imagem reconstruída são visíveis, mas há uma 

dificuldade em diferenciá-los. Após a filtragem, é perceptível uma melhoria e 

visualização dos quatro elementos. 

 



118 

 

  

 

 

 

Figura 46- Espectro de Fourier das projeções afetadas do Phantom 
heterogêneo afetadas pelo ruído Gaussiano. (a) Espectro de 
Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais  (c) 
afetadas pelo ruído e (d) filtradas. 

 

Na Figura 46, o ruído Gaussiano afeta principalmente as frequências mais 

altas. É possível notar que algumas das componentes mais altas foram recuperadas, 

enquanto outras que sofreram maiores distorções obtiveram pouco ganho (na faixa 

entre 80% e 90%). No espectro de Fourier da imagem reconstruída, nota-se que 

houve uma atenuação de frequências mais altas enquanto as frequências mais 

baixas foram mantidas. 



119 

 

 

 

Figura 47 - Phantom de calibração heterogêneo com ruído de Poisson. (a) 
Comparação entre os sinais da primeira linha da matriz de 
projeções. (b) Matriz de projeções do Phantom original. (c) Matriz 
de projeções com ruído. (d) Matriz de projeções filtrada. (e) 
Imagem do Phantom reconstruído. (f) Imagem do Phantom ruidoso 
reconstruído. (g) Imagem do Phantom filtrado reconstruído. 

Na Figura 47 é possível que o ruído Poisson afeta as áreas com menor 

contagem do que áreas com maior contagem de fótons. Isso é perceptível quando 

não há diferenciação entre certos elementos da imagem e a presença de ruídos no 

sinal com baixa contagem de fótons. A filtragem do sinal promoveu um melhor 

acompanhamento do sinal original. 



120 

 

  

 

 

Figura 48 - Espectro de Fourier das projeções afetadas do Phantom 
heterogêneo afetadas pelo ruído Gaussiano. (a) Espectro de 
Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais  (c) 
afetadas pelo ruído e (d) filtradas. 

 

Na Figura 48, é possível ver que no espectro de Fourier do sinal há  uma 

degradação maior do sinal nas frequências intermediárias e mais altas, pois o ruído 

de Poisson afeta as regiões de maior contraste. O filtro obteve uma eficiência maior 

na restauração das frequências médias e tendo atenuação nas frequências mais 

altas. No espectro de Fourier da imagem reconstruída da amostra ruidosa, o ruído 

afeta principalmente as frequências intermediárias e altas. No espectro da imagem 

restaurada, é possível notar a atenuação nas frequências enquanto o centro obteve 

um realce, visualizado pelo centro mais iluminado do que o restante do espectro. 



121 

 

Apesar de apresentar ruídos, é possível notar que ao adicionar diferentes 

tipos de ruído nas projeções e reconstruir suas respectivas imagens, há uma 

variação nos componentes em  todo o espectro. Esta mudança dos valores na faixa 

do espectro de Fourier ajuda a entender que houve realce nas frequências baixas, 

manteve as frequências intermediárias e reteve as frequências mais altas. 

Na Tabela 4, são apresentados os valores de ISNR para as filtragens do 

Phantom homogêneo enquanto na Tabela 5, são apresentados os valores para a 

filtragem do Phantom heterogêneo.  

 

Tabela 4 - Tabela de valores de ISNR obtidos pela filtragem do Phantom de 
calibração homogêneo com diferentes tipos de ruído.  

Funções 
Ruído 

Multiplicativo 
Ruído 

Gaussiano 
Ruído 

Poisson 

ISRN Máximo 94,07 dB 71,00 dB 84,75 dB 

ISRN Mínimo -69,13 dB -71,17 dB -66,69 dB 

ISRN Médio 4,45 dB 3,50 dB 4,49 dB 

Variância ISNR 130,77 dB 139,06 dB 130,70 dB 

ISNR da Imagem 4,55 dB 5,19 dB 4,38 dB 

 

Tabela 5 - Tabela de valores de ISNR obtidos pela filtragem do Phantom de 
calibração heterogêneo com diferentes tipos de ruído.  

Funções 
Ruído 

Multiplicativo 
Ruído 

Gaussiano 
Ruído 

Poisson 

ISRN Máximo 67,99 dB 60,43 dB 64,49 dB 

ISRN Mínimo -59,80 dB -84,59 dB -74,20 dB 

ISRN Médio 3,34 dB -0,75 dB -0,67 dB 

Variância ISNR 138,29 dB 172,51 dB 169,34 

ISNR da Imagem 4,28 dB 4,78 dB 5,62 dB 

 

A filtragem do ruído multiplicativo apresenta como melhoria uma média de 

4,45 dB para o Phantom homogêneo e de 3,34 dB para o Phantom heterogêneo 

com variâncias com valores mais baixos, ou seja, mais confiáveis.  

No caso das filtragens dos Phantoms com o ruído Gaussiano, a melhoria 

média foi de 3,50 dB para o homogêneo e -0,75 dB para o heterogêneo. O valor 

negativo representa que houveram mais perdas de dados do que ganho, estando 

ligado, nesse caso, aos detalhes do sinal que foram perdidos. Como no Phantom 

homogêneo há poucos detalhes, é esperado um valor mais alto do ISNR médio.  



122 

 

  

No caso dos Phantoms  que tiveram o ruído Poisson filtrado, repete-se a 

perda da qualidade do sinal no Phantom heterogêneo. Se analisar que os detalhes 

do sinal estão presentes nas baixas contagens, percebe-se que há um 

comportamento de que dados serão perdidos durante a filtragem, devido à 

suavização. 

O ISNR das imagens reconstruídas, apresentaram uma melhoria acima de 4 

dBs, o que garante um ganho na qualidade de imagem, o que pode se perceber na 

detecção de elementos que não eram bem visualizados nas imagens reconstruídas 

das projeções sem filtragem. 

 Ao ser aplicado em amostra de solos, é possível notar a qualidade do filtro. 

Ele se comporta de acordo com o ruído presente nas contagens de fótons e não 

diretamente à presença do ruído na imagem tomográfica após sua reconstrução. 

Isso faz com que, dependendo do número de fótons e do ruído presente nas 

projeções, ele se adapte, variando o corte e realce em determinadas frequências. 

Esse tipo de informação garante que mesmo o sinal tenha perdido detalhes, a 

imagem reconstruída vai ter um ganho de qualidade significativo. 

Para calcular o ISNR é necessário conhecer o ruído presente nos sinais e 

imagens. Em aplicações reais, feitas com amostras reais não é possível identificar o 

ruído de forma precisa. Dado esse problema, é utilizada a medição através do SNR 

que, apesar de não ser tão preciso quanto o ISNR, ainda serve como indicador de 

qualidade.  

Antes de aplicar a filtragem em amostras de solo, o filtro foi aplicado nos dois 

Phantoms sem adicionar qualquer tipo de ruídos. Como eles apresentam ruídos 

provenientes do tomógrafo e esses são caracterizados por aproximações, os 

resultados serão avaliados por SNR. 

Nas Figura 49, Figura 50, Figura 50Figura 51 e Figura 52 são apresentados 

os resultados com os Phantoms de calibração. Por haver perda de precisão, o sinal 

acaba sendo suavizado, não atingindo um valor próximo do final da projeção, 

diferentemente da filtragem anterior com mais precisão. Isso ocorre por vários 

fatores, os algoritmos em CORDIC possuem menor número de iterações para utilizar 

menos recursos na FPGA, tal como uma rede neural mais simplificada e número de 

bits da palavra reduzidos pela metade. 



123 

 

 

Figura 49 - Phantom de calibração homogêneo. (a) Comparação entre os 
sinais da primeira linha da matriz de projeções. (b) Matriz de 
projeções do Phantom original. (c) Matriz de projeções com ruído. 
(d) Imagem do Phantom original reconstruído. (e) Imagem do 
Phantom filtrado reconstruído.  

Na Figura 49, é possível observar que houve uma atenuação do ruído, o sinal 

se apresenta mais suave na matriz de projeções. A suavização do sinal aumentou o 

contraste na imagem reconstruída. Com a diminuição da granularidade da imagem, 

os pixels se apresentam na faixa mais clara. 



124 

 

  

 

Figura 50- Espectro de Fourier das projeções afetadas do Phantom 
homogêneo. (a) Espectro de Fourier da primeira linha da matriz de 
projeções. Espectros de Fourier das imagens reconstruídas das 
projeções: (b) originais e (c) filtradas. 

 

Na Figura 50, nota-se que algumas frequências tiveram suas amplitudes 

amplificadas, em diferentes faixas, enquanto na maioria das frequências, 

principalmente as mais altas, os valores se mantiveram. Visualizando o efeito no 

espectro das imagens reconstruídas, é possível notar que a perda de textura (no 

caso das imagens tomográficas reconstruídas, uma diminuição da granularidade). A 

imagem apresenta uma simetria mais definida após a filtragem. 

 



125 

 

 

Figura 51 - Phantom de calibração homogêneo. . (a) Comparação entre os 
sinais da primeira linha da matriz de projeções. (b) Matriz de 
projeções do Phantom original. (c) Matriz de projeções com ruído. 
(d) Imagem do Phantom original reconstruído. (e) Imagem do 
Phantom filtrado reconstruído.  

Na Figura 51 são apresentados os resultados obtidos com a filtragem do 

Phantom heterogêneo. É possível notar a suavização na comparação entre os 

sinais, havendo perda de alguns detalhes no sinal. No conjunto de projeções nota-se 

uma suavização em toda a matriz. Nas imagens reconstruídas, nota-se a diferença 

de contraste, apresentando objetos mais sólidos, com menor granularidade. 



126 

 

  

 

Figura 52 - Espectro de Fourier das projeções afetadas do Phantom 
heterogêneo. (a) Espectro de Fourier da primeira linha da matriz 
de projeções. Espectros de Fourier das imagens reconstruídas das 
projeções: (b) originais e  (c)  filtradas. 

 

Na Figura 52 é apresentado o espectro de Fourier filtrado do Phantom 

heterogêneo. Há uma menor variação nos coeficientes mais altos, com exceção da 

faixa entre 90% e 100%.  Ao se observar o espectro da imagem reconstruída, há um 

corte nas frequências mais altas, com os valores de intensidade mais baixos (cor 

azul escura) do que no espectro da imagem do Phantom original.  

Na Tabela 6 são apresentados os valores de SNR para os dois Phantoms de 

calibração. 

 

 

 



127 

 

Tabela 6 - Resultados obtidos com a análise de SNR das projeções e 
imagens reconstruídas.  

Phantoms 

Relação Sinal/Ruído (em dB) 

Projeção Imagem 

Original Filtrada Ganho Original Filtrada Ganho 

Homogêneo 14,52 14,68 0,16 2,34 2,56 0,22 

Heterogêneo 9,15 10,48 1,33 -1,32 -0,78 0,53 

 
 

A filtragem dos dois Phantoms apresentaram ganhos na qualidade do sinal. 

Fica evidente que o SNR é capaz de traduzir os resultados experimentais para 

resultados reais, mesmo que em uma escala de valor mais baixa.  

Após o processo de validação do filtro, aplicou-se o mesmo em projeções 

reais de tomografia de solos.  

 

 

4.2.2 RESULTADOS OBTIDOS COM AMOSTRAS DE SOLOS 
AGRÍCOLAS 

 

 

Nas Figuras 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67 e 68 são apresentados 

os resultados obtidos com os dados de tomografias de solo. Em geral, o sinal filtrado 

está dentro das expectativas de pouca perda de qualidade, garantindo uma imagem 

reconstruída de melhor qualidade, como foi verificado com os testes feitos com o 

Phantom  de calibração heterogêneo.  

Nas amostras de solo, o que se nota é a atenuação de determinadas faixas 

de  frequências, a granularidade é presente por toda imagem e a sua variação é 

designada por frequências mais altas. Os poros apresentam uma frequência 

intermediária por estarem em contraste com as partes sólidas das amostras e por 

terem uma menor variabilidade nos pixels enquanto as partes sólidas estão 

presentes nas frequências mais baixas. A atenuação de frequências altas tem como 

objetivo de eliminar os ruídos, mas também eliminam componentes importantes nas 

imagens, como as bordas e poros, que podem ser omitidos pela perda de contraste. 



128 

 

  

Por outro lado, o realce das partes sólidas faz com que o contraste aumente, 

deixando os poros mais evidentes.   

 
Figura 53 - Dados do arquivo areia2.dat. (a) Comparação entre os sinais da 

primeira linha da matriz de projeções. (b) Matriz de projeções do 
Phantom original. (c) Matriz de projeções com ruído. (d) Imagem 
do Phantom original reconstruído. (e) Imagem do Phantom filtrado 
reconstruído.  

 

Na Figura 53,  trata-se de uma microtomografia de um tubo contendo grãos 

de areia. A filtragem suavizou os picos e vales, aumentando o contraste da imagem 



129 

 

e eliminando porosidades onde não existem, como os grãos de areia. Os detalhes 

nas imagens foram mantidos como se vê a delimitação dos grãos e a presença dos 

pequenos círculos.  

 
Figura 54- Espectro de Fourier das projeções do tubo contendo grãos de 

areia. (a) Espectro de Fourier da primeira linha da matriz de 
projeções. Espectros de Fourier das imagens reconstruídas das 
projeções: (b) originais e  (c)  filtradas. 

 

No espectro do sinal restaurado apresentado na Figura 54, é possível notar 

uma atenuação de componentes por todo o sinal de forma discreta. No espectro de 

Fourier nota-se a atenuação dos componentes de frequências conforme se distancia 

do centro do espectro. É possível notar a atenuação de frequências mais altas por 

todo espectro, se apresentando de valores mais baixos, entre 1 e 2 no espectro da 

imagem reconstruída restaurada, enquanto esses valores estavam distribuídos entre 

2 e 3 no espectro da imagem reconstruída original. 



130 

 

  

 
Figura 55 - Dados do arquivo torrao.dat. (a) Comparação entre os sinais da 

primeira linha da matriz de projeções. (b) Matriz de projeções do 
Phantom original. (c) Matriz de projeções com ruído. (d) Imagem 
do Phantom original reconstruído. (e) Imagem do Phantom filtrado 
reconstruído. 

O sinal filtrado, apresentado na Figura 55, acompanha bem o sinal ruidoso 

mantendo as características das amostras, como os pequenos poros e eliminando 

os falsos artefatos gerados pelo ruído, como a falsa porosidade. Os detalhes ainda 

são consistentes e a imagem final apresenta um melhor contraste. 



131 

 

 

 
Figura 56 - Espectro de Fourier das projeções do torrão. (a) Espectro de 

Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais e  
(c)  filtradas. 

 

Na Figura 56, o espectro do sinal possui cortes em diferentes faixas de 

frequência. No espectro da imagem reconstruída original nota-se que o ruído está 

presente por todo o espectro, sendo que no espectro da imagem reconstruída após 

a filtragem das projeções há uma atenuação das frequências mais altas, com alguns 

componentes sendo mantidos (como a presença de uma borda e pequenos pontos 

mais claros no espectro). 

  



132 

 

  

 
Figura 57 - Dados do arquivo cimen2.dat. (a) Comparação entre os sinais da 

primeira linha da matriz de projeções. (b) Matriz de projeções do 
Phantom original. (c) Matriz de projeções com ruído. (d) Imagem 
do Phantom original reconstruído. (e) Imagem do Phantom filtrado 
reconstruído. 

Na Figura 57, o sinal se apresenta com uma maior porosidade e elementos 

com alto contraste no sinal, que podem ser vistos nas imagens reconstruídas como 

poros maiores e elementos mais claros.  O sinal é mais suavizado em comparação 

com o algoritmo proposto anteriormente, mas ainda realiza uma filtragem 

consistente. 

 



133 

 

 

 
Figura 58- Espectro de Fourier das projeções do solo cimentado. (a) Espectro 

de Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais e  
(c)  filtradas. 

 

Na Figura 58, por ser um sinal que apresenta vários detalhes, a frequência de 

diferentes valores é notada no espectro de Fourier. Nota-se o corte de determinadas 

frequências, baixas (em 30%) médias (em 47% e 70%) e altas (83% e 85%). Por ser 

afetado por diferentes ruídos, o filtra acaba determinando qual frequência deve ser 

atenuada, por se tratar de ruído. Nas imagens espectrais percebe-se como a 

atenuação permitiu o realce de outras frequências, como a presença de diferentes 

círculos no espectro.  



134 

 

  

 
Figura 59 - Dados do arquivo degri30.dat. (a) Comparação entre os sinais da 

primeira linha da matriz de projeções. (b) Matriz de projeções do 
Phantom original. (c) Matriz de projeções com ruído. (d) Imagem 
do Phantom original reconstruído. (e) Imagem do Phantom filtrado 
reconstruído. 

Na Figura 59,o sinal desta tomografia de solo se apresenta como um cone, 

devido às características físicas da amostra. O ruído se apresenta mais ao centro do 

sinal por haver baixa contagem e, quando reconstruída, a imagem apresenta falsa 

porosidade. Após a aplicação do filtro, os elementos principais são mantidos assim 

como os poros reais.  



135 

 

 
Figura 60- Espectro de Fourier das projeções do solo degradado. (a) Espectro 

de Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais e  
(c)  filtradas. 

 

Na Figura 60, como em outras amostras de solo, as atenuações em algumas 

faixas de frequências foram percebidas, desta vez, próximas às frequências de 5%, 

40%, 65% e 98%.  No espectro das imagens reconstruídas é possível notar que há 

uma atenuação, mas certas frequências ainda são mantidas. 

  



136 

 

  

 
Figura 61 - Dados do arquivo adub30.dat. (a) Comparação entre os sinais da 

primeira linha da matriz de projeções. (b) Matriz de projeções do 
Phantom original. (c) Matriz de projeções com ruído. (d) Imagem 
do Phantom original reconstruído. (e) Imagem do Phantom filtrado 
reconstruído. 

Na Figura 61, a característica principal do sinal dessa amostra é possuir uma 

parte menos porosa do lado esquerdo, caracterizado pela estabilização do sinal, e 

mais porosa do lado direito, caracterizado por um sinal mais tortuoso. O filtro 

aplicado se mostra eficiente, acompanhando o sinal bem próximo ao sinal original, 

eliminando a granularidade que poderia ser classificada como poros e  mantendo os 

detalhes da imagem reconstruída, como os pequenos poros.  



137 

 

 

 
Figura 62 - Espectro de Fourier das projeções do solo adubado. (a) Espectro 

de Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais e  
(c)  filtradas. 

 

Na Figura 62, é perceptível no sinal algumas atenuações nas frequências em 

diferentes faixas, sendo mais perceptível na frequência próxima a 70%. Nos 

espectros, nota-se uma maior atenuação, mas mantendo as características das 

frequências, mas com menores faixas de valores. 

  



138 

 

  

 
Figura 63 - Dados do arquivo mb1t1.dat. (a) Comparação entre os sinais da 

primeira linha da matriz de projeções. (b) Matriz de projeções do 
Phantom original. (c) Matriz de projeções com ruído. (d) Imagem 
do Phantom original reconstruído. (e) Imagem do Phantom filtrado 
reconstruído. 

 

Na Figura 63, o sinal apresenta vários detalhes que foram suavizados em 

conjunto com o ruído. Esses dados foram corrigidos a partir da classificação do filtro 

diretamente feito sobre o valor da projeção, assim, o que por haver baixa contagem 

no interior da amostra, os ruídos eram mais persistentes. Se analisar o topo do sinal, 

é notável a presença de ruído na alta contagem, o que determina que os detalhes 



139 

 

presentes nas baixas contagens tinha grande probabilidade de serem apenas 

ruídos. Analisando a imagem reconstruída pode se ver a diminuição efetiva da 

granularidade enquanto os pequenos poros e elementos de alto contraste foram 

mantidos.  

 

 
Figura 64 - Espectro de Fourier das projeções de solo argiloso. (a) Espectro 

de Fourier da primeira linha da matriz de projeções. Espectros de 
Fourier das imagens reconstruídas das projeções: (b) originais e  
(c)  filtradas. 

 

Na Figura 64, por ser um sinal com várias faixas de frequências, a filtragem 

apresenta cortes em diferentes frequências. Com a atenuação da frequência 

próxima a 75%, seguida de pequenas atenuações em frequências baixas como 13% 

e 21%, ligada a presença a granularidade e a textura da amostra. Essa densidade 

de sinais também é perceptível na imagem espectral original, onde há presença de 



140 

 

  

várias frequências altas. Na imagem espectral filtrada é possível notar o corte de 

algumas frequências altas. 

Analisando os valores apresentados na Tabela 6, é possível verificar a 

relação entre sinal e ruído do sinal e da imagem.  

 
Tabela 6 - Resultados obtidos com a análise de SNR das projeções e 

imagens reconstruídas.  

Arquivos 
das 

Projeções 

Relação Sinal/Ruído (em dB) 

Projeção Imagem 

Original Filtrada Ganho Original Filtrada Ganho 

areia2.dat 24,51 24,65 0,14 -1,36 -0,61 0,75 

torrao.dat 14,72 14,76 0,04 -1,29 -1,22 0,06 

cimen2.dat 18,08 18,16 0,08 -2,62 -1,68 0,94 

degri30.dat 18,90 18,96 0,06 -4,77 -5,09 -0,32 

adub30.dat 16,67 13,72 -3,00 -3,01 0,01 3,00 

mb1t1.dat 19,11 19,18 0,07 -1,71 -1,32 0,38 

 
 

As tomografias de solo obtiveram valores mais significativos na imagem do 

que no sinal, como as tomografias de grãos de areia (areia2,dat), latosolo 

(torrao.dat), de solo cimentado (cimen2.dat), solo adubado (adub30.dat) e o solo 

argiloso (mb1t1.dat), destacando que o solo adubado teve uma má avaliação no 

ganho do sinal, mas uma boa filtragem no ganho da imagem. Isso ocorre porque os 

valores de ISNR e SNR classificam que quanto mais suave é a imagem, maior é o 

valor. Ou seja, quanto menor a granularidade apresentada pela imagem 

reconstruída, mais confiável e melhor qualidade ela representará.  

Os resultados dos códigos gerados pela FPGA se apresentam semelhantes 

aos códigos gerados pelo simulador da  arquitetura feita com o uso do bloco HDL 

Import e o próprio código do Simulink
®
, após alterações necessárias devido a 

problemas ligados ao software de embarque, o Quartus II
®
. Nem sempre todas as 

operações na FPGA e no simulador são bem adequadas, como a inconsistência de 

dados gerados. Muitas vezes, uma linha de código deve ser dividida em pequenas 



141 

 

partes para que a leitura correta dos valores seja identificada de forma correta após 

o embarque ou a simulação. Ao compilar o código, o Quartus II
®
 gera latches que 

são necessários para resolver esses problemas, mas alguns acabam não sendo 

identificados. 

Após a correção, o código com pontos fixos executou da mesma maneira que 

o código embarcado pelas operações em ponto-fixo serem feitas com valores em 

binários como na FPGA. A diferença maior está no tempo de execução como pode 

ser visto na Tabela 7. Na Figura 69 são apresentados os dados da Tabela 6 em 

forma de gráfico para melhor análise do comportamento do processamento do filtro 

de Kalman em relação ao tempo. 

 

Tabela 7 - Tempo de processamento do filtro nos diferentes ambientes do 
Matlab

®
 e embarcado na FPGA. 

Ambiente 

Tempo de processamento em segundos 

Número de Posições no Sinal Digital 

10 50 100 200 400 600 

Matlab
®
 1,21 3,20 5,21 11,32 23,54 35,11 

Matlab
®
 com 

ponto fixo 
30,51 120,65 254,41 516,21 1002,61 1400,75 

Simulink
®
 0,09 0,67 2,22 5,29 8,22 10,68 

HDL Import 3,89 5,16 6,08 7,22 9,23 11,42 

FPGA 0,09 1,86 1,96 2,62 3,91 4,32 

 
No ambiente do Matlab

®
 com o código utilizando pontos flutuantes, o tempo 

foi o usual de operações normais. É considerado pesado por ser um código 

interpretado e não compilado. Ao se usar ponto-fixo, o tempo foi maior, pois há 

várias transformações e cálculos feitos em cima de pontos fixos.  



142 

 

  

 

Figura 65 - Comparação entre os diferentes tempos de processamento nos 
diversos ambientes usados para geração do código em HDL com 
o embarque do código na FPGA. O tempo de processamento da 
FPGA está ligado diretamente ao tempo de comunicação entre o 
computador e o dispositivo.  

 

Com o Simulink
®
, é feito uma compilação do código, gerando um arquivo 

executável em C, o que diminuiu o tempo até mesmo em relação ao código sendo 

executado no ambiente padrão do Matlab
®
. O código gerado pelo Simulink

®
 também 

já estava convertido em ponto-fixo. 

O bloco HDL Import é utilizado no Simulink
®
, mas a diferença é o código em 

HDL gerado numa fase anterior é importado e compilado. A estrutura segue o 

mesmo padrão do código a ser embarcado. Dependendo da versão do Matlab
®
, DSP 

Builder
®
, Quartus II

®
 e o compilador usado pelo Matlab

®
, o código gerado e 

embarcado pode atuar de forma diferente. O código inicial foi criado usando uma 

versão mais nova do Matlab
®
 (R2012b – 64 bits com um compilador externo), DSP 

Builder
®
 e Quartus II

®
 12.1. Ao usar um computador com versões mais antigas dos 

softwares, o mesmo precisou ser readequado. 



143 

 

Já o código embarcado na FPGA foi executado rapidamente, limitado apenas 

pela transferência de dados entre o computador e o dispositivo. É possível notar a 

vantagem de um sistema com base em lógica combinacional com menor poder de 

frequência, mas dedicado, do que um computador de uso geral que trabalha com 

processamento sequencial.  

Todos os testes foram feitos em um computador com processador Intel Core 

i7 com 8 núcleos de 3,6 GHz com 16 Gigabytes de memória RAM e HD SSD.  

A diferença do tempo de processamento não se deve à comparação normal 

sobre frequência de clock ou número de ciclos para executar uma instrução, algo 

presente em sistemas sequenciais. O trajeto dos dados já é pré-definido pelo projeto 

do código em HDL.  

O uso de FPGA também se difere de microcontroladores. Apesar de serem 

também usados para sistemas dedicados, eles possuem baixo poder de 

processamento e por serem baseados em lógica sequencial, dependem do ciclo de 

clock para realizar cada tarefa, perdendo para a capacidade de processamento em 

tempo real de dispositivos mais robustos.  

O uso de uma arquitetura baseada em algoritmos permitiu que dados fossem 

processados e disponibilizem a saída em um tempo menor. A eficiência depende 

mais da  estrutura da arquitetura do que a quantidade de ciclos, pois não há acesso 

em memória ou busca de instruções, como em computadores em tempo real.  

O filtro embarcado apresenta limitações relacionadas à precisão dos dados,  

reconfiguração da arquitetura (algo ainda indisponível na maioria das FPGAs atuais) 

e complexidade de sistemas não lineares. Contudo, essas limitações podem ser 

contornadas com o uso de um filtro de Kalman descentralizado para a correção em 

tempo real dos erros de precisão, da aplicação das redes neurais auto-

reconfiguráveis, que são atualizadas de acordo com a observância desses erros, 

dentro do contexto da FPGA, onde a arquitetura tem como referência a robustez e 

respostas em tempo real.   



144 

 

  

  



145 

 

5 CONCLUSÃO 
 

 

Em tomografia de raios X a filtragem convencional promove uma suavização 

dos valores devido à natureza da distribuição de dados (os coeficientes de 

atenuação) que apresentam uma distribuição uniforme, enquanto o filtro é limitado a 

trabalhar com um processo Gaussiano. Essa suavização promove a perda de 

detalhes, após a reconstrução da imagem,  que são elementos importantes e a 

ausência destes pode dificultar a caracterização de solos agrícolas. 

 Ao se usar filtragem de Kalman e RNAs para a estimação do processo, foi 

apresentado um resultado mais preciso através do mapeamento do comportamento 

das amostragens fazendo com que as transformações necessárias das incertezas 

sejam adequadas para garantir um melhor detalhamento das imagens.  

Algo que se nota, é que a qualidade da filtragem não depende mais do 

conhecimento das variâncias do processo. Em um filtro sem RNA a variância do 

processo é determinada pelas características físico-químicas da amostra ensaiada 

ou de ruídos presentes diretamente na projeção. Já na estimação do processo 

usando RNAs, a variância do processo passará a definir o grau de aprendizado da 

RNA em sua capacidade de se estimar os estados futuros livre de ruídos.  

O uso de funções não lineares permitiu que o processo (mapeado pela RNA) 

e a observação (baseada na equação de Beer-Lambert) alcancem a precisão 

necessária. A precisão tem um papel importante em uma estimação  próxima ao 

comportamento real do sistema através da observação das projeções afetadas pelos 

diferentes tipos de ruídos e suas diferentes distribuições. 

Para determinar o ruído que afeta o sistema, foi feito o uso da técnica de 

propagação de erros. Esta técnica foi necessária para se definir previamente o ruído 

do sistema que pode ser proveniente de diferentes fontes que afetam as medidas 

feitas pela contagem final de fótons, a incerteza na determinação dos coeficientes de 

atenuação do material e o tempo de exposição da amostra à radiação.  

Os algoritmos baseados em CORDIC permitiram a obtenção de um tempo 

menor de processamento e uma  mínima perda de precisão em relação ao uso das 

funções nativas do Matlab
®
. Este resultado foi alcançado devido às funções serem 

construídas dentro do sistema e usar em menor iteração dos laços para garantir 

precisão. 



146 

 

  

Uma melhor medida das variações dos ruídos do detector pode ser feita em 

tempo real. Quanto mais próximos são os valores da variância total do ruído medido, 

menor será o erro na etapa de reconstrução. A implementação do filtro em FPGA 

pôde assegurar melhores resultados devido à sua alimentação  com os valores mais 

precisos das variâncias  de cada  variável do sistema, de acordo com a calibração e 

energia utilizada pelo minitomógrafo. Ao ter o filtro implementado em hardware, o 

tempo de resposta da filtragem diminui consideravelmente.  

A limitação do uso de funções do Matlab
®
 e certos blocos para gerar HDL foi 

contornada pelo uso de funções implementadas especificamente para atender um 

grau de precisão nas medidas. Ao mesmo tempo, todas as funções não suportadas, 

como laços dinâmicos e matrizes dinâmicas tiveram que ser modificadas para 

aceitar um limite de número máximo, mesmo que nem todas as funções atinjam 

esse limite. Estas limitações, em relação ao baixo uso de recursos, vão contra o uso 

de facilidades permitidas no uso da linguagem M-code como a utilização de  

memória dinâmica. 

O bloco de função embarcada do Matlab
®,

 somente embarca um M-code em 

um bloco do Simulink
®
. Para transformar o código em HDL, existem outras opções, 

entre elas a ferramenta HDL Workflow Advisor. Esta ferramenta permite a otimização 

do sistema gerado com uma gama de opções para o balanceamento de atrasos, 

distribuição hierárquica de pipelines, otimização do controle de tempo e minimização 

de habilitação por clock.  

A configuração da placa de FPGA pôde ser feita automaticamente sem a 

necessidade de otimização do tempo de processamento e cálculo do consumo de 

energia pelo sistema. Após validar um código em HDL gerado pelo Matlab®, onde o 

mesmo deve ser aceito sem erros na compilação e simulado como se funcionassem 

na FPGA, as próprias ferramentas de embarque fizeram o processo de controle dos 

fluxos dos dados entre o computador e a FPGA, sem diretamente se envolverem 

com a análise da qualidade do código e poder de consumo ou uso de memória do 

sistema. 

Para uma simplificação do tratamento dos pontos fixos, adotou-se o mesmo 

valor para todas as variáveis do sistema por ser mais factível para controlar os erros 

ao analisar o código gerado.  



147 

 

A precisão do código embarcado foi a mesma do código gerado com pontos 

fixos, onde todas as funções foram trabalhadas como unidades lógicas, tanto no 

simulador quanto no próprio Simulink
®
 ao usar o tipo de ponto fixo. 

As ferramentas utilizadas permitiram diminuir a complexidade da construção 

da arquitetura usando HDL, mas apresentaram algumas limitações, principalmente 

para projetos complexos como uso de funções matemáticas exclusivas e funções de 

mapeamento de redes neurais. Por esta razão, o filtro teve que ser modificado para 

operar com uma rede neural mais simples, ainda que eficiente, como também utilizar 

de funções CORDIC com poucas iterações para liberar recursos na FPGA. Isso fez 

com que o filtro perdesse parte da precisão, antes garantida com um filtro 

trabalhando com pontos flutuantes em um computador de uso geral.  

Outro ponto importante na abordagem da filtragem usando FPGA foi o ganho 

no tempo de processamento dos dados, sua reserva de recurso do sistema 

computacional e possiblidade de portabilidade. O ganho no processamento de 

dados permitiu que sistemas de controle e armazenamento mais simples possam ser 

utilizados no sistema de tomografia computadorizada, sem exigir grandes recursos 

que acabem sendo desperdiçados para a tarefa de filtragem. Isto mostrou a 

possibilidade de se usar a FPGA como um dispositivo independente, onde os sinais 

gerados pelo tomógrafo são repassados a ela e automaticamente são tratados antes 

de chegar ao final do sistema. Como o filtro desenvolvido é on-line, ou seja, realiza a 

filtragem durante o processamento de cada projeção, o tempo de processamento 

pôde ser reduzido. 

Em geral, o uso do Matlab
®
 para gerar um código HDL de um sistema 

complexo como é um filtro de Kalman descentralizado com redes neurais foi 

adequado. Uma característica que se destacou foi a capacidade de se trabalhar com 

uma linguagem mais clara e menos ligada a blocos lógicos, o que  permitiu depurar 

o código de maneira mais eficaz ao invés de escrevê-lo em Verilog ou VHDL. Outra 

característica importante foi a otimização que permitiu reduzir o número de unidades 

multiplicadoras, trabalhar números fracionários (algo complexo em HDL) e 

desenrolar os laços antes da geração do código em HDL. 

 A capacidade de portabilidade não fica presa somente ao uso de FPGAs. 

Esses dispositivos também são usados para validar projetos de hardware de um 

modo mais físico do que simuladores de HDL, pois podem sofrer interferências, 

problemas com temporização e limitação de recursos. O projeto validado de uma 



148 

 

  

FPGA pode ser usado em um projeto de um ou mais processadores que operam em 

frequências mais próximas de processadores embarcados. Ao invés de requerer no 

final um hardware mais complexo e, possivelmente, menos robusto, a operação de 

filtragem pode ser feita totalmente em uma pastilha simples com o alto poder de 

processamento em um sistema totalmente paralelo e auto-reconfigurável.  

A auto-reconfigurabilidade é uma característica do filtro de Kalman, que, ao 

observar o erro, altera o ganho e, consequentemente, corrige o sinal. Essa tarefa 

passou a ser mais complexa e se mostrou mais eficiente com o uso de redes neurais 

artificiais, que, adicionalmente, corrige o processo de previsão do sinal, por meio de 

alterações nos valores dos pesos. Essas operações são feitas automaticamente 

apenas pela observação do sinal.  

 

 

5.1 TRABALHOS FUTUROS 
 

 

1. Utilizar uma FPGA de quinta geração com mais recursos para uso em 

computação de alto desempenho. 

2. Implementar o código diretamente em HDL para proporcionar o uso 

mais eficiente dos recursos e utilizando-se do próprio Quartus II
®
 com suas 

funcionalidades. 

3. Aplicar a filtragem embarcada de Kalman em processos dinâmicos da 

física dos solos.  

  



149 

 

REFERÊNCIAS 

 
 

1 PETROVIC, M.; SIEBERT, J. E.; RIEKE, P. E. Soil bulk analysis in three dimensions by 
computed tomographic scanning. Soil Science Society American Journal, v. 46, n.3, p. 445-
450, 1982. 

 

2 HAINSWORTH, J. M.; AYLMORE, L. A. The use of the computed-assisted tomography to 
determine spatial distribution of soil water content. Australian Journal Soil Research. v. 21, 
n.4 p. 435-443, 1983. 

 

3 CRESTANA, S. A tomografia computadorizada com um novo método para estudos da 
física da água no solo. 1985. 140p. Tese (Doutorado em Física Aplicada) – Instituto de 
Física de São Carlos, Universidade de São Paulo, São Carlos, 1985. 

 

4 EMBRAPA Instrumentação completa 23 anos de história, ousadia e persistência. Disponível 
em: &amp;lt;http://www.cnpdia.embrapa.br/noticia_04122007.html&gt; Acesso em: 29 de junho de 
2013. 

 

5 RIBEIRO, G. C. Desenvolvimento de um algoritmo para a reconstrução tridimensional 
para imagens de um minitomógrafo, baseado no método de reconstrução algébrica 
modificado e interpolação spline. 1994. 122p. Dissertação (Mestrado em Ciência da 
Computação) – Departamento de Computação. Universidade Federal de São Carlos, São 
Carlos, 1994.  

 

6 VENTURINI, Y. Análise quantitativa da qualidade de imagens digitais com o uso de 
espectro de Wiener. 1995. 84p. Dissertação (Mestrado em Ciência da Computação) – 
Departamento de Computação. Universidade Federal de São Carlos, São Carlos, 1995.  
 
7 MINATEL, E. R. Desenvolvimento de algoritmo para reconstrução e visualização 
tridimensional de imagens tomográficas com o uso de técnicas frequênciais e 
Wavelets. 1997. 121p. Dissertação (Mestrado em Ciência da Computação) – Departamento 
de Computação. Universidade Federal de São Carlos, São Carlos, 1997.  

 

8 GRANATO, L. F. Algoritmo adaptativo para a melhoria em imagens tomográficas 
obtidas em múltiplas energias. 1998. 135p. Dissertação (Mestrado em Ciência da 
Computação) – Departamento de Computação. Universidade Federal de São Carlos, São 
Carlos, 1998. 

 

9 PEREIRA, M. F. L. Algoritmo paralelo para reconstrução tridimensional de imagens 
tomográficas de amostras agrícolas em arquitetura DSP com técnicas Wavelets. 2002. 
142p. Dissertação (Mestrado em Ciência da Computação) – Departamento de Computação. 
Universidade Federal de São Carlos, São Carlos, 2002. 

 

10 LAIA, M. A. M. Filtragem de projeções tomográficas do solo utilizando Kalman e 
Redes Neurais. 2007. 131p. Dissertação (Mestrado em Ciência da Computação) – 
Departamento de Computação. Universidade Federal de São Carlos, São Carlos, 2007. 

 



150 

 

  

11 BOTEGA, L. C. Análise de imagens tomográficas da ciência do solo em ambiente de 
realidade virtual. 2008. 213p. Dissertação (Mestrado em Ciência da Computação) – 
Departamento de Computação. Universidade Federal de São Carlos, São Carlos, 2008. 

 

12 CRUVINEL, P. E. Minitomógrafo de Raios X e Raios gama computadorizado para 
aplicações multidisciplinares. 1987. 325p. Tese (Doutorado em Engenharia Elétrica, 
Universidade Estadual de Campinas, Campinas, 1987. 

 

13 CRESTANA, S.; CESAREO, R.; MASCARENHAS, S. Using a computed tomography 
miniscanner in soil science. Soil Science,  v.142, n.1, p.56-61, July 1985. 

 

14 CRESTANA, S.; MASCARENHAS, S.; MUCELLI, R. P. Tomografia computerizada 
aplicada à física de solos. Ciência e Cultura, , v. 36, n. 7, p. 676, ref. 10-F.3, 1984. 
Suplemento. 

 

15 CRUVINEL, P. E.; CESAREO, R.; CRESTANA, S.; MASCARENHAS, S. X-and ?-rays 
computerized minitomograph scanner for soil science. IEEE - Transactions on Instrumental 
and Measurement v. 39, n. 4, p. 745-750, 1990. 

 

16 LAIA, M. A. M.; CRUVINEL, P. E. An application approach to Kalman filter and CT 
scanners for Soil Science. In: GUNGOR,E. B. O.. (Ed). Principles, application and 
assessment in soil science. Naple, FL.: INTECH, 2011. Cap. 19, p 371-394. DOI: 
10.5572/1860. 

 

17 NAIME, J. M. Projeto e construção de um tomógrafo portátil para estudos de ciência 
do solo e planta, em campo. 1994. 87p. Dissertação (Mestrado em Engenharia Elétrica) – 
Escola de Engenharia de São Carlos, Universidade de São Paulo, São Carlos, 1994. 

 

18 WALLACE, J. S. Increasing agricultural water use efficiency to meet future food production. 
Agriculture Ecosystems &amp;amp; Environment.  v.82, n.3, p. 105-19. 2000. 

 

19 SHIPTALO, M. J.; DICK, W. A; EDUARDS, W.M. Conservation tillage and macropore 
factors that affect water movement and the fate of chemicals. Amsterdam, Soil &amp;amp; Tillage 
Research, v. 53, n. 3, p. 167-83. 2000. 

 

20 VAZ, C. M. P.  Tomografia computadorizada aplicada a estudos de compactação de 
solos. 1989. 110p. Dissertação (Mestrado em Engenharia Elétrica). Escola de Engenharia de 
São Carlos, Universidade de São Paulo, São Carlos, 1989. 

 

21 MACEDO, A.; VAZ, C. M. P.; CRUVINEL, P. E.; CRESTANA, S. Tomógrafo de resolução 
micrométrica para estudos do sistema água-solo-planta. Circular Técnica – Embrapa 
Instrumentação. p. 1-5, setembro, 1996. 

 

22 CRESTANA, S.; NIELSEN, D. R. Investigações não destrutivas de sistemas porosos 
multifásicos através de microtomografia de raios-X, gama e ressonância nuclear (RMN). In: 
ENCONTRO NACIONAL SOBRE ESCOAMENTO EM MEIOS POROSOS-ENEMP, 8., out. 
1990, Nova Friburgo, RJ. Anais... Nova Friburgo: Colégio Anchieta, 1990. p. 699-710, 1990. 

 



151 

 

23 VISÃO computacional. laboratório de robótica da Universidade de São Paulo. Disponível 
em&amp;lt;http://robot.lac.usp.br&gt; Acesso em: 29  de junho de  2013.  

 

24 MACEDO, A. Construção e uso de um tomógrafo com resolução micrométrica para 
aplicações em ciências do solo e do ambiente. 1997. 183p. Tese (Doutorado em 
Engenharia Elétrica). Escola de Engenharia de São Carlos, Universidade de São Paulo, São 
Carlos, 1997. 

 

25 CRUVINEL, P. E.; BALOGUN, F. A. Tomógrafo de espalhamento Compton para medidas 
agrícolas. Revista Engenharia Agrícola, v.26, n.1 ,p. 151-160, 2006. 

 

26 RADON, J. On the determination of functions from their integrals along certain manifolds. 
Ber Saechs Akad wiss. Leipzig Mathematical Physik,. v. 69, p. 262-277, 1917. 

 

27 BRACEWELL, R. N., Microwave transmission and cavity resonator theory. Sydney: 
Angus and Robertson 1946. 

 

28 TAKAHASHI, H.; SHIMODA, K.; TOWNES, C. H. Fluctuation in amplification of quanta with 
application to master amplifiers. Journal of Physics Society, Japan, v.12, n.6, p. 686-700, 
1957. 

 

29 CORMACK, A. M. Representation of a function by its line integrals, with some radiological 
applications. Journal of Applied Physics, v. 34, n. 9 p. 2908-2913, 1963. 

 

30 HOUNSFIELD, G. N. Computerized transverse axial scanning (tomography). 1. Description 
of system. Britannic Journal of  Radiology. v. 46, n. 552, p. 1016–1022, Dec. 1973. 

 

31 DEREMACK, E.; CROWE, D. G. Optical radiation detectors. New York: John Wiley &amp;amp; 
Sons, Inc., 1984. 

 

32 ZIEL, A. D. Noise in measurements. New York: John Wiley &amp;amp; Sons,1976. 
 

33 DUERINCKX, A. J.; MACOVSKI, A. Polychromatic streak artifacts in computed tomography 
images. Journal of Computering  Assisted Tomography, v. 2, n. 4, p. 481-487, 1978. 

 

34 JOSEPH, P. M. A method for correction bone-induced artifacts of CT scanners. Journal 
Computering  Assisted Tomography, v. 2, n. 1, p. 100-108, 1978. 

 

35 IBBOTT, G. S. Radiation therapy treatment planning and the distortion of CT images. 
Medical Physics, v.7, n. 3, p. 261,  1980. 

 

36 FURUIE, S. S. Reconstrucao tomografica de imagens com ruido Poisson: estimativa 
das projeções. 1990. 150p. Tese (Doutorado em Engenharia Elétrica) - Universidade de São 
Paulo, São Paulo, 1990.  

 



152 

 

  

37 PORTAL, A. L. S.. Refinamentos nos métodos de estimacao das projeções para a 
reconstrução tomográfica de imagens com ruido poisson. 1991. 122p.  Dissertação 
(Mestrado em Engenharia Elétrica) - Universidade de São Paulo, 1991. 

 

38 CÁSSARO, F. A. M. Tomografia de dupla energia para caracterização físico-hídrica 
de meios porosos deformáveis sob diferentes graus de hidratação. 1994.  194 p. 
Dissertação (Mestrado em Física) – Instituto de Física de São Carlos, Universidade de São 
Paulo, São Carlos. 1994. 

 

39 BIASSUSI, M. Estudo da expansão e contração de um vertissolo através da 
tomografia computadorizada simultânea. 1996. 91p. Dissertação (Mestrado em 
Agronomia) - Universidade Federal de Pelotas, Pelotas, 1996. 

 

40 GUERRA, A. C  Restauração de imagens de minitomógrafo de análise de solos por 
técnicas de regularização. 1998. 125p. Dissertação (Mestrado em Ciência da Computação) 
- Universidade Federal de São Carlos, São Carlos, 1998. 

 

41 HOMEM, M. R. P. Técnicas de reconhecimento de padrões aplicadas a imagens 
tomográficas adquiridas em múltiplas energias. 1998. 134 p. Dissertação (Mestrado em 
Ciência da Computação) - Universidade Federal de São Carlos, São Carlos, 1998. 

 

42 SALINA, F. V. Reconstrução tomográfica de imagens utilizando técnicas POCS 
sequenciais e paralelas. 2001. 112 p. Dissertação (Mestrado em Ciência da Computação)  - 
Universidade Federal de São Carlos, São Carlos, 2001. 

 

43 PEREIRA, M. F. L. Um modelo de reconstrução tomográfica 3D para amostras 
agrícolas com filtragem de Wiener em processamento paralelo. 2007. 148p. Tese 
(Doutorado em Física Aplicada) – Instituto de Física de São Carlos, Universidade de São 
Paulo, São Carlos, 2007. 

 

44 RIBEIRO, E. S. Novas propostas em filtragem de projeções tomográficas sob ruído 
poisson. 2010. 149p.  Dissertação (Mestrado em Ciência da Computação) - Universidade 
Federal de São Carlos, São Carlos, 2010. 

 

45 LAIA, M. A. M.; CRUVINEL, P. E. Evaluation of an embedded unscented Kalman filter for 
soil tomography. In: CONFERÊNCIA DE SISTEMAS EMBARCADOS CRÍTICOS, (CBSEC) 
USP, São Carlos. Anais…São Carlos:2011., v.1 n. 1, p. 1-6. 

 

46 LAIA, M. A. M.; CRUVINEL, P. E. Using Simulink to generate HDL code for validating an 
embedded Kalman filter. In: BRAZILIAN CONFERENCE ON CRITICAL EMBEDDED 
SYSTEMS, CBSEC, 2, 2012,Campinas. Proceedings… Canada:IEEE,2012. DOI 
10.1109/CBSEC.2012.17. 

 

47 ROJAS, R.; HASHAGEN, U. The first computers: history and architectures, New York: 
MIT Press, 2000. 

 

48 MARTINS, C. A. P. S.; ORDONEZ, E. D. M.; CORRÊA, J. B. T.; CARVALHO, M. B. 
Computação reconfigurável: conceitos, tendências e aplicações. Sociedade Brasileira de 
Computação, v.2, n.6,  p. 339-388, 2003. 

 



153 

 

49 VILLASENOR, J.; MANGIONE-SMITH, W. H. Configurable computing. Scientific 
American, v.. 276, n. 6,p. 54-59, June 1997. 

 

50 HWANG, K.; XU, Z. Scalable parallel computing: technology, architecture, programming, 
San Francisco: McGraw-Hill, 1998. 

 

51 LEWIS, T. G.; EL-REWINI, H. Distributed and parallel computing. Greenwich: Manning, 
1998. 

 

52 PFISTER, G. In search of clusters. 2nd ed.. New Jersey: Prentice Hall ,1998 
 

53 BUYYA, R. High performance cluster computing: architectures and systems. New 
Jersey: Prentice Hall, 1999. 

 

54 BUYYA, R. High performance cluster computing: programming and applications. New 
Jersey: Prentice Hall, 1999. 

 

55 TANENBAUM, A. S. Distributed operating systems. New Jersey: Prentice Hall, 1995. 
 

56 MULLENDER, S. J. Distributed-operating systems. ACM computing surveys, v. 28, n. 1, 
p. 22-33, March 1996. 

 

57 ALMASI, G. S.; GOTTLIEB, A. Highly parallel computing. 2.ed., Redwood City: 
Benjamin/Cummings, 1994. 

 

58 DECEGAMA, A. L. Parallel processing architectures and VLSI hardware.  New Jersey: 
Prentice Hall, 1989.v.1. 

 

59 WOLF, W. Modern VLSI design: a system approach. New Jersey: Prentice Hall, 1994. 
 

60 SANCHEZ, E.; SIPPER, M. HAENNI, J. B.; URIBE, A. P. Static and dynamic configurable 
systems, IEEE Transactions of computers, v. 48, n. 6. p. 556-564, June 1999. 

 

61 SIPPER, M.; SANCHEZ, E. Configurable chips meld software and hardware. IEEE 
Computer, v. 32, n. 1, p. 120-121, Jan, 2000. 

 

62 TURLEY, J. Triscend E5 reconfigures microcontrollers. Microprocessor report, p. 12-13, 
Nov. 16, 1998. 

 

63 BARR, M. Embedded systems glossary. Ethiopia: Neutrino Technical Library, 2007. 
 

64 HEATH, S. Embedded systems design: EDN series for design engineers 2nd. ed. 
Oxford: Newnes,2003. p. 88–89. ISBN 978-0-7506-5546-0, 

 



154 

 

  

65 SKLIAROVA, I.; FERRARI, A. B. Introdução à computação reconfigurável. Revista do 
Detua, v. 2, n. 6, p. 1-16, set., 2003. 

 

66 COMPTON, K.; HAUCK, S. Reconfigurable computing: a survey of systems and software. 
ACM Computing Survey, v. 34, n. 2, p. 171-210, June 2002. 

 

67 KATO, E. R. R.; PEDRINO, E. C. Introdução aos sistemas embarcados utilizando FPGAs. 
In: BRAZILIAN CONFERENCE ON CRITICAL EMBEDDED SYSTEMS, CBSEC, 2, 2012, 
Campinas. Proceedings…Canada: IEEE, 2012. v. 2, p. 42-47. 
 DOI 10.1109/CBSEC.2012.17.  

 

68  THE PROGRAMMABLE logic data book. San Jose, California: Xilinx Inc., 1994.  
 

69 MEHTA, G.; KINTALI, S. Hardware description languages. Santa Barbara: University of 
California, Oct., 2009. 

 

70 SMITH, D. J. HDL chip design: a practical guide for designing, synthesizing and 
simulating ASICs and FPGAs using VHDL or Verilog. California: Doone Publications, 1998. 

 

71 SOARES, A. B. Exploração do paralelismo em arquiteturas para processamento de 
imagens e vídeo. 2007. 128p. Tese (Doutorado em Computação) – Universidade Federal do 
Rio Grande do Sul, Porto Alegre, 2007. 

 

72 KALMAN, R.E. A new approach to linear filtering and prediction problems. Journal of 
Basic Engineering, v. 82, n.1, p. 35–45, 1960. 

 

73 SCHMIDT, S.F. The Kalman filter: recognition and development for aerospace applications. 
Journal of Guidance and Control, v. 4, n. 1, p. 4-7, 1981. 

 

74 O’BRIEN, F. The Apollo guidance computer: architecture and operation. Berlin: Springer 
Praxis Books / Space Exploration, 2010. 

 

75 HALL, E. C. Journey to the moon: the history of the Apollo guidance computer. Reston, 
Virginia, USA: American Institute of Aeronautics and Astronautics, 1996.. p. 196. ISBN 
156347185X. 

 

76 PORAT, B. A course in digital signal processing, New York: John Wiley &amp;amp; Sons,1997. 
ISBN 0-471-14961-6. 

 

77 OPPENHEIM, A. V.; SCHAFER, R. W.; BUCK, J. R. Discrete-time signal processing. 
2nd, ed, New Jersey: Prentice Hall,1999. ISBN 0-13-754920-2. 

 

78 WOLF, W. H. Computers as components: principle of embedded computing system 
design. San Francisco: Morgan Kaufmann, 2001. 

 

http://www.elo.utfsm.cl/~ipd481/Papers%20varios/kalman1960.pdf


155 

 

79 INCT-SEC. Instituto Nacional de Ciência e Tecnologia em Sistemas Embarcados Críticos. 
Disponível em: &amp;lt;http://www.inct-sec.org&gt;. Acesso em: 29 de junho de 2013.  

 

80 CARRO, L.; WAGNER, F. R. Sistemas computacionais embarcados. Jornadas de 
Atualização em Informática, n. 22, p.45-94, 2003. 

 

81 AYOUBI, R.; DUBOIS; J., MINKARA, R. FPGA Implementation of generalized maximal 
ratio combining receiver diversity. World Academy of Science, Engineering and 
Technology, v. 68, p. 1102-1107, 2010. 

 

82 CAI, J. J. Evolutionary bioinformatics with a scientific computing environment. 
Dallas: Texas A&amp;amp;M University, 2009. 

 

83 WELCH, G.; BISHOP, G.. An introduction to the Kalman filter. Chapel Hill:  University of 
North Carolina, 2004. 

 

84 HAYKIN, S. Kalman filtering and neural network, New York: John Wiley &amp;amp; sons, inc.; 
2001.285p. 

 

85 JULIER, S. J.; UHLMANN, J. K. A new extension of Kalman filter to nonlinear systems. 
Symposium. Aerospace/Defense Sensing Simulation and Controls, v.1, n. 1, p. 1-12, 
1997. 

 

86 HASTINGS, W. K. Monte Carlo sampling methods using Markov chains and their 
applications, Biometrika, v.  57, n. 1, p. 97-109, 1970. 

 

87 DOUCET, A.; DE FREITAS N.; GORDON, N.J., SMC methods in practice. 
Berlin:Springer-Verlag, 2001. 

 

88 VAN DER MERWE; R., WAN, E. The square-root unscented Kalman filter for state and 
parameter-estimation. IEEE International Conference on Acoustics, Speech, and Signal 
Processing (ICASSP), v. 6, p. 3461–3464, 2001. 

 

89 LAIA, M. A. M.; CRUVINEL, P. E.; LEVADA, A. L. Filtragem de projeções tomográficas da 
ciência do solo utilizando transformada de Anscombe e Kalman. In: CONFERÊNCIA 
BRASILEIRA DE DINÂMICA, CONTROLE E APLICAÇÕES,- DINCON’07,2007. São José do 
Rio Preto. Anais... São José do Rio Preto: Universidade Estadual de São Paulo, 2007. 

 

90 LAIA, M. A. M.; CRUVINEL, P. E. Filtragem de projeções tomográficas do solo utilizando 
Kalman e Redes Neurais numa estimação conjunta. In: CONFERÊNCIA BRASILEIRA DE 
DINÂMICA, CONTROLE E APLICAÇÕES, DINCON’08,2008, Presidente Prudente. Anais...  
Presidente Prudente: Universidade Estadual de São Paulo, 2008. 

 

91 LAIA, M. A. M.; CRUVINEL, P. E. Filtragem de projeções tomográficas utilizando Kalman 

Discreto e Rede Neurais. IEEE América Latina, v. 6, n.1, p. 114-121, 2008.  
 



156 

 

  

92 LAIA, M. A. M.; LEVADA, A. M; BOTEGA, L. C.; PEREIRA, M. F.; CRUVINEL, P. E. A 
novel model for combining projection and image filtering using Kalman and discrete wavelet 
transform in computerized tomography. IEEE  International Conference on Computational 
Science and Engineering,11

th
, v. 11, n. 7, 2008. 

 

93 LAIA, M. A. M.; CRUVINEL, P. E. Applying an improved square root unscented Kalman 
filtering in tomographic projections of agricultural soil samples. Revista Vetor, v. 18, n. 1, p. 1-
6, 2009. 

 

94 KAK, A. C.; SLANEY, M. Principles of computerized tomographic imaging. New York: 
IEEE Press, 1999. 

 

95 MASCARENHAS, N. D. A.; SANTOS, C. A. N.; CRUVINEL, P. E., Transmission 
tomography under poisson noise using the Anscombe transformation and Wiener filtering of 
the projections. Nuclear Instruments And Methods In Physics Research. Section A, v. 423, 
p. 265-271, 1999. 

 

96 VOLDER , J. E. The birth of CORDIC. Journal VLSI Signal Processing v. 25, n. 2, p. 
101-105, 2000. 

 

97 WALTHER, J. S. The Story of Unified CORDIC.  Journal VLSI Signal Processing v. 25,  
n.2 p. 107-112, 2000. 

 

98 LAKSHMI, B., DHAR A. S. CORDIC architectures: a survey, Kharagpur: Hindawi 
Publishing Corporation. 2010. 

 

99 BURKARDT J. Matlab. source code. Disponível em : 
&lt;http://people.sc.fsu.edu/~jburkardt/m_src/m_src.html&gt; Acesso em: 29 de junho de 2013.  
 

100 TEXAS INSTRUMENTS, TMS320C64x DSP Library Programmer's Reference, Appendix 
A.2. Disponível em :  &amp;lt;http://www.ti.com/lit/ug/spru565b/spru565b.pdf&gt; Acesso em: 12 de 
julho de 2013. 

 

101 MATHWORKS Fixed-Point Toolbox Documentation Glossary. Disponivel em: 
&lt;http://www.mathworks.com/help/fixedpoint/ref/bp7g699.html#f6811&gt;  Acesso em: 12 de julho 
de 2013. 

 

102 VISSIM Fixed-Point Toolbox.  Disponível em 
&lt;http://www.vissim.com/products/addons/vissim/fixed-point.html&gt; Acesso em: 12 de julho de 
2013 


</field>
	</doc>
</add>