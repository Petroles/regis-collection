<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-BG.04043</field>
		<field name="filename">BGP_1992_6_3_4_07_Aplicacao_de_inteligencia_artificial_na_identificacao.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">APLICAÇÃO DE INTELIGÊNCIA ARTIFICIAL NA IDENTIFICAÇÃO DE ELETROFÁCIES REDES NEURONIAIS VERSUS ANÁLISE
DISCRIMINANTE
APPLICATION OFARTIFICIAL INTELUGENCE TO ELETROFÁCIES IDENTIFICATION NEURAL NETWORKS VERSUS DISCRIMINANT ANALYSIS
Fernando da Silva Rodrigues1 1 e Izidro Avelino de Queiroz Neto2
RESUMO — Utiliza-se uma Rede Neuronial (RN), treinada com dados de perfis elétricos e de testemunho, para identificar eletrofácies. Diferentemente dos sistemas especialistas tradicionais, as RN's não necessitam de regras e o aprendizado se dá por meio da modificação dos pesos das conexões, após a entrada de estímulos. Além disso, as RN's estão preparadas para tratar dados incompletos e degradam suavemente quando partes da rede são destruídas. Perfis elétricos de raios gama, porosidade neutrônica e densidade da matriz, e ainda dados de testemunho, são utilizados como entrada para uma rede de retropropagação. Nesta, o erro se propaga da camada de saída para a de entrada, modificando os pesos nas conexões proporcionalmente à contribuição destas conexões para o erro total. Após treinada, a rede é capaz de identificar eletrofácies com um rendimento tão bom quanto o da análise discríminante. Acredita-se que combinando a neurocomputação com métodos tradicionais, como a análise discríminante, pode-se obter a solução de muitos problemas na definição de eletrofácies.
(Originais recebidos em 10.06.92).
ABSTRACT — Electro-facies are identified by a neurai network (NN) trained with weii-iog and core data. Uniike traditionai expert systems, it is unnecessary to feed ruies to an NN, iearning being achieved instead through changes that occur in the network "s connection weights foilowing stimuii input. Furthermore, NNs are we/f suited for anaiyzing missing or incomplete data, and they "degrade gracefuiiy" when a portion of the network is destroyed. in the proposed backpropagation network, gamma-ray, nêutron porosity, and bulk density iogs, coupied with core data, are used as input. The error is propagated backwards from the output layer to the input iayer, and the connection weights are modified in proportion to the contribution of the connections to the overaii error. Once trained, th/s NN performs as weii as discriminant anaiysis in identifying eiectric-log facies. The authors beiieve that the combination of neurocomputing and traditional computing methods iike discriminant anaiysis can help in the soiution of many probiems in electro-facies identification.
(Expanded abstract avaiiabie at the end o f the paper).
1	- INTRODUÇÃO
A utilização de inteligência artificial torna-se cada vez mais comum nos mais diversos setores. O uso da máquina, em tarefas que envolvem decisões e análise de dados com estrutura complexa, é hoje uma realidade bastante palpável. Recentemente, assistiu-se a uma demonstração impressionante do potencial dos métodos de inteligência artificial na Indústria Bélica. Mas mísseis "inteligentes", e programas de análise de alvos militares, não são ós únicos frutos do intenso esforço dispendido nos últimos anos em busca de máquinas com comportamento mais próximo ao do
homem. São encontradas aplicações em todas as áreas do conhecimento.
As Redes Neuroniais são uma tentativa de simular o funcionamento do cérebro, utilizando um modelo extremamente simplificado das interações entre os neurônios biológicos. A escolha de um modelo biológico se justifica pela dificuldade encontrada por sistemas tradicionais de computação para resolver problemas que parecem triviais aos organismos vivos.
Dentre os problemas já mencionados, existe uma classe muito interessante para a indústria do petróleo: problemas cujos dados estejam sujeitos a falhas e com elevado nível de ruído.
1	- Setor de Tratamento de Dados Geológicos (SETRAG); Divisão de Operações Geológicas (DIGEO), Departamento de Exploração (DEPEX)
Av. República do Chile, 65, Centro, CEP 20035, Rio da Janeiro, RJ, Brasil.
2	- Setor de Processamento de Dados (SEPROC), Superintendência de Pesquisa de Exploração e Produção (SUPEPI, Centro de Pesquisas
(CENPES), Cidade Universitária, Quadra 7, Ilha do Fundão, CEP 21910, Rio de Janeiro, RJ, Brasil.
0 cérebro dos organismos vivos, em particular o do homem, parece ter resolvido de forma satisfatória problemas que desafiam nossas máquinas mais sofisticadas. Alguns exemplos são mencionados a seguir:
—	o reconhecimento da voz humana mesmo em ambientes intensamente contaminados por ruído é um fato notável. Um bom exemplo é uma conversa com vários interlocutores falando ao mesmo tempo;
—	podem-se processar dados incompletos e com grande facilidade de erros. Um exemplo é a capacidade de se reconhecer uma melodia mesmo que várias notas musicais estejam incorretas ou ausentes;
—	o cérebro é muito mais tolerante a falhas nas unidades de processamento do que as máquinas convencionais. Imagine o que aconteceria com um computador digital se periodicamente fosse submetido a um tratamento semelhante ao dispensado aos lutadores de boxe.
A classificação de eletrofácies por meio de perfis elétricos é um problema que já mereceu a atenção de muitos especialistas. Atualmente, uma das soluções mais frequentes é a análise discriminante, cujos resultados serão comparados com os das RN's.
0 termo "análise discriminante" é a designação genérica de vários métodos utilizados para classificar amostras em dois ou mais grupos de características conhecidas, utilizando uma ou mais variáveis quantitativas.
2	- HISTORICO
As origens da neurocomputação podem ser identificadas nos trabalhos de Jackson (1958), que criticou as doutrinas "localizacionistas", isto é, afirmou que a distribuição de tarefas no cérebro não se dá de forma completamente localizada, como se pensava no séc. XIX. Este modelo, embora bastante rudimentar, do funcionamento do cérebro, contribuiu para o nascimento das primeiras idéias de processamento distribuído em paralelo.
Nos anos 40, iniciou-se o estudo dos modelos de aprendizado do cérebro (Hebb, 1949).
Em 1956, realizou-se a primeira conferência sobre inteligência artificial, patrocinada pela fundação Rockfeller, na qual foram lançados por pesquisadores de todo o mundo os fundamentos da inteligência artificial e da neurocomputação.
Nos anos 50, a utilização do computador digital permitiu a programação de modelos de RN's que simulavam a interação entre as células do cérebro. Como estes modelos apresentavam características de aprendizado semelhantes às dos organismos vivos, acreditava-se que, com uma máquina suficientemente grande e rápida, poder-se-ia reproduzir um cérebro humano.
O sonho acabou em 1969, quando Minsky e Pa-pert (Minsky et al. 1969), provaram matematicamente que os perceptrons (uma das mais simples RN's estudadas na época), eram incapazes de resolver
vários problemas. Os financiamentos e, conseqüente-mente, as pesquisas sobre o assunto diminuíram drasticamente nos anos 70.
Em 1982, John Hopfield, do CalTech, apresentou na Academia Nacional de Ciências dos EUA um trabalho sobre RN's. Este foi o primeiro trabalho sobre o tema relatado à Academia desde os anos 60 (Hopfield, 1982). A posição respeitada de Hopfield na comunidade científica contribuiu para que outros pesquisadores se interessassem pelas RN's. Este interesse foi acompanhado por um significativo aumento do suporte para as pesquisas.
Ainda na década de 80, mostrou-se que os problemas levantados por Minsky e Papert poderíam ser resolvidos por redes de arquitetura mais complexa que a dos perceptrons (Rumelhart etal. 1986).
Atualmente, o estudo das RN's encontra-se em franca expansão, tendo atingido recentemente a indústria do petróleo (Baldwin et at. 1989; Baldwin et al. 1990; McCormack, 1991).
3	- O MODELO BIOLOGICO
O neurônio é a unidade fundamental do cérebro (fig. 1). O núcleo atua como uma espécie de processador, que tem como entradas sinais provenientes de vários outros neurônios (frequentemente milhares). O caminho por onde se propagam os sinais de entrada são os dendritos. Se a combinação dos sinais de entrada (usualmente uma simples soma), ultrapassa um determinado nível, o neurônio produz um sinal de saída. O caminho por onde se propaga o sinal de saída é chamado axônio.
A transferência do sinal do axônio para outros neurônios se dá nas sinapses. Os axônios podem se ramificar, podendo desta forma enviar o mesmo sinal para muitos outros neurônios.
Acredita-se que é nas sinapses onde reside o que se chama de memória. A quantidade de informação
Fig. 1 - Representação simplificada de um neurônio biológico.
Fig. 1 - SimpUfied representation of biological neuron.
Fig. 2 - Modelo do neurônio artificial.
Fig. 2 ~ Model of artificiai neuron.
(nível de sinal), transmitida de um neurônio para outro depende do quão forte é a ligação sináptica. É esta força de ligação que se modifica quando o cérebro aprende.
O modelo apresentado não é, e nem pretende ser completo. A complexidade do comportamento dos seres vivos pressupõe algo mais sofisticado. No entanto, é notável a quantidade de aplicações bem sucedidas partindo-se, simplesmente, deste modelo.
Para se ter uma noção do nível de complexidade do cérebro, basta multiplicar o número estimado de neurônios do homem, da ordem de 101 0, pelo número médio de sinapses de um neurônio, da ordem de 103.
4	- REDES NEURONIAIS ARTIFICIAIS
Uma RN artificial é composta por elementos análogos aos neurônios biológicos (fig. 2). Associam-se às conexões entre estes elementos pesos escalares que desempenham o mesmo papel da força de ligação sináptica. São estes pesos que se modificam durante o processo de aprendizado (treinamento).
Anteriormente, foi visto que nos neurônios biológicos só existe sinal de saída após um certo nível de soma dos sinais de entrada. As funções que se mostram mais adequadas para reproduzir este comportamento nos neurônios artificiais são as do tipo sigmói-de, por exemplo :
f(x) = (1+6? (—1
A saída de um neurônio serve de entrada para outros neurônios. A cada linha, conectando dois neurônios artificiais, associa-se um único peso escalar. São estes pesos que se modificam durante o treinamento das RN's.
Usualmente, os neurônios artificiais se organi zam em camadas:
—	camada de entrada — recebe os sinais de entrada;
—	camadas intermediárias (ou escondidas);
—	camada de saída — fornece as respostas da rede.
Existem duas fases principais de funcionamento de uma rede — aprendizado e verificação (Recall).
Durante o aprendizado, os pesos se modificam até que a rede encontre um ponto de equilíbrio. Nesta fase, vários sinais são introduzidos na camada de entrada e, opcionalmente, na camada de saída.
O mais importante durante o processo de aprendizado é a forma de como os pesos se modificam à medida que são fornecidos dados à rede. Existem diversas estratégias de modificação destes pesos. Neste caso específico, utiliza-se a retropropagação (Rume-Ihart et at. 1986).
5	- DIFERENÇAS ENTRE A COMPUTAÇÃO TRADICIONAL E AS REDES NEURONIAIS
As RN's possuem características pouco ou nunca encontradas em programas "inteligentes" tradicionais, onde algumas podem ser vistas:
—	aprendizado por exemplos — as RN's modificam
seus pesos procurando reproduzir o comportamento dos dados, sendo, portanto, diferentes dos sistemas especialistas, onde é necessária a participação de uma pessoa experiente no problema que se pretende resolver, para gerar as regras que definirão o comportamento do sistema;
—	memória distribuída — as RN's estão mais adapta-
das para tratarem entradas incompletas que os sistemas tradicionais, além de serem mais tolerantes a falhas em suas unidades. Isto se deve à própria essência de construção das redes, elementos de processamento bastante simples e trabalhando em paralelo. Estas características garantem que é muito pequena a chance de qualquer elemento desempenhar um papel fundamental no processamento. Por outro lado, em sistemas tradicionais, é normalmente muito fácil identificar elementos fundamentais, isto é, elementos sem os quais o sistema entra em colapso;	v
—	reconhecimento de padrões — da mesma forma que o cérebro, as redes utilizam processamento em paralelo de forma maciça. Acredita-se que esta forma de processamento seja a principal responsável pela enorme capacidade do homem de reconhecimento de padrões.
6	- NOSSO PROBLEMA
Os perfis elétricos são registros de profundidade das propriedades físicas das diferentes litologias presentes em um poço. Estas propriedades podem ser a resistividade, densidade, porosidade, radioatividade, etc.
Os princípios físicos das medidas efetuadas pelas ferramentas de perfilagem, embora conhecidos, levam a equações de difícil solução. Além disso, em muitos casos, alguns parâmetros destas equações são desconhecidos, devido âs condições peculiares de um poço de petróleo (altas pressões, temperaturas superiores a 100 °C, interferências decorrentes do fluido de perfuração, etc.).
Por outro lado, os poços testemunhados oferecem uma ótima base de dados, com os resultados desejados do processamento e interpretação dos perfis efétricos.
7 - solução proposta
7.1	— Descrição da Rede
A identificação de eletrofácies utilizando RN's parece uma solução viável, considerando a boa performance deste método em outros problemas de classificação.
O objetivo da rede proposta é indicar, a partir dos perfis, qual a eletrofácies predominante em cada profundidade. Durante o processo de treinamento, são apresentados à rede os valores dos perfis elétricos (raios gama, densidade e porosidade neutrônica) e a eletrofácies correspondente para cada profundidade. Estas eletrofácies são obtidas a partir das descrições de testemunho. O poço escolhido para treinamento foi o 1-RUC-1-AM.
A rede tem a seguinte arquitetura básica (fig. 3):
—	uma camada de entrada, onde cada neurônio corresponde a um dos perfis. Um neurônio para raios gama, um para densidade, e um para a porosidade neutrônica (três neurônios);
—	uma camada intermediária (dez neurônios);
—	uma camada de saída (cinco neurônios), onde cada neurônio corresponde a uma das eletrofácies possíveis. A classificação da rede é dada pelo neurônio de saída com maior ativação.
A escolha do algoritmo retropropagação (Mc-Clelland e Rumelhart, 1988), para o aprendizado, deve-se à sua generalidade (Simpson, 1990) eà facilidade de implementação.
Para o treinamento foi montado um arquivo contendo os valores dos perfis, que servem de entrada para a rede, e o valor de saída desejado. Este valor de saída é um código binário onde cada bit representa uma das eletrofácies.
Fig. 3 - Arquitetura da rede proposta. Fig. 3 - Proposed network architecture.
O aprendizado consiste na apresentação do arquivo de treinamento diversas vezes â rede. Em cada passo, o algoritmo procura minimizar o erro entre a classificação calculada pela rede e a eletrofácies correta.
Cada passagem completa pelo arquivo de treinamento é chamada de época. Para medir o desempenho da rede, faz-se a verificação treca!!} do arquivo de treinamento a cada época, calculando-se o percentual de acerto obtido. Considera-se que a rede está suficientemente treinada quando o percentual de acerto atinge um nível previamente estabelecido.
Durante o período de projeto da rede, constatou-se que a escolha da forma de codificação dos dados é de fundamental importância. Uma escolha inadequada reduz enormemente a capacidade de classificação. A melhor performance é obtida quando se utiliza uma transformação linear para colocar todos os dados entre — 1 e 1.
7.2	— Implementação e Resultados
Inicialmente, usa-se um simulador que estabelece um ambiente para o projeto de RN's (Klimasauskas e Guiver, 1988), instalado em um microcomputador Itautec 286. A demora do processo de treinamento (várias horas) levou à implementação do algoritmo em FORTRAN, em ambiente IBM/3090. Para maiores detalhes do algoritmo, veja McCIelland e Rumelhart (1988).
Ao findar cada época, é feita a verificação do arquivo de treinamento e é calculado o percentual de acerto. Além disso, é montada uma matriz contendo o número de padrões incluídos em cada classe.
No ambiente do CENPES (IBM/3090-150-VF), o treinamento da rede consumiu aproximadamente 15 min de CPU. 0 arquivo de treinamento tem 2 000 pontos, e o índice de acertos estabelecido como satisfatório foi de 82%. Na figura 4 pode ser acompanhada a evolução do aprendizado.
Segundo a literatura (McCIelland e Rumelhart, 1988), a evolução do aprendizado é dependente do conjunto de pesos iniciais. Para testaresta dependência, efetuou-se três seqüências de treinamento, com pesos iniciais distintos. Como pode ser demonstrado na figura 4, não foram observadas diferenças significativas no treinamento.
Para medir a capacidade de generalização da rede, ou seja, de classificar dados desconhecidos, foram utilizados os perfis do poço 4-RUC-2-AM (fig. 5), obtendo-se 90% de acerto quando comparados os resultados com a classificação do testemunho. O tempo de CPU consumido na verificação é de aproximadamente 0.5 segundos.
Uma questão interessante é a razão da melhoria da performance na verificação {recall). Após uma análise mais detalhada dos dados, concluiu-se que os dados do poço de treinamento (1-RUC-1) têm uma estrutura mais complexa que o poço de verificação (4-RUC-2). Em outras palavras, a rede foi treinada pa-
Treinamento para o poço 1-RUC-1
1 QC*dtl
Fig. 4 ■ Evolução do aprendizado com pesos iniciais distintos. fig. 4 - Evofution of íearning with different initiai weights.
Fig. 5 - Resultado da classificação do poço 4-RUC-2 (AMV Apresentam-se, tambdm, para comparação, os dados de testemunho e o resultado da análise de discriminantes.
Fig. 5 - Classification results for Wall 4-RUC-2-AM. (A) discriminant analysis; (B) NN; (C) core sampling.
A B C
ra situações mais complexas do que as apresentadas durante a verificação. Quando a rede foi treinada com o poço 4-RUC-2 e feita a verificação com o poço 1-RUC-1,o índice de acertos cai para 78%.
Os resultados da análise discriminante, nos casos discutidos anteriormente, são ligeiramente inferiores aos das redes. A queda de performance é de aproxi madamente 5%. A análise discriminante foi realizada com o auxílio do pacote estatístico SAS.
Outro ponto interessante é o comportamento das redes e da análise discriminante quando os dados apresentam falhas, isto é, um dos perfis de entrada pode estar ausente. No quadro I, apresentam-se os resultados obtidos, com a mudança dos perfis de entrada, na classificação de eletrofácies do poço 4-RUC-2. Os índices de acerto indicam que a análise discriminante parece ser mais tolerante a falhas que a rede proposta. Nota-se, porém, que os métodos podem ser vistos como complementares, isto é, o uso conjunto melhora o desempenho.
QUADRO l/CHAfíT /
I Método	GR, Nphi, Rhob	Nphi, Rhob	GR, Rhob	GR, Nphi
Rede iDiscrimin.	90.5% 89%	81.5% 70.2%	68.6% 88%	60% 65%
Foi testada também a tolerância das RN's a danos em sua estrutura. 0 índice de acertos cai de 90% para 89% quando se eliminam dois neurônios de rede. Esta "degradação suave" de desempenho seria de grande utilidade para redes implementadas em hardware, pois poderíam ser projetadas máquinas com grande tolerância a falhas em seus componentes.
8	- CONCLUSÕES
Utiliza-se uma RN para auxiliar no trabalho de classificação de eletrofácies. Os resultados obtidos indicam que esta nova metodologia é promissora.
Podem ser ressaltados como pontos fortes das RN's a capacidade de "aprender" a partir dos dados, permitindo construir redes treinadas para cada situação específica, e a portabilidade, pois após o treinamento a rede pode ser instalada em micros, ocupando pouco espaço (aprox. 10k bytes}. As redes também podem ser empregadas em conjunto com outras ferramentas, como a análise discriminante, fornecendo informações complementares.
A performance da rede proposta na classificação de eletrofácies serve de estímulo para a busca de soluções de outros problemas, do cotidiano exploracio-nista, com o auxílio desta nova metodologia.
AGRADECIMENTOS
Ã colaboração dos Geólogos Elza Santa Oliveira e José Roberto Barbosa Corrêa (DENOC/DINTER/ SEGED), pela análise dos testemunhos dos poços utilizados no treinamento e na verificação da RN, ao APD Gustavo do Rosário Batista (DEPEX/DITREX/ SEPRAN), pela participação na fase inicial do trabalho, aos Geólogos Dirceu Abrahão (DEPEX/DIGEO) e Paulo Roberto Avila (DEPEX/DIGEO/SETRAG) pela correção de erros nos originais, ao Geofísico André White (DEPEX/DIGEO/SETRAG), pela ajuda na elaboração dos gráficos, ao Prof. Manoel Tenório, da Purdue University, pelas sugestões apresentadas para a construção da Rede e a Theógnis Castejon Rodrigues (DEPEX/DIGEO/SEDEX), pelo estímulo e apoio em todas as etapas do trabalho.
REFERÊNCIAS BIBLIOGRÁFICAS
BALDWIN, J. L., OTTT, D. N. Computer emulation of human mental processes: application of neural network simulator to problem in well log pattern recognition. In: CONFE-RENCE ON ARTIFICIAL INTELIGENCE IN PETROLEUM EXPLORATION AND PRODUCTION, Texas, 1989. Proceedings. .. Texas: A &amp;amp;M University, 1989. p. 145-175.
BALDWIN. J. L„ BATEMAN, M. B., WHÊATLEY, C. L. Application of a neural network to the problem of mineral identificaiion from well logs. The log analysts, p. 279-293, sep./oct. 1990.
HEBB, D. O. The organization of behavior. New York: Wiley, 1949.
HOPFIÊLD, J. J. Neural networks and physical systems with emergent collective computational. Proceedings of the Academy of Sciences, v. 79, p. 2554-2558, 1982.
JACKSON, J. On localization. In: SELECTED WRITINGS, v. 2. New York: Basic Book, 1958.
KLIMASAUSKAS, C. C., GUIVER, J. P. Neural Works. Pittsburgh: Neuralware, 1988.
McCORMACK, M. D. Neural computing in geophysics. Geo-physics: the leading edge of exploration, v. 10, n. 1, p. 1115, 1991.
McCLELLAND, J. L., RUMELHART, D. E. Explorations in parallel distributed processing: a handbook of models, program and exercices. Cambridge: Mit Press, 1988. 344 p.
MINSKY, M., PAPERT, S. Perceptrons. Massachusetts: Mit Press, 1969.
RUMELHART, D. E. et al. Parallel distributed processing: explorations in the microstructure of cognition. Cambridge: Mit Press, 1986. 2 v.
SIMPSON, K. S. Artificial neural system. [s.l.]: Pergamon Press, 1990.
EXPANDED ABSTRACT
Neura! networks (NNs) attempt to simuíate the workings of the human brain using an extremely simpHfied mode! of interactions between biological neurons.
The study of learning models of the brain began in the 1940s (Hebb, 1949). in 1956,at the first conference on artificial intelligence, sponsored by the Rockefeller Foundation, researchers from around the world launched the foundations of artificia! intelligence and neurocomputing. During the 1950s, use of the digita! computer made it possible to programm NN models that simulated the Interaction of brain cells. Since these models dispíayed tearning characteristics similar to those of living organisms, it was believed that a machine of sufficient size and speed coutd reproduce the human brain.
This dream ended in 1969 when Minsky and Papert (Minsky etal. 1969) proved mathematically thatperceptrons (one of the simplest NNs under study at that time) were incapable of solving various problems. Funding of research into the topic, and consequentiy research itself, fell sharply during the 1970s.
During the 1980s, it was shown that the problems raised by Minsky and Papert coutd be sotved using architecturai networks more comptex than perceptrons (Rumelhart et al. 1986). At present, the study of NNs is expanding steadüy and has recently reached the oi! industry (Baldwin et al. 1989; Baldwin et al. 1990; and McCormack, 1991).
The neuron is the basic unit of the brain. Its nucieus acts as a kind of processor, whose input are the signals from various other neurons (often from thousands of them). The dendrites are the paths along which these input signals are propagated. tf the combination of input signals (usually a simpte summation) surpasses a certain levei, the neuron wi/l produce an output signa!, which traveis alonga path called the axon.
The signa! trave!ing along the axon is transmitted to other neurons at the synapses. Axons can brandi out, sending the same signa! to many other neurons. !t is believed that what is usually known as memory resides at the synapses. The quantity of information (signa! levei) transmitted from one neuron to another depends upon how strong the synaptic connection is. It is the strength of this connection that is changed when the brain learns.
An artificial NN consists of e/ements analogous to biological neurons. Associated to the connections between these elements are scaled weights that play the same role as the strength of the synaptic connection. These weights are what change during the tearning process (i.e., training).
Electric logs are depth records of the physica! properties of the different lithologies found in a well. These properties indude resistivity, density, porosity, radiòactivity, and others.
Although the physica! principies behind the measurements taken by togging tools are known, they produce hard-to-solve equations. Furthermore, some
parameters of these equations are often unknown because of the particular conditions dispíayed by an oi! well (e.g., high pressures, temperatures above 100 deg.
C, or interferences caused by drilling mud). On the other hand, cored wellsprovide an exceUent data base, with the desired results from the processing and interpretation of E-logs.
Using NNs in the identification of electric-log fácies would appear to be a viabte proposal, considering how well this method has handled other classification problems. The purpose of the network proposed herein is to use well logs to indica te the predominant electro-facies at each depth. During the trainingprocess, the network is fed the E-!og values (gamma ray, density, and nêutron porosity) and the corresponding electric-log fácies obtained through core descriptions for each depth. Well 1-RUC-1-AM waschosen for training purposes.
The network's basic architecture (see fig. 3) consists of:
—	a three-neuron input layer, where each neuron corresponds to one of the logs (one neuron for gamma-ray logs, one for density, and one for nêutron porosity);
—	a ten-neuron intermediary layer;
—	a five-neuron output layer, where each neuron corresponds to one of the possible electric-log fácies. Classification of the network is defined by the most-activated output neuron.
An NN has two phases of operation: learning and recall. During the learning process, the connection weights are modified until the network reaches apoint of equitibríum. In this phase, various signals are introduced at the input layer and, optionally, at the output layer. What is most important during learning is the way in which the weights are modified as data are fed into the network. There are a number of strategies for alter ing these weights. !n this specific case, backpropagation is used.
For training purposes, a file was compiied containing a/I log values (which serve as input) and the desired output value. The latter is a binary code where each bit represents one of the etectro-facies. Learning consists of feeding the training fite to the network severa! times. At each step, the a/gorithm endeavors to minimize the error between the classification calculated by the network and the correct electric-log fácies.
Logs from Well 4-RUC-2-AM were used to measure the network's capacity for generaüzation that is, its ability to dassify nove! data. A comparison of NN results with the classification according to core samples yieldeda misdassification rate of 10%.
Toterance of damage to the NN structure was also tested. The misdassification rate encreases from 10% to 11% when two neurons are removed from the network. This "gracefu! degrading" in performance wouldbe most usefu! for networks implemented in hardware.
The performance achieved by the proposed network in dassifying electric-log fácies should encourage the search to sol ve other oil-exploration problems through reüance on this new methodology.
</field>
	</doc>
</add>