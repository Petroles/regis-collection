<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.05963</field>
		<field name="filename">10442_o%20problema%20da%20arvore%20de%20suporte%20de%20custo%20minimo%20com%20restri%c3%a7%c3%b5es%20de%20peso.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">2014
Eulália Maria Mota O Problema da Árvore de Suporte de Custo Mínimo Santos	com Restrições de Peso
Eulália Maria Mota Santos
Universidade de Aveiro Departamento de Matemática
2014
O Problema da Árvore de Suporte de Custo Mínimo com Restrições de Peso
Dissertação apresentada à Universidade de Aveiro para cumprimento dos requisitos necessários à obtenção do grau de Doutor em Matemática, realizada sob a orientação científica da Doutora Maria Cristina Saraiva Requejo Agra, Professora Auxiliar do Departamento de Matemática da Universidade de Aveiro.
Apoio financeiro da Fundação para a Ciência e Tecnologia e do Fundo Social Europeu no âmbito do III Quadro Comunitário de Apoio e por fundos nacionais do Ministério da Ciência, Tecnologia e Ensino Superior - Bolsa de doutoramento com a referência SFRH/BD/46394/2008.
o júri
presidente
Doutor Mário Guerreiro Silva Ferreira
Professor Catedrático da Universidade de Aveiro
Doutora Maria Teresa Nunes Chaves de Almeida
Professora Catedrática do Instituto Superior de Economia e Gestão da Universidade de Lisboa
Doutor Luís Eduardo Neves Gouveia
Professor Catedrático da Faculdade de Ciências da Universidade de Lisboa
Doutor Domingos Moreira Cardoso
Professor Catedrático da Universidade de Aveiro
Doutor José Manuel Vasconcelos Valério de Carvalho
Professor Catedrático da Escola de Engenharia da Universidade do Minho
Doutora Maria Cristina Saraiva Requejo Agra
Professora Auxiliar da Universidade de Aveiro (Orientadora)
agradecimentos	Em primeiro lugar agradeço à minha orientadora, a Professora Doutora Maria Cristina Saraiva Requejo Agra pela oportunidade que me deu de realizar este trabalho sob sua orientação e pela disponibilidade e apoio que me prestou ao longo da sua elaboração. Ao professor Agostinho Agra pela ajuda e sugestões. Aos meus pais, ao Luís, à Érica e ao senhor Carlos Jorge agradeço o apoio que sempre me deram. Aos meus amigos, Carlos Campos, Fátima Pina, Isabel Pego e Olga Oliveira agradeço a amizade e o apoio ao longo da realização deste trabalho. Em termos institucionais, agradeço o apoio concedido pelas seguintes entidades durante o período de preparação deste trabalho: FCT - Fundação para a Ciência e Tecnologia e CIDMA - Centro de Investigação e desenvolvimento em Matemática e Aplicações da Universidade de Aveiro. Para finalizar agradeço a todos os que têm contribuído direta ou indiretamente para a minha formação.
palavras-chave	Árvores com restrições de peso, Formulações, Relaxação Linear, Relaxação Lagrangeana, Desigualdades válidas, Separação, Heurísticas, Feasibility Pump, Local Branching.
resumo	Nesta tese abordam-se várias formulações e diferentes métodos para resolver o Problema da Árvore de Suporte de Custo Mínimo com Restrições de Peso (WMST - Weight-constrained Minimum Spanning Tree Problem). Este problema, com aplicações no desenho de redes de comunicações e telecomunicações, é um problema de Otimização Combinatória NP-difícil. O Problema WMST consiste em determinar, numa rede com custos e pesos associados às arestas, uma árvore de suporte de custo mínimo de tal forma que o seu peso total não exceda um dado limite especificado. Apresentam-se e comparam-se várias formulações para o problema. Uma delas é usada para desenvolver um procedimento com introdução de cortes baseado em separação e que se tornou bastante útil na obtenção de soluções para o problema. Tendo como propósito fortalecer as formulações apresentadas, introduzem-se novas classes de desigualdades válidas que foram adaptadas das conhecidas desigualdades de cobertura, desigualdades de cobertura estendida e desigualdades de cobertura levantada. As novas desigualdades incorporam a informação de dois conjuntos de soluções: o conjunto das árvores de suporte e o conjunto saco-mochila. Apresentam-se diversos algoritmos heurísticos de separação que nos permitem usar as desigualdades válidas propostas de forma eficiente. Com base na decomposição Lagrangeana, apresentam-se e comparam-se algoritmos simples, mas eficientes, que podem ser usados para calcular limites inferiores e superiores para o valor ótimo do WMST. Entre eles encontram-se dois novos algoritmos: um baseado na convexidade da função Lagrangeana e outro que faz uso da inclusão de desigualdades válidas. Com o objetivo de obter soluções aproximadas para o Problema WMST usam-se métodos heurísticos para encontrar uma solução inteira admissível. Os métodos heurísticos apresentados são baseados nas estratégias Feasibility Pump e Local Branching. Apresentam-se resultados computacionais usando todos os métodos apresentados. Os resultados mostram que os diferentes métodos apresentados são bastante eficientes para encontrar soluções para o Problema WMST.
keywords	Trees with weight constraint, Formulations, Linear relaxation, Lagrangean relaxation, Valid inequalities, Separation, Heuristics, Feasibility Pump, Local Branching.
abstract	In this thesis we discuss several formulations and different methods to solve the Weight-constrained Minimum Spanning Tree Problem (WMST). This problem, with applications in the design of communication networks and telecommunications, is a NP-hard combinatorial optimization problem. The WMST problem aims at obtaining, in a network with costs and weights associated to its edges, a minimum cost spanning tree such that its total weight does not exceed a given specified parameter. Various formulations to the problem are presented and compared. One is used to develop a procedure to introduce cuts based on separation and that became quite useful in obtaining solutions to the problem. To strengthen the formulations, new classes of valid inequalities, adapted from the well-known cover inequalities, extended cover inequalities and lifted cover inequalities, are introduced. These new inequalities incorporate information from two sets of solutions: the spanning trees set and the knapsack set. We present several separation heuristic algorithms that allow us to efficiently use the proposed valid inequalities. Based on Lagrangean decomposition, simple and efficient algorithms are presented and compared. The algorithms can be used to obtain upper and lower bounds to the optimal value of the WMST problem. Among them are two new algorithms: one based on the convexity of the Lagrangean function and another making use of the inclusion of valid inequalities. In order to obtain approximate solutions to the WMST problem, heuristic methods are used to find feasible solutions. The heuristic methods presented are based on the Feasibility Pump and Local Branching strategies. We present computational results using all these methods. Results show that the different methods presented are very efficient for finding solutions to the WMST problem.
Conteúdo
1	Introdução	1
2	O Problema WMST	7
2.1	Descrição do Problema	WMST ....................................... 9
2.2	Propriedades do Problema	WMST ................................... 11
2.3	Geração de Instâncias............................................ 15
3	Formulaçães	19
3.1	Formulações Naturais............................................. 21
3.2	Formulaçães Estendidas .......................................... 24
3.2.1	Formulação de Fluxos ...................................... 24
3.2.2	Formulação Miller-Tucker-Zemlin............................ 26
3.2.3	Formulação de Peso Miller-Tucker-Zemlin.................... 31
3.2.4	Formulacão de Fluxo com especificação de Pesos ............ 36
3.3	Procedimento com Introduçao de Cortes............................ 40
3.4	Experiâncias para Comparacão das Formulações e Resultados Compu-
tacionais ....................................................... 46
3.4.1	Exemplo Comparativo das Formulacães........................ 46
3.4.2	Comparacão das Formulaçães MTZ e WMTZ ..................... 48
3.4.3	Estudo Comparativo das Formulaçães......................... 57
3.4.4	Resultados Computacionais.................................. 67
3.4.5	Síntese dos Resultados Computacionais...................... 71
4	Algoritmos Lagrangeanos	73
4.1	Relaxação Lagrangeana para o Problema WMST ...................... 75
4.2	Algoritmo Lagrangeano Base....................................... 78
i
4.3	Comportamento Geométrico do Algoritmo Lagrangeano Base para o
Problema WMST................................................... 81
4.4	Definição dos Valores Ponderados Utilizados no Algoritmo Lagrangeano
Base para o Problema WMST....................................... 84
4.5	Experiências para Comparaçao dos Algoritmos Lagrangeanos e Resultados Computacionais .......................................... 105
4.5.1	Exemplo Comparativo dos Algoritmos Lagrangeanos ..........105
4.5.2	Descriçao dos Valores dos Parêmetros Usados nas Experiências
Computacionais Realizadas ............................... 106
4.5.3	Estudo Comparativo dos Algoritmos Lagrangeanos e Resultados
Computacionais........................................... 109
4.5.4	Séntese dos Resultados Computacionais.....................131
5	Desigualdades Válidas	133
5.1	Desigualdades de Cobertura (DC).................................135
5.2	Desigualdades	de	Cobertura Implécita	(DCI)..................... 138
5.3	Desigualdades	de	Cobertura Implécita	Estendida	(DCIE)...........141
5.4	Desigualdades	de	Cobertura Implécita	Levantada	(DCIL)...........144
5.5	Desigualdades	obtidas por Fixacão de	Variéveis..................149
5.5.1	Desigualdades de Cobertura Implécita Levantada por Down-Lifting
(DCILDL) ................................................ 150
5.5.2	Desigualdades de Cobertura Implécita Levantada por Up-Lifting
(DCILUL) ................................................ 155
5.5.3	Desigualdades Generalizadas de Cobertura Implécita Levantada
(DGCIL) ................................................. 160
6	Algoritmos de Separação	167
6.1	Algoritmos de Separacao Genéricos................................168
6.1.1	Algoritmo de	Separação	para as	DC.........................171
6.1.2	Algoritmo de	Separação	para as	DCI....................... 177
6.1.3	Algoritmo de	Separação	para as	DCIE...................... 182
6.1.4	Algoritmos de Separação para as DCIL..................... 186
6.1.5	Algoritmo de	Separacão	para as	DCILDL.....................201
6.1.6	Algoritmo de	Separacão	para as	DCILUL.....................207
6.1.7	Algoritmo de	Separacão	para as	DGCIL .....................214
ii
6.2	Experiências e Resultados Computacionais...........................220
6.2.1	Experiências realizadas com as DCs e as DCIs................221
6.2.2	Experiências Realizadas com as DCIEs........................222
6.2.3	Experiências Realizadas com as DCILs........................224
6.2.4	Experiências Realizadas com as DCILDLs......................226
6.2.5	Experiências Realizadas com as DCILULs......................228
6.2.6	Experiências Realizadas com as DGCILs.......................231
6.2.7	Comparaçao dos Algoritmos de Separaçao......................233
6.2.8	Resultados Computacionais...................................237
6.2.9	Síntese dos Resultados Computacionais.......................239
7	Método Feasibility Pump	241
7.1	Heurística Feasibility Pum Básica Aplicada ao Problema WMST .... 242
7.2	Alteracão da Funcao Objetivo na Heurística
Feasibility Pump Aplicada ao Problema WMST.........................247
7.3	Extensães da Heurística Feasibility Pump para o Problema WMST . . . 249
7.3.1	Modo de Obtencão das Solucães x*............................249
7.3.2	Critários de Arredondamento das Variáveis...................250
7.3.3	Mecanismos de Perturbacão...................................252
7.4	Comportamento da Heurística Feasibility Pump.......................253
7.5	Experiências e Resultados Computacionais...........................256
7.5.1	Descricão das Experiências Computacionais Realizadas........257
7.5.2	Exemplos Comparativos das Heurísticas Feasibility Pump .... 260
7.5.3	Resultados Computacionais...................................263
7.5.4	Síntese dos Resultados Computacionais.......................279
8	Método Local Branching	281
8.1	Local Branching Aplicado ao Problema WMST .........................282
8.2	Extensães do Mítodo Local Branching ...............................286
8.2.1	Solução de Referencia Inicial...............................287
8.2.2	Mecanismos de Intensificaçao e de Diversificacão............288
8.2.3	Critírios de Paragem........................................289
8.3	Local Branching versus Feasibility Pump............................290
8.4	Descrição dos Algoritmos Local Branching para o WMST...............292
iii
8.5	Experiências para Comparação dos Algoritmos Local Branching e Re-
sultados Computacionais........................................298
8.5.1	Exemplo Comparativo dos Algoritmos Local Branching......299
8.5.2	Estudo Comparativo dos Algoritmos Local Branching.......300
8.5.3	Resultados Computacionais...............................308
8.5.4	Síntese dos Resultados Computacionais...................317
9 Considerações Finais	319
Anexos	332
Notacao Utilizada	335
Siglas Utilizadas	343
Lista de Figuras	349
Lista de Tabelas	355
Bibliografia	362
iv
Capítulo 1
Introdução
O Problema da Arvore de Suporte de Custo Mínimo com Restrições de Peso, que designamos por WMST (Weight-Constrained Minimum Spanning Tree Problem), tem na literatura várias denominações e podemos encontrá-lo nas variantes de minimizaçõo e maximizaçõo. O problema foi mencionado pela primeira vez em 1982 por Aggarwal, Aneja e Nair [3], com a designaçõo de Minimum Spanning Tree Subject to a Side Constraint. Outros autores utilizam a designaçcõao Resource-Constrained Minimum Spanning Tree [58] e ainda outros a de Weight-Constraint Minimum Spanning Tree [4, 37, 55, 65]. Para o caso da variante de maximizaçõo a designaçao mais comum é Knapsack-Constrained Maximum Spanning Tree [52, 66].
O objetivo do Problema WMST é a obtencao de uma érvore de suporte de custo mínimo, de tal modo que o peso total da érvore nõo exceda um determinado valor. A introducõo da restriçõo de peso à érvore de suporte de custo mínimo transforma o WMST num problema NP-difícil [3].
O WMST ée um problema de Otimizaçcõao Combinatéoria que tem aplicacçõao, por exemplo, no desenho de redes de telecomunicaçcõoes e redes de comunicaçcaõo. Em Henn [37] encontram-se dois exemplos de aplicações do Problema WMST: design of physical systems subjected to limited budgets e minimum cost reliability constrained spanning tree, os quais têm aplicacõo em problemas de redes de comunicaçõo.
Na literatura, para este problema, podem ser encontradas fundamentalmente duas téecnicas para obtencçõao de soluçcõoes utilizando méetodos exatos. Uma das téecnicas consiste no uso da relaxaçcõao Lagrangeana combinada com uma estratéegia de Branch and Bound [3, 58] e outra consiste no uso de um algoritmo de tempo pseudo-polinomial
1
que usa a teoria espetral de grafos [38].
O artigo de Ravi e Goemans [54] descreve um esquema aproximado que usa a relaxação Lagrangeana e o artigo de Hong, Chung e Park [38] propõe um algoritmo de tempo pseudo-polinomial que usa a teoria espetral de grafos e também um esquema completo de aproximação bicritério. Os autores Hassin e Levin [35] melhoraram os resultados de [54] e consideram o problema como a interseção de matréides.
Em [66] os autores Yamada, Watanabe e Kataoka consideram o problema da arvore de suporte de custo méximo sujeita a restrições de peso. Provaram que o problema era NP-difícil, obtiveram limites superiores usando uma heurística de pesquisa local, utilizaram a relaxação Lagrangeana para a obtencão de limites inferiores, usaram o algoritmo Branch and Bound e por ultimo um método para acelerar o tempo computacional. Referem ainda que se pode facilmente aplicar ao caso da minimizaçcãao.
No artigo de Xue [65] é apresentado um simples, mas eficaz algoritmo primal-dual para obter soluçcãoes aproximadas para o problema de encontrar o caminho mais curto com restricães de peso (Weight-Constrained Shortest Paths) e para o Problema WMST. O autor apenas apresenta resultados computacionais para o algoritmo aplicado ao primeiro problema, mas afirma que tem intençcãao de estudar o segundo algoritmo para grafos aleatéorios e comparar com soluçcoães éotimas obtidas usando o Algoritmo k Smallest Spanning Tree [16].
Em Henn [37] é apresentado um estudo alargado de propriedades e relaxacão Lagrangeana para o Problema WMST e um novo algoritmo Branch and Bound.
Em vez da introduçcãao da restriçcãao de peso pode-se incluir o peso da éarvore como segundo objetivo. O problema resultante é de uma árvore de suporte biobjetivo/bicritério ([8, 31, 38, 53, 60, 61] entre muitos outros). Em Aggarwal, Aneja e Nair [3] são estabelecidas certas propriedades da soluçcaão éotima considerando uma aérvore de suporte bicritéerio.
Em 2007, Raidl, Pirkwieser e Puchinger [52] apresentaram um algoritmo evolutivo híbrido para o Problema da Arvore de Suporte de Custo Maximo com Restriçães Saco-mochila, baseado no algoritmo evolutivo proposto para o Problema da Aé rvore de Suporte de Custo Ménimo com Restriçães de Grau [39], sé adaptaram a inicializacão e a variação dos operadores.
Recentemente, Requejo et al. [55] descreveram varias formulaçães para o problema, Requejo e Santos [57] apresentaram algoritmos baseados em relaxação Lagrangeana e Agra et al. [4] descreveram desigualdades validas para o Problema WMST.
2
Nesta tese apresentamos várias formulações e diferentes métodos para resolver o Problema WMST, tais como, alguns procedimentos de introduçõo de cortes usando separaçõo, o metodo de relaxacõo: linear e Lagrangeana, alguns métodos de geraçõo e introducçaõo de desigualdades váalidas nas formulacçoões usando separacçõao, o máetodo Feasibility Pump para obter uma soluçõo inteira admissável, e por fim o método Local Branching para melhorar as soluções admissáveis.
Este trabalho esta organizado da seguinte forma. No Capátulo 2 fazemos uma pequena abordagem a problemas de árvores com restrições adicionais, nos quais se enquadra o Problema WMST. De seguida descrevemos o Problema WMST, apresentamos algumas propriedades importantes e descrevemos o processo de geraçõo de instâncias que servirõo para realizar experiâncias e obter resultados computacionais com os diferentes méetodos utilizados nesta tese para o Problema WMST.
No Capátulo 3 começamos por apresentar uma formulaçao genérica para o Problema WMST. De seguida, apresentamos duas formulações naturais: uma baseada nas desigualdades de eliminaçcõao de subcircuitos e a outra baseada em desigualdades de corte. Depois, apresentamos quatro formulaçcõoes compactas estendidas: uma formulaçcõao de fluxos, duas formulacões baseadas nas desigualdades Miller-Tucker-Zemlin e uma formulação de fluxos que especifica nos ándices o peso do caminho desde a raiz. Devido ao uso destas formulacçõoes se tornar limitado na práatica, vamos usar um procedimento, baseado em separaçcõao, no qual as restricçõoes de corte vaõo sendo introduzidas no modelo. Este procedimento permite obter a soluçõo átima, ou uma soluçõo admissável práxima da átima. No final do capátulo apresentamos resultados computacionais de váarias experiâencias realizadas com as formulacçõoes e tambáem efetuamos um estudo computacional comparativo entre as varias formulações apresentadas.
No Capátulo 4 começamos por fazer uma revisõo da literatura de alguns algoritmos Lagrangeanos existentes para o Problema WMST e para alguns problemas de Oti-mizacõo Combinatária. Com o objetivo de obter soluções aproximadas para o Problema WMST, propomos um algoritmo baseado na relaxaçõo Lagrangeana que denominámos de Algoritmo Lagrangeano Base para o Problema WMST e descrevemos o seu comportamento geométrico. Para o algoritmo base apresentado propomos diferentes variantes baseadas em algoritmos existentes para problemas de Otimizacõo Combinatária. Neste Capátulo discutimos ainda os resultados computacionais efetuando um estudo comparativo do ponto de vista computacional entre os vaários algoritmos derivados do Algoritmo
3
Lagrangeano Base.
No Capítulo 5 com o propósito de fortalecer as formulações apresentadas no Capítulo 3, discutimos classes de desigualdades válidas para o Problema WMST. Começamos por adaptar as conhecidas desigualdades de Cobertura para o Problema Saco-mochila Binario para o caso do Problema WMST e apresentamos novas desigualdades válidas baseadas numa estrutura em arvore, que designamos por Desigualdades de Cobertura Implícita. Propomos tambám Desigualdades de Cobertura Implícita Estendida baseadas nas conhecidas Desigualdades de Cobertura Estendida. Para fortalecer as desigualdades de Cobertura Implícita usamos a tácnica de levantamento sequencial de variáveis e obtemos as Desigualdades de Cobertura Implícita Levantada. Por fim, propomos uma generalização das Desigualdades de Cobertura Implícita Levantada que podem fortalecer ainda mais as formulaçães, sendo estas baseadas na fixacão de conjuntos de variíveis.
No Capítulo 6 descrevemos dois algoritmos heurísticos de separação genéricos para as classes de desigualdades vílidas apresentadas no Capítulo 5. Num dos algoritmos íe introduzida uma desigualdade víalida, em cada iteraçcaão, enquanto que no outro podem ser introduzidas víarias desigualdades víalidas na mesma iteraçcãao. De seguida especificam-se as alteraçães a efetuar nos algoritmos heurísticos de separação geníricos para introduzir as desigualdades validas descritas no Capítulo 5. Como para algumas classes de desigualdades vaílidas íe necessíario efetuar o levantamento de variíaveis, apresentamos tambím um algoritmo heurístico baseado em relaxação Lagrangeana para determinaçcãao dos coeficientes das variaíveis a efetuar levantamento. No final deste capítulo, apresentamos um estudo comparativo entre as vírias experiências computacionais realizadas com os algoritmos heurísticos de separacão propostos para as varias classes de desigualdades víalidas.
No Capítulo 7 para obter uma solucão inteira admissível descrevemos uma heurística denominada de Heurística Feasibility Pump Bísica Aplicada ao Problema WMST. Com o intuito de melhorar a qualidade das soluçoes obtidas, apresentamos uma versão onde se altera a funçao objetivo na Heurística Feasibility Pump Bísica aplicada ao Problema WMST. Para melhorar o desempenho das heurísticas Feasibility Pump propostas referimos algumas extensoes do Mítodo Feasibility Pump para o Problema WMST e apresentamos do ponto de vista geomítrico o comportamento da Heurística Feasibility Pump, no caso geral e no caso particular do problema em estudo. Para finalizar o capítulo, discutimos algumas experiêencias computacionais realizadas, descrevemos quatro estratíegias Heurísticas Feasibility Pump e comparamos essas estratíegias,
4
com a Heurística do Xpress aplicada ao nodo raiz utilizando a Formulação WMTZ e tambem com a primeira solução inteira admissível obtida através da Formulação WMTZ quando usa o procedimento Branch and Bound.
No Capítulo 8 para obter uma solucão inteira admissível aplicamos o Método Local Branching ao Problema WMST atravís da implementação de um algoritmo que deno-minímos de Algoritmo Local Branching Clíssico Aplicado ao Problema WMST. Com o propísito de melhorar o desempenho do algoritmo quando aplicado ao Problema WMST sãao apresentadas algumas extensoães do míetodo. Para alíem de se compararem os dois mítodos Feasibility Pump e Local Branching, tambím fazemos uma abordagem geomítrica do comportamento da Heurística Local Branching. Neste capítulo descrevemos ainda víarios algoritmos derivados do algoritmo clíassico e apresentamos um estudo computacional comparativo entre eles. Comparamos tambím o melhor destes algoritmos com o Algoritmo Branch and Bound do Procedimento de Introducão de Cortes P-WMTZ+C apresentado no Capítulo 3.
Por fim, no Capítulo 9 apresentamos algumas consideracoes finais.
No final dos Capítulos 3, 4, 6, 7 e 8 são apresentadas sínteses dos resultados computacionais obtidos para esse capítulo.
5
6
Capítulo 2
O Problema WMST
Diversos problemas do mundo real podem ser modelados por grafos. Em muitos problemas, os grafos devem ter estruturas mais próximas do problema real, particularmente, os problemas com estrutura em órvore.
Os problemas de Otimizaçao com topologia em órvore surgem num numero surpreendentemente grande de aplicações, tais como, redes informóticas, redes de transporte, distribuição de energia, localizaçõo de instalacoes, producõo industrial, telecomunicações e muitas outras.
O Problema da Arvore de Suporte de Custo Mínimo (MCST - Minimum Cost Spanning Tree ou, apenas, MST - Minimum Spanning Tree) ó um problema de Otimização Combinatória [49] para o qual se conhecem algoritmos eficientes, que em tempo polinomial, permitem obter a solução ótima.
Se incluirmos uma restrição adicional ao Problema MST, o problema resultante pertence a chamada classe dos problemas NP-difíceis [21].
Na literatura podemos encontrar alguns problemas de órvores de suporte de custo mónimo com restrições adicionais que têm sido alvo de estudo. Para cada problema podemos encontrar muitas referências, mas apenas vamos referir algumas. Sõo eles, o Problema da Arvore de Suporte de Custo Mónimo com:
• Restrições de Capacidade - Capacited Minimum Spanning Tree [23, 27]
Consiste em determinar uma órvore de suporte de custo mónimo centralizada num vértice do grafo 0 (raiz), com a restriçõo adicional de a soma dos pesos dos nos de qualquer sub-órvore conetada à raiz nõo poder ser maior que um dado valor Q (numero natural).
7
•	Restrições de Grau - Degree-constrained Minimum Spanning Tree [9, 48]
Pretende-se determinar uma árvore de suporte de custo mínimo tal que o grau dos vártices não exceda um valor máximo.
•	Restrições de Salto - Hop-constrained Minimum Spanning Tree [25, 28]
Consiste em determinar a árvore de suporte de custo mínimo tal que o numero de saltos no unico caminho desde o nodo raiz até qualquer outro nodo da árvore não á superior a H (numero natural).
•	Restrições de Diâmetro - Diameter-constrained Minimum Spanning Tree [26, 56]
Neste problema pretende-se determinar uma árvore de suporte de custo mánimo sujeita a um limite D (numero natural) para o seu diâmetro.
•	Restrições de Peso - Weight-constrained Minimum Spanning Tree [3, 4]
Consiste em encontrar uma arvore de suporte de custo mínimo, de tal modo que o peso total da árvore nao exceda um determinado valor W (numero natural). Este á o problema em estudo ao longo da tese e vai ser descrito de forma detalhada na Secçao 2.1.
A inclusao destas restriçães tem a ver com propriedades adicionais que á necessario incluir nas redes/arvores. Por exemplo, as restricoes de diâmetro e de salto estao relacionadas com restrições de atraso máximo e restriçães de fiabilidade da rede, de modo a evitar a degradação da qualidade do sinal. As restriçães de capacidade e de grau encontram-se relacionadas com restricães de capacidade de certos dispositivos instalados em alguns nás e as restriçães de peso ou saco-mochila como tambám são conhecidas encontram-se relacionadas com restricães nos custos de instalação da rede.
8
2.1	Descrição do Problema WMST
O Problema da Arvore de Suporte de Custo Mínimo com Restrições de Peso, WMST ( Weight-constrained Minimum Spanning Tree Problem), é definido do seguinte modo.
Consideremos um grafo completo nao orientado G = (V, E), com o conjunto de
nodos V = {0,1,... ,n — 1} e o conjunto de arestas E = {{i, j}, i,j G V,i = j}. O n(n — 1)
conjunto V contém n nodos e o conjunto E contém ------------2---- arestas. Cada aresta
e = {i, j} G E tem associado um custo ce e um peso we, ambos inteiros e positivos.
O Problema WMST consiste em encontrar uma érvore de suporte T = (V, ET) em G, Et G E, de custo mínimo C(T) VegET ce, onde o peso total da arvore W(T) Ve€^, we nao exceda um dado limite W (numero natural). No Problema WMST a restrição adicional que é incluída ao Problema MST é chamada de restricão
de peso ou restrição saco-mochila (Knapsack Constraint ou Weight Constraint) e deve
ser de tal forma que
£we &amp;lt;W.
Assim, com a introdução desta restricao adicional, o Problema MST transforma-se no Problema WMST que é um problema de Otimização Combinatória NP-difícil [3]. Denota-se por XWMST o conjunto de todas as solucoes admisséveis do Problema WMST e por d(WMST) o valor étimo.
Exemplo 2.1.
Consideremos uma instâancia do problema, um exemplo de um grafo com 5 nodos, para o qual os custos e pesos associados a cada aresta se encontram indicados nas seguintes matrizes:
	( - 6	3	8	7 A		( -	1	9	8	7 \
	- 6 2 2		-	1	15 16
H=	- 4	5	e	C =	- 30 16
	- 5		- 10
\	- J	\	- J
onde H e C são as matrizes de pesos e custos, respetivamente.
9
Pretendemos obter a éarvore de suporte de custo ménimo com a restriçcaão adicional de o peso da arvore nao poder exceder o valor W = 20 (W(T) &amp;lt;20). Usando, por exemplo, o Algoritmo de Kruskal ou Prim [6] obtemos a érvore de suporte de custo ménimo ilustrada na Figura 2.1.
( - 1
C =
9	8	7	\
1	15 16
- 30 16
- 10
-
Figura 2.1: Arvore de suporte de custo mínimo.
Esta érvore tem custo C(T) = 17 e peso W(T) = 27 pelo que é não admissével para o Problema WMST, pois nao verifica a restriçao de peso, ou seja, W(T) = 27 &gt; W = 20. Uma solucão admissével seria, por exemplo, a érvore de suporte da Figura 2.2.
-1
C =
9	8	7 &gt;
1	15	16
-	30	16
	-	10
-
Figura 2.2: Árvore de suporte com custo 27 e peso 19.
A árvore representada na Figura 2.2 tem custo C(T) = 27 e peso W(T) = 19. Além de ser admissével dado que verifica a restrição de peso (W(T) = 19 &amp;lt;20) ela corresponde a soluçao otima do Problema WMST para a instência de 5 nodos considerada.
10
Um problema definido num grafo não orientado G = (V, E) pode-se transformar num problema equivalente definido num grafo orientado, onde cada aresta do grafo não orientado e = {0, j} G E é substituída por um arco (0,j) e cada aresta e = {i,j} G E,i = 0, é substituída por dois arcos, o arco (i,j) e o arco (j,i). Assim, no grafo orientado G = (V, A), apenas se altera o conjunto de arcos, o qual é dado por A = {(i,j), i G V, j G V \ {0},i = j}. Cada arco (i,j) G A herda os custos e os pesos da aresta correspondente {i,j} do grafo não orientado. Deste modo, cada arco (i,j) tem associado um custo cij e um peso wij, ambos inteiros e positivos.
2.2	Propriedades do Problema WMST
Nesta secçao vamos apresentar algumas propriedades do Problema WMST. Para o fazer vamos usar três arvores: a Arvore de Suporte de Custo Mínimo, a Arvore de Suporte de Peso Mínimo e a Arvore de Suporte Ponderada Mínima.
Árvore de Suporte de Custo Mínimo (MST)
O Problema MST consiste em encontrar uma arvore de suporte Tc = (V, ATc), Atc G A em G = (V, A) de custo mínimo C(Tc) = W(i,j)eA^ Cj.
Para obtermos uma MST, árvore de suporte de custo mínimo, existem vários algoritmos polinomiais tais como os algoritmos de Sollin, Kruskal e Prim (ver [6]).
Árvore de Suporte de Peso Mínimo (MSTW)
O Problema MSTW consiste em encontrar uma arvore de suporte Tw = (V,ATw), Atw G A em G = (V, A) de peso mínimo W(Tw) = 12(i,j)eATw wij•
Neste caso tambíem podemos recorrer aos algoritmos polinomiais referidos anteriormente para obtençcãao da íarvore Tw (ver [6]).
11
As írvores Tc e Tw são duas arvores de G, sendo Tc a írvore de suporte de custo mínimo e Tw a írvore de suporte de peso mínimo. A arvore Tc tem associado um peso W(Tc) V	wij que, não sendo inferior ou igual a W, não í uma írvore ad-
missível para o Problema WMST. A íarvore Tw tem associado um custo C(Tw) = 12 (i , j)eArw j sendo esta admissível, no caso do seu peso ser inferior ou igual a W. Verifica-se que os custos da írvore Tc e da írvore Tw correspondem a um limite inferior e superior, respetivamente, para o valor otimo $(WMST) do Problema WMST, o que nos permite escrever
C(Tc) &amp;lt;$(WMST) &amp;lt;C(Tw).
Podemos assumir igualmente a seguinte proposicçãao.
Proposicao 2.1.
O Problema WMST tem solução ótima se e só se
W(Tw) &amp;lt;W &amp;lt;W(Tc).
Facilmente se conclui que se W(Tw) &gt; W, entao o Problema WMST não tem soluçcãao. E temos tambíem as seguintes proposiçcãoes.
Proposicao 2.2.
Se W(Tc) &amp;lt;W, entao Tc í uma írvore correspondente a solucao otima para o Problema WMST.
Proposicçõao 2.3.
Se W(Tw) &amp;lt;W e C(Tw) = C(Tc), então Tw í a írvore correspondente a solução otima para o Problema WMST.
Apesar de Tw ser uma arvore admissível, no caso de W(Tw) &amp;lt;W, o objetivo e encontrar melhores soluções admissíveis do que a correspondente solucao da arvore de suporte Tw.
12
Exemplo 2.2.
A árvore de suporte de custo mínimo Tc encontra-se representada na Figura 2.1 e temos que C(Tc) = 17 e W(Tc) = 27 pelo que Tc á uma árvore nao admissível para o Problema WMST (W(Tc) = 27 &gt; 20 = W).
A árvore de suporte de peso mínimo Tw encontra-se representada na figura seguinte.
	í -	1	9	8 -	1	15	7 16	
C =		- 30	16	
		-	10	
			-	/
Figura 2.3: Arvore de suporte de peso mínimo.
A árvore Tw tem custo C(Tw) = 70 e peso W(Tw) = 11, pelo que Tw á uma árvore admissível para o Problema WMST (W(Tw) = 11 &amp;lt;20 = W).
Assim, 17 &amp;lt;^(WMST) &amp;lt;70 e 11 &amp;lt;W = 20 &amp;lt;27.
Árvore de Suporte Ponderada Mínima (MSTP)
O Problema MSTP consiste em associar valores positivos a cada arco (i, j) G A, os quais são combinação linear do custo e do peso, sendo estes da forma, pij = awij + bcij, com a e b escalares reais não negativos.
O Problema MSTP consiste em encontrar a arvore de suporte Tp = (V, ATp),
ATp C A, em G = (V, A) de valor ponderado mánimo P(Tp) V(ij)eAT Pj com um peso	W(Tp)	=	(i ;j)€A	Wj	e um custo	C(Tp)	=	(i ;j)€A	Cj.	Para a obtenção
desta arvore Tp também podemos recorrer aos algoritmos polinomiais descritos em [6].
Em particular:
• Se a = 0e b =1, entao obtemos a arvore de suporte de custo mánimo Tc (Tp = Tc).
13
• Se a = 1 e b = 0, então obtemos a árvore de suporte de peso mínimo Tw (Tp = Tw).
Note-se que a árvore Tp pode ser uma árvore admissível, caso W(Tp) &amp;lt;W ou uma árvore nao admissível no caso de W(Tp) &gt; W.
Exemplo 2.3.
Dependendo da escolha dos valores dos parâmetros a e b no cálculo dos valores ponderados de cada arco (i, j) G A, podemos obter arvores admissíveis ou nao admissíveis. Consideremos, por exemplo, os valores ponderados da forma, pij = 0,5wij + 0,5cj para cada arco (i,j) G A. Na Figura 2.4 encontram-se a matriz de valores ponderados L e a correspondente írvore de suporte ponderada mínima Tp.
	/ - 3,5	6	8	7	\
	-	3,5 8,5	9
L =	-	17	10,5
	-	7,5
	\ - /
Figura 2.4: Arvore de suporte ponderada mínima (pj = 0,5wj + 0,5cj para todos os (i, j) G A).
A írvore Tp obtida na Figura 2.4 tem valor ponderado P(Tp) = 21,5, custo C(Tp) = 19 e peso W(Tp) = 24 pelo que é uma írvore nao admissível para o Problema WMST, pois W(Tp) = 24 &gt; 20 = W.
Caso se utilize, por exemplo, os valores ponderados da forma, pij = wij + 0,2cij para cada arco (i,j) G A obtemos a matriz de valores ponderados L e a correspondente írvore de suporte ponderada mínima Tp representadas na Figura 2.5.
14
L =
í - 6,2 4,8 9,6
-	6,2	5
- 10
5.2
8.2
7
8,4 \
- /
Figura 2.5: Arvore de suporte ponderada mínima (pj = Wj + 0,2cj para todos os (i, j) G A).
A érvore Tp da Figura 2.5 tem valor ponderado P(Tp) = 21,2, custo C(Tp) = 41 e peso W(Tp) = 13, sendo uma arvore admissével para o Problema WMST.
2.3	Geração de Instâncias
Nesta secção descrevemos o modo como foram geradas as instâncias para o Problema WMST, as quais sao usadas ao longo de toda a tese para obtencao de resultados computacionais dos vérios métodos propostos. Para gerar as instâncias temos de ter em consideracao que cada aresta e = {i, j} G E tem associado um custo ce e um peso we e temos ainda de definir a constante W que limita o peso. Assim, para obter as matrizes de custos e de pesos e o valor da constante W geramos os seguintes trâs tipos de instancias.
• Instâncias Eüclideanas (E)
Os custos ce e os pesos we são obtidos usando distancias Euclideanas. Para obter estas instancias Euclideanas geramos aleatoriamente as coordenadas de n pontos/nodos numa grelha de dimensao 100 x 100. O custo de cada aresta e = {i,j} G E é a parte inteira da distância Euclideana entre os pontos/nodos i e j gerados na rede. Procedemos de modo semelhante para obter os pesos, gerando uma nova grelha.
O valor da constante W é obtido depois de geradas as matrizes de custos e de pesos. Para obter um valor (admissével) para o peso limite W temos de ter em consideraçao a Proposicao 2.1, onde W(Tw) &amp;lt;W &amp;lt;W(Tc). Assim, comecamos
15
por obter o peso da árvore de suporte de custo mínimo W(Tc) = Wc e o peso da árvore de suporte de peso mínimo W(Tw) = Ww e depois testamos os seguintes
valores para Wi,
Wi = W+Ww,
2i
com i G {1,..., 10}. No caso do valor de Wi náo ser inteiro, efetua-se o arredondamento simátrico. Dos vários valores Wi testados escolheu-se para o valor de
W aquele que tornava a instância mais difícil de resolver.


Instâncias Aleatórias (R)
Os custos ce e os pesos we sõo gerados aleatoriamente no intervalo [1; 1000].
O valor da constante W foi obtido como no grupo de instâncias Euclideanas e também apás a geracõo das matrizes de custos e pesos.
Instâncias Quase Caminhós (QC)
Os custos ce sõo gerados de acordo com o conjunto de instancias Spanner descrito em Pisinger [50]. Para obter os custos ce usando o conjunto spanner neste grupo de instâncias sõo necessários, os parâmetros s e m inteiros e positivos, onde s á o tamanho do conjunto spanner e m á o limite superior do intervalo para o multiplicador, isto e, gera-se aleatoriamente um multiplicador ma no intervalo [1; m]. Tendo fixado valores para os parâmetros s e m, os custos ce sao obtidos da seguinte forma:
1. gera-se aleatoriamente cj no intervalo [1; 100], j G {1,..., s};
2. obtêm-se os itens do conjunto spanner ck =
2cj
m
j,k G {1,...,s};
3. gera-se aleatoriamente um multiplicador ma (inteiro) no intervalo [1; m] e escolhe-se de forma aleatoria um custo ck, k G {1,..., s};
4. obtem-se ce = mack.
Apos a realização de experiâncias computacionais com varios valores de s e m, verificamos que as instâncias sao mais difíceis de resolver quando usamos m =10 e valores inteiros entre 2 e 6 para o valor do parâmetro s.
Depois de gerados os custos, geram-se os pesos we de tal modo que a estrutura da correspondente solução seja um quase caminho, ou seja, um grafo com diâmetro grande, mas cujo diametro seja inferior a n — 1. Para gerar os pesos começa-se
16
por definir um valor para a constante W e inicializa-se o peso de cada aresta a 1. De seguida, obtém-se a arvore de suporte de custo mínimo e atribuem-se pesos elevados às arestas que pertencem a esta érvore. Para as restantes arestas, aquelas que nao pertencem à MST, os pesos são gerados de forma a obter-se uma solução proxima de um caminho. Para o conseguir, os pesos das arestas que não pertencem à MST obtêm-se do seguinte modo
W
we =-------(1 - p) + r,
n — 1
onde p G [0,5; 1] e r ó gerado aleatoriamente no intervalo
1 W 1 1;------,p .
n — 1
No caso
das arestas continuarem a ter peso 1 usamos a seguinte féormula para determinar
os pesos
W
we =------(1 + aip) + a2r,
n — 1
onde a1 e a2 E [0; 10]. No caso dos valores dos pesos we não serem inteiros efetua-se o arredondamento simétrico. A constante W toma valores no intervalo [1000; 3500] consoante a dimensao n da instência.
Em todos os grupos de instências foram gerados exemplos de 10, 20, 40, 60, 80, 100, 150, 200, 300, 400, 500 e 1000 nodos. Nas instências Aleatérias e Euclideanas foram gerados 5 exemplos de cada dimensaão, perfazendo um total de 60 instêancias em cada um dos grupos. Nas instências Quase Caminhos foram gerados 10 exemplos de cada dimensãao com menos de 200 nodos e 5 exemplos para instêancias com 200 ou mais nodos. Assim no grupo de instências Quase Caminhos existem um total de 95 instancias teste. Em suma, foram geradas 215 instancias no total.
17
18
Capítulo 3
Formulações
O WMST á um problema de Otimização Combinatoria que pode ser formulado em Programação Linear Inteira (PLI). Para um mesmo problema diferentes formulaçães podem diferir em termos dos correspondentes limites inferiores obtidos através da relaxação em programação linear. A qualidade do limite inferior obtido depende da formulaççãao em PLI que se utiliza.
Para o Problema MST são conhecidas algumas formulações (ver Magnanti e Wolsey [45]). Para obter formulaçães para o Problema WMST pode-se facilmente adaptar uma formulação para o MST e adicionar a restrição que limita o peso das arestas na érvore de suporte. Esta restricao é uma restrição tipo saco-mochila. A introdução desta restriçao torna o problema NP-difácil [3].
As formulaçcãoes em Programaçcaão Linear Inteira para Problemas de Otimizaçcãao Combinatoria são, de um modo geral, consideradas formulações naturais ou formulaçães estendidas. Informalmente, e para problemas em arvores, podemos dizer que uma formulação natural usa apenas as variáveis de desenho topolágico da árvore (uma unica variável associada a cada arco do grafo). Uma formulação diz-se estendida se usa, adicionalmente, outras variáveis (associadas aos arcos ou nao). Estas variaveis adicionais, apesar de nãao serem necessaárias para a obtençcãao de uma formulaçcãao vaálida para o problema, contêm informaçao adicional que pode reduzir, consideravelmente, o numero de restriçcãoes envolvidas no modelo. Aláem disso, o seu uso permite derivar formulaçcãoes compactas (formulacoes que envolvem um numero polinomial de restriçães e variáveis).
Nesta secçcãao apenas consideramos formulaçcãoes orientadas para o Problema WMST definidas num grafo orientado. Sem perda de generalidade, consideramos o nodo 0 como o nodo raiz.
19
Considerem-se as variáveis binárias xij para todos os arcos (i,j) G A, que indicam se o arco (i,j) está ou nao na soluçao, ou seja,
{1,	se o arco (i,j) pertence à solução;
z
0,	caso contrário.
e para simplificar a notacão assumimos que as variáveis xi0, i G V\{0} têm sempre valor nulo.
Vamos considerar que XT representa o conjunto de todas as solucoes admissíveis definidas por uma formulação para o Problema MST, no qual o conjunto de desigualdades definido para x, com x = (xij-) G R|A|, descreve o involucro convexo das solucães inteiras do Problema MST. Assim, este conjunto de restrições garante que a solução tem uma estrutura de arvore (mais precisamente arborescência) de suporte. Uma formulação genárica para o Problema WMST pode ser dada pelo seguinte modelo:
(WMST) :	min	Cjjxij	(3.1)
		
	s.a. x G XT	(3.2)
	yy wij xij &amp;lt;w.	(3.3)
		
A função objetivo, dada pela expressão (3.1), indica que se pretende minimizar o somatório dos custos dos arcos na solução. A desigualdade (3.3) é a restrição que limita o peso total da arvore de suporte e garante que a soma dos pesos dos arcos na solução não pode exceder um limite W, sendo esta denominada de restriçao de peso.
Notamos que a validade de uma qualquer formulacão para o Problema WMST obtida juntando a restrição (3.3) a uma conhecida formulação para o Problema MST (conjunto de restricoes dadas por (3.2)) torna-se imediata. As quatro primeiras for-mulaçães que apresentamos (ES, CS, MF e MTZ) são obtidas desta forma. O processo de obtencão das duas ultimas formulações (WMTZ e WE) ja foi diferente.
20
Neste capítulo, apresentamos formulações naturais e estendidas para o Problema WMST e apresentamos também um procedimento com introduçao de cortes baseado em separacõo.
Na Secçõo 3.1 fazemos uma breve apresentaçõo de duas formulações naturais para o Problema WMST, uma onde a expressõo designada por (3.2) representa desigualdades de eliminaçao de subcircuitos e a outra desigualdades de corte. Na Seccõo 3.2 sõo apresentadas quatro formulações compactas estendidas: uma formulaçõo de fluxos, duas formulações baseadas nas desigualdades Miller-Tucker-Zemlin e uma formulaçõo de fluxos que especifica nos índices o peso do caminho desde a raiz. Uma vez que o uso destas formulacões na prética torna-se limitado, na Seccõo 3.3 vamos usar um procedimento, baseado em separacçõao, no qual as restriçcoões de corte võao sendo introduzidas e que nos permite obter a soluçcõao íotima, ou uma solucçõao admissível príoxima da étima. Por fim, na Secçõo 3.4 apresentamos resultados computacionais de varias experiências realizadas com as formulações e efetuamos um estudo comparativo entre as vaérias formulaçcoões apresentadas em termos de qualidade do limite inferior obtido e tempo de execuçcõao na obtençcõao da solucçaõo éotima ou de uma soluçcõao admissével. No final da Seccõo 3.4, em forma de resumo do capítulo apresentamos uma síntese dos resultados computacionais obtidos.
3.1	Formulacoes Naturais
Nesta secçao apresentamos duas formulações naturais para o Problema WMST, uma onde a expressãao designada por (3.2) representa desigualdades de eliminaçcaão de subcircuitos e a outra desigualdades de corte. Nas duas formulacçãoes naturais que se seguem considere-se, apenas o conjunto de variéveis binérias orientadas xij.
Uma das formulaçcãoes usa as desigualdades de eliminaçcãao de subcircuitos e a outra desigualdades de corte para assegurar a conexidade/prevencao de circuitos na solucão.
Dados dois subconjuntos S1,S2 Ç V. O conjunto
A(Si, S2) = {(i,j) E A : i E Si,j E S2}
designa o conjunto de arcos com um extremo em S1 e outro extremo em S2 e orientados
21
no sentido de Sj, para S2. Quando, Sj, = S2 = S, A(S) designa o conjunto de arcos com ambos os extremos em S. Seja Sc = V \ S, o conjunto complementar de S.
Formulaçõo de Eliminaçõo de Subcircuitos
A Formulacçãao de Eliminaçcaão de Subcircuitos (ES) tambíem conhecida por Packing/Subsets Formulation [45] no contexto do Problema WMST í dada por
min 52 cijxij (i, j)eA
s.a.
E Xij = |V| - 1	(3.4)
(i , j')€A
52 Xij &amp;lt;|S|- 1, S C V,S = 0, 2 &amp;lt;|S| &amp;lt;|V|- 1	(3.5)
(i , j)eA(S)
52 WijXij &amp;lt;W	(3.6)
(i , j)eA
xij G {0, 1},	(bj) G A-	(3.7)
As restricães de cardinalidade (3.4) asseguram que são escolhidos exatamente |V| —1 arcos para estarem na solução. Estas restricães podem ser substituídas pelo seguinte conjunto de restriçcãoes
52xij = 1	j G V\{0}	(3.8)
iev
que garantem que um e apenas um arco chega a cada nodo, exceto para o nodo raiz.
O conjunto de restriçcãoes (3.5) impede que o conjunto de arcos escolhidos para a solucçãao contenha ciclos. Estas restricçãoes sãao chamadas de restricçoães de eliminaçcãao de subcircuitos ou packing constraints e restringem o nuímero de arcos que podem ser adicionados (packed) em qualquer conjunto de nodos S. Observe-se que este segundo conjunto de restricães com |S| = 2 implica xij + Xji &amp;lt;1, para qualquer arco (i, j) G A, o que indica que o arco (i, j) e o seu simítrico (j,i) nao podem estar simultaneamente na solucçãao. Estas restricçãoes (3.5) quando conjugadas com as restricçãoes (3.8), garantem a obtencçaão de uma solucçãao com estrutura de íarvore de suporte.
A restriçcãao de peso (3.6) assegura que o peso total dos arcos na soluçcãao nãao pode exceder W. Por fim, as restricçãoes (3.7) sãao as restriçcãoes de integralidade das variíaveis.
22
Formulação de Cortes
A Formulação de Cortes (CS) é conhecida por CutSet Formulation [45] e, no contexto do Problema WMST, é dada através do seguinte modelo:
min
cij xij
(i,j)eA
s.a.
xij = 1,
ieV
xij — 1,
(i,j)eA(S',sc)
wij xij &amp;lt;W
(i,j)eA
xij E {0, 1},
j E V\{0}
S c V,S = 0,0 E S
(i, j) E A.
(3.9)
(3.10)
(3.11)
(3.12)
Relativamente à formulação anterior, nesta formulação, apenas houve alteração no conjunto de restrições dado por (3.10). As restriçães (3.10) estabelecem que, qualquer corte direcionado A(S, Sc), separando o nó 0 G S de qualquer outro conjunto de nós, Sc, deve conter pelo menos um arco. Estas desigualdades são chamadas de restriçães de corte. As restrições (3.10) juntamente com as restriçães (3.9) garantem a obtençao de uma soluçcaão com estrutura de óarvore de suporte.
Substituindo as restriçães de integralidade nas duas formulações por,
xij &gt; 0,	(i,j) G A,	(3.13)
obtemos, em ambos os modelos, a respetiva relaxaçao linear que designamos por ESL e CSL, respetivamente. A relaxacao linear de ambos os modelos fornece o mesmo limite inferior, d(ESL) = i9(CSl) [45]. Como o numero de desigualdades em ambos os conjuntos aumenta exponencialmente com o tamanho do modelo, vamos usar na Secçcãao 3.3 um procedimento que efetua a inserçcãao das restriçcãoes de corte no modelo apenas quando estas nãao estaão a ser satisfeitas pela soluçcãao obtida usando a atual relaxacçãao.
23
3.2	Formulaçoes Estendidas
Com o objetivo de garantir a conexidade/prevencõo de circuitos na solucõo, em vez de usar a famólia de desigualdades (3.5) ou (3.10) com um numero exponencial de desigualdades, podemos usar formulaçcõoes compactas estendidas. Nesta secçcõao propomos quatro formulacões estendidas: uma formulaçõo de fluxos, duas formulações baseadas nas desigualdades Miller-Tucker-Zemlin e uma formulacõo de fluxos que especifica nos óndices o peso do caminho desde a raiz.
3.2.1	Formulaçõo de Fluxos
Começamos por apresentar uma formulaçao orientada com fluxos desagregados para o Problema WMST. Esta formulação obtem-se adicionando as restriçães de peso a uma conhecida formulação de fluxos para o Problema MST (veja-se, por exemplo, Magnanti e Wolsey [45]).
Para alem das variaveis binarias xij usamos tambem as variaveis de fluxo orientadas, fij, para todos os arcos (i,j) E A e k E V\{0, i}, que indicam se o arco (i,j) é ou não utilizado no caminho da raiz para o nodo k, ou seja,
fk = &amp;lt;’
fij	¡0,
se o arco (i, j) e utilizado no caminho da raiz ate ao nodo k caso contrario
e para simplificar a notação assumimos tambem que as variaveis ji0, i E V\{0} e k E V\{0, i} têm sempre valor nulo.
A Formulagao de Fluxo (MF - Multicommodity Flow Formulation) para o Problema WMST e a seguinte:
24
min	Cij Xij
s.a.
xij	1,		j G V\{0}	(3.14)
ÍGV			
1	' -1 j = 0		
E fj - E fk = (	0 j = 0,k ,	j G V, k G V\{0}	(3.15)
iGV\{k}	iev\{0}	1	1 j = k		
fij &amp;lt;xij,		(i,j) G A,k G V\{0,i}	(3.16)
wij xij &amp;lt;w			(3.17)
(Í,3)ZA			
fij &gt; 0,		(i,j) G A,k G V\{0,i}	(3.18)
xij G {0, 1}		(i, j) G A.	(3.19)
As restriçães de cardinalidade (3.14) garantem que um e apenas um arco chega a cada nodo exceto para o nodo raiz.
As restricães (3.15) são as restriçães de conservação de fluxo e estabelecem que a solucão deve ter um caminho entre o nodo 0 e cada nodo k, para todo k G V\{0}. O primeiro conjunto de restrições de conservacão de fluxo garantem que a raiz envia uma unidade de fluxo para o nodo k, o segundo conjunto de restricçãoes garantem que a quantidade de fluxo que entra num no é igual a quantidade de fluxo que sai desse no e o terceiro conjunto de restriçcãoes implicam que o nodo k recebe uma unidade de fluxo.
As restricães de ligação (3.16) garantem que é possível enviar fluxo para cada nodo k atraves do arco (i,j), apenas se o arco se encontra na soluçao. Juntamente com as restricçãoes de conservaçcaão de fluxo estas restriçcãoes asseguram a ligaçcãao dos arcos da solução. A restrição de peso (3.17) assegura que o peso total dos arcos na solucão não pode exceder W. As restriçães (3.18) garantem que a quantidade de fluxo enviado entre dois quaisquer nodos é não negativa. Por fim, as restriçães (3.19) sao as restricães de integralidade das variaveis.
25
0
= 1
f54 = 1
til = 1
Ó
Figura 3.1: Exemplo com o
valor das variáveis de fluxo na Formulacao MF.
Na Figura 3.1 mostramos um exemplo onde podemos observar uma solução para o problema mostrando apenas o valor das variaveis de fluxo no caminho do nodo 0 para o nodo 1. Podemos observar que o nodo 0 envia uma unidade de fluxo para o nodo 1, pelo que o nodo 1 vai receber essa unidade de fluxo, para cada um dos restantes nodos do caminho a quantidade de fluxo que entra em cada nodo é igual à quantidade de fluxo que sai desse né.
Substituindo as restrições de integralidade (3.19), por:
Xij &gt; 0,	(i,j) G A,	(3.20)
obtemos a relaxaçao linear da Formulaçõo MF que designamos por MFL. Note que nõo é necessario incluir as restricões Xj &amp;lt;1 ((i,j) G A) nem fj &amp;lt;1 ((i,j) G A, k G V\{0,i}), pois estas restrições estõo implícitas por (3.14) e (3.16).
A relaxaçõo linear deste modelo fornece o mesmo limite inferior que os modelos da secçõo anterior, isto é, d(MFL) = d(ESL) = d(CSL) [45]. Resultado que nõo se altera por ter sido incluída a restricao de saco-mochila.
3.2.2	Formulação Miller-Tucker-Zemlin
Podemos obter uma formulacçaõo para o Problema WMST baseada nas restriçcõoes Miller-Tucker-Zemlin se substituirmos as restricões (3.15), (3.16) e (3.18) pelas res-triçcõoes de eliminaçcõao de subcircuitos de Miller-Tucker-Zemlin (MTZ Subtour Elimination Constraints). Nesta formulaçcõao usamos as variéaveis binaérias usuais xij
26
((i, j) G A) que indicam se o arco (i,j) esta ou nao na solução e que são usadas para definir a topologia das solucoes. Consideramos tambím as variaveis u (i = 0,1,..., n-1), as quais definem a posiçcãao do nodo i na íarvore, isto íe, o nuímero de arcos no caminho entre o nodo raiz e o nodo i.
A Formulacão Miller-Tucker-Zemlin (MTZ) para o Problema WMST í a seguinte:
min	cij xij (i,j)eA
s.a.
Xij	1,	j G V\{0}	(3.21)
ieV		
nxij + ui &amp;lt;Uj + (n - 1),	(i,j) G A	(3.22)
wij xij &amp;lt;w		(3.23)
(i,j)eA		
0 &amp;lt;ui &amp;lt;n - 1,	iGV	(3.24)
xij G {0, 1 } ,	(i,J) G A.	(3.25)
Tal como vimos nas formulaçães anteriores as restriçães de cardinalidade (3.21) garantem que um e apenas um arco chega a cada nodo exceto para o nodo raiz. A restriçao de peso (3.23) assegura que o peso total dos arcos na soluçao não excede W. As restriçães (3.25) são as restricães de integralidade das variíveis.
As restriçães (3.22) sao as conhecidas restrições de eliminação de subcircuitos dadas em Miller et al. [46] para o Problema do Caixeiro Viajante (TSP - Travelling Salesman Problem) e que foram adaptadas para o Problema MST com restriçães de salto [24]. As restrições (3.24) asseguram que o numero de arcos no caminho entre o nodo raiz e o nodo i íe nãao negativo e que nunca excede o nuímero de arestas da aírvore.
27
Se Xij	= 1, então u	&lt;	Uj	- 1.
Se Xj	= 0, então ui	&lt;	Uj	+ (n	- 1).
U5 = 2
u4 = 2
u0 = 0
U6 — 1
U3 = 2
Figura 3.2: Exemplo do cálculo das posições dos nodos na arvore.
Na Figura 3.2 podemos observar um exemplo onde indicamos as vérias posicães dos nodos na arvore. Por exemplo, a posição do nodo 5 na érvore é dada pelo numero de arcos no caminho entre o nodo raiz (0) e o nodo 5 que é igual a 2 arcos, u5 = 2.
No exemplo da Figura 3.2, se a solução for um caminho, com nodo origem 0 e nodo destino 6, a posicão do ultimo nodo do caminho é u6 = 6. As posicoes dos nodos nunca excedem o numero de arestas da arvore (uj &amp;lt;n - 1, j G V).
Note-se que para a formulacão do Problema WMST nao é necessario conhecer as posiçães exatas dos nodos na arvore, o que e importante é que se o arco (i,j) esta na soluçao, a diferenca maxima entre as posiçães dos nodos j e i seja superior ou igual a um, isto e,
Uj - Ui &gt; 1,	(i,j) G A.
Substituindo as restriçcoães de integralidade (3.25) por:
Xij &gt; 0,	(i,j) G A,	(3.26)
obtemos a relaxacao linear da Formulacão MTZ que designamos por MTZL. Note que não e necessario incluir as restrições xij &amp;lt;1 ((i,j) G A), pois estas restricoes estão implícitas por (3.21).
28
As restricães (3.22) podem ser fortalecidas (ver Desrochers e Laporte [15] e Gouveia [24]) da seguinte forma:
Desigualdades Levantadas 1 - MTZl1
(n - 2)xji + nxij + Ui &amp;lt;Uj + (n - 1),	(i,j) G A	(3.27)
A validade destas restriçães decorre do facto das variáveis xij e Xji nao poderem tomar simultaneamente o valor 1, xij + Xji &amp;lt;1. Se Xji = 0, as restricães (3.27) estão implácitas por (3.22) e no caso de Xji = 1, temos que xij = 0, o que significa que existe um arco direcionado que liga os dois nodos j e i, sendo que a diferença máxima entre a posição dos nodos i e j á inferior ou igual a 1, o que se verifica nas restriçães (3.27), pois para este caso u — Uj &amp;lt;1.
Desigualdades Levantadas 2 - MTZl2
xkj + nxij + Ui &amp;lt;Uj + (n — 1),	(i,j) G A	(3.28)
kev\{i,j}
Das restrições (3.21) temos que 52kev\{i,j} Xkj &amp;lt;1, pelo que 52kev\{i,j} Xkj e a variavel xij nao podem tomar simultaneamente o valor 1. Se 52\{i j} xkj = 0, as restrições (3.28) estao implácitas por (3.22). Caso 52k£V\{i j} xkj = 1 temos que para algum k G V\{i,j}, xkj = 1 e xij = 0, o que significa que existe um arco direcionado que liga os nodos k e j, e desta forma a diferença máxima entre a posição dos nodos i e j nao pode ser superior a n — 2, o que está de acordo com as restriçães (3.28), onde para este caso se obtám u — Uj &amp;lt;n — 2. Portanto, estas restrições sao válidas para o Problema WMST.
Desigualdades Levantadas 3 - MTZl3
(xik + Xkj) + nxij + Ui &amp;lt;Uj + (n — 1),	(i,j) G A	(3.29)
kev\{i,j}
29
Das restriçães (3.21) temos que 52kev\{i j} xkj &amp;lt;1 e também V(i jjgA xij- = n — 1, entao 52keV\{i j} xik &amp;lt;n — 2, pois o nodo i pode ligar a todos os nodos exceto ao nodo j. Deste modo, temos que o somatério 52keV\{i j}(xik + xkj) pode tomar valores inferiores ou iguais a n — 1.
Se 52keV\{i j}(xik + xkj) = 0, as restriçães (3.29) estão implécitas por (3.22).
Se 52keV\{i j} xik = 0, as restricoes (3.29) estao implécitas por (3.28).
Se 52keV\{i j}(xik + xkj) = p &amp;lt;n — 1 com p E Z+, ao substituirmos nas restricães
(3.29)	o somatório por p, obtemos p+nxj+ui &amp;lt;Uj+n—1. No caso de 52keV\{i j} xkj = 1 temos que para algum k E V\{i, j}, xkj = 1 e xij = 0, temos que ui — Uj &amp;lt;n — 1 — p &amp;lt;n — 1. No caso de 52kgV\{i j} xkj = 0 e xij = 1 temos que Uj — ui &gt; p + 1. Ambas estas restriçcãoes sãao véalidas para o Problema WMST.
Desigualdades Levantadas 4 - MTZl4
xkj + (n — 3)xji + nxij + Ui &amp;lt;Uj + (n — 1),	(i,j) E A	(3.30)
keV\{i,j}
Das restriçães (3.21) temos que 52keV\{i ,j} xkj &amp;lt;1. Se 52keV\{i j xkj = 0, as restricçãoes (3.30) transformam-se nas restriçcãoes
(n — 3)xji + nxij + Ui &amp;lt;Uj + (n — 1),	(i, j) E A	(3.31)
A validade das restriçcãoes (3.31) decorre do facto das variéaveis xij e xji nãao poderem tomar simultaneamente o valor 1, xij + xji &amp;lt;1. Se xji = 0, as restrições (3.31) estão implécitas por (3.22) e no caso de xji = 1, temos que xij = 0, o que significa que existe um arco direcionado que liga os dois nodos j e i, sendo que a diferençca méaxima entre a posiçcaão dos nodos i e j ée inferior ou igual a 2, o que se verifica nas restriçcoães (3.31), pois para este caso Ui — Uj &amp;lt;2. No caso do somatério 52keV\{i j} xkj = 1 temos que para algum k E V\{i, j}, xkj = 1 e xij = 0, pelo que as restriçães (3.30) ficam (n — 3)xji + Ui &amp;lt;Uj + n — 2. Se j = 1 temos que existe um arco direcionado que liga os nodos j e i, e desta forma a diferençca méaxima entre a posiçcãao dos nodos i e j nãao pode ser superior a 1, o que esta de acordo com as restrições (3.30), onde para este caso se obtéem Ui — Uj &amp;lt;1. No caso de xji = 0, a diferencça méaxima entre a posicçãao dos nodos i e j naão pode ser superior a n — 2, o que estéa de acordo com as restriçcãoes
(3.30)	, onde para este caso se obtém Ui — Uj &amp;lt;n — 2. Portanto, as restriçães (3.30) sao
30
válidas para o Problema WMST.
As relaxações lineares das Formulacoes MTZl1, MTZl2, MTZl3 e MTZl4 designamos por MTZl1L, MTZl2L, MTZl3L e MTZl4L, respetivamente.
3.2.3	Formulação de Peso Miller-Tucker-Zemlin
Nesta formulacao alám das variáveis binarias xij ((i, j) G A), que definem a topologia da solucão, consideramos as variaveis pi, (i = 0,..., n — 1), as quais especificam o estado de peso do nodo i na áarvore, isto áe, indicam o valor do peso do caminho entre a origem e o nodo i, dado pela soma dos pesos dos arcos no caminho. A Formulaçao de Peso Miller-Tucker-Zemlin (WMTZ) á a que se segue:
mm	cij xij
(í,j)eA
s.a.
Xij = 1,
ieV
Wij Xij + Pi &amp;lt;Pj + W (1 - Xij)
wij Xij &amp;lt;W
(í,j)eA
0 &amp;lt;Pi &amp;lt;W,
Xij G {0 , 1 } 1
j G V\{0}	(3.32)
(i,j) G A	(3.33) (3.34)
i G V	(3.35)
(i,j) G A.	(3.36)
As restrições (3.32), (3.34) e (3.36) são as mesmas da formulacão anterior. As restrições (3.33) sao baseadas nas conhecidas restrições de eliminação de subcircuitos dadas em Miller et al. [46] para o Problema TSP. As restrições (3.35) impãem limites nas variáaveis pi, isto áe, asseguram que a soma dos pesos no caminho entre o nodo origem e o nodo i áe nãao negativo e nunca excede o limite W.
31
Proposição 3.1.
As restriçães (3.33) evitam a existencia de circuitos.
Demonstração.
Somando as restriçães (3.33) para os arcos de um circuito C (xij = 1, (i,j) G C) obtemos (i j)&amp;amp;c Wj — 0, o que contradiz o facto dos pesos wij serem positivos. □
Para qualquer érvore de suporte de peso admissével podemos sempre encontrar valores para as variaveis pj, ¥j G V, tais que (3.33) e (3.35) sao satisfeitas. Se pj é o peso do caminho da origem a qualquer nodo j, pj = pi + wij para todos os arcos (i,j) tal que xij = 1 e p0 = 0. As restricães (3.33) e (3.35), para todos os arcos (i,j) tal que xij = 0, estao implécitas pela restrição de peso (3.34). Assim, as restricães (3.33) e (3.35) são validas para o Problema WMST.
Se xij = 1, então wij + pi — pj	pi &amp;lt;pj.
Se xij = 0, então pi — pj + W.
3
ps = 4
pe = 2
p2 = 10
p4 = 14
ps = 15
Figura 3.3: Exemplo do cálculo dos estados dos pesos dos nodos na árvore.
Na Figura 3.3 podemos observar como sao obtidos os estados dos pesos de cada nodo na érvore. Por exemplo, o estado de peso do nodo 3 corresponde a soma dos pesos dos arcos (0, 2) e (2, 3), p3 = p2 + w23 = 10 + 5=15.
Se a solucão do exemplo dado na Figura 3.3 for um caminho, com nodo origem 0 e nodo destino 6, o estado de peso do ultimo nodo do caminho é igual ao peso da érvore de suporte obtida, pe = W(T) — W.
32
Note-se que para a formulaçcãao do Problema WMST naão íe necessíario conhecer os estados de peso dos nodos na íarvore, o que íe importante íe que se o arco (i, j) estía na solução, a diferença máxima entre os estados de peso pj e pi seja superior ou igual a Wj, isto í,
Pj - Pi &gt; wij,	(i,j) G A.
Substituindo as restriçães de integralidade (3.36) por:
Xij &gt; 0,	(i,j) G A,	(3.37)
obtemos a relaxaçao linear da Formulação WMTZ que designamos por WMTZL. Note que nao í necessario incluir as restricães Xij &amp;lt;1 ((i, j) G A), pois estas restrições estao implícitas por (3.32).
Notamos que as Formulaçães MTZL e WMTZL são incomparáveis e para comprovar este facto apresentamos o seguinte exemplo.
Exemplo 3.1.
Na Tabela 3.1 podemos observar os valores obtidos pela relaxacão linear das Formulaçães MTZ e WMTZ em algumas instências de 10 e 20 nodos dos três grupos de instências, Quase Caminhos, Aleatórias e Euclideanas.
Instância	MTZl	wmtzl
QC10-1	70,850	68,087
R10-2	11856,200	11861,700
E10-1	29161,700	29076,100
QC20-1	1004,530	1017,800
R20-1	25226,500	25308,900
E20-1	40383,700	40368,600
Tabela 3.1: Comparação dos valores obtidos usando as Formulações MTZL e WMTZL.
Nas instancias QC10-1, E10-1 e E20-1 o valor obtido pela Formulaçao MTZL í superior ao valor obtido pela Formulação WMTZL, mas nas instancias R10-2, QC20-1
33
e R20-1 verifica-se o contrario, ou seja, o valor obtido pela Formulaçao MTZL é inferior ao valor obtido pela Formulacão WMTZL. Deste modo verificamos que as Formulações MTZl e WMTZl não sao comparáveis em termos de valor da relaxacao linear.
Tal como foi feito anteriormente para as restriçães (3.22) da Formulacão MTZ, as restricoes (3.33) também podem ser fortalecidas (ver Desrochers e Laporte [15] e Gouveia [24]) da seguinte forma:
Desigualdades Levantadas 1 - WMTZl1
WjiXji + WijXij + Pi &amp;lt;Pj + W(1 — Xij), (i,j) E A	(3.38)
A validade destas restriçães decorre do facto das variáveis xij e Xji não poderem tomar simultaneamente o valor 1. Se Xji = 0, as restriçcoães (3.38) estaão implécitas por (3.33) e no caso de Xji = 1, temos que Xij = 0, o que significa que existe um arco direcionado que liga os dois nodos j e i, sendo que a diferençca maéxima entre os estados de peso dos nodos i e j ée inferior ou igual a W — wji, o que se verifica nas restriçcãoes (3.38), pois para este caso pi — pj &amp;lt;W — Wji.
Desigualdades Levantadas 2 - WMTZl2
(W — Wji)xji + WijXij + pi &amp;lt;pj + W(1 — Xij),	(i,j) E A	(3.39)
Temos que as variéaveis Xij e Xji naão podem tomar simultaneamente o valor 1. Se Xji = 0, as restriçcoães (3.39) estaão implécitas por (3.33) e no caso de Xji = 1, temos que Xij = 0, o que significa que existe um arco direcionado que liga os dois nodos j e i, sendo que a diferençca maéxima entre os estados de peso dos nodos i e j nãao excede o peso do arco (j, i), o que se verifica nas restricçoães (3.39), pois para este caso pi — pj &amp;lt;Wji. Portanto, estas restriçcãoes sãao véalidas para o Problema WMST.
34
Desigualdades Levantadas 3 - WMTZl3
WkjXkj + WijXij + Pi &amp;lt;Pj + W(1 — Xij), (i,j) G A	(3.40)
keV\{i,j}
Das restricoes (3.32) temos que 52keV\{i j Xkj &amp;lt;1. No caso de 52keV\{i j Xkj = 0, então 52keV\{j, j} wkjxkj = 0 e as restriçães (3.40) estão implécitas por (3.33). Caso para algum k G V\{i,j}, Xkj = 1, 52keV\{i , j} wkjXkj = Wj e Xj = 0, o que significa que existe um arco direcionado que liga os nodos k e j, e desta forma a diferença méxima entre os estados de peso dos nodos i e j não pode ser superior a W — wkj, o que esta de acordo com as restrições (3.40), onde para este caso se obtém pi — pj &amp;lt;W — wkj &amp;lt;W. Portanto, estas restriçcãoes saão véalidas para o Problema WMST.
Desigualdades Levantadas 4 - WMTZl4
(WkjXkj +	WikXik)+	WjiXji	+ WijXij	+ 'Pi	&lt;	'Pj	+ W(1 — Xij),	(i,j)	G A (3.41)
keV\{i,j}
Das restriçães (3.32) temos que 52keV\{i j} Xkj &amp;lt;1 e da restricao (3.34) temos que 52keV\{i j} wikXik &amp;lt;W, pois o nodo i pode ligar a todos os nodos exceto ao nodo j. Deste modo temos que o somatório 52keV\{i j}(wkjXkj + wikXik) toma valores inferiores ou iguais a W + wkj para algum k G V\{i, j}.
Se £keV\{i, j}(wikXik + wkjXkj) = 0, as restriçães (3.41) estao implécitas por (3.38).
Se ^2keV\{i j}(wikXik + wkjXkj) = q &amp;lt;W + wkj com q G Z+, ao substituir nas res-
tricoes (3.41) o somatério por q, obtemos q + WjiXji + wijXij + pi &amp;lt;pj + W(1 — Xij). Caso
EkeV\{i ,j} Xkj = 1 temos que para algum k G V\{i,j} Xkj = 1^2keV\{i ,j} wkjXkj = wkj e Xij = 0, temos que q + WjiXji + pi &amp;lt;pj + W. Se Xji = 0, então pi — pj &amp;lt;W — q &amp;lt;W
e se Xji = 1 temos que pi — pj &amp;lt;W — q — Wji &amp;lt;W. No caso de 52kev\{$ j} xkj = 0, então Xj = 1 e Xji = 0, pelo que temos pj — pi &gt; q + wij. Assim, estas restrições são
véalidas para o Problema WMST.
As relaxaçães lineares das Formulações WMTZl1, WMTZl2, WMTZl3 e WMTZl4 designamos por WMTZl1L, WMTZl2L, WMTZl3L e WMTZl4L, respetivamente.
35
3.2.4	Formulação de Fluxo com especificação de Pesos
Esta nova formulaçõo estendida sera denominada de WE. Para além das variéveis binarias usuais Xj ((i, j) G A) usamos variáveis de fluxo de peso direcionado zj* (para todo (i, j) G A, k G V\{0, i} e h1 &amp;lt;h2, h1, h2 = 0,..., W), as quais especificam se o arco (i,j) é ou nõo utilizado no caminho da raiz até ao nodo k, sendo h1 o peso do caminho da raiz ao nodo i e h2 o peso do caminho do nodo raiz ao nodo j. Para simplificar a notacõo assumimos que as variaveis z#**2 para todo i G V\{0}, k G V\{0,i}, h1 &amp;lt;h2, h1,h2 = 0,..., W e as variaveis zj^2 para todo h2 &amp;lt;h1 e h2 &gt; W têm sempre valor nulo. A Formulacao WE é dada pelo seguinte conjunto de restriçcõoes:
min	CjjXj
(i,j)eA
s.a.
Xij = 1,	j G V\{0}	(3.42)
ieV		
h	h	1	' _1 j = 0, h = 0
zh~wi / .	/ .	zijk	jh _ y^	y^	zh,h+wji = J	0 j = 0, k, h = W ,
iGV\{k} h=0|h-wij&gt;0	iEV\{0} h=0|h+wji&lt;W	1	1 j = k, h = W
	j G V, k G V\{0}	(3.43)
W		
X"&gt; h,h+wij &amp;lt;x / y zijk	&amp;lt;xij ,	(M) G A,k G V\{0,i}	(3.44)
h=0		
h2 &gt; 0	(M) g A,k g V\{o,o,	(3.45)
xij G {0 , 1 } ,	(i, j) G A.	(3.46)
As restrições de cardinalidade (3.42) garantem que um e apenas um arco chega a cada nodo exceto para o nodo raiz.
As restricões de conservaçõo de fluxo (3.43) estabelecem que a solucõo deve conter um caminho entre o nodo 0 e o nodo k (para todo k G V\{0}). O primeiro conjunto de restricçõoes de conservaçcõao de fluxo garantem que a raiz envia uma unidade de fluxo para o nodo k, o segundo conjunto de restriçcõoes garantem que a quantidade de fluxo que entra num no e igual à quantidade de fluxo que sai desse no e o terceiro conjunto de restriçcõoes implicam que o nodo k recebe uma unidade de fluxo.
As restricoes de ligaçao (3.44) garantem que é possível enviar fluxo para cada nodo
36
k atraves do arco (i, j) apenas se o arco esta na soluçcãao.
Juntamente com as restriçcoães de conservacçãao de fluxo estas restriçcãoes asseguram a ligaçcaão dos arcos da solucçãao. As restricçãoes (3.45) garantem que a quantidade de fluxo enviado entre dois quaisquer nodos e naão negativa. Por fim, as restricçãoes (3.46) sãao as restriçcãoes de integralidade das variaveis.
= 1
Figura 3.4: Exemplo com o valor das variáveis de fluxo na Formulação WE.
Na Figura 3.4 mostramos um exemplo onde podemos observar uma soluçao e indicamos apenas o valor das variaveis de fluxo no caminho do nodo raiz para o nodo 1. Podemos observar que o nodo 0 envia uma unidade de fluxo para o nodo 1, pelo que o nodo 1 vai receber essa unidade de fluxo, temos tambem que para os nodos que estaão no caminho do nodo origem para o nodo 1 a quantidade de fluxo que entra em cada nodo e igual à quantidade de fluxo que sai desse no. Assim as variaveis zj’h2 para os arcos (i,j) no caminho do nodo origem para o nodo 1 terao valor um para valores apropriados de hi e h2 . Por exemplo, para o nodo 3 o valor de h1 corresponde ao peso do caminho do nodo raiz ao nodo 3, isto e, h1 = w02 + w23 = 3 + 5 = 8eo valor de h2 corresponde ao peso do caminho do nodo raiz ao nodo 5, ou seja, h2 = w02 + w23 + w35 = 3 + 5 + 7 = 15.
Proposição 3.2.
A Formulação WE é valida para o Problema WMST.
Demonstração.
Dada uma solução para o Problema WMST, facilmente, podemos construir uma solucao (x, h) para a Formulaçao WE, onde as variaveis binarias usuais xij ((i,j) G A) indicam se o arco pertence ou não à solução e as variaveis de fluxo de peso direcionado zjh2 (para todo (i,j) G A, k G V\{0, i} e h1 &amp;lt;h2, hi, h2 = 0,..., W), indicam se o
37
arco (i, j) é ou não utilizado no caminho da raiz até ao nodo k, sendo h1 o peso do caminho da raiz ao nodo i e h2 o peso do caminho da raiz ao nodo j.
Tomemos uma solução (x, h) que satisfaz as restricães da Formulaçao WE acima e consideremos as variéveis de fluxo orientado fj, para todos os arcos (i, j) G A e k G V\{0, i} definidas do seguinte modo
W
fijj	E ' •	(3-47)
h=0
Quando substituémos (3.47) nas restriçães (3.43) obtemos as restrições de conservação de fluxo usuais. Desta forma, conjuntamente, com as restrições de cardinalidade (3.42) e integralidade (3.46) obtemos uma érvore de suporte. Como fj &gt; 0 para qualquer arco (i, j) G A e k G V\{0, i}, entao temos que zh1fc’h2 &gt; 0.
Além disso, se multiplicarmos cada restricão (3.44) por wij e depois adicioné-las para todos os arcos (i, j) G A obtemos a restriçcãao de peso. O que nos garante que a érvore obtida satisfaz a restricão de peso. Desta forma verificamos que a solução (x, h) é capaz de determinar uma solução para o Problema WMST.	□
Substituindo as restrições de integralidade (3.46) por:
xij &gt; 0, (i, j) G A,	(3.48)
obtemos a relaxaçao linear da Formulação WE que designamos por WEL. Note que naão ée necesséario incluir as restricçãoes xij &amp;lt;1 ((i, j) G A) nem '	&amp;lt;1 ((i,j) G A
k G V\{0,i}), pois estas restriçães estão implécitas por (3.42) e (3.44).
Exemplo 3.2.
Neste exemplo apresentamos os diferentes valores obtidos pela relaxaçcãao linear das diferentes formulacães para o Exemplo 2.1. Usando formulaçães diferentes podemos encontrar solucçãoes éotimas da relaxaçcaão linear tambéem diferentes. Neste exemplo de 5 nodos, para as diferentes formulacçoães apresentadas ao longo deste capétulo, ée possével encontrar quatro diferentes limites inferiores para o valor do custo, os quais se encontram na seguinte tabela.
38
	Relaxaçãc	) Linear
Formulaççãoes	Custo	Peso
MTZ, MTZl2, MTZl3, WMTZ e WMTZll,	25,333	20
WMTZl3 e WMTZl4	25,3425	20
MTZl4	25,3913	20
ES, MF, WE, MTZl1, WMTZl2	25,4	20
Tabela 3.2: Comparação das formulaçães usando	um exemplo de 5 nodos	
Os limites inferiores mais baixos são obtidos utilizando as Formulaçães MTZ, MTZl2, MTZl3, WMTZ e WMTZl1, com custo 25,333 e peso 20 e os limites inferiores mais elevados são obtidos através das Formulacães ES, MF, WE, MTZl1 e WMTZl2. A melhor soluçcaão áotima da relaxaçcãao linear encontra-se representada na Figura 3.5.
Xoi = 1 xo4 = 0,2
X12 = 1
xi3 = 0,8
X34 = 0,8
X43 = 0,2
restantes xij = 0, (i,j) G A
Figura 3.5: Solução ótima da relaxação linear obtida pelas Formulações ES, MF, WE, MTZll e WMTZ12.
O custo da solucão átima da relaxacao linear obtida na Figura 3.5 á de 25,4 e o peso áe de 20.
39
3.3	Procedimento com Introdução de Cortes
Neste procedimento as restriçães de corte são introduzidas no modelo como cortes usando separaçao. Apenas quando a atual soluçao da relaxaçao considerada nao satisfaz alguma restriçcãao de corte áe que essa restriçcãao seráa adicionada ao modelo. Desta forma apenas sãao incluádas no modelo as restriçcãoes de corte necessáarias para obter a soluçcãao áotima do Problema WMST.
Para adicionarmos as restricçãoes de corte teremos de saber como identificar a res-tricçaão de corte a incluir no modelo. Para o fazer áe necessáario identificar um corte mánimo na solucão atual obtida pela soluçao da relaxacão. Um corte mánimo A(S, Sc) pode ser determinado se aplicarmos o Algoritmo de Ford-Fulkerson [20] para encontrar o fluxo máximo entre a raiz, o no 0, e cada um dos outros nás i G V \ {0}. Denotamos por fmax(0,i), i G V\{0}, o fluxo maximo entre o nodo zero/raiz e cada um dos restantes nodos do grafo.
Para descrever os principais passos para efetuar um procedimento genáerico com introducão de cortes, vamos começar por denotar por FORM o modelo que será usado para inclusãao dos cortes. Os diferentes passos necessaários para este procedimento sãao os seguintes.
Procedimento com Introducao de Cortes
Passo 1: Inicializar o conjunto de corte
Considerar os conjuntos S = 0 e Sc = V.
Passo 2: Relaxacão
1)	Introduzir o corte
xij &gt; 1 S C V,S = 0, 0 G S.
(i , j)6A(S, Sc)
2)	Resolver uma relaxaçcaão da Formulaçcãao FORM.
Passo 3: Obter o corte
Para cada i G V\{0} obter fmax(0,i) considerando como capacidade dos arcos o valor da soluçcãao obtida pela relaxaçcaão no Passo 2.
40
Se fmax(0,i) &amp;lt;1, entao
Se fmax(0,i) = 0, então
o conjunto S é constituído pelos nodos i G V\{0} para os quais foi possível enviar fluxo do nodo 0.
Caso contríario,
identificar o conjunto S para obter o conjunto de corte A(S, Sc).
Voltar para o Passo 2.
Este processo termina quando o grafo estiver conectado e o fluxo míaximo entre 0 e cada nodo i G V\{0} for 1.
Passo 4: Introduzir as restrições de subcircuito
1)	Introduzir as restrições Xij + Xji &amp;lt;1, i, j G V, i = j.
2)	Resolver uma relaxação da Formulação FORM.
No Passo 1 começcamos por inicializar o conjunto de corte, onde S = 0 e Sc = V. No Passo 2 introduzimos o corte e resolvemos uma relaxacçãao de uma formulaçcãao que designamos por FORM. Notamos que inicialmente (na primeira iteracçãao) a relaxacçãao naão contíem qualquer corte, íe apenas constituída pelas restriçcoães do modelo FORM sem cortes. Enquanto o fluxo máximo entre 0 e cada nodo i G V\{0} não for um temos de usar o Algoritmo Ford-Fulkerson [20] para obter o fluxo maíximo entre o nodo zero/raiz e cada um dos restantes nodos do grafo considerando como capacidade dos arcos o valor da soluçcãao obtida pela relaxaçcãao no Passo 2. Se o valor do fluxo míaximo for inferior a um, temos de considerar dois casos. Um dos casos ocorre quando não í possível obter um fluxo entre o nodo 0 e o nodo i G V\{0}, então vamos considerar o conjunto S constituído pelos nodos i G V\{0}, para os quais foi possível enviar fluxo do nodo 0. O outro caso ocorre quando o fluxo míaximo íe positivo, onde temos de identificar o conjunto de corte. Em qualquer um destes casos voltamos ao Passo 2 para introduzir um novo corte e resolver uma nova relaxaçcãao. No Passo 4 sãao introduzidas as restricçãoes de subcircuito e resolve-se uma nova relaxaçcãao da Formulacçaão FORM. Deste modo foi obtido um valor para o limite inferior para o custo, o qual í o valor obtido pela relaxacçao linear deste procedimento com introduçcãao de cortes.
41
Observe-se que o procedimento com introduçao de cortes pode ser aplicado a um modelo que no Passo 2 denotímos por FORM. Nesta tese aplicamos este procedimento às Formulações CS, MTZ e WMTZ. Deste modo, podemos definir os seguintes procedimentos:
•	Procedimento P-CS
Neste procedimento substituímos o modelo FORM no Passo 2 pela Formulação CS. A relaxação linear deste procedimento serí designada por P-CSL.
•	Procedimento P-MTZ+C
Neste procedimento substituímos o modelo FORM no Passo 2 pela Formulação MTZ. A relaxação linear deste procedimento serí designada por P-MTZ+CL.
•	Procedimento P-WMTZ+C
Neste procedimento substituímos o modelo FORM no Passo 2 pela Formulaçao WMTZ. A relaxacão linear deste procedimento serí designada por P-WMTZ+CL.
Exemplo 3.3.
Para exemplificar o funcionamento do procedimento com introdução de cortes vamos considerar a instância E10-1 do grupo de instâncias Euclideanas.
Passo 1:
Considerar os conjuntos S = 0 e Sc = V.
Passo 2:
42
Figura 3.6: Representação da solução da relaxação linear da Formulação WMTZ.
Passo 3:
Como podemos observar na Figura 3.6, não é possével enviar fluxo do nodo 0 para o nodo 9, isto é, do nodo origem para o nodo 9, fmax(0, 9) = 0. Deste modo, a solucao, neste caso, não é conexa pelo que formamos o conjunto S = {0, 2, 3, 5,6, 8} e o conjunto Sc = {1, 4, 7, 9} e voltamos ao Passo 2.
Passo 2:
1) Introduzir o corte 1:
Xoi + X04 + X07 + X09 + X21 + X24 + X27 + X29 + X31 + X34 + X37 + X39 + X51 + X54 + X57 + X59 + X61 + X64 + X67 + X69 + X81 + X84 + X87 + X89 &gt; 1-
2) Os valores de cada variével na solução da relaxação linear da Formulação WMTZ com a introducao do corte 1 são os seguintes: x03 = 1; x06 = 1; x17 = 1; x25 ~ 0,94; x52 ~ 0,06; x28 = 1; x32 ~ 0,94; x69 = 1; x85 = 0,06; x91 = 1; e x94 = 1 (restantes variéveis com valor nulo). O valor do limite inferior obtido para o custo é de 36416,2 com peso 24251 e na Figura 3.7 podemos encontrar a representaçao da solução através de um grafo.
43
0
Figura 3.7: Representação da solução da relaxação linear da Formulação WMTZ após a introdução do corte 1.
Passo 3:
O fluxo maximo entre o nodo 0 e o nodo 8 e aproximadamente igual a 0,94, isto é, fmax(0, 8) ~ 0,94. Deste modo, podemos dizer que ha um constrangimento na aresta {2, 3} que nos permite formar os conjuntos S = {0,1, 3, 4,6, 7, 9} e Sc = {2, 5, 8} e voltamos ao Passo 2.
Passo 2:
1)	Introduzir o corte 2:
x02 + x05 + x08 + x12 + x15 + x18 + x32 + x35 +	x38 + x42	+	x45 + x48	+ x62 + x65	+
x68 + x72 + x75 + x78 + xg2 + xg5 + xg8 &gt; 1.
2)	Os valores de cada variavel na solução da relaxação linear da Formulação WMTZ
com a introducão do corte 2 sao os seguintes: x03	=	1;	x05	0,08; x06	= 1; xi7 =	1;
x25 ~ 0,92; x52 ~ 0,08; x28 = 1; x32 ~ 0,92; x6g	=	1;	xgi	=	1 e xg4 = 1 (restantes
variaveis com valor nulo). O valor do limite inferior obtido para o custo e de 36530,6 com peso 24251 e na Figura 3.8 podemos encontrar a representaçcãao da soluçcãao atraves de um grafo.
44
Figura 3.8: Representação da solução da relaxacáo linear da Formulação WMTZ apos a introdução do corte 2.
Passo 3:
Como o fluxo maximo entre o nodo 0 e cada nodo i G V\{0} é igual a 1, não é possével inserir mais cortes e passamos ao Passo 4.
Passo 4:
Neste passo sao inseridas 72 restricoes do tipo xij + xji — 1, i,j G V, i = j e resolve-se novamente a relaxaçcãao linear da Formulaçcãao WMTZ. A soluçcãao obtida encontra-se representada na Figura 3.8 e o valor da relaxação linear é $(P-WMTZ+CL) = 36530,6.
Como a solução otima desta instância tem custo 39983 e peso 23608, o gap do limite „	,	,	,	,	,	, , 39983 - 36530,6
inferior obtido com a aplicacao deste procedimento é de	x 100 = 8,63%.
39983
45
e Resultados Computacionais
Atendendo a que existem diferencas entre as vírias formulaçães apresentadas para
o Problema WMST í necessírio avaliar qual í a mais eficiente. Neste sentido pretendemos avaliar a qualidade do valor do limite inferior obtido pela relaxaçcãao linear de
cada formulacçãao e os tempos de execuçcãao. Para avaliar a qualidade do limite infe-
,	,	,	,	, ,	, ,	OPT - ^(WMSTl)
rior obtido em cada um dos modelos calculamos o qap = -----.---------- x 100,
y	OPT
onde ê(WMSTl) í o valor do limite inferior obtido pela relaxacao linear do modelo em causa e OPT í o valor ítimo MST)) ou o melhor valor de uma solução admissível obtida, e, portanto, um limite superior para o valor do custo.
Para resolver os modelos de Programaçao Linear Inteira apresentados ao longo deste capítulo usamos o software Xpress 7.3 (Xpress-Optimizer 23.01.03 e Xpress-Mosel 3.4.0) [1] e todos os testes foram efetuados num Intel(R) Core(TM)2 Duo CPU (T7100) 2.00 GHz processador e 4Gb de RAM.
3.4.1	Exemplo Comparativo das Formulações
Para comparar as formulacçãoes vamos começcar por usar um exemplo de 10 nodos com W = 79, para o qual os valores obtidos nos vaírios modelos se encontram na Tabela 3.3. Na primeira coluna da referida tabela, encontram-se as designaçcoães atribuídas a cada uma das formulacçãoes apresentadas ao longo deste capítulo, as trâes colunas seguintes contâem os valores obtidos pela relaxaçcãao linear, isto íe, o valor do limite inferior para o custo, o valor do correspondente peso e o tempo de execuçcaão (em segundos). As uíltimas duas colunas contâem o tempo de execuçcãao (em segundos) e o nuímero de nodos na aírvore de pesquisa do Algoritmo Branch and Bound.
Para este exemplo, a soluçcaão íotima corresponde a uma aírvore de suporte com custo 335 e peso 61.
46
Formulação	Custo	Peso	Tempo	Tempo	#Nodos
ES	279,435	79	0,063	0,093	1
P-CS	279,435	79	0,101	0,143	1
MF	279,435	79	0,047	1,903	3
MTZ	178,750	79	0,032	0,078	1
MTZll	279,435	79	0,032	0,078	9
MTZl2	180,594	79	0,031	0,078	1
MTZl3	184,728	79	0,015	0,203	3
MTZl4	275,330	79	0,015	0,063	3
WMTZ	169,632	79	0,031	0,078	1
WMTZll	174,397	79	0,032	0,109	13
WMTZl2	279,435	79	0,031	0,078	5
WMTZl3	174,653	79	0,015	0,109	1
WMTZl4	175,490	79	0,032	0,234	9
WE	279,435	79	0,655	1,201	9
P-MTZ+C	279,435	79	0,138	0,206	7
P-MTZll+C	279,435	79	0,031	0,097	6
P-MTZl2+C	279,435	79	0,141	0,2	3
P-MTZl3+C	279,435	79	0,142	0,212	5
P-MTZl4+C	279,435	79	0,048	0,132	9
P-WMTZ+C	279,435	79	0,102	0,175	17
P-WMTZll+C	279,435	79	0,133	0,183	1
P-WMTZl2+C	279,435	79	0,029	0,157	67
P-WMTZl3+C	279,435	79	0,13	0,229	5
P-WMTZl4+C	279,435	79	0,136	0,26	22
Tabela 3.3: Comparação das formulaçães usando um exemplo de 10 nodos.
O melhor valor obtido pela relaxacõo linear das diferentes formulações foi 279,435, este valor está assinalado a negrito na Tabela 3.3. Para o exemplo de 10 nodos considerado obtemos os mesmos valores da relaxaçõo linear nas Formulações ES, MF, MTZl1, WMTZl2 e WE. Em todas as formulacões onde se aplica o procedimento com introduçõo de cortes tambám se obtám o mesmo valor da relaxacõo linear 279,435. Notamos que comparando a qualidade do valor do limite inferior obtido pelas desigualdades levantadas podemos verificar que tanto no exemplo de 5 nodos (Exemplo 3.2) como neste exemplo de 10 nodos, as Desigualdades Levantadas 1 na Formulaçao MTZ (MTZl1) e as Desigualdades Levantadas 2 na Formulacao WMTZ (WMTZl2) sõo as que apresentam melhores resultados de entre as varias desigualdades levantadas
47
derivadas das Formulaçcoães MTZ e WMTZ.
3.4.2	Comparaçõo das Formulações MTZ e WMTZ
Para cada uma das Formulaçcãoes MTZ e WMTZ apresentaímos nas Secçcãoes 3.2.2 e
3.2.3	algumas desigualdades denominadas de Desigualdades Levantadas. Nesta secção começcamos por comparar, computacionalmente, os valores dos limites inferiores obtidos e dos tempos de execuçcaão usando cada uma das desigualdades levantadas propostas na Formulaçcaão MTZ. De seguida, efetuamos o mesmo estudo para as desigualdades levantadas propostas para a Formulaçcãao WMTZ. Esta comparacçãao íe efetuada com o objetivo de averiguar qual das desigualdades levantadas, em cada uma das Formulaçcoães MTZ e WMTZ, produz melhor valor do limite inferior da relaxacçaão linear. Depois de escolhidas as desigualdades que quando introduzidas no modelo produzem melhor valor do limite inferior da relaxacçãao linear de cada uma das Formulaçcoães MTZ e WMTZ, pretendemos comparar, computacionalmente, as duas formulaçcãoes.
Formulaçcõao MTZ
Para comparar, computacionalmente, os valores dos limites inferiores obtidos usando cada uma das desigualdades levantadas propostas para a Formulacçãao MTZ elaboraímos as Tabelas 3.4 e 3.5. A primeira coluna destas tabelas refere-se à designação da instêancia e as restantes colunas contêem os valores dos limites inferiores obtidos pelas Formulacães MTZ, MTZl1, MTZl2, MTZl3 e MTZl4. A Tabela 3.4 contím instências de 10 nodos e a Tabela 3.5 contím instências de 20 nodos dos três grupos de instências em estudo. Notamos que no interior de ambas as tabelas se encontram duas linhas horizontais que separam os trêes grupos de instêancias, Quase Caminhos, Aleatíorias e Euclideanas.
48
Instância	MTZl	MTZl1L	MTZl2L	MTZl3L	MTZl4L
QC10-1	70,850	102,846	71,354	73,437	101,750
QC10-2	180,558	277,893	181,160	183,068	276,205
QC10-3	101,189	282,320	102,561	104,173	269,248
QC10-4	148,118	282,940	149,592	154,284	276,805
QC10-5	295,290	480,818	298,061	323,849	480,818
QC10-6	88,687	128,771	88,998	89,246	128,771
QC10-7	269,666	364,790	270,000	277,005	364,065
QC10-8	267,364	474,800	268,739	276,392	473,219
QC10-9	122,943	217,663	124,044	127,471	211,672
QC10-10	413,217	533,522	413,654	418,521	531,433
R10-1	12589,3	17066,5	12661	12746,6	17066,5
R10-2	11856,2	16824	11932,1	12808,6	16824
R10-3	6402,33	8796,34	6429,56	6558,05	8796,34
R10-4	10659,3	16627,4	10755,4	11256,4	16627,4
R10-5	23911,9	26048,3	23976,6	24559	26012,6
E10-1	29161,7	33619,7	29202,2	29427,5	33619,7
E10-2	25480,6	32734,9	25621,2	26213,4	32290,9
E10-3	25501,9	29698,6	25532,3	25648,3	29698,6
E10-4	14870,3	22379,5	15046,1	15612,9	22223,1
E10-5	35837,3	38040,1	35898,7	35977,8	37998,6
Tabela 3.4: Comparação dos valores da relaxação linear da Formulação MTZ com as várias desigualdades levantadas em instâncias de 10 nodos.
49
Instancia	MTZl	MTZl1L	MTZl2L	MTZl3L	MTZl4L
QC20-1	1017,800	1477,310	1019,100	1030,800	1470,370
QC20-2	1028,600	1345,330	1029,520	1034,930	1343,920
QC20-3	844,136	1293,780	845,667	853,500	1290,690
QC20-4	400,352	565,526	400,581	404,039	565,269
QC20-5	168,315	440,339	168,484	169,235	438,258
QC20-6	607,602	847,329	608,394	613,906	847,329
QC20-7	519,714	1022,540	521,196	529,368	1022,540
QC20-8	211,335	296,717	211,638	213,445	296,543
QC20-9	176,805	559,421	177,886	181,276	554,623
QC20-10	774,781	1300,880	775,725	785,813	1293,250
R20-1	25308,900	30518,100	25330,500	25516,300	30412,500
R20-2	26211,500	31057,400	26227,100	26754,800	31012,300
R20-3	25357,100	30826,400	25377,800	25748,700	30826,400
R20-4	23844,000	30596,300	23879,200	24126,400	30555,100
R20-5	24327,700	28647,700	24333,400	24686,500	28576,800
E20-1	40368,600	50041,500	40404,300	40560,200	50041,500
E20-2	62689,600	77740,400	62727,500	63072,200	77740,400
E20-3	45953,400	57072,100	46004,100	46289,000	57063,300
E20-4	44808,000	51277,900	44812,600	44845,700	51274,500
E20-5	44445,400	54287,900	44481,700	44922,600	54287,900
Tabela 3.5: Comparação dos valores da relaxação linear da Formulação MTZ com as várias desigualdades levantadas em instancias de 20 nodos.
50
Os valores a negrito nas Tabelas 3.4 e 3.5 correspondem ao melhor valor do limite inferior obtido. Podemos observar que se verifica a seguinte relação entre os valores obtidos pela relaxacao linear nas diversas formulações para todas as instâncias consideradas.
Para comparar, computacionalmente, os tempos de execução obtidos usando cada uma das desigualdades levantadas propostas na Formulação MTZ elaborámos o gráfico da Figura 3.9, onde se apresentam os tempos mádios, em segundos, necessários para a obtençao do valor otimo em cada uma das Formulacães MTZ, MTZll, MTZL2, MTZl3 e MTZl4 em instâncias de 10, 20 e 40 nodos.
Figura 3.9: Tempos médios, em segundos, necessários para a obtenção do valor ótimo da Formulação
MTZ com as várias desigualdades levantadas em instâncias de 10, 20 e 40 nodos.
Através do gráfico da Figura 3.9 é possível observar que os tempos médios mais baixos são obtidos usando a Formulação MTZll e os tempos médios mais elevados são obtidos usando a Formulaçao MTZl3.
Assim, verificamos que os melhores resultados são obtidos quando as Desigualdades Levantadas 1 (Formulação MTZll) sao incorporadas no modelo quer em termos de melhor valor do limite inferior quer em termos de melhores tempos médios de execução necessários para a obtencão do valor étimo. Deste modo e daqui em diante consideramos a Formulaçao MTZ com as desigualdades (3.33) substituédas por
(n - 2)xji + nxij + Ui &amp;lt;Uj + (n - 1),	(i, j) G A.
51
Formulação WMTZ
Para comparar, computacionalmente, os valores dos limites inferiores obtidos usando cada uma das desigualdades levantadas propostas na Formulacçãao WMTZ elaboréamos as Tabelas 3.6 e 3.7. A primeira coluna destas tabelas refere-se à designação da instência e as restantes colunas contêem os valores dos limites inferiores obtidos pelas Formulacçoães WMTZ, WMTZl1, WMTZl2, WMTZl3 e WMTZl4. A Tabela 3.6 contem instancias de 10 nodos e a Tabela 3.7 contém instências de 20 nodos dos três grupos de instências em estudo. Notamos que no interior de ambas as tabelas se encontram duas linhas horizontais que separam os trêes grupos de instêancias, Quase Caminhos, Aleatéorias e Euclideanas.
Instancia	WMTZl	WMTZl1L	WMTZl2L	WMTZl3L	WMTZl4L
QC10-1	68,087	69,272	102,846	69,457	71,898
QC10-2	178,512	180,943	277,893	181,397	183,665
QC10-3	93,654	96,854	282,320	97,740	99,806
QC10-4	142,483	148,007	282,940	149,518	158,827
QC10-5	283,673	292,998	480,818	295,012	327,451
QC10-6	87,994	89,096	128,771	89,886	90,336
QC10-7	268,808	270,369	364,790	270,711	281,230
QC10-8	262,573	268,037	474,800	271,337	283,628
QC10-9	115,192	118,295	217,663	119,823	124,517
QC10-10	411,754	413,537	533,522	413,868	423,625
R10-1	12422,800	12750,700	17066,500	12867,300	12917,000
R10-2	11861,700	12297,900	16824,000	12413,300	13101,400
R10-3	6388,140	6553,230	8796,340	6572,760	6607,750
R10-4	10245,500	10584,700	16627,400	10913,600	12016,400
R10-5	23718,600	24000,800	26048,300	24130,900	25094,600
E10-1	29076,100	29261,400	33619,700	29380,900	29572,000
E10-2	25284,200	26005,700	32734,900	26286,900	27053,600
E10-3	25426,300	25570,000	29698,600	25589,100	25656,400
E10-4	14822,700	15902,900	22379,500	16139,300	16773,000
E10-5	35540,900	35835,700	38040,100	35887,100	35954,700
Tabela 3.6: Comparaçao dos valores da relaxação linear da Formulação WMTZ com as varias desigualdades levantadas em instâncias de 10 nodos.
52
Instancia	WMTZl	WMTZl1L	WMTZl2L	WMTZl3L	WMTZl4L
QC20-1	1004,530	1014,120	1477,310	1014,680	1036,750
QC20-2	1024,370	1035,710	1345,330	1036,980	1042,310
QC20-3	828,600	839,914	1293,780	841,609	846,907
QC20-4	399,060	401,685	565,526	401,775	406,760
QC20-5	166,906	169,220	440,339	169,879	170,985
QC20-6	600,583	607,423	847,329	607,927	616,592
QC20-7	503,581	519,391	1022,540	521,910	532,799
QC20-8	208,947	211,816	296,717	212,757	216,625
QC20-9	166,153	180,256	559,421	181,285	185,302
QC20-10	767,331	779,376	1300,880	779,893	791,667
R20-1	25226,500	25506,700	30518,100	25586,600	25812,600
R20-2	25957,000	26133,800	31057,400	26134,200	26645,600
R20-3	25199,800	25400,000	30826,400	25424,000	25933,200
R20-4	23735,000	24212,000	30596,300	24275,800	24599,600
R20-5	24156,300	24254,800	28647,700	24261,500	24534,200
E20-1	40383,700	40966,700	50041,500	41065,700	41170,000
E20-2	62536,800	63020,600	77740,400	63083,100	63547,700
E20-3	45546,500	46001,400	57072,100	46068,100	46691,700
E20-4	44812,100	45239,800	51277,900	45243,500	45256,000
E20-5	44326,000	44801,000	54287,900	44881,200	45349,100
Tabela 3.7: Comparação dos valores da relaxação linear da Formulação WMTZ com as várias desigualdades levantadas em instâncias de 20 nodos.
Os valores a negrito nas Tabelas 3.6 e 3.7 correspondem ao melhor valor do limite inferior obtido. Podemos observar que se verifica a seguinte relaçcaão entre os valores obtidos pela relaxaçcaão linear nas diversas formulacçãoes para todas as instêancias consideradas.
53
Para comparar, computacionalmente, os tempos de execução obtidos usando cada uma das desigualdades levantadas propostas na Formulação WMTZ elaborámos o gráfico da Figura 3.10, onde se apresentam os tempos mádios, em segundos, necessários para a obtencão do valor átimo em cada uma das Formulaçães WMTZ, WMTZll, WMTZL2, WMTZl3 e WMTZl4 em instâncias de 10, 20 e 40 nodos.
Figura 3.10: Tempos médios, em segundos, necessários para a obtenção do valor ótimo da Formulação WMTZ com as várias desigualdades levantadas em instâncias de 10, 20 e 40 nodos.
Através do gráfico da Figura 3.10 á possível observar que os tempos médios mais baixos sãao obtidos usando a Formulaçcãao WMTZl2 e os tempos máedios mais elevados sãao obtidos usando a Formulaçcaão WMTZl4.
Assim, verificamos que os melhores resultados são obtidos quando as Desigualdades Levantadas 2 (Formulação WMTZl2) são incorporadas no modelo. Deste modo e daqui em diante consideramos a Formulação WMTZ com as desigualdades (3.33) substituídas por
(W - Wji)xji + WijXij + pi &amp;lt;pj + W(1 - Xij), (i,j) G A.
54
Comparaçõo entre as Formulações MTZ e WMTZ
A partir deste momento vamos usar as Formulaçães MTZ e WMTZ para representar as Formulacães MTZl1 e WMTZl2, respetivamente. Alím disso, podemos verificar que nas instências de 10 e 20 nodos nos três grupos de instancias (ver Tabelas 3.4, 3.5, 3.6 e 3.7) e de estudos computacionais realizados para as restantes instâncias verificamos a seguinte relação
tf(MTZL) = tf(WMTZL).
Pretendemos agora verificar qual, dentre estas duas formulaçães, a que apresenta melhores tempos computacionais na obtenção do valor do limite inferior para o custo. Nas tabelas que se seguem apresentamos, para cada grupo de instancias em teste, os tempos mídios, em segundos, para obtenção do valor da relaxação linear acompanhados dos respetivos desvios padrães em cada uma das Formulaçães MTZ e WMTZ para instências até 1000 nodos.
	Temp&lt;	&amp;lt;Médio	Desvie	) Padrão
N» Nodos	MTZl	WMTZl	MTZl	WMTZl
10	0,003	0,003	0,007	0,001
20	0,005	0,008	0,008	0,001
40	0,022	0,024	0,008	0,002
60	0,050	0,056	0,007	0,002
80	0,106	0,113	0,014	0,005
100	0,223	0,200	0,070	0,014
150	0,721	0,788	0,119	0,223
200	1,807	1,679	0,254	0,125
300	6,101	4,807	2,842	0,264
400	18,561	11,538	11,473	0,407
500	26,068	23,001	1,132	0,653
1000	195,298	76,388	36,262	14,615
Tabela 3.8: Comparação dos tempos médios (em segundos) e dos desvios padrães necessários para a obtencao do valor da relaxacao linear nas Formulacães MTZ e WMTZ em instancias QC.
55
N» Nodos	mtzl	WMTZl	MTZl	WMTZl
10	0,000	0,000	0,000	0,000
20	0,003	0,009	0,007	0,008
40	0,025	0,022	0,008	0,009
60	0,144	0,069	0,058	0,014
80	0,219	0,196	0,037	0,101
100	0,387	0,331	0,168	0,152
150	1,105	1,098	0,318	0,245
200	2,683	2,271	0,229	0,550
300	8,250	6,683	0,446	2,826
400	20,336	10,446	1,089	1,786
500	60,651	31,782	7,682	13,284
1000	154,099	115,664	48,808	8,702
Tabela 3.9: Comparação dos tempos médios (em segundos) e dos desvios padrões necessários para a obtençao do valor da relaxaçao linear nas Formulações MTZ e WMTZ em instâncias R.
Tempo Médio	Desvio Padrão
N» Nodos	mtzl	WMTZl	MTZl	WMTZl
10	0,003	0,000	0,007	0,000
20	0,016	0,006	0,000	0,008
40	0,031	0,025	0,016	0,014
60	0,081	0,050	0,007	0,007
80	0,147	0,103	0,023	0,008
100	0,275	0,212	0,034	0,060
150	0,839	0,418	0,138	0,051
200	2,043	0,933	0,205	0,160
300	7,506	2,480	1,751	0,168
400	16,049	6,318	1,064	0,478
500	39,225	11,132	6,477	0,093
1000	172,568	73,114	62,173	4,347
Tabela 3.10: Comparaçao dos tempos medios (em segundos) e dos desvios padrões necessários para a obtençao do valor da relaxaçao linear nas Formulações MTZ e WMTZ em instâncias E.
56
Nas instâncias Quase Caminhos, os tempos mádios gastos na obtenção do valor da relaxação linear de ambas as Formulaçães MTZ e WMTZ são semelhantes. De notar apenas que para instâancias de 1000 nodos, os tempos máedios usando a Formulação MTZL aumentam para mais do dobro dos tempos mádios usando a Formulacao WMTZL. Em relacao as instâncias Aleatórias para mais de 200 nodos usando a Formulação WMTZL obtâm-se menores tempos mádios, sendo os tempos mádios semelhantes para as restantes instâancias Aleatáorias. Nas instaâncias Euclideanas atáe 100 nodos os tempos máedios sãao semelhantes, mas para instâancias com mais de 100 nodos usando a Formulacão WMTZL obtâm-se menores tempos mádios. Nos vários grupos de instâncias de entre as Formulaçães MTZL e WMTZL, em geral, usando a Formulacao WMTZL obtêm-se tempos mádios de execucão inferiores.
3.4.3	Estudo Comparativo das Formulacães
Nesta secçcaão apresentamos e comparamos o tempo de execuçcaão e a qualidade das soluçcãoes encontradas usando as formulaçcãoes e os procedimentos apresentados ao longo do capátulo. Para cada grupo de instâancias apresentamos algumas tabelas, onde se reunem os gap (em percentagem) encontrados na obtencçãao de um limite inferior para o valor do custo e os tempos (em segundos) encontrados na obtençcãao do valor oátimo ou de um limite superior para o valor do custo. Notamos que o gap = OPT-Op1MSTL) x 100, onde i9(WMSTl) á o valor do limite inferior obtido para o valor do custo e OPT á o valor átimo (d(WMST)) ou o melhor valor de uma solucão admissável obtida, e, portanto, um limite superior para o valor do custo. Nas váarias tabelas que vamos apresentar a designaçcãao Mem representa falta de memáoria. No Algoritmo Branch and Bound usando as Formulaçães ES, MF, WE, MTZ e WMTZ foi imposto um tempo de execucçãao de 5000 segundos e usando os procedimentos de introduçcaão de cortes um limite no tempo de execucçãao de 10800 segundos. Em relaçcãao aos Procedimentos P-MTZ+C e P-WMTZ+C, apenas apresentamos os resultados computacionais relativos ao Procedimento P-WMTZ+C dado que na subsecção anterior, a relaxaçao linear da Formulaçcãao WMTZ foi a que apresentou tempos máedios de execuçcãao inferiores.
Instâncias Quase Caminhos
Neste grupo de instâancias nãao foi possável correr as instâancias com 40 ou mais nodos usando as Formulaçcãoes ES e WE por falta de memáoria, sendo assim apenas áe possável
57
comparar as véarias formulaçcoões e procedimentos com introducçõao de cortes para as instências de 10 e 20 nodos. Quanto a Formulaçõo MF apresenta falta de meméria para instências com mais de 150 nodos. Usando as Formulacoes MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C é possível obter um valor para o limite inferior para instancias que tenham até 1000 nodos.
Em termos de qualidade do valor do limite inferior, as formulaçcõoes apresentadas podem ser divididas em dois grupos como se pode observar na Tabela 3.11 através da existência de um risco vertical. Na Tabela 3.11 a primeira coluna refere-se à designaçõo da instência, a segunda coluna contém o gap obtido usando as Formulações ESL, MFL e WEl e os Procedimentos P-CSL e P-WMTZ+CL. A coluna oito contém o gap obtido usando as Formulacoes MTZL e WMTZL. Nas restantes colunas podemos observar os tempos de execucõo (em segundos) necessérios para a obtençao do valor étimo usando as Formulacões ES, MF, WE, MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C.
Gap	Tempos	Gap	Tempos
Instância	ES		MF	WE	P-CS	P-WMTZ+C		MTZ	WMTZ
QC10-1	38,78	0,16	0,28	3,08	0,06	0,08	38,78	0,08	0,11
QC10-2	23,66	0,19	0,84	3,42	0,12	0,22	23,66	0,11	0,05
QC10-3	24,71	0,23	0,28	2,62	0,05	0,11	24,71	0,16	0,10
QC10-4	22,27	0,41	1,51	3,18	0,11	0,11	22,27	0,14	0,17
QC10-5	17,00	0,23	0,56	3,23	0,03	0,09	17,24	0,19	0,14
QC10-6	28,06	0,19	0,98	2,98	0,23	0,11	28,06	0,08	0,12
QC10-7	16,90	0,16	0,56	3,48	0,14	0,09	16,90	0,11	0,14
QC10-8	17,51	0,53	1,50	3,46	0,09	0,13	17,71	0,13	0,15
QC10-9	17,24	0,38	1,28	3,54	0,08	0,06	17,24	0,08	0,06
QC10-10	16,79	0,42	0,70	2,93	0,16	0,09	18,79	0,17	0,28
QC20-1	6,56	1179,24	19,45	43,16	0,90	0,95	6,56	0,89	0,72
QC20-2	8,04	4946,99	14,47	37,78	0,64	1,09	8,04	0,84	1,12
QC20-3	5,15	1192,27	42,79	58,82	0,95	1,12	5,15	1,25	1,13
QC20-4	16,07	1351,41	7,78	33,43	0,67	0,73	16,09	1,01	0,95
QC20-5	19,12	1379,94	7,53	34,74	0,63	0,62	19,50	0,94	0,55
QC20-6	8,34	1812,30	33,77	66,62	1,23	1,45	8,89	1,09	1,60
QC20-7	8,33	3073,37	71,39	61,98	2,25	3,61	8,54	2,17	2,12
QC20-8	7,18	1874,57	12,06	34,94	0,66	1,28	7,28	1,08	0,90
QC20-9	9,91	1010,29	30,70	57,78	0,95	1,81	9,92	2,09	0,91
QC20-10	10,04	4218,94	11,68	44,51	1,00	0,83	10,04	1,05	1,35
Tabela 3.11: Comparação das formulações em instâncias QC de 10 e 20 nodos.
58
Os gaps obtidos usando as Formulacães ESL, MFL e WEL e os Procedimentos P-CSL e P-WMTZ+Cl sao iguais. Estes gaps sao inferiores aos obtidos através do uso das Formulaçães MTZL e WMTZL em 40% das instâncias apresentadas na Tabela 3.11 (8 em 20 instâncias).
Os tempos de execucçãao usando a Formulaçcãao ES começcam a ser bastante elevados para instâancias de 20 nodos. O uso da Formulaçcaão MF torna-se mais ríapido do que o uso da Formulação WE. Em geral, para instancias de 10 e 20 nodos os tempos de execuçcãao saão inferiores usando o Procedimento P-CS.
Na Tabela 3.12 tambím podemos observar a existência de um risco vertical, o qual indica que as formulaçcãoes apresentadas tambíem podem ser divididas, em termos de qualidade do valor do limite inferior, em dois grupos. Para instaâncias com 40, 60 e 80 nodos sío íe possível comparar as Formulacçãoes MF, MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C dado que as Formulaçcãoes ES e WE apresentam falta de memoria. Na Tabela 3.12 a primeira coluna refere-se à designação da instância, a segunda coluna contíem o gap obtido usando a Formulaçcaão MFL e os Procedimentos P-CSL e P-WMTZ+CL. A coluna seis contíem o gap obtido usando as Formulaçcoães MTZL e WMTZL. Nas restantes colunas podemos observar os tempos de execuçcaão (em segundos) necessíarios para a obtençcãao do valor íotimo ou de um limite superior para o valor do custo usando as Formulacçãoes MF, MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C.
Note-se que nas instâancias com 40, 60 e 80 nodos usando a Formulaçcaão MF nãao foi possível no tempo limite imposto (5000 segundos) provar a otimalidade em nenhuma das intaâncias.
59
	Gap		Tempos	Gap		Tempos	
Instância		MF	P-CS	P-WMTZ+C		MTZ	WMTZ
QC40-1	5,83	5012,23a	61,43	29,89	5,92	32,61	67,98
QC40-2	7,18	5010,42a	55,87	49,55	7,18	42,20	28,68
QC40-3	5,60	5012,01a	27,69	34,77	5,77	38,19	5,51
QC40-4	5,38	5007,71a	164,14	88,26	5,70	186,48	148,97
QC40-5	6,40	5009,16a	37,21	25,88	6,42	36,78	24,81
QC40-6	5,95	5010,74a	45,20	28,58	5,95	15,27	24,16
QC40-7	8,15	5010,32a	45,44	101,58	8,15	36,03	54,28
QC40-8	6,73	5030,13a	28,14	17,33	6,77	5,71	21,07
QC40-9	6,60	5011,85a	25,08	14,64	6,66	11,53	28,88
QC40-10	5,81	5009,64a	62,62	27,06	5,81	24,07	30,00
QC60-1	4,54	5328,16a	345,54	473,61	4,58	487,59	857,77
QC60-2	4,56	5145,07a	418,85	610,92	4,56	621,32	456,46
QC60-3	2,87	5137,45a	304,87	554,68	2,87	297,38	584,50
QC60-4	4,36	5151,68a	1121,22	1250,37	4,36	872,04	2100,82
QC60-5	5,48	5124,27a	400,90	214,55	5,48	234,70	189,30
QC60-6	5,26	5153,44a	185,12	201,32	5,26	227,57	248,73
QC60-7	5,46	5176,42a	972,59	783,62	5,46	2361,43	1032,19
QC60-8	5,11	5128,38a	310,45	414,94	5,13	394,41	332,79
QC60-9	6,00	5108,40a	563,06	603,84	6,00	752,00	710,41
QC60-10	4,66	8223,73a	169,76	66,36	4,66	1110,18	107,88
QC80-1	3,29	6159,59a	700,68	4605,85	3,33	2524,85	1129,14
QC80-2	4,30	5424,06a	1726,52	3618,82	4,33	1336,79	1013,28
QC80-3	3,07	5425,27a	1592,13	2102,90	3,13	4283,73	992,12
QC80-4	3,28	5660,65a	3104,76	732,30	3,31	2968,99	4999,24a
QC80-5	4,92	5777,09a	1164,13	1424,12	4,96	1860,88	1288,65
QC80-6	2,88	6238,23a	9679,97	7280,69	3,02	3888,80	4999,48a
QC80-7	3,39	5976,62a	1731,47	1916,47	3,44	853,57	2951,94
QC80-8	3,04	5944,65a	480,45	393,98	3,04	4897,01	325,45
QC80-9	4,17	5747,04a	2363,90	1255,64	4,37	2736,49	4999,84a
QC80-10	5,45	5508,36a	1793,40	2025,78	5,59	4883,93	2541,65
Tabela 3.12: Comparação das formulaçães em instâncias QC de 40, 60 e 80 nodos. a Não foi possível provar a otimalidade no tempo imposto.
60
Na Tabela 3.12 continuamos a observar que os gaps usando a Formulacão MFL e os Procedimentos P-CSL e P-WMTZ+CL sao um pouco mais baixos em 56,67% das instancias apresentadas (17 em 30 instâncias). Pela observaçao da Tabela 3.12 verificamos que em 15 instâncias usando o Procedimento P-CS obtem-se tempos de execução inferiores e nas outras 15 instancias os tempos de execuçao sao menores usando o Procedimento P-WMTZ+C.
Jé vimos que os dois procedimentos com introducão de cortes apresentam os mesmos gaps. Para averiguar qual dos procedimentos é mais répido na obtenção de um limite inferior elaborémos a Tabela 3.13, onde se encontram os tempos médios (em segundos) e os respetivos desvios padrães obtidos para instâncias de 10 a 80 nodos.
Tempos PL	Desvio Padrão
N.Q Nodos	P-CSL	P-WMTZ+Cl	P-CSL	P-WMTZ+Cl
10	0,011	0,003	0,007	0,006
20	0,233	0,025	0,061	0,008
40	7,541	0,086	1,201	0,015
60	49,439	0,201	9,570	0,042
80	214,574	0,587	36,718	0,188
Tabela 3.13: Comparação dos Procedimentos P-CS e P-WMTZ+C em termos de tempo medio de execução (em segundos) da relaxação linear em instâncias QC de 10, 20, 40, 60 e 80 nodos.
Na Tabela 3.13 podemos observar que para a obtenção de um limite inferior para o valor do custo, os tempos médios e correspondentes desvios padroes sao menores usando o Procedimento P-WMTZ+CL.
Instâncias Aleatórias
Nas instâncias Aleatérias usando a Formulação WE sé é possével executar a instancia R10-1, não sendo possével correr as restantes instâncias por falta de meméria, sendo assim apenas é possével comparar as vérias formulaçães e procedimentos com introdução de cortes para a instância R10-1. A Formulacão ES apresenta falta de meméria nas instancias R20-1, R20-2, R20-3 e para instâncias com 40 ou mais nodos. Quanto à Formulacão MF apresenta falta de meméria para instâncias com mais de 200 nodos.
61
Usando as Formulaçães MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C é possrvel obter um valor para o limite inferior para instancias que tenham até 1000 nodos.
Em termos de qualidade do valor do limite inferior, as formulaçães apresentadas podem ser divididas em dois grupos como se pode observar na Tabela 3.14 através da existência de um risco vertical. Na Tabela 3.14 a primeira coluna refere-se à designação da instancia, a segunda coluna contém o gap obtido usando as Formulaçães ESL, MFL e WEl e os Procedimentos P-CSL e P-WMTZ+CL. A coluna oito contém o gap obtido usando as Formulações MTZL e WMTZL. Nas restantes colunas podemos observar os tempos de execucçãao (em segundos) necesséarios para a obtençcaão do valor éotimo usando as Formulacães ES, MF, WE, MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C.
Gap	Tempos	Gap	Tempos
Instância		ES	MF	WE	P-CS	P-WMTZ+C		MTZ	WMTZ
R10-1	10,70	0,14	1,12	109,75	0,06	0,06	11,59	0,13	0,08
R10-2	18,96	0,16	0,55	Mem	0,12	0,23	18,96	0,05	0,06
R10-3	19,25	0,16	0,66	Mem	0,03	0,05	42,21	0,16	0,13
R10-4	14,96	0,45	1,31	Mem	0,25	0,22	14,96	0,06	0,09
R10-5	11,42	0,14	0,28	Mem	0,06	0,37	11,42	0,03	0,03
R20-1	3,96	Mem	3,84	Mem	0,27	1,01	4,79	0,17	0,27
R20-2	3,97	Mem	2,36	Mem	0,41	1,92	3,97	0,12	0,09
R20-3	3,94	Mem	8,14	Mem	0,45	0,45	7,61	0,77	0,33
R20-4	3,89	2458,65	1,42	Mem	0,44	0,66	3,89	0,64	0,09
R20-5	4,63	3183,96	4,59	Mem	0,50	1,62	4,63	0,28	0,16
Tabela 3.14: Comparação das formulaçães em instancias R de 10 nodos.
Os gaps obtidos usando as Formulações ESL, MFL e WEL e os Procedimentos P-CSL e P-WMTZ+Cl são iguais. Estes gaps sao inferiores aos obtidos através do uso das Formulaçães MTZL e WMTZL em 40% das instâncias apresentadas na Tabela 3.14 (4 em 10 instências).
Na instêancia R10-1 obtêem-se os valores éotimos mais rapidamente usando os Procedimentos P-CS e P-WMTZ+C. Para a uénica instêancia que ée possével resolver usando a Formulaçcãao WE obtéem-se o tempo mais elevado. Nas restantes instêancias de 10 nodos e nas instências R20-1, R20-2 e R20-3, em geral, usando a Formulaçao MF obtêm-se tempos mais elevados.
62
Os tempos de execucão usando a Formulação ES são bastante elevados para as instâncias R20-4 e R20-5, as unicas de 20 nodos que resolve. O Procedimento P-CS para instâncias de 10 e 20 nodos parece ser o que, em geral, apresenta tempos de execução inferiores.
Na Tabela 3.15 também podemos observar a existância de um risco vertical, o qual indica que as formulaçcãoes apresentadas tambáem podem ser divididas, em termos de qualidade do valor do limite inferior, em dois grupos. Para instâncias com 40, 60 e 80 nodos sá é possível comparar as Formulaçães MF, MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C dado que as Formulaçães ES e WE apresentam falta de memoria. Na Tabela 3.15 a primeira coluna refere-se à designacão da instância, a segunda coluna contám o gap obtido usando a Formulação MFL e os Procedimentos P-CSL e P-WMTZ+Cl. A coluna seis contám o gap obtido usando as Formulaçães MTZl e WMTZl. Nas restantes colunas podemos observar os tempos de execução (em segundos) necessários para a obtençao do valor átimo ou de um limite superior para o valor do custo usando as Formulaçcoães MF, MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C.
63
Instância		MF	P-CS	P-WMTZ+C		MTZ	WMTZ
R40-1	1,84	26,35	3,68	4,51	1,84	0,44	0,28
R40-2	1,72	34,93	6,26	3,68	1,72	0,67	0,33
R40-3	1,74	27,86	9,50	5,73	5,32	4,99	11,22
R40-4	2,03	35,32	10,28	2,57	2,03	0,41	0,28
R40-5	1,53	62,85	16,44	4,18	1,53	0,58	0,50
R60-1	0,63	91,82	58,66	4,51	0,63	1,36	0,70
R60-2	0,56	124,89	54,24	6,07	0,56	1,33	0,98
R60-3	0,52	369,99	34,65	6,93	0,52	1,30	0,81
R60-4	0,70	418,42	44,15	7,27	1,59	9,50	6,30
R60-5	0,53	318,72	52,43	5,03	0,59	2,17	2,75
R80-1	0,34	595,91	153,36	15,19	0,34	2,37	1,33
R80-2	0,40	973,80	143,55	16,18	0,97	24,26	22,11
R80-3	0,44	240,03	164,03	12,42	0,78	4,34	2,59
R80-4	0,37	346,58	158,05	11,17	0,37	1,86	1,14
R80-5	0,38	1127,72	176,53	16,29	0,93	5,46	6,18
R100-1	0,10	1172,18	524,12	12,90	1,75	1515,59	1328,88
R100-2	0,13	2934,95	369,84	28,80	1,67	2635,51	4999,92a
R100-3	0,02	651,38	670,05	23,10	0,20	3,92	3,99
R100-4	0,06	1273,22	619,69	16,80	0,82	18,43	20,70
R100-5	0,04	1788,42	560,92	21,81	1,04	19,86	40,28
Tabela 3.15: Comparação das formulações em instâncias R de 40, 60, 80 e 100 nodos. a Não foi possível provar a otimalidade no tempo imposto.
Os gaps obtidos usando a Formulacao MFL e os Procedimentos P-CSL e P-WMTZ+CL saão inferiores aos gaps obtidos usando as Formulaçcoães MTZL e WMTZL em 55% das instancias apresentadas na Tabela 3.15 (11 em 20 instancias). A medida que se aumenta a dimensãao das instâancias, verificamos que o tempo de execuçcãao íe inferior usando o Procedimento P-WMTZ+C. Note-se que usando a Formulaçcãao MF obtâem-se tempos de execuçcaão mais elevados.
Instancias Euclideanas
Usando a Formulaçcãao WE todas as instaâncias Euclideanas apresentam falta de memíoria. A Formulacçãao ES nãao corre por falta de memíoria para instâancias de 20 ou mais nodos. Quanto a Formulacao MF apresenta falta de memíria para instâncias
64
com mais de 200 nodos. Usando as Formulaçcãoes MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C í possível obter um valor para o limite inferior para instências que tenham atíe 1000 nodos.
Em termos de qualidade do valor do limite inferior, as formulacçãoes apresentadas podem ser divididas em dois grupos como se pode observar na Tabela 3.16 através da existência de um risco vertical. Na Tabela 3.16 a primeira coluna refere-se à designacão da instência, a segunda coluna contem o gap obtido usando as Formulaçães ESL e MFL e os Procedimentos P-CSL e P-WMTZ+CL. A coluna sete contím o gap das Formulações MTZl e WMTZl. Nas restantes colunas podemos observar os tempos de execucão (em segundos) necessíarios para a obtençcãao do valor íotimo usando as Formulaçcoães ES, MF, MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C.
Gap	Tempos	Gap	Tempos
Instância		ES	MF	P-CS	P-WMTZ+C		MTZ	WMTZ
E10-1	8,63	0,27	0,90	0,08	0,09	15,92	0,17	0,28
E10-2	10,42	0,17	0,22	0,05	0,03	11,33	0,36	0,14
E10-3	8,85	0,22	1,16	0,06	0,09	15,65	0,33	0,38
E10-4	9,51	0,17	0,05	0,02	0,17	14,86	0,30	0,09
E10-5	7,76	0,17	0,19	0,05	0,16	7,76	0,05	0,06
E20-1	3,92	Mem	5,07	0,36	0,61	6,39	1,14	1,64
E20-2	2,42	Mem	0,53	0,16	0,17	13,13	1,50	1,17
E20-3	2,61	Mem	5,07	0,78	1,59	4,91	1,05	0,67
E20-4	3,08	Mem	2,92	0,41	0,81	9,31	1,20	1,28
E20-5	2,40	Mem	4,10	0,53	1,28	10,16	4,65	3,76
E40-1	0,88	Mem	56,24	13,57	6,41	8,31	100,09	389,14
E40-2	1,05	Mem	47,92	11,79	7,08	7,08	17,69	41,36
E40-3	0,79	Mem	37,88	9,17	4,74	3,15	6,65	11,06
E40-4	0,95	Mem	166,67	6,01	5,66	7,09	13,00	34,45
E40-5	0,81	Mem	56,24	10,95	4,09	4,28	6,55	10,11
Tabela 3.16: Comparação das formulacães em instâncias E de 10 nodos.
Os gaps obtidos usando as Formulaçães ESL e MFL e os Procedimentos P-CSL e P-WMTZ+Cl sao inferiores aos gaps obtidos usando as Formulações MTZL e WMTZL em 93,33% das instências apresentadas na Tabela 3.16 (14 em 15 instancias).
Os tempos de execucçaão mais elevados obtêem-se usando a Formulaçcãao MF. Nas instaências de 10 e 20 nodos observamos tempos inferiores quando se utiliza o Proce-
65
dimento P-CS, mas para instâancias de 40 nodos os tempos de execuçcãao saão inferiores usando o procedimento P-WMTZ+C.
Na Tabela 3.17 também podemos observar a existância de um risco vertical, o qual indica que as formulaçcãoes apresentadas tambéem podem ser divididas, em termos de qualidade do valor do limite inferior, em dois grupos. Para instâancias com 60, 80 e 100 nodos só é possível comparar as Formulaçoes MF, MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C dado que as Formulaçães ES e WE apresentam falta de meméria. Na Tabela 3.17 a primeira coluna refere-se à designação da instância, a segunda coluna contém o gap obtido usando a Formulacão MFL e os Procedimentos P-CSL e P-WMTZ+Cl. A coluna seis contém o gap obtido usando as Formulaçoes MTZl e WMTZl. Nas restantes colunas podemos observar os tempos de execucao (em segundos) necesséarios para a obtençcãao do valor éotimo ou de um limite superior para o valor do custo usando as Formulaçcãoes MF, MTZ e WMTZ e os Procedimentos P-CS e P-WMTZ+C.
Gap	Tempos	Gap	Tempos
Instância		MF	P-CS	P-WMTZ+C		MTZ	WMTZ
E60-1	0,39	464,96	43,67	11,75	3,10	76,66	47,35
E60-2	0,49	2545,94	69,44	11,36	5,92	579,28	755,92
E60-3	0,34	254,42	35,68	7,85	4,35	793,01	532,07
E60-4	0,39	322,67	39,73	10,62	7,29	710,44	4768,68
E60-5	0,34	902,43	33,24	20,22	9,20	5000,41a	4999,99a
E80-1	0,22	397,72	175,42	29,89	7,18	5000,32a	5000,33a
E80-2	0,24	408,71	283,39	29,27	3,47	161,85	142,68
E80-3	0,23	5068,13	151,38	61,28	7,88	4999,64a	5000,23a
E80-4	0,25	1659,03	160,81	42,79	7,19	5000,31a	5000,48a
E80-5	0,21	5967,62a	224,94	42,35	8,28	5000,47a	5000,51a
E100-1	0,11	6056,17a	686,10	78,61	3,35	2032,71	2462,64
E100-2	0,06	4376,29	518,48	98,70	7,62	4999,99a	5000,17a
E100-3	0,09	3827,08	476,77	166,30	6,00	4999,63a	5000,31a
E100-4	0,10	1384,07	478,98	102,98	5,35	5001,39a	5000,79a
E100-5	0,10	2665,98	527,56	135,39	6,79	5000,34a	5000,96a
Tabela 3.17: Comparacão das formulaçoes em instâncias E de 20, 40, 60 e 80 nodos. a Não foi possível provar a otimalidade no tempo imposto.
Os gaps obtidos usando a Formulacão MFL e os Procedimentos P-CSL e
66
P-WMTZ+Cl sao inferiores aos gaps obtidos usando as Formulações MTZL e WMTZL em todas as instâncias apresentadas na Tabela 3.17. Usando a Formulaçao MF obtem-se tempos de execução mais elevados. Em instâncias de 60, 80 e 100 nodos, usando o Procedimento P-WMTZ+C obtám-se tempos de execucão inferiores.
3.4.4	Resultados Computacionais
Na subsecçao anterior verificámos que, em geral, o Procedimento P-WMTZ+C á o mais eficiente nos trâs grupos de instâncias consideradas. Para este procedimento nas 215 instancias testadas, não foi possável obter soluçao inteira admissável em 14 instancias, sendo 4 delas instâncias de 1000 nodos do grupo Quase Caminhos, 1 instância de 1000 nodos do grupo Aleatórias e 9 instâncias de 500 e 1000 nodos do grupo Euclideanas.
Em instâncias Quase Caminhos a partir de 100 nodos (exceto QC100-10) não á possável resolver as instâncias atá provar a otimalidade, o que corresponde a 46,32% das instâncias (44 instancias em 95). Em relacão às instancias Aleatorias apenas não á possável provar a otimalidade em 3 instâncias de 1000 nodos (5% das instâncias) e por fim no grupo de instaâncias Euclideanas naão foi possável provar a otimalidade em 25% das instâncias (15 instancias em 60), sendo elas instâncias com mais de 300 nodos.
Na Tabela 3.18 apresentamos para os três grupos de instâncias os tempos mádios, em segundos, e os respetivos desvios padrãoes obtidos com a aplicaçcãao do Procedimento P-WMTZ+C na obtenção do valor átimo ou de um limite superior para o valor átimo. A primeira coluna contáem o nuámero de nodos das instâancias, as trâes colunas seguintes apresentam os tempos máedios, em segundos, necessáarios para a obtençcãao do valor áotimo ou de um limite superior para o valor oátimo e as trâes uáltimas colunas contâem os correspondentes desvios padroães.
67
	Tempo Medio		Desvio Padrão			
N» Nodos	QC	R	E	QC	R	E
10	0,109	0,187	0,109	0,042	0,136	0,211
20	1,350	1,133	0,893	0,867	0,625	0,558
40	41,756	4,134	5,597	29,749	1,188	1,213
60	517,422	5,960	12,358	338,821	1,188	4,650
80	2535,656	14,249	41,115	2095,439	2,325	13,012
100	10597,763	20,683	116,395	646,021	6,096	34,540
150	10809,301	95,072	585,157	3,413	37,464	181,108
200	10826,760	310,588	1905,269	9,115	222,722	737,561
300	10931,065	1566,215	12368,562	68,410	866,040	3070,597
400	11054,431	2647,825	23590,768	159,831	854,527	5483,945
500	11307,302	9225,342	27611,014	267,266	2740,351	7483,639
1000	13082,191	17168,960	31071,300	823,942	2724,852	86,227
Tabela 3.18: Tempos médios, em segundos, e respetivos desvios padroes obtidos com a aplicaçao do Procedimento P-WMTZ+C na obtencão do valor otimo ou de um limite superior para o valor otimo em cada grupo de instâncias.
Nas instâncias de 10 e 20 nodos, os tempos médios de execução obtidos com a aplicação do Procedimento P-WMTZ+C nos vérios grupos de instâncias são semelhantes. Para instâncias com mais de 20 e menos de 300 nodos, verificamos que as instâncias Quase Caminhos são as que apresentam maior tempo médio na obtenção do valor étimo ou de um limite superior para o valor étimo, depois temos as instâncias Euclideanas e por fim as instâncias Aleatorias. Nas instâncias de 300 ou mais nodos o comportamento dos tempos altera-se, sendo as instâncias Euclideanas as que que apresentam maior tempo médio de execucão.
Dado que através da observação da Tabela 3.18 se verificou uma grande diferença nos tempos médios de execuçao do Procedimento P-WMTZ+C (tempo de execucão da relaxaçao linear + tempo de execução do Algoritmo Branch and Bound) nos três grupos de instâncias em teste, decidimos analisar os tempos médios de execuçao da relaxação linear e os tempos médios de execuçao do Algoritmo Branch and Bound nos vérios grupos de instâncias. Com esta anélise pretendemos averiguar se existem diferentes comportamentos a nével destes dois tempos médios. Para efetuar a anélise elaborémos os gréficos das Figuras 3.11, 3.12 e 3.13 para os grupos de instâncias Aleatorias, Euclideanas e Quase Caminhos para instâncias com mais de 40 nodos. Nestes gréficos encontram-se as percentagens de tempo médio obtidas com a execução da relaxação
68
linear e as percentagens de tempo médio obtidas com a execução do Algoritmo Branch and Bound. Estas duas percentagens distinguem-se nos gréficos por duas cores diferentes. Cada gréfico contém ainda uma tabela onde se pode observar o tempo médio, em segundos, de execução da relaxaçao linear (Tempo PL) e o tempo médio, em segundos, de execução do Algoritmo Branch and Bound (Tempo B&amp;amp;B).
Instâncias R
■	Tempo B&amp;amp;B	5.74	13,68	17,26	67,63	246,09	1121,13	2045,98	5298,78	5298,78
■	Tempo PL	0,22	0,57	3,42	27,44	64,50	445,08	601,85	3926,57	3926,57
Figura 3.11: Comparação das percentagens de tempo médio de execução (em segundos) da relaxação linear e do Algoritmo Branch and Bound do Procedimento P-WMTZ+C em instancias R.
69
Instâncias E
■	Tempo B&amp;amp;B	10,10	30,55	77,59	378,20	1048,74	6960,71	17198,92 19212,04 20978,60
■	Tempo PL	2,26	10,57	38,81	206,96	856,53	5407,86	6391,85	8398,97 10092,70
Figura 3.12: Comparação das percentagens de tempo médio de execução (em segundos) da relaxação linear e do Algoritmo Branch and Bound do Procedimento P-WMTZ+C em instâncias E.
Instâncias QC
■	Tempo B&amp;amp;B 517,22	2535,07 10596,60 10804,61 10813,50 10866,94 10929,46 11057,40 11988,70
■	TempoPL 0,20	0,59	1,16	4,69	13,26	64,13	124,97	249,90 1093,49
Figura 3.13: Comparaçao das percentagens de tempo médio de execução (em segundos) da relaxação linear e do Algoritmo Branch and Bound do Procedimento P-WMTZ+C em instancias QC.
70
Podemos observar que nos véarios grupos de instêancias existem dois comportamentos diferentes. Nas instêancias Aleatéorias e Euclideanas os comportamentos dos tempos méedios sõao semelhantes. Em instêancias de dimensõao superior a 100 nodos, em méedia, mais de 20% do tempo é ocupado a resolver a relaxacõo linear e o restante do tempo na execucçõao do Algoritmo Branch and Bound para encontrar o valor otimo ou um limite superior para o valor otimo. Este comportamento nõao se verifica no grupo de instêancias Quase Caminhos, pois neste grupo de instaências o valor da relaxaçcõao linear e obtido rapidamente em comparaçcõao com o tempo de execuçcõao do Algoritmo Branch and Bound para encontrar o valor otimo ou um limite superior para o valor otimo. Nas instancias Quase Caminhos mais de 90% do tempo medio de execuçõo e gasto no Algoritmo Branch and Bound. Notamos que a percentagem representada a azul nos graficos das Figuras 3.11 e 3.12 poderia ser maior, no caso de nõo ser introduzido um procedimento de interrupcçõao da relaxacçõao linear. Este procedimento consistiu em interromper a relaxaçcõao linear quando o gap, em percentagem, entre duas solucçõoes consecutivas for inferior a 0,000001, mais do que 20 vezes ou quando o limite de tempo na introduçcõao de cortes exceder 10000 segundos (limite imposto).
3.4.5	S íntese dos Resultados Computacionais
Os resultados computacionais mostram a seguinte relaçcõao entre os valores obtidos na relaxaçcaõo linear
tf(WMST)
t
&lt;-WMTZ+Cl) = $(P-CSl) = ^(MFl) = tf(WEL) = ^(ESl)
t
$(MTZl) = ^(WMTZl )
Figura 3.14: Relação entre os valores obtidos pela relaxação linear das diferentes formulações e procedimentos de introducçãao de cortes.
71
Os valores dos limites inferiores obtidos usando as Formulacães MTZ e WMTZ encontram-se mais afastados do valor éotimo e os obtidos usando as Formulacçãoes ES, MF e WE e os Procedimentos P-CS e P-WMTZ+C encontram-se mais préximos do valor éotimo.
De entre as duas Formulaçcãoes MTZ e WMTZ a que, em geral, apresenta tempos méedios de execuçcaão da relaxaçcãao linear inferiores ée a Formulaçcaão WMTZ.
De entre todas as formulacçãoes e procedimentos de introducçãao de cortes usando separaçcaão, o Procedimento P-WMTZ+C ée o que apresenta os melhores resultados em termos de tempo de execuçcãao da relaxaçcãao linear e do Algoritmo Branch and Bound para todos os grupos de instaâncias em teste.
Em instâancias Aleatéorias e Euclideanas de maiores dimensãoes, a resolucçãao da re-laxaçcãao linear torna-se lenta, enquanto que nas instaâncias Quase Caminhos ée bastante réapida.
72
Capítulo 4
Algoritmos Lagrangeanos
Neste capítulo vamos apresentar algoritmos baseados numa relaxação Lagrangeana que determinam uma soluçcãao aproximada para o Problema WMST. Este tipo de algoritmos sao muito comuns para o Problema do Caminho Mais Curto com Restrições de Peso (CSP - Constrained Shortest Path) [13, 33, 40, 41, 64, 65]. Notamos que a forma de resolucçãao atraves desta tecnica e muito semelhante para ambos os problemas CSP e WMST, de tal modo que e frequente nos artigos referentes ao CSP aparecer a observação de que o mesmo pode ser aplicado ao Problema WMST. Neste capítulo, para aláem de apresentarmos resultados computacionais para algoritmos adaptados do CSP para o WMST, apresentamos três novos algoritmos para o WMST e os respetivos resultados computacionais.
O trabalho de Xue [65] descreve dois algoritmos: um para encontrar solucães aproximadas para o Problema CSP e outro para o Problema WMST. Os resultados computacionais para o primeiro algoritmo mostraram ser bastante bons, encontrando soluçães átimas em mais de 80% dos casos e soluçães práximas das átimas nos restantes casos. Nãao sãao apresentados quaisquer resultados computacionais para o algoritmo para o WMST. Os autores apenas manifestam o seu interesse em fazêe-lo futuramente para grafos aleatários e comparar com soluçães õtimas obtidas usando o Algoritmo k Smallest Spanning Tree [16].
No artigo de Block e Gutin [13] podemos consultar um algoritmo aproximado bastante eficiente para problemas de Otimização Combinatária com dois parêmetros associados a elementos combinatários em geral. Embora o algoritmo não seja polinomial, o autor fornece algumas evidêencias teáoricas e práaticas que mostram que o algoritmo pode ser bastante ráapido em muitos casos.
Juttner et al. [41] desenvolveram o Algoritmo LARAC (Lagrangean Relaxation
73
Based Agregated Cost) para resolver a relaxação Lagrangeana proposta para o Problema CSP. Os autores aplicam uma aproximacão algábrica e estabelecem vários resultados relacionados com a estrutura de soluçcãoes áotimas da relaxacçãao Lagrangeana. Juttner [40] provou a complexidade do Algoritmo LARAC. No artigo de Xiao et al. [64] foi apresentada a equivalância de certos algoritmos, simplesmente designados LARAC, os quais foram apresentados independentemente em alguns trabalhos anteriores [13, 33, 41]. Este artigo tambám apresenta um estudo algábrico que estabelece diversas novas propriedades de soluçcãao áotima e um novo algoritmo chamado LARAC-BIN baseado numa pesquisa binária.
Yamada et al. [66] apresentam um algoritmo baseado numa relaxaçao Lagrangeana para o Problema da Arvore de Suporte de Custo Maximo com Restriçães de Peso, o qual á semelhante ao Algoritmo LARAC-BIN descrito em [64] para o Problema CSP.
Amado e Barcia [7] apresentam uma relaxação para o Problema da Mochila Matroi-dal (Matroidal Knapsack), sendo casos especiais deste problema, o Problema Saco-mochila de Muáltipla Escolha e o Problema WMST, sendo este denominado pelos autores de Problema da Arvore de Suporte de um Grafo com uma Restrição de Capacidade.
Com o objetivo de obter solucoes aproximadas para o Problema WMST, na Secção 4.1 fazemos uma breve descrição da relaxação Lagrangeana para o problema. Nas duas secçcãoes seguintes (Secçcãao 4.2 e 4.3) descrevemos um algoritmo genáerico baseado na relaxaçcãao Lagrangeana, que denominamos de Algoritmo Lagrangeano Base para o Problema WMST, fazemos uma anáalise da complexidade e apresentamos a ideia geomáetrica do algoritmo. Este algoritmo descreve e uniformiza os passos comuns a todos os algoritmos e na Secçao 4.4 apresentamos vários algoritmos tendo todos como princápio o mesmo algoritmo base apresentado. Na Secção 4.5 descrevemos algumas experiâencias computacionais realizadas e apresentamos os resultados computacionais, onde se efetua uma comparaçcãao entre os vaários algoritmos, a nável de tempo e da qualidade das soluçcãoes aproximadas obtidas. Para finalizar o capátulo apresentamos uma sántese dos resultados computacionais obtidos.
74
Nesta secção, considera-se a aplicação da relaxação Lagrangeana ao Problema WMST, sendo esta uma técnica clássica usada como alternativa a relaxação de Programação Linear para calcular limites inferiores para o valor otimo e encontrar boas soluçães para Problemas de Otimizacão com Restricães.
Para obtermos a relaxacçãao Lagrangeana da formulaçcãao genéerica para o problema WMST que se encontra na parte introdutária do Capétulo 3, associamos um multiplicador de Lagrange A (A &gt; 0) à restriçao de peso (3.3) e incluémos essa restricão, a moda Lagrangeana, na funcao objetivo. Obtemos, deste modo o seguinte problema relaxado.
(WMSTx) :	— AW + min	(cj + Awij')xij
s.a. x G XT,
onde x = (xj) G R|A| e XT descrevem o involucro convexo das soluções inteiras do Problema MST. Para todos os multiplicadores nãao negativos A, as solucçãoes com estrutura em áarvore para este problema relaxado daão-nos limites inferiores para o valor oátimo, isto áe,
V(WMSTX) &amp;lt;ê(WMST).
O Problema relaxado WMSTx pode ser resolvido usando qualquer algoritmo polinomial conhecido para o Problema MST [6]. Se, para cada multiplicador A &gt; 0, definirmos os valores ponderados pxj = Cj + Awij associados a cada arco (i,j) G A e Tpx for a correspondente árvore de suporte ponderada ménima com custo C(Tpx) e peso W(Tpx), entao a funcão Lagrangeana pode-se escrever do seguinte modo
V(WMSTX) = — AW + P (Tpx),
onde P(Tpx) = C(Tpx) + AW(Tpx). Seja Tx* a arvore correspondente à solucão átima do Problema WMST, com custo C(Tx*) e peso W(Tx*), então consegue-se facilmente mostrar que o valor da relaxaçcãao Lagrangeana áe um limite inferior para o valor áotimo, isto áe,
ti (WMSTx) = — AW + P (Tpx)
&amp;lt;— AW + P (Tx*)
75
= -AW + C (Ta* ) + AW (TÀ*)
= C(TÀ*) + A(W(Ta*) - W)
&amp;lt;C (Ta* )
= í(WMST ).
Para obter o melhor limite inferior há que resolver o Problema Dual Lagrangeano, isto e, precisamos de maximizar a funçao $(WMSTa) para todo A &gt; 0, ou seja,
tf* := max tf (WMSTa)
s.a. A &gt; 0.
Seja A* o valor de A que maximiza tf(WMSTA).
De seguida apresentam-se duas propriedades da funcao tf (WMSTa).
Lema 4.1.
Para qualquer A &gt; 0, dtf(WMSTA) = w(Ta)-W e um subgradiente de tf(WMSTA),
dA
onde a arvore de suporte Ta corresponde a soluçao otima do problema relaxado WMSTa.
Lema 4.2.
Para qualquer A &gt; 0, tf(WMSTA) e
uma funcão linear por partes e concava.
Figura 4.1: Representação gráfica de fi(WMSTx) em função do valor de A.
76
A cada árvore de suporte T com custo C(T) e peso W(T), podemos fazer corresponder a funçáo linear d(A) = C(T) + A(W(T) — W) com A &gt; 0, a qual tem ordenada na origem C(T) e declive W(T) — W. Quando obtemos uma arvore não admissível, temos que W(T) &gt; W, o que corresponde a um declive positivo. No caso da árvore ser admissível, entao W(T) &amp;lt;W, ou seja, W(T) — W &amp;lt;0, o que corresponde a um declive negativo ou nulo. O gráfico da Figura 4.1, representa o inválucro superior de todas as retas correspondentes a todas as árvores de suporte do grafo G. Podemos observar que a funcão fiÇWMSTx) á linear por partes e concava.
A relaxacão Lagrangeana pode ser resolvida, na grande maioria das vezes, usando o Método do Subgradiente [59]. Este método começa por inicializar o multiplicador de Lagrange, Ao. Depois, iterativamente, resolve o Problema relaxado WMST\k, atualiza, em cada iteracao o multiplicador de Lagrange para Ak+i = max{0, Ak + skdk} usando a direção dk e o tamanho do passo sk e finalmente verifica se o critário de paragem á satisfeito.
Uma escolha apropriada para a direçao dk e para o tamanho do passo sk produz um máetodo convergente.
Para a direção dk podemos usar as ideias de Held, Wolfe e Crowder [36]
dk =	— W.
(w)eA
Como à solucão xk = (xj) do problema relaxado WMST\k, corresponde a arvore de suporte Tpxk, temos que ^2(ij)eA wijxkj á o peso dessa arvore. Assim, temos que
dk = W A) — W.
Podemos usar o tamanho do passo sk de acordo com [59]
=	C (Tw) — &amp;amp;(WMSTXk)
Sk	P (E(i,j)eA wijxkj — W)dk ’
= C (Tw) — P (Tpxk) + Ak W
Sk = P	(W (TpAk) — W )dk	.
77
Assim, em cada iteracao atualiza-se o multiplicador Ak e definem-se os valores ponderados = Cij + AkWij associados a cada arco (i, j) G A e obtím-se uma arvore de
suporte ponderada mínima TPXk
com valor ponderado P (Tpxk) = C (Tpxk) + Ak W (Tpxk).
4.2	Algoritmo Lagrangeano Base
Esta abordagem algorítmica determina sucessivamente árvores de suporte até encontrar o melhor valor da variavel dual Lagrangeana A. O objetivo do algoritmo é procurar melhores soluções admissíveis do que a correspondente soluçao da árvore Tw usando combinações lineares do custo e do peso das soluções das árvores Tc e Tw. As sucessivas árvores de suporte obtidas podem ser admissíveis ou nõo admissíveis. No caso da írvore obtida ser admissível atualiza-se o valor do limite superior (LS) para o custo, caso contrario, atualiza-se o valor do limite inferior (LI) para o custo.
Apresentamos de seguida, em forma esquematizada, o Algoritmo Lagrangeano Base (ALagB) para o Problema WMST.
Algoritmo Lagrangeano Base (ALagB) para o Problema WMST
Passo 1: Inicializações
Passo 1.1: Obter um limite inferiõr
Obter a írvore de suporte de custo mínimo Tc = (V, ATc).
Se W(Tc) &amp;lt;W, entao
Tc í a arvore correspondente a solucao ítima. STOP.
Caso contrario,
T = Tc.
Calcular C(Ts).
Passo 1.2: Inicializar õ intervalõ (quandõ aplicavel)
Inicializar o intervalo [l0,u0] e a írvore Tlo = Tc (obtida no Passo 1.1).
Calcular os valores ponderados pij = u0 wij + cij para cada arco (i, j) G A.
78
Obter a árvore de suporte ponderada mínima Tuo = (V, At ).
Se W(Tuo) &gt; W, entao
não existe solucão, STOP.
Caso contréario,
T = T
Calcular C(Ta) e P(Ta) e ir para o Passo 2.
Passo 1.3: Obter um limite superior
Obter a árvore de suporte de peso mínimo Tw = (V, ATw).
Se W(Tw) &gt; W, entao
nãao existe soluçcaão, STOP.
Caso contraério,
Calcular C(Ta) e P(Ta).
Passo 2: Obter uma nova árvore
Calcular os valores ponderados pij = awij + bcj para cada arco (i, j) G A.
Obter a arvore de suporte ponderada mínima Tp = (V, ATp) e calcular C(Tp), W(Tp) e P(Tp).
Passo 3: Atualização de limites
Se W(Tp) &amp;lt;W, entao
atualizar o LS, isto é, se C(Tp) &amp;lt;C(Ta) substituir Ta por Tp.
Caso contrério,
atualizar o LI, isto é, se C(Tp) &gt; C(Tp) substituir Tp por Tp.
Passo 4: Critário de paragem
Se |P(Ta) — P(Tp)| &amp;lt;tol, entao
Ta é a arvore correspondente à solucão aproximada, STOP.
Caso contréario,
ir para o Passo 2.
79
No Passo 1.1 é obtida a árvore de suporte de custo mínimo Tc. Se esta não verificar a restriçcãao de peso, entãao foi encontrado um limite inferior para o valor do custo e T/i = Tc. No caso de verificação da restricao de peso significa que foi encontrada a solução étima e o algoritmo termina. No Passo 1.3 é obtida a arvore de suporte de peso mínimo, Tw. Se esta não verificar a restricao de peso, entao não existe solucao e o algoritmo termina. Caso a restrição de peso seja verificada, então foi encontrado um limite superior para o valor do custo e Ta = Tw.
O Passo 1.2 sá é aplicável quando os limites inferior e superior forem inicializados tendo em conta o intervalo [l0,u0], onde a arvore correspondente a l0 é a árvore de suporte de custo ménimo (Tlo = Tc) obtida no Passo 1.1 e para obter a érvore de suporte correspondente a u0 é necessério calcular os valores ponderados pij = u0 Wj + Cij, para cada arco (i,j) G A, o parametro u0 depende do algoritmo utilizado e sera definido na préxima seccao. Se a érvore de suporte ponderada ménima Tuo verificar a restricao de peso é obtido um limite superior para o valor do custo e Ta = Tuo e neste caso vamos para o Passo 2. Caso contréario, nãao existe soluçcãao para o Problema WMST e o algoritmo termina.
No Passo 2 são determinados os valores ponderados pij = awij + bcj para cada arco (i,j) G A e é obtida a arvore de suporte ponderada ménima Tp. Os valores dos parámetros a e b que utilizamos para definir os valores ponderados pij vao depender do algoritmo utilizado e serao definidos na préxima secção. No Passo 3 atualizam-se os limites, isto é, no caso da restrição de peso ser verificada e o custo da érvore Tp nao ser superior ao custo da érvore Ta, atualizamos o valor do limite superior e subtituémos Ta por Tp. Caso a restricão de peso seja violada e o custo da érvore Tp não seja inferior ao custo da érvore Tp, atualizamos o valor do limite inferior e subtituémos Tp por Tp. Os Passos 2 e 3 são executados até que se verifique |P(Ta) — P(Tp)| &amp;lt;tol, e quando tal acontece o algoritmo termina, sendo Ta a érvore correspondente a solucao aproximada.
A complexidade do Algoritmo ALagB depende do algoritmo utilizado para a ob-tencçãao das sucessivas éarvores de suporte e do nuémero de éarvores que ée possével determinar.
Quanto ao algoritmo que determina as érvores de suporte, a sua complexidade é O(p(m,n)) [5], onde a funçao&amp;lt;p(m,n) = mlog(n) depende de duas variaveis, sendo elas o numero de arestas m = |E| e o numero de nodos n = |V| do grafo G = (V, E). No Passo 1 do Algoritmo ALagB, sãao obtidas duas éarvores e para a obtençcaão de cada
80
uma delas usamos um algoritmo que efetua O(^(m, n)) operações.
Se K for o numero total de arvores de suporte que se podem formar no grafo G, entõo o algoritmo vai terminar ao fim de O(log(K)) iterações, pois o numero de arvores de suporte a determinar no pior dos casos e proporcional a K. Portanto, os Passos 2, 3 e 4 do algoritmo obtêm-se fazendo O(log(K)) x O(^(m,n)) operações. Logo, no Algoritmo ALagB para obter os valores dos limites inferior e superior sao necessarias O(log(K) p(m,n)) operações.
4.3	Comportamento Geométrico do Algoritmo La-grangeano Base para o Problema WMST
Para estudar o comportamento geometrico do algoritmo descrito na secçcõao anterior consideramos um sistema de coordenadas cartesianas, onde o eixo horizontal representa os pesos e o eixo vertical os custos. Os pesos e os custos das arvores Tc e Tw podem ser representados como pontos com coordenadas A = (W(Tc),C(Tc)) e B = (W(Tw), C(Tw)) (ver Figura 4.2). A equaçao da reta AB é da forma aW + bC = d, onde a = C(Tw) - C(Tc), b = W(Tc) - W(Tw) e d = W(Tc)C(Tw) - W(Tw)C(Tc).
Figura 4.2: Representação geométrica dos pesos e dos custos das árvores Tc e Tw.
Como existe a restriçõo de peso, temos que introduzir na figura anterior a reta de equacõo w = W (apresentada a vermelho nas Figuras 4.3, 4.4 e 4.5). Dessa introduçõo
81
podem ocorrer três situações:
• A primeira situação ocorre quando a árvore Tw não satisfaz a restrição de peso e então nao ha solução para o Problema WMST (Figura 4.3).
Figura 4.3: Representação geométrica dos pesos e dos custos das árvores Tc e Tw e da reta w = W com W (Tw) &gt; W.
Note-se que no caso de nao existir nenhuma árvore com custo inferior a C(Tw) e W(Tw) = W, entao Tw á a arvore correspondente à soluçao átima.
• A segunda situaçao ocorre quando a árvore Tc satisfaz a restriçao de peso e entao concluímos que Tc á a árvore correspondente à soluçao otima (Figura 4.4).
82
Figura 4.4: Representação geométrica dos pesos e dos custos das árvores Tc e Tw e da reta w = W com W(Tc) &amp;lt;W.
• A terceira e Ultima situação ocorre quando não se verificam as condições anteriores (ver Figura 4.5). Nesta situação pretendemos obter uma arvore de suporte cujo valor de custo se aproxime do valor otimo. Para a obter associamos novos valores Pij a cada arco (i,j) G A e obtemos uma árvore de suporte ponderada mínima Tp = (V,ATp), onde W(Tw) &amp;lt;W(Tp) &amp;lt;W(Tc) e C(Tc) &amp;lt;C(Tp) &amp;lt;C(Tw).
Figura 4.5: Representação geomátrica dos pesos e dos custos das árvores Tc e Tw e da reta w = W, onde W(Tw) &amp;lt;W &amp;lt;W(Tc).
83
Se o ponto (W(Tp), C(Tp)) correspondente a arvore Tp pertence à reta AB, entõo isso significa que encontrémos a soluçao aproximada, que corresponde à érvore Tp se esta for uma érvore admissével, isto é, W(Tp) &amp;lt;W.
Se o ponto (W(Tp),C(Tp)) correspondente a érvore Tp nõo pertence a reta AB e a érvore Tp for admissível, entao substituémos Tw por Tp e obtemos um novo valor para o limite superior, caso contrario substituémos Tc por Tp e atualizamos o valor do limite inferior. Apéos termos atualizado um dos limites, repetimos o Passo 2 do Algoritmo ALagB, ou seja, voltamos a obter uma nova arvore de suporte ponderada ménima Tp.
Saliente-se que as sucessivas éarvores Tw que designamos no Algoritmo ALagB por Ta sao sempre arvores admisséveis, enquanto que as arvores Tc, que designamos no Algoritmo ALagB por Tp, sao sempre arvores nao admisséveis.
Recordamos que o objetivo é encontrar soluções admisséveis com custo inferior ao da érvore Tw.
4.4	Definiçcãao dos Valores Ponderados Utilizados no Algoritmo Lagrangeano Base para o Problema WMST
No Algoritmo ALagB os valores ponderados definidos no Passo 2 sõo da seguinte forma:
Pij awij + bcij
para cada arco (i, j) E A. Consoante os valores atribuídos aos parâmetros a e b assim vamos obter diferentes algoritmos. De seguida, discutimos diferentes formas de obtencçõao dos valores ponderados.
84
Algoritmo Lagrangeano 1 (Algl)
Neste algoritmo consideramos que os valores ponderados pij ((i,j) G A) sao caracterizados por associar o parametro a =1 — Yk para os pesos e o parametro b = Yk para os custos segundo o artigo [65], ou seja,
pij	(1	Yk )wij + Yk Cij
onde, o parametro Yk G [0,1] é obtido da seguinte forma:
W (Tp) — W (Ta)
C(Ta) — C(Tp) + W(Tp) — W(Ta) ’ Ya + Yb
se a iteracao k for émpar
se a iteracao k for par.
Neste algoritmo o Passo 1.2 não á necessário. Os valores de Ya e Yb sao inicializados a 0 e 1 respetivamente. Estes valores sao atualizados no Passo 3. O valor de Ya á atualizado para Yk quando a arvore Tp obtida verifica a restricão de peso. O valor de Yb á atualizado para Yk quando a árvore Tp obtida não verifica a restriçao de peso.
De seguida, apresenta-se uma descriçcãao do Passo 3 para este algoritmo cuja al-teraçcãao áe apenas a atualizaçcãao dos valores Ya e Yb.
Passo 3: Atualização de limites
Se W(Tp) &amp;lt;W, então
atualizar Ya := Yk;
atualizar o LS, isto é, se C(Tp) &amp;lt;C(Ta) substituir Ta por Tp.
Caso contrério,
atualizar Yb := Yk;
atualizar o LI, isto é, se C(Tp) &gt; C(Tp) substituir Tp por Tp.
Em particular, quando Yk = 1, Tp corresponde a Tc da MST, e quando Yk = 0, Tp corresponde a Tw da MSTW. A ideia deste algoritmo é encontrar um intervalo, o mais pequeno possível [Ya, Yb] C [0,1], tal que o peso da arvore Ta e menor ou igual a W e o custo da arvore correspondente à solução étima esteja entre o custo da arvore Tp e
85
o da arvore Ta. Os valores 7a e u, serâo obtidos usando o Método da Bissecção nas iterações pares.
Tendo em conta que os valores de P(Ta) e P(Tg) se aproximam, então temos,
.C /■. + (1 - 7fc)W /■. = 7fcC(Tg) + (1 - 7fc)W(Tg)
o que é equivalente a ter,
1 - 7k 	 C(Ta ) - C (Tg )
.	W(Tg) - W(Ta)'
Assim, o valor de Ak obtido nas sucessivas relaxacoes Lagrangeanas é dado por:
Ak —
1 - 7fe
7k
Para exemplificarmos os vérios algoritmos propostos ao longo desta seccão vamos considerar o Exemplo 2.1.
Exemplo 4.1.
Na seguinte tabela sumariamos os resultados da aplicação do Algoritmo Alg1 para o Exemplo 2.1.
c T)	W (Tg )	C (Ta)	W (Ta)	Ya	Yb	Yk	C (Tp)	W (Tp)	P (Ta)	P (Tp)	tf(Ak)
17	27	70	11	0	1	0,5	19	24	40,5	21,5	23
19	24	70	11	0	0,5	0,203	41	13	22,984	18,688	13,538
19	24	41	13	0,203	0,5	0,352	27	19	22,844	21,813	25,156
19	24	27	19	0,352	0,5	0,385	27	19	22,077	22,077	25,4
Tabela 4.1: Resultados da aplicação do Algoritmo Algl para o exemplo de 5 nodos.
A primeira coluna déa-nos os sucessivos valores dos limites inferiores obtidos para o valor do custo e a terceira coluna déa-nos os sucessivos valores dos limites superiores obtidos para o valor do custo. Os custos e os pesos das éarvores de suporte que sãao, sucessivamente, atualizadas encontram-se a negrito na tabela. O algoritmo usa 4
86
iterações do Passo 2 para obter a soluçao otima com custo 27 e peso 19. A arvore Ta e atualizada duas vezes, enquanto que a arvore Tp e atualizada uma so vez. O valor obtido atraves da relaxação Lagrangeana e de 25,4.
Algoritmo Lagrangeano 2 (Alg2)
Nos algoritmos descritos em [13, 64] aplicados ao problema do caminho mais curto com restricoes de peso, os valores ponderados de cada arco (i,j) E A sõo obtidos das seguintes formas:
Pij	awij + bcij ou Pij	Awij + cij
a
onde a = C(Ta) — C(T,), b = W(T,) — W(Ta) e A =	. Podemos ver em [64] que
estes valores ponderados sõao equivalentes. Nesta tese, para descrever um algoritmo aproximado para o Problema WMST vamos associar o parâmetro a = Ak aos pesos e b =1 aos custos,
pij	Akwij + cij,
onde Ak =
C (Ta) — cT ) W (T,) — W (Ta)
e k designa o numero da iteracõo.
Exemplo 4.2.
Na seguinte tabela sumariamos os resultados da aplicação do Algoritmo Alg2 para o Exemplo 2.1.
c (Tp)	W (Tp)	C (Ta)	W (Ta)	râ	C (Tp)	W (Tp)	P (Ta)	P (Tp)	
17	27	70	11	3,313	41	13	106,438	84,063	17,813
17	27	41	13	1,714	27	19	63,286	59,571	25,286
17	27	27	19	1,25	19	24	50,75	49	24
19	24	27	19	1,6	27	19	57,4	57,4	25,4
Tabela 4.2: Resultados da aplicaçao do Algoritmo Alg2 para o exemplo de 5 nodos.
87
A primeira coluna dé-nos os sucessivos valores dos limites inferiores obtidos para o valor do custo e a terceira coluna dé-nos os sucessivos valores dos limites superiores obtidos para o valor do custo. Os custos e os pesos das arvores de suporte que são, sucessivamente, atualizadas encontram-se a negrito na tabela. O algoritmo usa 4 iteraçoes do Passo 2 para obter a soluçao étima com custo 27 e peso 19. A érvore Ta é atualizada duas vezes, enquanto que a arvore Tp é atualizada uma sé vez. O valor obtido através da relaxacão Lagrangeana é de 25,4.
Algoritmo Lagrangeano 3 (Alg3)
Neste algoritmo os valores ponderados de cada arco (i,j) G A são obtidos como descritos na Seccao 4.1, ou seja, os parâmetros a e b são obtidos como no algoritmo
anterior, sendo	pij	Akwij + cij,
onde o multiplicador Xk é obtido tal como descrito no Método do Subgradiente.
O Metodo do Subgradiente é uma generalização do Metodo dos Gradientes, no qual o gradiente da função é substituédo por um subgradiente para obter uma nova direção de busca.
Método do Subgradiente
Passo 1: Inicializar o multiplicador de Lagrange
Seja Aq —
C(Ta) - CT) W T) - W
Passo 2: Resolver iterativamente o problema relaxado WMSTxk
Obter a arvore de suporte Tpxk tal que d(WMSTxk) = — AkW + P(Tpxk), onde
Ak
= max
0, Ak-1 + P
C(Ta) - P(TpX—) + A-W W(TpXk-i) - W
• Na direçao usar as ideias de Held, Wolfe e Crowder [36]
dk — W (Tpxk) - W.
88
C(Ta) - P(Tpxk) + XkW
Sk = P--;---;---;-----;----- com
k 1	(W(TpXk) - W)dk
0 &amp;lt;p &amp;lt;2.
Passo 4: Critério de paragem
Definido no Passo 4 do Algoritmo ALagB para o Problema WMST apresentado na Secção 4.2.
No Capítulo 3 usámos varias formulaçães para encontrar o valor da relaxação linear e para resolver o Problema WMST. A principal vantagem de utilizar o Método do Subgradiente para obter o valor da relaxaçao Lagrangeana comparando com a relaxação linear usando as formulacoes é a rapidez em termos de tempo computacional. A grande desvantagem reside na escolha do valor de p, a qual pode tornar o metodo mais lento e também piorar a qualidade do limite inferior obtido.
Exemplo 4.3.
Na seguinte tabela sumariamos os resultados da aplicacão do Algoritmo Alg3 para o Exemplo 2.1 para diferentes valores de p.
p	Iteraçães	N.Q Atualizacães Tc	N.Q Atualizacoes Tw	A	tf(A)
0,9	4	1	2	3,086	19,4
0,8	4	1	2	2,743	21,8
0,7	9	4	4	1,700	25,3
0,6	7	3	3	2,649	22,406
0,5	7	3	3	1,679	25,321
0,49	7	3	3	1,662	25,338
0,48	7	3	3	1,645	25,355
0,47	6	2	3	2,258	23,969
Tabela 4.3: Resultados da relaxação Lagrangeana aplicando o Algoritmo Alg3 para diferentes valores de p.
No Algoritmo Alg3 foram utilizados varios valores de p (Tabela 4.3). Neste exemplo, para valores de p préximos de 0,48 o valor da relaxação Lagrangeana aproxima-se do
89
valor da relaxacçõao linear (25,355 &amp;lt;25,4). Foram necesséarias seis iteracçõoes do Passo 2 para obter a solucõo étima com custo 27 e peso 19. As arvores Ta e Tp sõo atualizadas trêes vezes cada uma.
Algoritmo Lagrangeano 4 (Alg4)
Neste algoritmo para encontrar o valor do A étimo usamos a ideia da técnica de pesquisa binéria, apresentada em [64] para reduzir o intervalo [l0 ,u0]. Os valores ponderados sõao obtidos da mesma forma que nos Algoritmos Alg2 e Alg3, isto ée,
Pij	^kWij + Cij.
onde Ak iteração.
lk + uk
2
ou seja, Ak é o ponto médio entre lk e uk, sendo k o numero da
C (T ) _ C(T ) No Passo 1.2 o intervalo [l0, u0] é inicializado fazendo l0 = 0 e u0 = ——'—TTr/rT, . .
W _ W (Ta )
O valor uk é atualizado no Passo 3 quando a restriçao de peso for verificada e lk é
atualizado caso a restrição de peso não seja verificada.
De seguida apresentamos a descrição do Passo 3 para este algoritmo cuja Unica alteracao é na atualizaçao dos limites inferior e superior do intervalo [lk	].
Passo 3: Atualização de limites
Se W(Tp) &amp;lt;W, entao
atualizar o limite superior do intervalo uk := Ak;
atualizar o LS, isto e, se C(Tp) &amp;lt;C(Ta) substituir Ta por Tp.
Caso contrario,
atualizar o limite inferior do intervalo lk := Ak;
atualizar o LI, isto e, se C(Tp) &gt; C(Tp) subtituir Tp por Tp.
No artigo de Yamada et al. [66] e apresentado um algoritmo semelhante a este, mas para o Problema da Arvore de Suporte de Custo Maximo com Restricçõoes de Peso,
90
de paragem. Ao adaptar esse algoritmo para o Problema WMST ficamos com
dtf(WMSTÃ) dA
• a inicializacao do limite superior do intervalo u0 = —
7
• o criterio de paragem utilizado é |uk — | &amp;lt;tol em vez de |P(Ta) — P(Tp)| &amp;lt;tol.
Exemplo 4.4.
Na seguinte tabela sumariamos os resultados da aplicaçao do Algoritmo Alg4 para o Exemplo 2.1.
c T)	W T)	C (Ta)	W (Ta)	lk	uk	Ak	C (Tp)	W (Tp)	P (Ta)	P (Tp)	^(Ak)
17	27	70	11	0	5,889	2,944	41	13	102,389	79,278	20,389
17	27	41	13	0	2,944	1,472	19	24	60,139	54,333	24,889
19	24	41	13	1,472	2,944	2,208	33	16	69,708	68,333	24,167
19	24	33	16	1,472	2,208	1,84	27	19	62,444	61,965	25,160
19	24	27	19	1,472	1,84	1,655	27	19	58,469	58,469	25,344
Tabela 4.4: Resultados da aplicação do Algoritmo Alg4 para o exemplo de 5 nodos.
A primeira coluna da-nos os sucessivos valores dos limites inferiores obtidos para o valor do custo e a terceira coluna da-nos os sucessivos valores dos limites superiores obtidos para o valor do custo. Os custos e os pesos das arvores de suporte que são,
sucessivamente, atualizadas encontram-se a negrito na tabela. Para este exemplo, o C (T ) — C (T)
Algoritmo Alg4 usando a inicializacão l0 = 0 e u0 = W w(T ) ~ 5,8889 usa cinco iteracães do Passo 2 para obter a solução õtima com custo 27 e peso 19. A
arvore Ta e atualizada três vezes, enquanto que, a arvore T$ e atualizada uma sõ vez. O valor obtido pela relaxação Lagrangeana esta prõximo do valor da relaxação linear (25,344 &amp;lt;25,4).
Se usarmos a inicializaçõo proposta em [66] e adaptada para o Problema WMST,
dtf(WMSTÃ)	M . , . ,	,
isto e, u0 =--------------= 9 e o criterio de paragem |uk—lk | &amp;lt;0,001, sao necessarias
dA
catorze iterações do Passo 2 para obter a soluçao otima com custo 27 e peso 19. A
arvore Ta e atualizada nove vezes, enquanto que, a arvore Ts e atualizada cinco vezes. O valor obtido pela relaxação Lagrangeana esta muito prõximo do valor da relaxação linear (25,3998 &amp;lt;25,4).
91
Algoritmo Lagrangeano 5 (Alg5)
O algoritmo que apresentamos de seguida e baseado no artigo de Amado e Barcia [7]. Este algoritmo inicializa o intervalo [l0,u0] fazendo l0 = 0 e u0 = U, onde U := max(i,j)eA {cij,wij}, ou seja, o maximo valor entre os custos e os pesos associados a todos os arcos (i,j) G A do grafo G.
Iterativamente o intervalo [lk ,uk] e reduzido ate que uk — lk	e, consequente-
u2 l mente, é identificada a soluçao otima no intervalo reduzido. Fazendo a = Ak = k	Uk
e b = 1 o intervalo reduzido e obtido por comparacão dos valores de ã(WMSTlk), d(WMSTXk) e d(WMSTUk). Para simplificar a notaçao iremos usar d(lk), d(Ak) e d(uk) em vez de ã(WMSTík), ã(WMSTXk) e ã(W M STUk), respetivamente.
Inicialmente d(l0) = C(Tlo) = C(Tc), que corresponde ao custo da árvore de suporte de custo mínimo obtido no Passo 1.1 e o valor de d(u0) á obtido usando a árvore de suporte TU0 de valor ponderado mínimo P(TU0) (Passo 1.2). Comparando com o Algoritmo ALagB, o Passo 1.3 pode ser omitido e os Passos 3 e 4 irão sofrer modificaçães que passamos a descrever de seguida.
Passo 3: Atualização de limites
Se d(Ak) &gt; max {ã(lk),ã(uk)}, então
calcular Ak :=
lk + Ak
2
e Ak :=
Ak + uk
e obter •0(Ak) e ã(Abk).
2
Se ã(A&lt;k) &gt; ã(Ak), entao
atualizar o limite superior do intervalo uk := Ak e Ak := Ak;
atualizar o LS, isto á, se C(TXk) &amp;lt;C(Tuk) substituir Tuk por TXk.
Caso contrario,
se ã(Abk) &gt; ã(Ak), entao
atualizar o limite inferior do intervalo lk := Ak e Ak := Abk;
atualizar o LI, isto e, se C(Tlk) &amp;lt;C(TXk) substituir Tlk por TXk.
Caso contrario,
atualizar ambos os limites do intervalo lk := Ak e uk := Abk;
atualizar o LS, isto e, se C(TXk) &amp;lt;C(Tuk) substituir Tuk por TXk;
92
atualizar o LI, isto é, se C(Tlk) &amp;lt;C(TXk) substituir Tlk por TXk.
Caso contrério,
se d(lk) &amp;lt;d(Ak) &amp;lt;$(uk), então
atualizar o limite inferior do intervalo lk := Ak e Ak :=
Afc + Uk;
2 ’
atualizar o LI, isto é, se C(Tlk) &amp;lt;C(TXk) substituir Tlk por TXk.
Caso contréario,
atualizar o limite superior do intervalo Uk := Ak e Ak :=
lk + Ak;
2 ’
atualizar o LS, isto é, se C(TXk) &amp;lt;C(Tuk) substituir Tuk por TXk.
Passo 4: Critério de paragem
Se (Uk - lk) &amp;lt;Â, então
U 2
Se (W(Tuk) - W)(W(Tík) - W) &gt; 0, entao
seja T a arvore Tuk ou Tlk para a qual o max{d(lk),d(uk)} ocorre.
Caso contraério,
. m	A	C(Tuk) - C(Tik) , 1	, .	,
seja TAk , com Ak = W(T ) - W(T ) de valor mlnimo P(TXk )• Se W(TXk) &amp;lt;W, então
T = TXk.
Caso contréario,
T = Tuk.
A solução aproximada corresponde à érvore T, STOP.
Caso contréario,
ir para o Passo 2.
93
C(Tik) &amp;lt;^(WMST) &amp;lt;C(Tuk).
Se os declives de ambas as retas tâem o mesmo sinal, entãao o limite inferior para a solução ítima corresponde à arvore cujo valor da relaxação Lagrangeana í maior,
$(A*) = max{d(ík )-Muk)}.
Caso os declives tenham sinais contrarios, (A*,$(A*)) corresponde ao ponto de interseção destas duas retas. Para o obtermos calculamos um novo Ak, dado por:
Ak =
C (Tuk) — C T) W (Tík) — W (TUk)
que corresponde a abcissa do ponto de interseçao das duas retas. De seguida com este ponto de interseção das duas retas obtem-se uma nova arvore de suporte T\k. Se esta verificar a restricão de peso, então a solução aproximada corresponde à arvore T\k, caso contrario, a solução aproximada corresponde à arvore Tuk, uma vez que, neste caso a arvore Tuk verifica a restricão de peso.
Proposição 4.1.
O valor do multiplicador de Lagrange Ak e limitado
0 &amp;lt;Ak&amp;lt;
C (Tw) — C (Tc) W — W (Tw)
Demonstraçao.
Qualquer arvore de suporte admissável T verifica
C(Tc) &amp;lt;C(T) &amp;lt;C(Tw) e W(Tw) &amp;lt;W(T) &amp;lt;W &amp;lt;W(Tc).
A reta definida pelos pontos de coordenadas (W(Tw),C(Tw)) e (W(Tc),C(Tc)) tem declive m = W (y) - W^ &amp;lt;0 e equacão y = C (Tw) + m(x - W (Tw)).
Se o declive í negativo, temos que &gt; 0, dado que	—,, -.
W(Tc) - W(Tw)
Para a írvore ser admissível o seu peso tem de ser inferior ou igual a W, isto í, x &amp;lt;W, assim y = C(Tw) + m(x - W(Tw)) &gt; C(Tw) + m(W - W(Tw)). Alím disso, qualquer írvore admissível T deve ser tal que C(T) &gt; C(Tw) + m(W - W(Tw)). Como a írvore Tc í nao admissível, temos C(Tc) &amp;lt;C(Tw) + m(W - W(Tw)). Portanto,
&amp;lt;C(Tw) - C(Tc)	.	.	c &amp;lt;C(Tw) - C(Tc)
-m &amp;lt;W - W(Tw) ’ o que slgniflca' que &amp;lt;W - W(T.) ■
Logo, 0 &amp;lt;: &amp;lt;C w &gt; - C .
6 ’ “	W - W (Tw)
□
94
Exemplo 4.5.
Na seguinte tabela sumariamos os resultados da aplicação do Algoritmo Alg5 para o Exemplo 2.1.
lk	Uk	Ak	Ak	Ak	0(4)	0(«k)	0(Ak)	0(Ak)	^(Ak)
0	5,889	2,944	1,472	—	17	-0, 222	20,389	24,889	—
0	2,944	1,472	0,736	2,208	17	20,389	24,889	21,944	24,167
0,736	2,208	1,472	1,104	1,840	21,944	24,167	24,889	23,417	25,160
1,472	2,208	1,840	1,656	1,840	24,889	24,167	25,160	25,344	25,160
1.472	1,840	1,656	1,564	1,748	24,889	25,160	25,344	25,257	25,252
1,564	1,748	1,656	1,610	1,748	25,257	25,252	25,344	25,390	25,252
1,564	1,656	1,610	1,587	1,633	25,257	25,344	25,390	25,349	25,367
1,587	1,633	1,610	1,599	1,633	25,349	25,367	25,390	25,395	25,367
1,587	1,610	1,599	1,593	1,605	25,349	25,390	25,395	25,372	25,396
1,599	1,611	1,605	1,602	1,605	25,395	25,390	25,396	25,398	25,396
1,599	1,605	1,602	1,600	1,605	25,395	25,396	25,398	25,400	25,400
1,599	1,602	1,600	1,600	1,601	25,395	25,398	25,400	25,400	25,400
1,600	1,601	1,600	1,600	1,601	25,398	25,399	25,400	25,400	25,400
1,600 1,601
Tabela 4.5: Resultados da aplicação do Algoritmo Alg5 para obtenção do intervalo [lk,uk].
Para este exemplo de 5 nodos, o Algoritmo Alg5 usando a inicialização l0 = 0 e u0 = U =	{cij,wij} = 30 precisa de quinze iteracães e e necessario determi-
nar 38 arvores de suporte para obter a solução otima no intervalo [1,6; 1,601].

Tendo em conta a Proposição 4.1 verificamos que podemos utilizar para este exemplo uma nova inicialização do intervalo [l0, u0], fazendo l0 = 0 e u0 = C () T,,c)
W	W (Tw )
5,8889. Usando estes valores, sao precisas treze iteraçães e é necessario determinar 36 arvores de suporte para a obtencão do intervalo [1,5998; 1,6005] o qual, contem A* = 1,6.
Os limites inferior e superior para o valor otimo sao, respetivamente, C(Tlk) = 19 e C (TU,) = 27.
O valor obtido atraves da relaxacão Lagrangeana e igual ao valor da relaxação linear 25,4 usando qualquer uma das inicializaçães propostas.
95
Algoritmo Lagrangeano 6 (Alg6)
Devido às propriedades da convexidade da função Lagrangeana, os limites do intervalo [lk ,uk] podem ser atualizados tendo em conta os declives das retas. Assim, podemos simplificar o Algoritmo Alg5.
Se os declives das retas correspondentes a Xk e tám o mesmo sinal, então é atualizado o limite inferior do intervalo . Caso contario, se os declives das retas correspondentes a Xk e uk tám o mesmo sinal, então é atualizado o limite superior do intervalo uk. Caso um dos declives seja nulo, entao temos de atualizar ambos os limites inferior e superior do intervalo. De seguida apresenta-se o novo Passo 3 simplificado.
Passo 3: Atualização de limites
Se (W(TXk) — W)(W(Tik) — W) &gt; 0, entao
atualizar o limite inferior do intervalo, := Xk e Xk := k ;
atualizar o LI, isto é, se C(TXk) &gt; C(Tlk) substitui-se Tlk por TXk.
Caso contréario,
se (W(TXk) — W)(W(Tuk) — W) &gt; 0, então
atualizar o limite superior do intervalo, uk := Xk e Xk := ~~~2,—~’ atualizar o LS, isto é, se C(TXk) — C(Tuk) susbtitui-se Tuk por TXk.
Caso contraério,
atualizar ambos os limites do intervalo	:= —+—- e uk := k +—-;
22 atualizar o LS, isto é, se C(TXk) &amp;lt;C(Tuk) substituir Tuk por TXk;
atualizar o LI, isto é, se C(Tlk) &amp;lt;C(TXk) substituir Tlk por TXk.
O critéerio de paragem deste algoritmo seréa efetuado de acordo com o Passo 4 do Algoritmo Alg5.
96
Exemplo 4.6.
Na seguinte tabela sumariamos os resultados da aplicaçcãao do Algoritmo Alg6 para o Exemplo 2.1.
lk	Uk	Ak	W (Tik) — W	W (TUk) — W	W (TXk) — W	^(4)	^(Uk)	^(Ak)
0	5,8889	2,9444	7	—7	—7	17	—0, 2222	20,3889
0	2,9444	1,4722	7	—7	4	17	20,3889	24,8889
1,4722	2,9444	2,2083	4	—7	—4	24,8889	20,3889	24,1667
1,4722	2,2083	1,8403	4	—4	—1	24,8889	24,1667	25,1597
1,4722	1,8403	1,6563	4	— 1	—1	24,8889	25,1597	25,3438
1,4722	1,6563	1,5642	4	—1	4	24,8889	25,3438	25,2569
1,5642	1,6563	1,6102	4	—1	—1	25,2569	25,3438	25,3898
1,5642	1,6102	1,5872	4	—1	4	25,2569	25,3898	25,3490
1,5872	1,6102	1,5987	4	—1	4	25,3490	25,3898	25,3950
1,5987	1,6102	1,6045	4	—1	—1	25,3950	25,3898	25,3955
1,5987	1,6045	1,6016	4	—1	—1	25,3950	25,3955	25,3984
1,5987	1,6016	1,6002	4	—1	—1	25,3950	25,3984	25,3998
1,5987	1,6002	1,5995	4	—1	4	25,3950	25,3998	25,3978
1,5995	1,6002							
Tabela 4.6: Resultados da aplicação do Algoritmo Alg6 para obtenção do intervalo [lk, uk].
Na tabela encontram-se a negrito os declives com o mesmo sinal. Para este exemplo, no Algoritmo Alg6 usando a inicializaçao l0 = 0 e u0 = U = max^^ {cij,wij} = 30, sãao necessarias quinze iteraçcãoes e e necessario encontrar 18 arvores de suporte para obtençcaão da soluçcãao otima.

Tendo em conta a Proposição 4.1 verificamos que podemos utilizar para este exemplo uma nova inicializaçao do intervalo [l0, u0], fazendo l0 = 0 e u0 = , (.w) ___ . C
W - W (Tw) 5,8889. Usando estes valores, são necessarias treze iterações e obtem-se 16 arvores de suporte para obtenção do intervalo [1,5995; 1,6002] (Tabela 4.6) que contem o valor
A* = 1,6. Os limites inferiores e superiores para o valor otimo sao, respetivamente, C(Tek) = 19 e C(Tuk) = 27. O valor obtido pela relaxaçao Lagrangeana é de 25,4 usando qualquer uma das inicializaçães propostas.
97
Algoritmo Lagrangeano 7 (Alg7)
Este algoritmo tem por objetivo obter melhores limites inferiores. Portanto, em vez de considerar apenas a restricçaão de peso,
Wij Xij &amp;lt;W,
(W)€A
vamos introduzir a seguinte desigualdade véalida,
&amp;lt;|S| - 1,	(4.1)
(i,j)€S
designada de Desigualdade de Cobertura [4]. Observe-se que poderé ser utilizada qualquer outra desigualdade vélida. Adicionando a desigualdade (4.1) ao modelo genérico, obtemos a seguinte formulaçcãao:
(WMST-C) :	min	cjxj (í,j)eA	
	s.a. x G	
	Wij xij &amp;lt;W (í,j)eA	(4.2)
	xij &amp;lt;|S 1 — 1 (í,j)es	(4.3)
Onde x = (xj) G R|A| e descrevem o invólucro convexo das soluções inteiras do Problema MST. Associando à restrição de peso (4.2) um multiplicador de Lagrange A e associando à desigualdade válida (4.3) um outro multiplicador de Lagrange v, e incluindo na funcão objetivo uma penalização destas duas restricães, podemos definir o seguinte problema relaxado:
(WMST-Cav): — AW — v(|S| — 1) + min ^2 (co + Awj)xij + min	v xj
(í,j)eA	(í,j)es
s.a. x G .
Para todos os multiplicadores nãao negativos A e v as soluçcãoes para este problema relaxado dao-nos limites inferiores para o valor átimo. A proposição que se segue permite concluir que os limites inferiores obtidos atravás desta relaxacão Lagrangeana são melhores do que os obtidos com a relaxacão Lagrangeana descrita anteriormente.
98
Proposição 4.2.
Seja A &gt; 0 e v &gt; 0, então
V(WMSTX) &amp;lt;^(WMST-CAv) &amp;lt;’ã(WMST).
Demonstração.
Para demonstrar a primeira desigualdade consideramos a funçcaão dual Lagrangeana,
$(WMST-CAv) = -AW - v(|S|- 1) + min iV (cj + Awj')xij + v Xj xEXr 1	y	y
\(i,f)&amp;amp;A	(i,3)eS
= — AW — v|S| + v + P(Tx) + v min	xij
(i,j)es
Como minxeX^2(ij)es Xj &gt; |S| — 1, então obtemos,
^(WMST-Cav) &gt; -AW - v|S| + v + P(Tx) + v(|S| - 1)
= -AW + P (Ta)
= ■ã(WMSTx).
Logo, ■ã(WMSTx) &amp;lt;^(WMST-Cav).
Para provar a segunda desigualdade começcamos por notar que a desigualdade considerada é uma desigualdade valida para o Problema WMST e, portanto, a Formulação WMST-C e uma formulaçao para o problema. Observamos agora que, sendo WMST-CAv uma relaxacao linear, pela Teoria da Dualidade Lagrangeana, obtemos um limite inferior para o valor otimo do problema.
□
O objetivo agora e o de maximizar a funcão dual Lagrangeana $(WMST-CAv), ou seja, encontrar os valores de A e v que a maximizam.
Para obter o valor do parâmetro A, vamos começar por assumir que v e uma constante e vamos reduzir o intervalo [lk,uk] ate que uk -	~ • Para tal, ini-
u2	1
cialmente considera-se um valor pequeno para v, que designamos por ví = g, com U := max(ij)eA {aj,wij}, e considera-se o intervalo [l0,u0] inicializado com l0 = 0 e u0 = (Tw) TTr.c). Depois desta inicialização, vamos aplicar o Passo 3 do Algoritmo
W - W (Tw)
99
Alg6 para reduzir o intervalo [lk, uk]. Durante o processo iterativo de redução do intervalo [lk,uk], obtém-se uma desigualdade do tipo (4.3) quando obtemos uma érvore de suporte nao admissrvel Tlk. Para construir a desigualdade (4.3) é necessario optar pela escolha de uma ordem de inclusão do conjunto de arestas ETlk na desigualdade. Para escolher a ordenacçaão utilizamos os seguintes procedimentos:
Procedimento 1
Ordenar as arestas do conjunto ET^ por ordem crescente de custo.
Procedimento 2
Ordenar as arestas do conjunto ET^ por ordem decrescente de peso.
Procedimento 3
Cij
Ordenar as arestas do conjunto ETl por ordem decrescente de valor —.
k	wij
Utilizando os procedimentos anteriores forma-se um conjunto S C Et^ de arestas tal que a soma dos pesos das arestas contidas em S é superior a W, ou seja, verifica-se a desigualdade e&lt;=s we &gt; W, onde e = {i,j}. Logo, S é uma cobertura e também pode ser uma cobertura minimal, no caso de ao remover qualquer aresta da cobertura S, a soma dos pesos das restantes arestas contidas na cobertura for inferior ou igual a W, isto é, para toda a aresta f = {k,t} G S temos ^2e&amp;amp;s-{f} we &amp;lt;W.
Note-se que quando introduzimos uma desigualdade véalida ao Problema WMST, associamos à desigualdade (4.3) um multiplicador de Lagrange v e desta forma as arestas contidas em S vãao ser penalizadas na funçcaão objetivo.
No Capétulo 5 saão apresentadas desigualdades véalidas para o Problema WMST.
100
Exemplo 4.7.
w01 = 6 &amp;lt;20
w01 + w12 = 6 + 6=12 &amp;lt;20
W01 + W12 + W04 = 12 + 7 = 19 &amp;lt;20
W01 + W12 + W04 + W03 = 19 + 8 = 27 &gt; 20,
obtemos a desigualdade vélida x01 + x03 + x04 + x12 &amp;lt;3.
No caso de se efetuar o Procedimento 2, entõo ordenam-se as arestas por ordem decrescente de peso, ou seja, {0, 3}	{0, 4}	{0,1}	{1,2}.
Como,
w03 = 8 &amp;lt;20
W03 + W04 = 8 + 7 = 15 &amp;lt;20
W03 + W04 + W01 = 15 + 6 = 21 &gt; 20,
obtemos a desigualdade valida x01 + x03 + x04 &amp;lt;2.
Esta desigualdade também é obtida com a aplicaçõo do Procedimento 3.
Observe-se que a desigualdade obtida no Procedimento 2 e 3 ée mais forte do que a obtida no Procedimento 1.
Jé vimos como reduzir o intervalo do parâmetro A e como obter uma desigualdade valida. Decorre ainda a necessidade de determinar o valor do multiplicador de Lagrange v que faz com que $(WMST-Cav) seja méximo.
Proposicao 4.3.
Dado um intervalo [lk ,uk], o multiplicador de Lagrange v é dado por:
(C(TUk) - C(Tik))(W - W(TUk)) Sik(W - W(Tuk)) - W(Tuk) + W(Tik) ’
(4.4)
C (Ti.) + lk W (Tik) + vSik = C (Tu.) + UkW (Tu.) + vSu.,	(4.5)
101
onde Sik e Suk designam o número de arestas contidas em S na árvore Tlk e Tuk, respetivamente.
Quando a arvore obtida é admissível, nao é possível obter-se uma desigualdade válida, neste caso Suk = 0. Substituindo Suk = 0 na equacão (4.5) e tendo em conta que os valores de lk e uk se aproximam de Xk, obtemos
C(Tk) - C(Tuk) + vSik = Xk(W(Tuk) - W(Tk))•
Resolvendo a equação anterior em ordem a v obtém-se,
.. = C(TUk) - C(T,„) , X W u ) - W(Tk)
v =------------------+ Xk
(4.6)
S k
S k
Como W ) - W) &amp;lt;0, concluímos que estas retas tem declive negativo. S k
Necessitamos agora de encontrar retas cujo declive seja positivo para podermos fazer a respetiva interseção com as retas definidas pela equaçao (4.6).
Sabemos que em cada iteraçao o valor do limite superior pode ser atualizado LS = C(Tuk), portanto
WXk, v) &amp;lt;C(Tuk)	C(Tuk) + Xk (W(Tuk) - W) + v &amp;lt;C(TUk)
Resolvendo a inequaçao anterior em ordem a v obtemos,
v &amp;lt;Xk (W - W(Tuk))
(4.7)
onde W - W(Tuk) &gt; 0, ou seja, o declive das retas v = Xk (W - W(Tuk)) é positivo.
Em cada iteração vamos obter os sucessivos valores das intersecães das retas (4.6)
e (4.7). Resolvendo as equacães (4.6) e (4.7) em ordem a Xk, vem,
Xk =
Sek v - C (Tuk) + C(Tk) W (Tuk) - W (Tk)
(4.8)
Xk =
v
W - W (Tuk).
(4.9)
Igualando (4.8) e (4.9) vem,
S ik v - C(Tuk) + C (Tk) =	v
W (Tuk) - W (Tik)	W - W (Tuk)’
Resolvendo a equaçcãao anterior em ordem a v obtemos,
(C(Tu,) - C(Tlt)) (W - W(Tu,))
S,t (W - W (T.t)) - W(T„,) + W(Ti,,) •
(4.10)
□
102
E no Passo 4 que a seguir se descreve que se obtém o valor v do multiplicador de Lagrange e se calcula o maior valor das relaxacães das érvores TlkV e T„k v.
Passo 4: Critério de paragem
Se uk — 4&amp;lt;	, então
U 2
Obter v =
(C(T„k) — C(Tik)) (W — W(T„k))
Sik (W — W (T.k)) — W (T„t) + W (T,k) •
Seja T a érvore T„k,v ou Tlkv para o qual max{$(4, v),$(uk, v)} ocorre.
A solução aproximada corresponde a érvore T, STOP.
Caso contrério,
voltar ao Passo 2.
Exemplo 4.8.
Para exemplificar o Algoritmo Alg7 utilizamos o Exemplo 2.1. Vamos aplicar o Procedimento 2 para obtençcãao da desigualdade de cobertura.
Inicializacão de valores:
lo = 0,
70 — 17 Uo	.
53
y - 5,89
U = max{30,8} = 30
vi =
1
30.
e
Iteração 1: Inicializar Tlk e T„k.
Tik : C(Tt„) = 17, W(Tik) = 27 e Stk = 3.
Tu* : C t ) = 41 e W (T„„) = 13.
Desigualdade valida: x03 + x04 + x01 &amp;lt;2.
Intervalo obtido: [0; 2,9(4)].
Iteração 2: Atualizar Tlk.
T : C(7K) = 19, W(Ttk) = 24 e S,k = 4.
103
T„. : C(T„) = 41 e W (T„) = 13.
Desigualdade valida: x04 + x01 + x12 + x43 &amp;lt;3.
Intervalo obtido: [1,47(2); 2,9(4)].
Iteracão 3: Atualizar Tuk.
Ti, : C(Tk) = 19, W(Ttk) = 24 e Si, = 4.
Tuk : C(Tu,) = 33 e W(Tu,) = 16.
Intervalo obtido: [1,47(2); 2,208(3)].
Iteração 4: Atualizar Tuk.
Ti, : C(Ti.,) = 19, W(T,k) = 24 e Sik = 4.
Tuk : C(Tu, ) = 27 e W (Tu, ) = 19.
Intervalo obtido: [1,47(2); 1,840278].
Nas restantes treze iterações obtêm-se os mesmos resultados da Iteraçõo 4 com excecõo do intervalo reduzido que e sucessivamente atualizado. Quando se atualiza e adicionada a desigualdade valida x01 + x04 + x12 + x43 &amp;lt;3. O intervalo reduzido obtido e [1,594428; 1,595147].
No Passo 4 obtem-se v =
(27 - 19) (20 - 19)
4 x (20 - 19) - 19 + 24
8
9	W9.
Assim, ^(WMST-Cav) = max{26,266602; 26,293742} = 26,293742.
O valor da relaxaçao linear neste exemplo de 5 nodos e de 25,4 e o valor otimo é de 27 - 25,4
27, logo o gap e-27—~ x 100 = 5,93%. Aplicando o Algoritmo Alg7 com qualquer
um dos três procedimentos o valor da relaxaçõo Lagrangeana e de 26,293742. O gap 27 - 26,293742	q
passa a ser------—------ x 100 = 2,62% e obtemos assim uma reduçao de 3,31%.
27
104
Lagrangeanos e Resultados Computacionais
Nesta secção descrevemos algumas experiências computacionais realizadas com o objetivo de definir parêmetros e estratégias a serem adotadas para a utilização dos algoritmos Lagrangeanos expostos. Apresentamos igualmente os resultados computacionais obtidos quando utilizamos os algoritmos descritos ao longo deste capétulo para resolver o conjunto de instências geradas e descritas na Seccao 2.3 e fazemos uma comparacçãao entre os algoritmos em termos de tempo de execucçãao e de qualidade das solucçãoes aproximadas obtidas. Pretendemos tambéem averiguar se o valor obtido pela relaxaçcãao Lagrangeana dos diversos algoritmos corresponde ao valor da relaxacçaão linear do Procedimento P-WMTZ+C.
Os algoritmos Lagrangeanos foram implementados em C++ e todos os testes foram efetuados num Intel(R) Core(TM)2 Duo CPU (T7100) 2.00 GHz processador e 4Gb de RAM.
4.5.1	Exemplo Comparativo dos Algoritmos Lagrangeanos
Com o objetivo de comparar os diferentes algoritmos Lagrangeanos descritos ao longo deste capétulo elaborémos a Tabela 4.7, onde se resume a informaçao já dada para o exemplo de 5 nodos que foi utilizado ao longo deste capétulo para exemplificar o comportamento de cada um dos algoritmos Lagrangeanos. Para este exemplo com 5 nodos, a solucão otima tem custo 27 e peso 19 e o valor de W = 20.
	C (Ta)	W (Ta)	Iter.	Ak	lk	uk	^(Ak)	v	^(Ak, v)	Gap
Alg1	27	19	4	1,5970	-	-	25,400	-	-	5,93
Alg2	27	19	4	1,6000	-	-	25,400	-	-	5,93
Alg3	27	19	7	1,6450	-	-	25,355	-	-	6,09
Alg4	27	19	5	1,6550	1,4720	1,8400	25,344	-	-	6,13
Alg5	27	19	13	1,6000	1,6000	1,6010	25,400	-	-	5,93
Alg6	27	19	13	1,6000	1,5995	1,6002	25,400	-	-	5,93
Alg7	27	19	13	1,5948	1,5944	1,5951	-	0,89	26,294	2,62
Tabela 4.7: Comparação dos algoritmos Lagrangeanos no Exemplo 2.1.
105
Para o exemplo de 5 nodos considerado podemos observar que todos os algoritmos Lagrangeanos obtiveram a solução aproximada correspondente a solucão otima, isto é, foi obtida a arvore de suporte com custo 27 e peso 19. Os Algoritmos Alg3 e Alg4 são os que apresentam um valor de gap mais elevado. Nos Algoritmos Alg1, Alg2, Alg5 e Alg6 o valor obtido pela relaxaçcaão Lagrangeana e igual ao valor obtido pela relaxaçcãao linear. Como ja tinha sido observado, o Algoritmo Alg7 melhora o valor da relaxação Lagrangeana havendo uma reducão no gap de 3,31%.
4.5.2	Descrição dos Valores dos Parámetros Usados nas Experiências Computacionais Realizadas
Um parâmetro comum a todos os algoritmos Lagrangeanos apresentados e a tolerancia tol usada no criterio de paragem. Apos efetuarmos algumas experiências computacionais com varios valores de tol no intervalo [0,0001; 0,1] decidimos utilizar tol = 0,001.
Para a execução do Algoritmo Alg3 e necessario definir o parêmetro p e para tal, foram efetuadas diversas experiências com varios valores de p no intervalo ]0, 2[, nos trêes grupos de instêancias em estudo.
Nas instancias Quase Caminhos, ao diminuirmos o valor de p, a qualidade das soluçães obtidas melhora, isto é, os valores obtidos para o limite superior e para o valor da relaxacçaão Lagrangeana aproximam-se cada vez mais dos correspondentes valores obtidos atraves dos Algoritmos Alg2, Alg5 e Alg6.
No grafico da Figura 4.6 podemos observar que nas instências Quase Caminhos quanto mais pequeno e o valor de p maior e o tempo de execucçãao do algoritmo.
Com o objetivo de encontrar soluçcãoes de melhor qualidade e de forma rapida decidimos utilizar para as instências Quase Caminhos o valor p = 0,001.
106
Figura 4.6: Comparação dos tempos de execução em instâncias QC para diferentes valores de p.
Nas instancias Aleatórias e Euclideanas, verificamos que ao diminuirmos o valor de p para as instâncias de maiores dimensões, as soluções são de pior qualidade.
Para que o Algoritmo Alg3 seja convergente nos grupos de instâncias Aleatorias e Euclideanas é necessario adotar diferentes valores de p para as diferentes dimensães das instâncias. Apos diversas experiâncias decidimos utilizar os valores de p que se encontram nas Tabelas 4.8 e 4.9.
NA Nodos	10	20	40	60	80	100
R	0,001	0,0065	0,075	0,25	0,095	0,125
E	0,0001	0,0001	0,0001	0,0001	0,0001	0,04
Tabela 4.8: Valores de p utilizados no Algoritmo Alg3 nas instancias Aleatórias e Euclideanas de
10 a 100 nodos.
NA Nodos	150	200	300	400	500	1000
R	0,085	0,06	0,045	0,04	0,04	0,03
E	0,04	0,04	0,04	0,04	0,035	0,015
Tabela 4.9: Valores de p utilizados no Algoritmo Alg3 nas instancias Aleatórias e Euclideanas de
150 a 1000 nodos.
107
No Algoritmo Alg5 foram referidas, na Subsecção 4.4, as seguintes duas inicia-lizacães para o extremo superior do intervalo [l0,u0]:
• inicializacao proposta por [7] (Alg5IB): u0 = U = max^A {cj,wij};

nova inicializacao proposta na Subseccao 4.4 (Alg5IN): u0 =
C (Tw) — C (Tc) W — W (Tw)
Das experiências realizadas com ambas as inicializaçães e a tétulo de exemplo, cons-truémos a Tabela 4.10 indicando o numero médio de iteraçoes, o numero médio de arvores de suporte obtidas e o tempo de execução (em segundos) usando cada uma das inicializacães nas diferentes dimensães das instências Quase Caminhos (QC).
	Alg5IB				Alg5IN	
NA Nodos	NQ. Iterações	NQ. Arvores	Tempo (s)	NQ. Iteraçoes	NQ. Arvores	Tempo (s)
10	27,1	66,6	0,004	18,7	57,7	0,002
20	26	64,3	0,008	19	56,4	0,002
40	25	61,9	0,007	19,2	57,1	0,006
60	24,8	63,2	0,018	19,3	57,2	0,018
80	24	60,9	0,023	19,1	55,9	0,024
100	24	61,9	0,037	19,8	58	0,028
150	25	63,3	0,064	20,5	58,3	0,066
200	23	59,2	0,102	20,4	57	0,091
300	23	57,8	0,172	20	54,6	0,165
400	23	57,2	0,279	18,2	50,6	0,260
500	23	59,4	0,449	20	55,6	0,429
1000	22,2	61,4	1,745	21,6	59,6	1,708
Tabela 4.10: Comparação das duas estratégias de inicialização do Algoritmo Alg5 em instâncias QC.
108
Relativamente ao Algoritmo Alg7 foram propostos três procedimentos de ordenacão de arestas na Subseccão 4.4. Para todos os grupos de instências e usando todos os procedimentos de ordenacçãao de arestas, o valor obtido atraváes da relaxacçãao Lagrangeana aumenta comparativamente ao valor obtido pela relaxacçãao Lagrangeana dos outros algoritmos, sendo de realçcar que os valores mais práoximos da soluçcaão oátima sãao obtidos usando o Procedimento 2 em 85,26% das instancias Quase Caminhos (81 em 95 instências). No grupo de instências Aleatárias, o Procedimento 2 á melhor em 98,33% das instências (59 em 60 instências) e no grupo de instências Euclideanas, e melhor em 81,67% das instências (49 em 60 instancias). Os tempos de execução dos três procedimentos sãao muito semelhantes.
4.5.3	Estudo Comparativo dos Algoritmos Lagrangeanos e Resultados Computacionais
Nesta secçcãao apresentamos e comparamos os resultados computacionais obtidos atraves dos algoritmos Lagrangeanos descritos na Secção 4.2 para as instências geradas e descritas na Secçao 2.3.
Para avaliar a qualidade dos valores obtidos pelos algoritmos Lagrangeanos apresentados comparou-se o valor do limite superior obtido em cada algoritmo Lagrangeano com o valor otimo ou o melhor valor do limite superior obtido usando o Procedimento P-WMTZ+C descrito no Capátulo 3.
Sejam LS o valor do limite superior obtido para o valor do custo usando os algoritmos Lagrangeanos, 'â(WMSTx) o valor obtido pela relaxacao Lagrangeana usando os algoritmos Lagrangeanos e OPT o valor otimo (P(W MST)) ou o melhor valor obtido até ao momento através do Procedimento P-WMTZ+C. Como todos estes algoritmos obtem um limite superior (LS) e um limite inferior (LI) (valor da relaxação Lagrangeana), podemos considerar dois tipos de gap, o gap correspondente ao valor do limite superior que áe dado por
LS — OPT GaPLS = ---OpT  x 100,
a este valor passaremos a designar de gap do limite superior (GapLS) e o gap correspondente ao valor do limite inferior obtido atraváes da relaxaçcaão Lagrangeana que áe
109
dado por
GapR =
OPT _ tf(WMSTÃ) O PT
x 100,
a este valor passaremos a designar de gap da relaxacõo Lagrangeana (GapR).
Os testes desta subsecçcõao consistem no uso de todos os algoritmos apresentados
neste capétulo para obter soluções para as 215 instancias dos grupos Quase Caminhos, Aleatérias e Euclideanas e cuja descriçõo foi efetuada na Secçõo 2.3.
Vamos começar por efetuar uma analise geral aos algoritmos Lagrangeanos e em seguida passamos a estudar o comportamento em termos de qualidade e tempo de execuçcõao dos véarios algoritmos em cada grupo de instâancias em separado. Em forma de séntese, no final do capétulo sõao apresentadas as principais conclusoões obtidas.
Na Tabela 4.11 podemos observar em cada grupo de instâncias em estudo as percentagens de gaps nulos obtidas através do limite superior nos varios Algoritmos Lagrangeanos propostos. Na ultima linha da tabela encontram-se as percentagens de GapLS = 0 obtidas tendo em consideracõo todas as instâncias em estudo.
	Algl	Alg2	Alg3	Alg4	Alg5	Alg6	Alg7
QC	6,32	35,79	16,84	6,32	35,79	35,79	37,89
R	5,00	6,67	l,67	5,00	6,67	6,67	5,00
E	25,00	30,00	11,67	23,33	30,00	30,00	28,33
% GapLs = 0	ll,l6	26,05	11,16	10,70	26,05	26,05	26,05
Tabela 4.11: Percentagens de gaps nulos obtidas através do LS nos vários algoritmos por cada grupo de instâncias.
Em geral, dos véarios algoritmos em estudo, os Algoritmos Alg2, Alg5, Alg6 e Alg7 sao os que apresentam a maior percentagem de gaps nulos 26,05% (56 instâncias em 215). Nos grupos de instâncias Quase Caminhos e Euclideanas é onde se obtêm a maior percentagem de gaps nulos.
110
Na Tabela 4.12 podemos observar em cada grupo de instâancias em estudo, as percentagens de gap do limite superior que sãao inferiores aos gap da relaxaçcãao Lagrange-ana obtidos nos varios algoritmos Lagrangeanos propostos. Na ultima linha da tabela encontram-se as percentagens de gap do limite superior que sãao inferiores aos gap da relaxaçcaão Lagrangeana obtidas tendo em consideracçaão todas as instâancias em estudo.
	Algl	Alg2	Alg3	Alg4	Alg5	Alg6	Alg7
QC	54,74	75,79	67,37	97,89	75,79	75,79	76,84
R	16,67	20,00	11,67	13,33	20,00	20,00	18,33
E	38,33	40,00	25,00	31,67	40,00	40,00	35,00
% GapLs &amp;lt;GapR	39,53	50,23	40,00	55,81	50,23	50,23	48,84
Tabela 4.12: Percentagens de GapLS que sao inferiores aos GapR nos vários algoritmos por cada grupo de instâncias.
Observamos uma maior percentagem de GapLS inferior ao GapR nas instâncias Quase Caminhos, isto á, na maior parte destas instâncias o valor do limite superior obtido encontra-se mais práoximo do valor áotimo comparativamente ao valor do limite inferior. Já nos outros dois grupos de instâncias verifica-se um comportamento diferente, o que significa que a relaxaçcãao Lagrangeana nos grupos de instâancias Aleatoárias e Euclideanas apresenta soluçcãoes mais práoximas da soluçcãao áotima. Portanto, no grupo de instâncias Quase Caminhos á preferível encontrar um valor para o limite superior para o custo, pois este encontra-se mais práoximo do valor oátimo, enquanto que nos grupos de instâancias Aleatáorias e Euclideanas áe mais conveniente a escolha do valor do limite inferior para o custo dado pelo valor da relaxaçcãao Lagrangeana.
Os Algoritmos Alg2, Alg5 e Alg6 mostraram-se apropriados nos grupos de instâancias considerados para encontrar um valor muito práoximo do valor da relaxaçcãao linear, pois os valores obtidos atraváes da aplicaçcãao da relaxaçcaão Lagrangeana aproximam-se dos valores da relaxaçao linear obtidos atravás do Procedimento P-WMTZ+C descrito na Secçao 3.3.
Em 11,67% das instancias do grupo Aleatorias (7 em 60 instâncias) e em 25% das instancias Euclideanas (15 em 60 instancias), mais precisamente as instancias com mais de 300 nodos, o valor obtido atraváes da relaxaçcãao Lagrangeana encontra-
111
se mais proximo do valor otimo do que o valor da relaxacçãao linear do Procedimento P-WMTZ+C. Este facto ocorre, pois para instâncias do grupo Aleatórias e Euclideanas com mais de 300 nodos, a relaxacão linear do Procedimento P-WMTZ+C e interrompida quando o gap, em percentagem, entre duas solucoes consecutivas é inferior a 0,000001, mais do que 20 vezes ou quando o limite de tempo na introdução de cortes exceder 10000 segundos.
De seguida e para facilitar a analise, vamos comparar os algoritmos, em cada grupo de instâncias em estudo e para tal separamos as instâncias em 12 subgrupos (um por cada valor para o numero de nodos). Para analisar a qualidade das soluçcoães obtidas sãao apresentados para cada algoritmo os gap medios, em percentagem, do valor do limite superior, Gap^s, e do valor da relaxaçao Lagrangeana, GapR, e os respetivos desvios padrães (ver Tabelas 4.13, 4.14, 4.17, 4.18, 4.21 e 4.22). Para se poder avaliar a rapidez dos algoritmos Lagrangeanos sãao apresentados tambem para cada algoritmo, os valores dos tempos medios de execuçao (em segundos) nos varios subgrupos de nodos com os respetivos desvios padroes (ver Tabelas 4.15, 4.16, 4.19, 4.20, 4.23 e 4.24).
112
Instências Quase Caminhos
Atraves da observação das Tabelas 4.13 e 4.14 conclui-se que os Algoritmos Alg1 e Alg4 apresentam Gap^s e GapR muito elevados quando comparados com os correspondentes gaps dos restantes algoritmos. Os Algoritmos Alg2, Alg5 e Alg6 determinam as mesmas soluçães. Em relacão ao Algoritmo Alg3 podemos dizer que os GapR se aproximam dos GapR dos Algoritmos Alg2, Alg5 e Alg6 e os GapLS sao mais elevados do que os GapLS dos Algoritmos Alg2, Alg5 e Alg6 mas, apesar disso e, em geral, sao melhores do que os dos Algoritmos Alg1 e Alg4.
No grafico da Figura 4.7 podemos comparar os GapR do Algoritmo Alg7 com os do Algoritmo Alg6 (os Algoritmos Alg2 e Alg5 têm GapR igual ao Algoritmo Alg6).
10	20	40
NODOS
■ Alg6 «Alg7
NODOS
150	200	300
NODOS
400	500	1000
NODOS
Figura 4.7: Comparaçao dos GapR médios, em percentagem, entre os Algoritmos Alg6 e Alg7 nas instâncias QC.
O Algoritmo Alg7 e o que apresenta gaps da relaxacão Lagrangeana mais baixos em todas as instâncias. Em relação ao GapLS, o Algoritmo Alg6 apresenta gaps mais baixos do que o Algoritmo Alg7, em 7,37% dos casos (7 instancias em 95) e o Algoritmo Alg7 apresenta menores gaps em 4,21% dos casos (4 instâncias em 95). Nas restantes 84 instâncias os GapLS são iguais nos dois algoritmos.
113
114
	Alg1		Alg2		Alg3		Alg4		Alg5		Alg6		Alg7	
N» Nodos	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs
10	46,516	45,433	22,292	7,138	23,551	37,666	28,855	28,688	22,292	7,138	22,292	7,138	18,987	7,138
20	26,899	17,027	9,874	0,574	10,732	6,031	31,769	17,533	9,874	0,574	9,874	0,574	9,145	0,574
40	15,654	18,451	6,362	0,579	7,004	9,332	35,398	23,925	6,362	0,579	6,362	0,579	6,101	1,545
60	11,061	11,658	4,831	0,022	5,277	7,870	40,532	12,949	4,831	0,022	4,831	0,022	4,729	0,022
80	10,767	9,798	3,778	0,058	4,277	7,888	42,424	9,798	3,778	0,058	3,778	0,058	3,701	0,058
100	7,406	6,083	3,192	1,048	3,417	6,349	43,984	7,147	3,192	1,048	3,192	1,048	3,141	0,346
150	11,774	8,559	1,680	0,773	1,867	3,893	42,587	9,439	1,680	0,773	1,680	0,773	1,651	0,445
200	4,618	3,716	0,771	0,719	0,831	1,837	42,050	3,716	0,771	0,719	0,771	0,719	0,739	1,837
300	3,647	3,050	0,299	1,628	0,350	2,399	42,251	3,050	0,299	1,628	0,299	1,628	0,282	1,628
400	10,074	9,291	0,232	1,433	0,675	9,291	40,651	9,291	0,232	1,433	0,232	1,433	0,219	2,030
500	3,455	3,314	0,207	1,265	0,224	2,351	41,860	3,894	0,207	1,265	0,207	1,265	0,198	1,771
1000	3,598	0,292	1,757	0,292	1,806	0,292	44,696	0,292	1,757	0,292	1,757	0,292	1,754	0,292
Tabela 4.13: Gaps médios, em percentagem, obtidos pelos algoritmos Lagrangeanos nas instancias QC.
115
	Alg1		Alg2		Alg3		Alg4		Alg5		Alg6		Alg7	
N» Nodos	GapR	GapjRs	GapR	GapjLs	GapR	GapjLs	GapR	GapjLs	GapR	GapjLs	GapR	GapjLs	GapR	GapjLs
10	26,556	41,545	7,061	8,075	7,058	45,160	11,237	28,365	7,061	8,075	7,061	8,075	6,756	8,075
20	23,118	8,109	4,380	0,610	4,588	9,238	8,347	7,768	4,380	0,610	4,380	0,610	4,074	0,610
40	9,213	10,500	0,840	0,614	1,230	10,831	3,919	5,751	0,840	0,614	0,840	0,614	0,762	2,974
60	6,314	4,918	0,863	0,029	1,020	5,937	3,096	2,721	0,863	0,029	0,863	0,029	0,853	0,029
80	5,351	1,740	0,884	0,051	1,155	4,487	1,198	1,740	0,884	0,051	0,884	0,051	0,883	0,051
100	4,791	2,538	0,274	1,690	0,275	1,444	1,394	0,602	0,274	1,690	0,274	1,690	0,280	1,087
150	8,054	3,462	0,360	1,271	0,582	4,545	1,589	1,750	0,360	1,271	0,360	1,271	0,361	0,931
200	3,300	0,911	0,345	0,679	0,330	1,500	2,141	0,911	0,345	0,679	0,345	0,679	0,350	1,500
300	1,597	0,923	0,214	1,629	0,194	1,539	1,966	0,923	0,214	1,629	0,214	1,629	0,218	1,629
400	8,370	10,450	0,057	1,867	0,677	10,450	4,709	10,450	0,057	1,867	0,057	1,867	0,052	1,966
500	3,565	1,903	0,082	1,295	0,083	2,040	1,856	1,049	0,082	1,295	0,082	1,295	0,079	2,108
1000	1,704	0,652	1,115	0,652	1,157	0,652	3,638	0,652	1,115	0,652	1,115	0,652	1,116	0,652
Tabela 4.14: Desvios Padrões dos gap obtidos pelos algoritmos Lagrangeanos nas instâncias QC.
Na Tabela 4.15 encontram-se representados os tempos médios, em segundos, de execução dos varios algoritmos Lagrangeanos para as instancias Quase Caminhos e na Tabela 4.16 encontram-se os respetivos desvios padroes.
Da observação das tabelas referidas e do grafico da Figura 4.8 podemos constatar que de todos os algoritmos Lagrangeanos apresentados o mais lento e o Algoritmo Alg3.
I nstâncias QC de 10 a 150 nodos
0,14
■ Algl ■ Alg2 B Alg3 B Alg4 B Alg5 ■ Alg6 BAIg7
Instâncias QC de 200 a 1000 nodos
200nodos 300nodos 400nodos 500nodos 1000 nodos
BAIgl B Alg2 B Alg3 B Alg4 B Alg5 BAIg6 B Alg7
Figura 4.8: Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instâncias QC).
N» Nodos	Alg1	Alg2	Alg3	Alg4	Alg5	Alg6	Alg7
10	0,005	0,005	0,002	0,002	0,002	0,000	0,000
20	0,000	0,000	0,006	0,002	0,002	0,003	0,002
40	0,006	0,005	0,012	0,006	0,006	0,008	0,006
60	0,011	0,014	0,020	0,011	0,018	0,014	0,015
80	0,015	0,015	0,036	0,015	0,024	0,015	0,021
100	0,026	0,021	0,064	0,026	0,028	0,021	0,029
150	0,037	0,043	0,120	0,042	0,066	0,046	0,045
200	0,043	0,056	0,231	0,056	0,091	0,065	0,062
300	0,087	0,087	0,465	0,081	0,165	0,112	0,118
400	0,127	0,130	0,649	0,115	0,260	0,171	0,174
500	0,190	0,212	1,254	0,184	0,429	0,271	0,283
1000	0,742	0,801	5,622	0,689	1,708	1,076	1,232
Tabela 4.15: Tempos medios, em segundos, obtidos pelos algoritmos Lagrangeanos (instancias QC).
NA Nodos	Alg1	Alg2	Alg3	Alg4	Alg5	Alg6	Alg7
10	0,010	0,015	0,005	0,005	0,004	0,000	0,000
20	0,000	0,000	0,008	0,005	0,001	0,006	0,005
40	0,008	0,007	0,006	0,008	0,002	0,008	0,008
60	0,007	0,005	0,008	0,007	0,002	0,009	0,000
80	0,007	0,007	0,007	0,007	0,004	0,010	0,008
100	0,008	0,013	0,016	0,008	0,010	0,011	0,011
150	0,018	0,022	0,013	0,023	0,021	0,024	0,014
200	0,013	0,024	0,026	0,009	0,010	0,013	0,011
300	0,008	0,014	0,039	0,007	0,015	0,013	0,021
400	0,007	0,009	0,148	0,014	0,015	0,011	0,007
500	0,006	0,008	0,193	0,012	0,016	0,007	0,006
1000	0,028	0,014	0,100	0,034	0,079	0,036	0,047
Tabela 4.16: Desvios padrões dos tempos obtidos pelos algoritmos Lagrangeanos (instancias QC).
Os Algoritmos Alg3 e Alg5 sao os que, em geral, demoram mais tempo. Quanto ao Algoritmo Alg3, vimos na Subsecção 4.5.2 que é necessário escolher um valor de p adequado, este facto pode aumentar o tempo de execucão. Para explicar o motivo que leva o Algoritmo Alg5 a demorar mais tempo elaborámos o gráfico da Figura 4.9 que compara o numero médio de árvores de suporte obtidas usando cada um dos Algoritmos Alg5 e Alg6.
Figura 4.9: Número médio de árvores de suporte obtidas pelos Algoritmos Alg5 e Alg6 nas instâncias
QC.
Em geral, o tempo de execução do Algoritmo Alg6 é inferior ao tempo de execucão do Algoritmo Alg5, o que áe facilmente explicado pelo facto do nuámero máedio de áarvores formadas ao longo da execuçcãao do algoritmo diminuir para mais do que metade no Algoritmo Alg6 (Figura 4.9).
Instancias Aleatorias
Atraves da observacõo das Tabelas 4.17 e 4.18 conclui-se que, ao contrario do que acontecia para as instêancias Quase Caminhos, neste grupo de instêancias os Algoritmos Alg1 e Alg4, em geral, nao apresentam gaps muito elevados quer do limite superior quer da relaxaçcõao Lagrangeana, quando comparados com os restantes algoritmos.
Os Algoritmos Alg2, Alg5 e Alg6 determinam as mesmas soluções. Em relaçõo ao Algoritmo Alg3 podemos dizer que os GapR se aproximam dos GapR dos Algoritmos Alg2, Alg5 e Alg6 e os Gap^s sõo os piores de todos os algoritmos.
No grafico da Figura 4.10 podemos comparar os GapR do Algoritmo Alg7 com os do Algoritmo Alg6 (os Algoritmos Alg2 e Alg5 têm GapR igual ao Algoritmo Alg6).
■ Alg6 IAlg7
m ca
NODOS
■ Alg6 «Alg7 m
kD
150	200	300	400	500	1000
NODOS
Figura 4.10: Comparação dos GapR medios, em percentagem, entre os Algoritmos Alg6 e Alg7 nas instâncias R.
O Algoritmo Alg7 e o que apresenta GapR mais baixo em todas as instêancias Aleatórias. Os GapLS sõo iguais em todas as instâncias.
120
	Alg1		Alg2		Alg3		Alg4		Alg5		Alg6		Alg7	
N» Nodos	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs
10	15,055	3,840	15,055	3,840	15,612	7,713	16,780	3,840	15,055	3,840	15,055	3,840	12,542	3,840
20	4,196	6,208	4,079	5,285	7,304	22,292	6,350	14,955	4,079	5,285	4,079	5,285	3,477	5,285
40	1,788	2,743	1,769	2,743	3,549	8,828	1,889	2,743	1,769	2,743	1,769	2,743	1,556	2,743
60	0,622	1,312	0,589	1,312	0,818	2,775	0,622	1,312	0,589	1,312	0,589	1,312	0,529	1,312
80	0,401	1,505	0,387	1,505	1,255	5,343	0,447	2,242	0,387	1,505	0,387	1,505	0,328	1,505
100	0,072	0,547	0,069	0,547	0,250	3,581	0,070	0,547	0,069	0,547	0,069	0,547	0,054	0,547
150	0,064	0,787	0,063	0,787	0,132	2,068	0,065	0,787	0,063	0,787	0,063	0,787	0,055	0,787
200	0,044	0,533	0,040	0,533	0,299	4,111	0,046	0,704	0,040	0,533	0,040	0,533	0,034	0,533
300	0,016	0,567	0,016	0,567	0,057	1,811	0,020	0,713	0,016	0,567	0,016	0,567	0,013	0,567
400	0,003	0,145	0,003	0,145	0,030	0,930	0,004	0,145	0,003	0,145	0,003	0,145	0,003	0,145
500	0,003	0,220	0,003	0,220	0,060	1,445	0,004	0,275	0,003	0,220	0,003	0,220	0,002	0,220
1000	0,036	0,143	0,036	0,071	0,038	0,303	0,036	0,143	0,036	0,071	0,036	0,071	0,036	0,117
Tabela 4.17: Gap médios, em percentagem, obtidos pelos algoritmos Lagrangeanos nas instâncias R.
121
	Alg1		Alg2		Alg3		Alg4		Alg5		Alg6		Alg7	
N» Nodos	GapR	GapLs	GapR	GapjLs	GapR	GapjLs	GapR	GapjLs	GapR	GapjLs	GapR	GapjLs	GapR	GapjLs
10	4,034	3,430	4,034	3,430	3,950	8,592	3,811	3,430	4,034	3,430	4,034	3,430	3,685	3,430
20	0,365	4,670	0,312	5,006	3,816	28,414	3,873	17,027	0,312	5,006	0,312	5,006	0,142	5,006
40	0,183	1,676	0,182	1,676	3,073	12,972	0,267	1,676	0,182	1,676	0,182	1,676	0,209	1,676
60	0,117	1,074	0,077	1,074	0,205	3,226	0,090	1,074	0,077	1,074	0,077	1,074	0,066	1,074
80	0,029	1,320	0,037	1,320	1,862	8,213	0,077	1,645	0,037	1,320	0,037	1,320	0,034	1,320
100	0,047	0,264	0,045	0,264	0,294	3,901	0,046	0,264	0,045	0,264	0,045	0,264	0,042	0,264
150	0,035	0,684	0,035	0,684	0,123	1,619	0,036	0,684	0,035	0,684	0,035	0,684	0,034	0,684
200	0,019	0,379	0,019	0,379	0,418	5,374	0,025	0,515	0,019	0,379	0,019	0,379	0,018	0,379
300	0,001	0,621	0,001	0,621	0,043	1,256	0,005	0,692	0,001	0,621	0,001	0,621	0,002	0,621
400	0,003	0,098	0,003	0,098	0,054	1,417	0,003	0,098	0,003	0,098	0,003	0,098	0,003	0,098
500	0,002	0,136	0,002	0,136	0,106	1,861	0,002	0,223	0,002	0,136	0,002	0,136	0,002	0,136
10000	0,046	0,120	0,046	0,081	0,046	0,183	0,046	0,120	0,046	0,081	0,046	0,081	0,046	0,085
Tabela 4.18: Desvios Padrões dos gap obtidos pelos algoritmos Lagrangeanos nas instâncias R.
No gráfico da Figura 4.11 encontram-se representados os tempos médios, em segundos, de execucáo dos varios algoritmos Lagrangeanos para as instâncias Aleatórias. Estes tempos medios encontram-se registados na Tabela 4.19 e os correspondentes desvios padrões na Tabela 4.20.
I nstândas R de 10 a 150 nodos
0,12
BAIgl BAIg2 BAIg3 BAIg4 BAIgS ■ Alg6 BAIg7
I nstâncias R de 200 a 1000 nodos
s
i
■ Algl BAIg2 »Alg3 ■ Alg4 BAIg5 »Alg6 BAlg7
Figura 4.11: Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instâncias R).
Em relação ao algoritmo que demora mais tempo na obtenção das soluções aproximadas podemos observar atraves do grafico da Figura 4.11 dois comportamentos diferentes. Em instâncias com um numero de nodos inferior ou igual a 300, o Algoritmo Alg5 e o que apresenta maiores tempos medios de execucao, enquanto que para as restantes instâancias e o Algoritmo Alg3 que apresenta tempos mais elevados.
E de notar que todos os algoritmos com exceçcãao do Algoritmo Alg3 correm em menos do que 5 segundos. Se considerarmos apenas instâncias com menos de 200 nodos, estas correm, em media, em menos de 0,12 segundos.
N» Nodos	Alg1	Alg2	Alg3	Alg4	Alg5	Alg6	Alg7
10	0,000	0,000	0,000	0,000	0,001	0,001	0,001
20	0,000	0,000	0,000	0,000	0,003	0,002	0,002
40	0,003	0,015	0,006	0,003	0,012	0,008	0,006
60	0,009	0,006	0,003	0,006	0,020	0,015	0,016
80	0,012	0,012	0,015	0,009	0,034	0,028	0,024
100	0,021	0,015	0,034	0,018	0,060	0,045	0,031
150	0,037	0,046	0,078	0,052	0,114	0,062	0,095
200	0,078	0,081	0,190	0,075	0,205	0,149	0,121
300	0,208	0,162	0,315	0,215	0,463	0,275	0,303
400	0,318	0,302	1,120	0,309	0,699	0,446	0,436
500	0,502	0,480	1,812	0,477	1,101	0,661	0,686
1000	1,853	1,828	6,686	1,922	4,034	2,405	2,477
Tabela 4.19: Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instâncias R).
NA Nodos	Alg1	Alg2	Alg3	Alg4	Alg5	Alg6	Alg7
10	0,000	0,000	0,000	0,000	0,001	0,000	0,000
20	0,000	0,000	0,000	0,000	0,001	0,001	0,001
40	0,007	0,000	0,008	0,007	0,005	0,004	0,001
60	0,008	0,008	0,007	0,008	0,003	0,004	0,005
80	0,007	0,007	0,000	0,008	0,004	0,016	0,007
100	0,009	0,000	0,013	0,007	0,032	0,027	0,007
150	0,008	0,011	0,019	0,009	0,029	0,015	0,078
200	0,000	0,007	0,102	0,007	0,087	0,067	0,043
300	0,067	0,008	0,243	0,124	0,100	0,043	0,120
400	0,052	0,018	0,349	0,007	0,101	0,064	0,055
500	0,063	0,047	1,048	0,067	0,062	0,075	0,073
1000	0,035	0,063	1,931	0,147	0,423	0,074	0,142
Tabela 4.20: Desvios padrões dos tempos obtidos pelos algoritmos Lagrangeanos (instâncias R).
Para justificar o motivo que leva o Algoritmo Alg5 a demorar mais tempo elaborámos o gráfico da Figura 4.12 que compara o nUmero médio de árvores de suporte obtidas usando cada um dos Algoritmos Alg5 e Alg6.
NÚMERO MÉDIO DE ÁRVORES
■ Alg5 BAIg6
Figura 4.12: Número médio de árvores de suporte obtidas pelos Algoritmos Alg5 e Alg6 nas instâncias R.
Tal como vimos para o caso do grupo de instâncias Quase Caminhos, neste grupo de instâncias também, em geral, o tempo de execução do Algoritmo Alg6 é inferior ao tempo de execuçao do Algoritmo Alg5, o que é facilmente explicado pelo facto do numero medio de arvores formadas ao longo da execucao do algoritmo diminuir para metade no Algoritmo Alg6 (Figura 4.12).
Notamos que nas 2 instâncias de 1000 nodos do grupo de instancias Aleatórias em que nao tinha sido possível encontrar um valor para o limite superior atraves do Procedimento P-WMTZ+C, com a aplicaçao dos varios algoritmos Lagrangeanos foi possível obter um valor para o limite superior para o custo.
Instancias Euclideanas
Através da observaçao das Tabelas 4.21 e 4.22 conclui-se que ao contrario do que acontecia para as instâancias Quase Caminhos, neste grupo de instâancias os Algoritmos Alg1 e Alg4, em geral, naõo apresentam gaps muito elevados quer do limite superior quer da relaxacçõao Lagrangeana quando comparados com os restantes algoritmos tal como se verificou no grupo de instancias Aleatórias.
Os Algoritmos Alg2, Alg5 e Alg6 determinam as mesmas soluçoes. Em relaçõo ao Algoritmo Alg3 podemos dizer que os GapR e GapLS se aproximam dos GapR e GapLS dos Algoritmos Alg2, Alg5 e Alg6.
Figura 4.13: Comparaçõo dos GapR medios, em percentagem, entre os Algoritmos Alg6 e Alg7 nas instâancias E.
O Algoritmo Alg7 é o que apresenta GapR mais baixo em todas as instancias Euclideanas. Os GapLS sõo iguais exceto numa instância de 1000 nodos (E1000-4) onde o gap do Algoritmo Alg6 é mais baixo.
126
	Alg1		Alg2		Alg3		Alg4		Alg5		Alg6		Alg7	
N» Nodos	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs
10	9,035	5,274	9,035	5,274	9,039	5,274	10,816	5,274	9,035	5,274	9,035	5,274	7,237	5,274
20	2,938	2,250	2,888	2,250	2,888	2,250	6,058	11,323	2,888	2,250	2,888	2,250	2,425	2,250
40	0,894	1,959	0,894	1,959	0,894	1,959	0,969	1,959	0,894	1,959	0,894	1,959	0,758	1,959
60	0,399	0,890	0,390	0,747	0,394	0,747	0,428	1,039	0,390	0,747	0,390	0,747	0,357	0,747
80	0,239	0,576	0,231	0,576	0,232	0,576	0,239	0,576	0,231	0,576	0,231	0,576	0,209	0,576
100	0,104	0,706	0,091	0,563	0,120	1,378	0,127	1,480	0,091	0,563	0,091	0,563	0,078	0,563
150	0,043	0,284	0,040	0,284	0,058	0,628	0,041	0,284	0,040	0,284	0,040	0,284	0,035	0,284
200	0,013	0,402	0,012	0,402	0,064	1,416	0,012	0,402	0,012	0,402	0,012	0,402	0,009	0,402
300	0,011	0,280	0,011	0,219	0,014	0,280	0,012	0,280	0,011	0,219	0,011	0,219	0,009	0,219
400	0,103	0,000	0,103	0,000	0,115	0,500	0,103	0,000	0,103	0,000	0,103	0,000	0,102	0,000
500	0,106	0,034	0,106	0,000	0,114	0,572	0,106	0,108	0,106	0,000	0,106	0,000	0,105	0,000
1000	0,046	0,007	0,046	0,000	0,052	0,496	0,046	0,030	0,046	0,000	0,046	0,000	0,046	0,007
Tabela 4.21: Gap médios, em percentagem, obtidos pelos algoritmos Lagrangeanos nas instancias E.
127
	Alg1		Alg2		Alg3		Alg4		Alg5		Alg6		Alg7	
N» Nodos	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs	GapR	GapjRs
10	0,993	3,493	0,993	3,493	0,994	3,493	2,833	3,493	0,993	3,493	0,993	3,493	0,915	3,493
20	0,610	2,685	0,640	2,685	0,640	2,685	2,726	11,121	0,640	2,685	0,640	2,685	0,459	2,685
40	0,106	0,390	0,106	0,390	0,106	0,390	0,126	0,390	0,106	0,390	0,106	0,390	0,099	0,390
60	0,056	0,793	0,059	0,708	0,060	0,708	0,094	1,336	0,059	0,708	0,059	0,708	0,066	0,708
80	0,026	0,428	0,016	0,428	0,015	0,428	0,013	0,428	0,016	0,428	0,016	0,428	0,016	0,428
100	0,049	0,675	0,029	0,665	0,040	0,890	0,076	1,526	0,029	0,665	0,029	0,665	0,027	0,665
150	0,018	0,194	0,016	0,194	0,025	0,578	0,017	0,194	0,016	0,194	0,016	0,194	0,015	0,194
200	0,008	0,195	0,007	0,195	0,069	1,585	0,007	0,195	0,007	0,195	0,007	0,195	0,006	0,195
300	0,040	0,156	0,040	0,187	0,042	0,156	0,040	0,156	0,040	0,187	0,040	0,187	0,040	0,187
400	0,115	0,000	0,115	0,000	0,120	0,687	0,115	0,000	0,115	0,000	0,115	0,000	0,115	0,000
500	0,057	0,076	0,056	0,000	0,064	0,497	0,056	0,242	0,056	0,000	0,056	0,000	0,056	0,000
1000	0,041	0,016	0,041	0,000	0,040	0,439	0,041	0,050	0,041	0,000	0,041	0,000	0,041	0,016
Tabela 4.22: Desvios Padrões dos gap obtidos pelos algoritmos Lagrangeanos nas instâncias E.
No grafico da Figura 4.14 encontram-se representados os tempos médios, em segundos, de execução dos vérios algoritmos Lagrangeanos para as instancias Euclideanas. Estes tempos médios encontram-se registados na Tabela 4.23 e os correspondentes desvios padrãoes na Tabela 4.24.
Instâncias E de 10 a 150 nodos
1,4
1,2 „ 1,0 w un 0,8
o
£ 0,6
CD
0,4
0,2
0,0
	
	
	
	
	
1	
. 1 1		_■		!
10 nodos 20 nodos 40 nodos 60 nodos 80 nodos 100 nodos 150 nodos
■ Algl "Alg2 ■ Alg3 BAlg4 BAlg5 "Alg6 BAlg7
Instâncias Ede 200 a 1000 nodos
B
■ Algl «Alg2 BAlgS BAlg4 «Alg5 BAIgõ ■ Alg7
Figura 4.14: Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instancias E).
N» Nodos	Alg1	Alg2	Alg3	Alg4	Alg5	Alg6	Alg7
10	0,003	0,003	0,003	0,000	0,008	0,003	0,000
20	0,009	0,000	0,084	0,003	0,006	0,001	0,003
40	0,003	0,003	0,149	0,006	0,015	0,010	0,004
60	0,009	0,006	0,427	0,012	0,022	0,022	0,013
80	0,015	0,031	1,332	0,015	0,062	0,022	0,025
100	0,021	0,025	0,046	0,018	0,064	0,033	0,043
150	0,043	0,053	0,100	0,052	0,118	0,107	0,076
200	0,090	0,078	0,174	0,128	0,318	0,200	0,125
300	0,174	0,258	0,792	0,230	0,572	0,336	0,297
400	0,449	0,408	1,213	0,387	0,723	0,528	0,471
500	0,539	0,596	1,307	0,617	1,253	0,684	0,739
1000	2,084	2,130	7,531	2,187	4,234	2,669	2,722
Tabela 4.23: Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instâncias E).
N» Nodos	Alg1	Alg2	Alg3	Alg4	Alg5	Alg6	Alg7
10	0,007	0,007	0,007	0,000	0,015	0,004	0,000
20	0,008	0,000	0,171	0,007	0,004	0,001	0,004
40	0,007	0,007	0,032	0,008	0,007	0,006	0,004
60	0,008	0,008	0,107	0,007	0,005	0,013	0,004
80	0,011	0,035	0,271	0,000	0,038	0,002	0,004
100	0,009	0,009	0,025	0,007	0,024	0,006	0,019
150	0,007	0,014	0,045	0,014	0,024	0,060	0,016
200	0,030	0,000	0,058	0,094	0,094	0,089	0,031
300	0,007	0,099	0,500	0,074	0,118	0,091	0,076
400	0,072	0,086	0,790	0,071	0,052	0,133	0,051
500	0,101	0,093	0,800	0,106	0,117	0,056	0,101
1000	0,085	0,094	2,808	0,072	0,120	0,086	0,066
Tabela 4.24: Desvios padrões dos tempos obtidos pelos algoritmos Lagrangeanos (instâncias E).
Para justificar o motivo que leva o Algoritmo Alg5 a demorar mais tempo elaborámos o gráfico da Figura 4.15 que compara o nUmero médio de árvores de suporte obtidas usando cada um dos Algoritmos Alg5 e Alg6.
Figura 4.15: Número médio de árvores de suporte obtidas pelos Algoritmos Alg5 e Alg6 nas instâncias E.
O tempo de execuçao do Algoritmo Alg6 é inferior ao tempo de execução do Algoritmo Alg5 tal como ocorreu nos outros dois grupos de instâncias, o que se explica pelo nuámero máedio de áarvores obtidas no Algoritmo Alg5 ser mais do que o dobro do Algoritmo Alg6 (Figura 4.15).
4.5.4	Síntese dos Resultados Computacionais
Os resultados computacionais mostram que todos os algoritmos Lagrangeanos apresentados demoram menos de 13 segundos. Pelo que se conclui serem bastante réapidos na obtencçãao do valor da relaxaçcãao Lagrangeana e de um limite superior para o Problema WMST.
Os Algoritmos Alg2, Alg5, Alg6 e Alg7 revelaram ser bastante eficientes em todos os grupos de instêancias, pois com a aplicaçcãao destes algoritmos foram obtidas algumas soluçcoães éotimas e outras muito proéximas das soluçcoães éotimas. Destes o Algoritmo Alg5 tem a desvantagem de demorar mais tempo.
Os valores obtidos pela relaxacçãao Lagrangeana dos Algoritmos Alg2, Alg5 e Alg6 sãao iguais aos da relaxação linear do Procedimento P-WMTZ+C apresentado no Capítulo 3. O Algoritmo Alg7 obtém melhores valores da relaxacão Lagrangeana comparativamente à relaxação linear do Procedimento P-WMTZ+C.
A relaxação Lagrangeana nos grupos de instências Aleatórias e Euclideanas apresenta soluçcãoes mais proéximas da soluçcãao éotima, enquanto que no grupo de instêancias Quase Caminhos é preferível encontrar um valor para o limite superior para o custo, pois este encontra-se mais préoximo do valor éotimo.
132
Capítulo 5
Desigualdades Válidas
Com o propósito de fortalecer as formulações apresentadas no Capítulo 3, neste capítulo discutimos classes de desigualdades vólidas para o Problema WMST. As desigualdades vólidas podem ser incorporadas no modelo usando um algoritmo de planos de corte. Assim sendo íe de interesse desenvolver classes de desigualdades víalidas fortes de modo a tornarem o algoritmo de planos de corte eficiente.
Neste capítulo começamos por apresentar uma pequena introducõo sobre desigualdades vólidas, particularizando ao caso das desigualdades de saco-mochila. Na Secçõo
5.1	fazemos uma abordagem as conhecidas Desigualdades de Cobertura para o Problema Saco-mochila Binório adaptando-as para o caso do Problema WMST. Na Secçõo
5.2	apresentamos novas desigualdades vaólidas que consideram simultaneamente a estrutura de óarvore de suporte e a estrutura de saco-mochila. Designóamos estas novas desigualdades por Desigualdades de Cobertura Implícita. Tendo por base o processo usado para obter as conhecidas Desigualdades de Cobertura Estendidas, propomos na Seccõo 5.3 estender as Desigualdades de Cobertura Implícita, formando as Desigualdades de Cobertura Implícita Estendida. Na Secçõo 5.4 fortalecemos as desigualdades das secçcõoes anteriores usando a tóecnica de levantamento de varióaveis e apresentamos as Desigualdades de Cobertura Implícita Levantada. Por fim, na Secçõo 5.5 propomos uma generalizacçõao das desigualdades que podem fortalecer ainda mais as formulaçcõoes, sendo estas baseadas na fixaçõo de conjuntos de variaveis.
Dada uma desigualdade
nx &amp;lt;n0,	(5.1)
diz-se que e valida para um conjunto XWMST Ç RA se ela for verificada por todos os pontos x G XWMst .
Para o caso do Problema WMST, o conjunto das soluções admissíveis XWMST, pode ser visto como a intersecao de dois conjuntos conhecidos: XWMST = XT n XK, onde XT é o conjunto formado pelas árvores de suporte e XK é o conjunto saco-mochila binario definido pelos pontos x G R|A| tais que
WijXij &amp;lt;W,	(5.2)
e,
xij G {0,1},	(i,j) G A.	(5.3)
As desigualdades vélidas para XT e para XK sõo também vélidas para XWMST. Enquanto que a descricõo poliédrica do invélucro convexo de XT, PT = conv(XT), é bem conhecida (ver, por exemplo [45]), para a caracterizaçõo poliédrica do invélucro convexo dos conjuntos saco-mochila PK = conv(XK), so sao conhecidas descricões parciais. Este poliedro, é provavelmente, um dos poliedros que ocorre na Otimizaçao Combinatoria mais estudado.
Teoricamente as desigualdades validas mais fortes sõao aquelas que definem facetas de PK. Seja,
F = &amp;lt;x G Pk :	Kj Xij = no
[	(i,j)eA
A desigualdade (5.1) diz-se que define face de PK se satisfaz a igualdade do conjunto F (F = 0) e diz-se que define uma faceta de PK se define uma face de PK e se dim(F) = dim(PK) — 1, onde dim(PK) e a dimensao de PK.
5.1	Desigualdades de Cobertura (DC)
As Desigualdades de Cobertura foram introduzidas independentemente por Balas [10], Hammer et al. [32] e Wolsey [62] no contexto do Problema Saco-mochila Binério, mas podem ser aplicadas a qualquer Problema Linear Binaério.
Para escrever o que se segue usamos as referências [10, 32, 62, 63]. Dado o conjunto E, constituído por todas as arestas do grafo G = (V, E) define-se uma cobertura do seguinte modo.
Definição 5.1. Cobertura
O conjunto S C E é uma Cobertura, se a soma dos pesos das arestas contidas em S for superior a W, ou seja, se se verificar a seguinte desigualdade
&gt; W.
eeS
Definição 5.2. Cobertura Minimal
O conjunto S C E é uma Cobertura Minimal, se ao removermos qualquer aresta f da Cobertura S, a soma dos pesos das restantes arestas contidas na cobertura for inferior ou igual a W, ou seja,
&amp;lt;W.
ees\{/}
Proposiçao 5.1.
Se o conjunto S C E ée uma Cobertura entãao, a seguinte desigualdade
xe &amp;lt;|S| — 1,	(5.4)
eeS
é valida para o conjunto de soluções admisséveis XWMST e é chamada de Desigualdade de Cobertura (DC).
A prova da proposiçcaão anterior pode ser consultada em [63].
Se considerarmos duas Coberturas S1 e S2 com S1 C S2, em que S1 e uma Cobertura Minimal, as correspondentes desigualdades de cobertura sõo dadas por
J2 Xe&amp;lt;|S1|_ 1 e	52 Xe &amp;lt;|S2| _ 1.
eSSi	eSS2
Dado que S1 C S2 tambem se verifica que |S1| &amp;lt;|S2| e assim a primeira desigualdade e mais forte do que a segunda. Note-se que a desigualdade eSS2 xe &amp;lt;|S2| _ 1 pode ser obtida como a soma de ^2eSSí xe &amp;lt;|S1| _ 1 com as desigualdades xe &amp;lt;1, para todo e G S2\S1. Portanto, tal como observado em [10, 32, 62], as desigualdades de cobertura sõao mais fortes quando a cobertura considerada for a cobertura minimal.
Para qualquer subconjunto S C E, |S| = s, considera-se
Ps = Corojz G {0,1}s ^2 wexe &amp;lt;W
l	eSS
Se o conjunto S e uma Cobertura Minimal, entõao a desigualdade (5.4) define uma faceta de PS (ver, por exemplo, [10, 11, 32, 62]).
Exemplo 5.1.
Considere-se o Exemplo 2.1 de 5 nodos definido no Capétulo 2 onde o conjunto E = {{0,1}, {0, 2}, {0, 3}, {0, 4}, {1, 2}, {1, 3}, {1,4}, {2, 3}, {2, 4}, {3, 4}}.
Considerando, por exemplo, os seguintes conjuntos S1 = {{0, 1}, {0, 3}, {0, 4}, {1, 2}}, S2 = {{0,1},{0,4},{1, 2}, {3, 4}} e S3 = {{0,1},{0,4},{1,2}, {2, 3}}.
O conjunto S1 ée uma Cobertura, pois a soma dos pesos das arestas do conjunto S1 é maior do que 20 (w01 + w03 + w04 + w12 = 6 + 8 + 7 + 6 = 27 &gt; 20), mas nõo ée uma Cobertura Minimal dado que se removermos a aresta {1, 2} da Cobertura S1 a soma dos pesos das restantes arestas contidas na cobertura nõao ée inferior ou igual a 20 (w01 + w03 + w04 = 6 + 8 + 7 = 21 &gt; 20). Assim, x01 + x03 + x04 + x12 &amp;lt;3 é uma Desigualdade de Cobertura, onde a Cobertura S1 nõao ée minimal.
Os conjuntos S2 e S3 saõo tambéem Coberturas. A soma dos pesos das arestas do conjunto S2 é w01 + w04 + w12 + w34 = 6 + 7 + 6 + 5 = 24 &gt; 20 e para o conjunto S3 é w01 + w04 + w12 + w23 = 6 + 7 + 6 + 4 = 23 &gt; 20. Em ambas as Coberturas S2 e S3 se removermos qualquer aresta, a soma dos pesos das restantes arestas da cobertura seraé menor do que 20, logo ambos os conjuntos S2 e S3 sõao Coberturas Minimais.
Por conseguinte, dado que S2 e S3 são Coberturas Minimais, podemos construir as seguintes Desigualdades de Cobertura
Xoi + X04 + Xi2 + X34 &amp;lt;3 e	X01 + X04 + X12 + X23 &amp;lt;3,	(5-5)
que são válidas no conjunto das soluções admissíveis XWMST-
As coberturas podem assim incluir várias combinacães de variáveis, contudo algumas coberturas nao cortam a solução fracionária- Por exemplo, as desigualdades formadas pelas Coberturas S1 e S3 não cortam a solucao da relaxacão linear dada no Exemplo 3-2, isto á, se substituirmos nas desigualdades (5-5) o valor das variaveis da relaxacao linear obtemos 3 &amp;lt;3 e 2,2 &amp;lt;3, respetivamente, sendo 3 o valor do segundo membro das desigualdades, pelo que estas coberturas nãao cortam a solucçãao da relaxaçcãao linear-
Note-se que, com as arestas de cada uma das três coberturas apresentadas no Exemplo 5-1, é possável formar três arvores de suporte diferentes, mas como se pode ver no Exemplo 5-2 a seguir, nem sempre áe possável formar uma áarvore de suporte com as arestas de uma cobertura-
Exemplo 5.2.
Usando novamente o Exemplo 2-1 de 5 nodos podemos considerar a Cobertura S4 = {{0,1}, {0, 3}, {0, 4}, {3, 4}} (para o qual w01 + w03 + w04 + w34 = 6 + 8 + 7 + 5 = 26 &gt; 20)- Se representarmos num grafo estas arestas, podemos observar na Figura 5-1 que as arestas da Cobertura S4 naão formam uma áarvore de suporte-
	í -	1	9	8 -	1	15	7 16	
C =		- 30	16	
		-	10	
	1		-	
Figura 5-1: Representação das arestas da Cobertura S4 no grafo.
Com o ob jetivo de tornar as desigualdades de cobertura mais fortes, vamos introduzir uma nova classe de desigualdades véalidas que toma em consideracçãao propriedades dos conjuntos PT e PK simultaneamente. Para obter a nova classe de desigualdades vamos associar as desigualdades de cobertura alguma informação proveniente da estrutura em aérvore.
Deflnição 5.3. Cobertura Implícita
A um conjunto S C E, tal que as arestas de S não formam ciclos, chama-se Cobertura Implécita (CI) se para cada arvore de suporte T = (V, ET) tal que S C ET se verifica a seguinte desigualdade
W (T) =	We &gt;W.
Para verificar se o conjunto S define uma CI, consideramos as arestas do conjunto S e, sucessivamente, adicionamos arestas de E\S até formarmos uma érvore de suporte de peso ménimo, T. No caso da arvore de suporte T, que contém as arestas de S, não verificar a restriçao de peso, então o conjunto S é uma CI. Note-se que usamos a érvore T apenas para validar a Cobertura Implécita S.
Definição 5.4. Cobertura Implícita Minimal
O conjunto S C E, tal que as arestas de S não formam ciclos, é uma Cobertura Implícita Minimal, se ao removermos qualquer aresta f da Cobertura Implécita S, o peso da arvore de menor peso que contém as arestas de S \ {f} for inferior ou igual a W, ou seja,
We &amp;lt;W.
eeEr\{f }
As Desigualdades de Cobertura Implícita generalizam as conhecidas Desigualdades de Cobertura, nos casos em que as coberturas nãao formam ciclos.
Proposicao 5.2.
Se o conjunto S G E é uma CI, entao a desigualdade
&amp;lt;|S| - 1,	(5.6)
eeS
é valida para o conjunto de soluçães admisséveis Xwmst e é chamada de Desigualdade de Cobertura Implécita (DCI).
Demonstração.
Suponhamos que x* 6 Xwmst é uma soluçao que corresponde a uma arvore de suporte Tq (x* = 1 se j 6 Q e x* = 0 se j 6 Q) e nao satisfaz a DCI, então temos de mostrar que x* / Xwmst.
Se x* não satisfaz a DCI, então VegSx* &gt; |S|, logo |Q Gl S| = |S| e assim S G Q. Como S ée uma CI, entãao para validar a Cobertura Implécita S foi utilizada uma éarvore de suporte de peso ménimo, T, tal que S G ET.
Como	egQ w*x* = 12eQ w*	e Et w* &gt; W e assim x* / Xwmst.
□
Quando S é uma CI com um unico elemento, S = {e}, a DCI correspondente ó simplesmente xe = 0. Estas desigualdades particulares podem ser usadas num procedimento inicial de preprocessamento para reduzir o tamanho do modelo.
Exemplo 5.3.
No Exemplo 2.1 podemos considerar o conjunto S = {{0,1}, {0, 4}, {1, 2}}, cuja órvore correspondente estó representada pelas arestas a vermelho na Figura 5.2, onde podemos observar que as arestas de S nõo formam ciclos. Podemos adicionar a órvore a aresta de peso mínimo {1,3}. Desta forma completamos a órvore, obtendo a órvore de suporte T, onde ET = {{0,1}, {0, 4}, {1, 2}, {1, 3}} que corresponde a uma solucao nõo admissível com peso 21. Dado que o peso da arvore ó 21 &gt; 20, o conjunto S ó
uma CI. Se removermos qualquer aresta de S, o peso da árvore resultante é inferior a W = 20 e portanto o conjunto S define uma Cobertura Implécita Minimal.
C =
-1
8	7	\
15	16	
30	16	
-	10	
	-	/
( -	1	9
Figura 5.2: Arvore de suporte com custo 24 e peso 21.
Assim, usando as arestas do conjunto S podemos construir a seguinte DCI
Xoi + X04 + Xi2 &amp;lt;2	(5.7)
vélida para o conjunto XWMST das solucoes admisséveis. Se considerarmos a solução da relaxacão linear dada no Exemplo 3.2 verificamos que esta desigualdade corta a soluçao fracionéria (2,2 &gt; 2).
Comparação entre DC e DCI
De seguida apresentamos um exemplo para mostrar as diferençcas existentes entre a Desigualdade de Cobertura e a Desigualdade de Cobertura Implécita.
DC:
DCI:
Xoi + X04 + X12 + X34 &amp;lt;3.
X01 + X04 + X12 &amp;lt;2.
Figura 5.3: Desigualdade de Cobertura e Desigualdade de Cobertura Implícita.
Na Figura 5.3 podemos observar que nas DCIs apenas usamos a estrutura de érvore para validar a cobertura, nãao sendo o conjunto S constituédo por todas as arestas da éarvore de suporte , enquanto que nas DCs o conjunto S pode ou naão ser formado pelo conjunto de arestas da érvore de suporte (no Exemplo 5.2 podemos ver que a cobertura aé considerada nao era formada pelo conjunto de arestas da érvore de suporte). Ambas as coberturas representadas são minimais, a DCI é mais forte do que a DC, pois a desigualdade (5.7) e x34 &amp;lt;1 implicam a desigualdade x01 + x04 + x12 + x34 &amp;lt;3 obtida através da Cobertura S2 no Exemplo 5.1. Com este exemplo, constatamos que a estrutura em éarvore ée importante na construçcaão de desigualdades véalidas, permitindo a obtençcaão de desigualdades mais fortes que as desigualdades de cobertura.
5.3	Desigualdades de Cobertura Implícita Estendida (DCIE)
Segundo Balas [10] podemos obter desigualdades mais fortes se estendermos as desigualdades de cobertura. De modo semelhante podemos também obter desigualdades mais fortes se estendermos as desigualdades de cobertura implícita.
O seguinte resultado, pode ser consultado em [10, 62, 63], sendo a prova anéloga a da Proposicão 5.1 (ver [63]).
Proposição 5.3.
Seja S C E uma Cobertura e seja
S'	e G E \ S : we &gt; max{wf : f G S} j&gt;.
A seguinte desigualdade
y^Xe +	Xe &amp;lt;|S| - 1
eeS	eeS'
é valida para o conjunto de soluçães admisséveis XWmst e é chamada de Desigualdade de Cobertura Estendida (DCE).
O facto de estas desigualdades serem validas para XWMST e dominarem (se S1 = 0) as desigualdades de cobertura nãao garante que definam facetas.
Ha que ter atenção à forma de realizar a extensão, pois uma extensao da DCI pode conduzir a desigualdades nãao validas tal como podemos observar no seguinte exemplo.
Exemplo 5.4.
Neste exemplo as matrizes de pesos e custos saão dadas por:
	( - 6	7	8	7 A		-	1	9	8	7
	- 6 2 2		-	1	15 16
H =	- 4	5	e	C =	- 30 16
	- 5		- 10
--
O exemplo apresentado foi adaptado do Exemplo 2.1, com uma unica alteração na matriz de pesos, o peso da aresta {0, 2} alterou para w02 = 7. A soluçao da relaxaçao linear e a solução otima não sofrem alteracão (ver Exemplos 3.2 e 2.1, respetivamente).
Considere-se a DCI, x12+x24+x34 &amp;lt;2. Seja 0 = max{w12, w24, w34} = max{6, 5,5} = 6 e como w01 = 6 &gt; 0,w04 = 7 &gt; 0, w02 = 7 &gt; 0 e w03 = 8 &gt; 0, o conjunto S1 = {{0,1}, {0, 2}, {0, 3}, {0, 4}}. Logo, a desigualdade obtida e dada por
X12 + X24 + X34 + X01 + X02 + X03 + X04 &amp;lt;2,
que e uma desigualdade nãao valida. Tal acontece pois, por exemplo, a soluçcãao otima desta instencia do problema corresponde à arvore de suporte da Figura 2.2. Esta arvore não verifica a desigualdade acima, pois para esta arvore teremos x12 + x24 + x34 + x01 + x02 + x03 + x04 =1+0+1+1+0+0+0=3 &gt; 2, sendo 2 o valor do segundo membro da desigualdade.
A extensao que é efetuada das desigualdades de cobertura é baseada apenas nos valores dos pesos das arestas. Para estender as desigualdades de cobertura implícita, vamos ter de considerar naão séo os pesos das arestas mas, tambéem, a informaçcãao relativa à estrutura de arvore. Notamos que, mais uma vez, é necessario usar informacão relativa à estrutura da arvore para desenvolver desigualdades validas para este problema.
Proposiçao 5.4.
Seja S C E uma CI e seja
S'	e G E \ S : we &gt; max{wf : f G S} e as arestas de S U {e} formam ciclo j&gt;.
A Desigualdade de Cobertura Implícita Estendida (DCIE)
y^Xe + Xe &amp;lt;|S| — 1
eeS	eeS'
é valida para o conjunto de solucões admisséveis Xwmst.
Demonstração.
Suponhamos que existem conjuntos S e S' nas condicões dadas na Proposicõo 5.4. Seja x* G XWMST uma soluçõo que corresponde a uma arvore de suporte, T, e que nao satisfaz a DCIE, isto é,
y^ Xe + y^ Xe &gt; |S|.
eeS	eeS'
Seja S = {j G S : x* = 1} e S' = {j G S' : x* = 1}. Entao V,. S S- x* = |£| + |S'|. Por construçao do conjunto S', na solucao x* a soma de variáveis fixas a um (nos conjuntos S e S') nao pode exceder |S| e, portanto, |S + |S'| = |S|. Seja ainda Et = {j G E : x* = 1} o conjunto de arestas da arvore T que nao satisfaz a DCIE e R = Et\(S U S'). Considere-se o grafo conexo S U T. Como S G S e os elementos de S formam ciclos com os elementos de S, a érvore de suporte deste grafo que contém o conjunto Sé T' tal que ET/ = S U R e
12 wjxj = H wj &gt;22 wj &gt; W
j.E	j.SuS^UR	j.SuR
onde a primeira desigualdade resulta de |S?| + |S' | = |S| e da definicao dos pesos de S' e a segunda desigualdade resulta da suposiçõo de que S e uma CI. Logo x* G XWMST, o que contradiz a suposicçõao inicial.
□
Vamos tentar estender a DCI x01 + x04 + x12 &amp;lt;2 obtida no Exemplo 5.3. Se considerarmos as arestas que formam ciclo com as arestas da CI, ou seja, as arestas {1,4}, {0, 2} e {2,4} (ver Figura 5.4) nenhuma tem peso superior a 7 (sendo 7 = max{w01, w04, w12}) pelo que nõo e possiVel obter uma DCIE para este exemplo.
6
Figura 5.4: Ciclos formados com as arestas da Cobertura Implícita S do Exemplo 5.3 .
Assim, quando o conjunto S1 = 0, temos apenas uma DCI. De seguida apresentamos um exemplo em que S' = 0.
Exemplo 5.5.
Considere-se o Exemplo 5.4 e a DCI, x01 + x04 + x12 &amp;lt;2. A aresta {0, 2} forma ciclo com as arestas da CI e w02 = max{w01, w04, w12} = 7, logo S' = {{0, 2}}. Incluindo esta variável correspondente a esta aresta na DCI obtemos a DCIE
X01 + X04 + X12 + Xo2 &amp;lt;2,
que á válida para o conjunto XWMST das soluções admissáveis.
5.4	Desigualdades de Cobertura Implícita Levantada (DCIL)
As desigualdades discutidas nas três secções anteriores podem ser fortalecidas atravás da aplicacõo de uma tácnica designada por levantamento (lifting). Este processo á efetuado por introducõo de novas variáveis na desigualdade ou pela modificacao de coeficientes existentes na desigualdade que permitam fortalecer a desigualdade. Gomory [22] foi o primeiro a utilizar a tácnica de levantamento.
Ao adicionarmos variáveis ao lado esquerdo da desigualdade de cobertura implícita obtem-se a chamada Desigualdade de Cobertura Implácita Levantada.
Definição 5.5. Desigualdade de Cobertura Implícita Levantada
Dada uma DCI egSXe &amp;lt;|S| — 1, a seguinte desigualdade válida
Xe +	PeXe &amp;lt;|S| — 1,
egS	egE\S
com e &gt; 0, para todas as arestas e G E \ S, é chamada de Desigualdade de Cobertura Implícita Levantada (DCIL).
As Desigualdades de Cobertura Implícita Estendida, abordadas na seccão anterior, são casos particulares das Desigualdades de Cobertura Implícita Levantada em que apenas efetuamos o levantamento de algumas variéveis, tendo essas variéveis coeficiente um.
Para incluir outras variaveis na desigualdade vélida com o objetivo de a fortalecer, podem ser encontradas na literatura duas técnicas: a técnica de levantamento sequencial de variáveis e a técnica de levantamento simultaneo de variaveis. Nesta tese apenas se aborda a técnica de levantamento sequencial onde os coeficientes &gt;, são introduzidos um a um de forma sequencial e sendo a sequência de levantamento das variaveis prée-estabelecida.
Vamos de seguida ver como determinar os coeficientes das variáveis a efetuar levantamento.
Dada a DCI ^egSxe &amp;lt;|S| — 1 e a DCIL ^egSxe + ^egR fieXe &amp;lt;|S| — 1, onde R Q E \ (S U {f}) é o conjunto de variéveis que jé foram sujeitas a levantamento, podemos fazer o levantamento da variavel Xf, com f G E \ (S U R), calculando o coeficiente fif tal que 0 &amp;lt;fif &amp;lt;g(S, R,fi), onde
g(S, R, fi)	= min &amp;lt;|S|	— 1 — ^2 Xe	22 ^Xe	: x G Xwmst, Xf =	1 &gt; .	(5.8)
l	egS	egR	)
Caso o problema de minimização seja inadmissível atribuiremos a g(S, R, ) o valor zero.
Proposição 5.5.
Dada a DCI ^2e&amp;amp;s xe &amp;lt;|S| — 1 e a DCIL	ees xe + Px &amp;lt;|SI - 1, onde
R Ç E \ (SU{f}) e o conjunto de variaveis que ja foram sujeitas a levantamento, então
^Xe +	fieXe + Pf Xf &amp;lt;|S| — 1,	(5.9)
ees	eeR
e valida para o conjunto das solucães admisséveis Xwmst se Pf &amp;lt;g(S, R,P). Demonstração.
Se Xf = 0, temos que a desigualdade (5.9) e a DCIL que é valida para o conjunto das soluçoes admisséveis XWMST. No caso em que Xf = 1 na desigualdade (5.9) ficamos com
Pf &amp;lt;|S| — 1 —	Xe — ^2
ees	eeR
pelo que a sua validade para o conjunto das soluçães admisséveis Xwmst resulta da prépria definição da funçao g(S, R,P).
□
Exemplo 5.6.
Consideremos a DCI x01 + x04 + x12 &amp;lt;2 obtida no Exemplo 5.3. Para fazer o levantamento da variével x03 calcula-se o seu coeficiente P03 da seguinte forma:
P03 = min{2 — Xoi — X04 — X12 : X G Xwmst,Xo3 = 1} = 1.
Usando o levantamento sequencial exato para o célculo dos restantes coeficientes verificamos que estes sãao todos nulos. A Desigualdade de Cobertura Implécita Levantada ée dada por:
X01 + X04 + X12 + x03 &amp;lt;2.
Proposição 5.6.
Se Pe e inteiro para todo e G R, entao g(S, R, P) em 5.8 é inteiro.
Demonstração.
Admitamos que o conjunto das soluçães admissáveis do problema de minimização considerado em 5-8 não á vazio- Se as variáveis desse problema são binárias (inteiras) e os coeficientes da funçao objetivo, os valores dos fie,e G R, sao inteiros, então o seu valor oátimo tem de ser inteiro-
□
Note-se que diferentes sequêencias de levantamento de variáaveis podem produzir diferentes DCILs- Tal tambám se verifica com as Desigualdades de Cobertura Levantadas (ver Balas [10] e Wolsey [62])-
Exemplo 5.7.
Neste exemplo as matrizes de pesos e custos sãao dadas por:
	( -	7	7	5	5 A		( - 1	9	8	7 \
	- 5	8	5		-	1	15 16
H =	- 6	7	e	C =	- 30 16
	- 5		- 10
\ - / \ - /
Consideremos W = 20 e a DCI, x01 + x02 + x03 &amp;lt;2- Se pretendermos efetuar o levantamento das variáveis x04 e x12, o calculo dos seus coeficientes pode ser efetuado segundo duas sequêencias diferentes- Podemos calcular primeiro o coeficiente da variáavel x04 e depois o da variavel x12 e fazemos,
^04 = min{2 - X01 - X02 - X03 : x G Xwmst, X04 = 1} = 1.
^12 = min{2 - X01 - X02 - X03 - X04 : x G Xwmst, X12 = 1} = 0.
Deste modo obtáem-se a seguinte DCIL
x01 + x02 + x03 + x04 &amp;lt;2-
Se calcularmos primeiro o coeficiente da variavel x12 e depois o da variável x04 fazemos,
^12 = min{2 - xoi - X02 - X03 : x G Xwmst, X12 = 1} = 1.
v, = min{2 - xoi - X02 - X03 - X12 : x G Xwmst, Xo4 = 1} = 0.
Usando esta segunda sequência obtemos a DCIL
x01 + x02 + x03 + x 12 &amp;lt;2-
Verificamos assim que utilizando diferentes sequências de levantamento de variáveis á possível obter diferentes Desigualdades de Cobertura Implícita Levantada.
Gerar DCILs usando o levantamento sequencial exato envolve a resolução de muitos subproblemas o que pode ser computacionalmente dispendioso. Entao, uma questão que surge é como calcular os coeficientes &gt;, de tal forma que nao se torne computacionalmente dispendioso, ou seja, procuram-se métodos mais rápidos e simples pois, o céalculo de forma eficiente de coeficientes ée um elemento crucial para o uso com sucesso de DCILs.
Observemos que em vez de obter o valor átimo de g(S,R,fi) podemos usar uma relaxação de g(S, R, ^). Testamos duas relaxaçães, a relaxação linear e a relaxaçao La-grangeana onde o conjunto Xwmst é substituído pelo conjunto de solucoes admissíveis da sua relaxacão linear, XL:
gL(S, R,fi) = min &amp;lt;|S| - 1 - y^ xe - y^ ¡xe : x G XL, xf = 1
l	egS	eSfí
Caso o problema de minimização seja inadmissível atribuiremos a g(S, R, ) o valor zero.
De testes computacionais realizados com os grupos de instancias Quase Caminhos, Aleatárias e Euclideanas verificámos que o uso da relaxacao linear para determinar os coeficientes de forma sequencial torna-se bastante lento. Deste modo, no Capátulo 6 vamos apresentar um algoritmo heurístico para o cálculo dos coeficientes de levantamento usual, down-lifting e up-lifting baseado em relaxação Lagrangeana.
Exemplo 5.8.
Dada a DCI x01 + x04 + x12 &amp;lt;2 obtida no Exemplo 5.3. Podemos efetuar o levantamento das variaveis usando o levantamento sequencial aproximado baseado na relaxaçõo linear ou na relaxaçõo Lagrangeana. O coeficiente ^03 e obtido da seguinte forma:
^03 = min{2 _ x04 _ #01 _ ^12 : x G XL, x03 = 1} = 0,5
e os restantes coeficientes sõo todos nulos. Assim, a DCIL é dada por:
x01 + x04 + x12 + 0,5x03 &amp;lt;2.
Se arredondarmos o valor do coeficiente da variavel x03 para 1, usando a Proposicçõao 5.6, obtemos a mesma desigualdade que obtivemos usando o levantamento sequencial exato (ver Exemplo 5.6).
5.5	Desigualdades obtidas por Fixação de Variáveis
Quando se introduzem desigualdades levantadas naõo existem conjuntos de variaveis fixas à priori. Contudo, podem ser criadas novas classes de desigualdades de levantamento generalizadas derivadas do procedimento usual de levantamento, onde o levantamento das variaveis é efetuado fixando à priori o valor de conjuntos de variaveis. Nesta tese utilizamos trâes estrategias diferentes de fixacçaõo de variaveis que originam trâes tipos de desigualdades. Na primeira começcamos por fixar apenas um conjunto de variaveis a um, na segunda apenas um conjunto de variaveis a zero e por ultimo fixamos dois conjuntos de variaveis em simultâaneo, um conjunto de variaveis fixas a zero e um conjunto de variaveis fixas a um. Uma questao importante é a escolha do conjunto ou conjuntos de variaveis a fixar à priori.
5.5.1	Desigualdades de Cobertura Implícita Levantada por Down-Lifting (DCILDL)
Para obter Desigualdades de Cobertura Implícita Levantada através do designado Down-Lifting é necessério começar por fixar um conjunto de variéveis a um. Designamos por Ei o conjunto de variéveis a fixar a um e por XE1 o conjunto restrito definido da seguinte forma
XEi = Xwmst n {x : Xf = 1, f G Ei} ,
onde as variaveis f G Ei encontram-se fixas a um, Xf = 1. Notamos que o conjunto X E
é uma restricao do conjunto XWMST.
De seguida vamos definir uma cobertura implécita para o conjunto restrito XE1. Vamos assumir XE1 = 0.
Definição 5.6. Cobertura Implícita para o conjunto restrito XE1
O conjunto S G E\E1, cujas arestas de SUE1 nao formam ciclos, é uma Cobertura Implícita para o conjunto restrito XE1, se para cada érvore de suporte T = (V, ET) tal que S G Et e E1 G ET se verifica a seguinte desigualdade
W (T) =	we &gt;W.
Para verificar que S G E \ E1 é uma CI para o conjunto restrito XE1, construímos uma sub-aérvore com as arestas do conjunto S e com as arestas do conjunto E1, e sucessivamente, adicionamos arestas de Ef = E\(S U E1) à sub-érvore até formarmos uma érvore de suporte de peso mínimo, T, contendo as arestas dos conjuntos S e E1. No caso da aérvore de suporte T, nõao verificar a restricçõao de peso, entõao S ée uma CI para o conjunto restrito XE1.
Proposição 5.7.
Se S C E \ E1 é uma CI para o conjunto restrito XE1, então a Desigualdade de Cobertura Implícita
xe &amp;lt;|S| - 1
eeS é valida para o conjunto restrito XE1.
Demonstração.
Seja E1 o conjunto de variéveis fixas a 1 e x* G XE1 = XWMSTC{x : Xf = 1, f G E1} uma solucao que corresponde a uma érvore de suporte, Tq (xe = 1 se e G Q e xe = 0 se e / Q), notamos que as arestas de E1 estao na arvore Tq .
Suponhamos que a solucao x* correspondente à érvore Tq não satisfaz a DCI, entao J2egS xe &gt; |S|, logo |Q CS| = |S| e assim S G Q. Contudo S é uma CI para o conjunto restrito XE1, para validar a Cobertura Implécita S foi utilizada uma arvore de suporte de peso mínimo T, contendo arestas de S e de E1, ou seja, S U E1 C ET. Como
Wexe =	We &gt;	We &gt; W.
eeQ	eeQ	eeET
Assim x* / XWMSt , logo x* / XE1.
□
Observação 1.
A DCI para o conjunto restrito XE1 não tem de ser necessariamente valida para Xwmst. A desigualdade vélida é obtida apenas quando se faz o levantamento das variaveis do conjunto E1 (xe, e G E1).
Exemplo 5.9.
Considere-se o Exemplo 2.1 de 5 nodos, onde os valores de cada variével na solucão da relaxaçao linear (ver Figura 3.5) sao os seguintes: x01 = 1; x04 = 0,2; x12 = 1; x13 = 0,8; x34 = 0,8 e x43 = 0,2 (restantes variéveis com valor nulo).
Seja EX = {{0,1}, {1, 2}} o conjunto de variáveis fixas a um. As arestas de EX tomam o valor um na solução da relaxação linear e não pertencem à árvore de suporte de peso mánimo (ver Figura 2.3).
De seguida, ordenam-se as restantes arestas não fixas a um, ou seja, as arestas de E\EX. Considere-se, por exemplo, a seguinte ordenacao:
{0, 4}	{3, 4}	{1,3}	{0, 3}	{2, 4}	{2, 3}	{0, 2}	{1, 4}.
Para formar a DCI para o conjunto restrito XE1 = XWMST C {xe : x0X = xX2 = 1} considere-se a aresta {0, 4} e com esta aresta forma-se uma arvore de suporte de peso mánimo que contenha as arestas de EX, a qual se encontra representada na Figura 5.5.
	í -	1	9 - 1	8 15	7 &gt; 16	
C =		-	30	16	
			-	10	
				-	/
Figura 5.5: Arvore de suporte com custo 24 e peso 21.
Como W(T) = 21 &gt; 20, obteve-se uma arvore de suporte não admissável e S = {{0, 4}} á uma CI para o conjunto restrito XE1, então a DCI obtida á x04 &amp;lt;0, a qual á valida para o conjunto restrito XE1. Notamos que as arestas {0, 2}, {0, 4}, {1,3} e {1,4}, formam uma arvore de suporte com peso 14 e custo 47, portanto uma solucão admissável de Xwmst, e na qual x04 = 1 o que evidencia o facto da desigualdade x04 &amp;lt;0 não ser valida para Xwmst.
De uma forma genárica, se considerarmos que Ef = E \ (S U EX) e R Ç EX U Ef á o conjunto de variáaveis que jáa foram sujeitas a levantamento, para calcular os coeficientes das variáveis de (EX U Ef )\R resolve-se o seguinte subproblema:
Pt = min &amp;lt;|S |- 1 -	xe -	¡3e xe -	pe(1 - xe) : xGX (t), (5.10)
eES	e&amp;amp;RQEf	e&amp;amp;RQEt
onde X(t) é definido de uma das seguintes formas:
X(t) = |x G XWMST : xe = 1,e G E1 \ (R U {t}),xt = ü},t G E1 \ R. (5.11)
X(t) = |x G XWMST : xe = 1,e G E1 \ R,xt = 1} ,t G Ef \ R.	(5.12)
Nestes casos, se X(t) = 0 atribuímos ao coeficiente o valor zero (fit = 0). Para efetuar o chamado down-lifting, ou seja, o levantamento das variaveis fixas a um, usamos o conjunto definido em (5.11). Neste caso, estamos a atribuir o valor zero à variável xt,t G E1 \ R da qual se esta a fazer o down-lifting e as restantes variaveis de E1 (E1 \ (R U {t})) das quais ainda nãao efetuíamos o levantamento tomam o valor um.
Para efetuar o levantamento das variaveis de Ef, ou seja, o chamado levantamento usual usamos o conjunto definido em (5.12). Neste caso, estamos a atribuir o valor um à variavel xt, t G Ef \ R, da qual se esté a fazer o levantamento e atribuímos também o valor um as variaveis fixas a um das quais ainda nao efetuámos o levantamento (E1 \ R).
Apéos o levantamento sequencial de todas as variéaveis do conjunto R obtemos uma Desigualdade de Cobertura Implícita Levantada por Down-Lifting.
Proposição 5.8.
Dada a CI	e&amp;amp;s xe &amp;lt;|S| - 1 para o conjunto restrito XE1, Ef = E \ (S U E1) e
R G E1 U Ef, a seguinte desigualdade valida
^xe +	ex, +	^e(1 - xe)&amp;lt;|S|- 1.
eES	eeRCiEf	i:^Jl^'El
é chamada de Desigualdade de Cobertura Implícita Levantada por Down-Lifting (DCILDL) e é valida no conjunto das solucães admissíveis Xwmst, onde os coeficientes fie são obtidos sequencialmente resolvendo o subproblema (5.10).
A prova desta proposiçao é aníloga à prova da Proposicão 5.5.
No caso do conjunto E1 = 0, ou se todos os coeficientes correspontentes as variíveis fixas a um forem nulos, entãao a desigualdade anterior ée uma simples DCIL.
Exemplo 5.10.
Considere-se a DCI x04 &amp;lt;0 valida para o conjunto restrito
XE1 = XWMST n {xe : x01 = x12 = 1},
obtida no Exemplo 5.9. Para efetuar o levantamento das variáveis de E1 podemos comecçar por calcular sequencialmente os coeficientes associados a cada uma das variaéveis fixas a um, isto ée,
An = min{-xo4 : x G Xwmst,xoi = 0,xi2 = 1} = -1;
^12 = min{1 - xo1 - xo4 : x G Xwmst, #12 = 0} = -1.
Apéos o céalculo dos coeficientes das variaéveis fixas a um obtéem-se a seguinte desigualdade
x04 + x01 + x 12 &amp;lt;2.
De seguida para tornar mais forte a desigualdade anterior efetua-se o levantamento das variaveis de Ef = E \ (S U E1) = {{0, 2}, {0, 3}, {1, 3}, {1, 4}, {2, 3}, {2, 4}, {3, 4}}, usando o levantamento sequencial usual, ou seja, calculam-se da seguinte forma os coeficientes das variaveis a efetuar o levantamento
^14 = min{2 - x01 - x04 - x12 ^02 = min{2 - xo1 - xo4 - ^12 ^23 = min{2 - xo1 - xo4 - ^12
/2i = min{2 - x01 - x04 - x12 ^03 = min{2 - xo1 - xo4 - ^12
x G xwmst,x14 = 1} = 0; x G XWMST, x02 = 1} = 0;
x G XWMST,x23 = 1} = 0; x G XWMST, x24 = 1} = 0;
x G XWMST ,x03 = 1} = 1;
^13 = min{2 - xo1 -	xo4	- ^12 -	xo3	: x G Xwmst, ^13 =	1}	= 0;
&amp;amp;4 = min{2 - xo1 -	xo4	- ^12 -	xo3	: x G Xwmst, x34 =	1}	= 0.
A DCILDL e dada por
x01 + x04 + x12 + x03 &amp;lt;2,
que e valida para o conjunto das soluções admisséveis Xwmst, corta a soluçao fra-cionéria (2,2 &gt; 2) e define uma faceta de PWMST (verificado através do software PORTA [14]).
Observação 2.
Como se fixaram a um variáveis cujas correspondentes arestas nõo pertencem à árvore de suporte de peso mínimo, os seus coeficientes obtidos usando down-lifting sõo inferiores ou iguais a zero &amp;lt;0).
5.5.2	Desigualdades de Cobertura Implícita Levantada por Up-Lifting (DCILUL)
Para obter Desigualdades de Cobertura Implícita Levantada através do designado Up-Lifting é necessario comecar por fixar a zero um conjunto de variéveis. Designamos por Eo o conjunto de variaveis fixas a zero e por XE° o conjunto restrito definido da seguinte forma
xEo = XWMST p : xj = 0, f E Eo} ,
onde as variaveis f E Eo se encontram fixas a zero, xj = 0. Notamos que o conjunto X Eo
é uma restricao do conjunto XWMST.
De seguida vamos definir uma cobertura implícita para o conjunto restrito XEo. Vamos assumir XEo = 0.
Definição 5.7. Cobertura Implícita para o conjunto restrito XEo
O conjunto S C E \ Eo, cujas arestas de S nao formam ciclos, é uma Cobertura Implícita para o conjunto restrito XE°, se para cada árvore de suporte T = (V, ET) tal que S C ET e Eo C ET se verifica a seguinte desigualdade
W (T) =	We &gt;W-
Proposição 5.9.
Se S C E \ E0 á uma CI para o conjunto restrito XE°, entao a Desigualdade de Cobertura Implácita
xe &amp;lt;|S| - 1
e&amp;amp;S á valida para o conjunto restrito XE° -
A prova desta proposição á análoga à prova da Proposiçao 5-7-
Observação 3.
A DCI para o conjunto restrito XE° não tem de ser necessariamente valida para XWMst- A desigualdade válida á obtida apenas quando se faz o levantamento das variáveis do conjunto E0 (xe, e G E0)-
Exemplo 5.11.
Considere-se o Exemplo 2-1 de 5 nodos, onde os valores de cada variáavel na soluçcãao da relaxação linear (ver Figura 3-5) são os seguintes: x01 = 1; x04 = 0,2; x12 = 1; x13 = 0,8; x34 = 0,8 e x43 = 0,2 (restantes variaveis com valor nulo)-
Seja E0 = {{0, 2}, {1, 3}, {1,4}, {2, 3}} o conjunto de variáveis fixas a zero- As arestas de E0 pertencem à arvore de suporte de peso mánimo (ver Figura 2-3) e nao tomam o valor um na soluçcaão da relaxacçãao linear-
De seguida ordenam-se as restantes arestas nãao fixas a zero, ou seja, as arestas de E \ E0- Considere-se, por exemplo, a seguinte ordenacao:
{0,1} {1,2} {3, 4} {0, 4} {0, 3} {2,4}-
(— 1
C =
9	8	7 &gt;
1	15	16
—	30	16
	—	10
— /
Figura 5.6: Arvore de suporte com custo 28 e peso 22.
Como W(T) = 22 &gt; 20, obteve-se uma érvore de suporte não admissível e S = {{0,1}} é uma CI para o conjunto restrito XEo, então a DCI obtida é x01 &amp;lt;0, a qual é valida para o conjunto restrito XEo. Notamos que as arestas {0,1}, {0, 2}, {1,3} e {1, 4}, formam uma érvore com peso 13 e custo 41, portanto uma solução admissível de Xwmst, e na qual x01 = 1 o que evidencia o facto da desigualdade x01 &amp;lt;0 não ser vílida para Xwmst •
De uma forma genérica, se considerarmos que Ef = E \ (S U E0) e R Ç E0 U Ef é o conjunto de variéaveis que jéa foram sujeitas a levantamento, para calcular os coeficientes das variéveis de (E0 U Ef )\R resolve-se o seguinte subproblema:
Pt = min &amp;lt;|S | — 1 — üXe — E
e^S	eGRn(EoUEf)
onde X(t) é definido da seguinte forma:
X (t) = {X G Xwmst : Xe = 0,e G E0 \ (R U {t}),xt = 1} ,t G E0 \ R.	(5.14)
X(t) = |X G XWMST : xe = 0,e G E0 \ R,xt = 1},t G Ef \ R.	(5.15)
Nestes casos, se X(t) = 0 atribuímos ao coeficiente Pt o valor zero (Pt = 0). Para efetuar o chamado up-lifting, ou seja, o levantamento das variéveis fixas a zero, usamos o conjunto definido em (5.14). Neste caso, estamos a atribuir o valor um à variével xt, t G E0\R da qual se esta a fazer o up-lifting e as restantes variaveis de E0 (E0\(RU{t})) das quais ainda naão efetuéamos o levantamento tomam o valor zero.
Para efetuar o levantamento das variéveis de Ef, ou seja, o chamado levantamento usual usamos o conjunto definido em (5.15). Neste caso, estamos a atribuir o valor um à variavel Xt, t G Ef \ R, da qual se esta a fazer o levantamento e as variéveis de Eo \ R atribuimos o valor zero.
Apéos o levantamento de todas as variéaveis do conjunto R obtemos uma Desigualdade de Cobertura Implécita Levantada por Up-Lifting.
Proposição 5.10.
Dada a DCI	egC Xe &amp;lt;|C| — 1 para o conjunto restrito XE°, Ef = E \ (S U Eo) e
R Q Eo U Ef a seguinte desigualdade vélida
y^Xe +	fieXe&amp;lt;|S| — 1,
egS	egRn(Eo UEf)
ée chamada de Desigualdade de Cobertura Implécita Levantada por Up-Lifting (DCILUL) e é vélida no conjunto das solucães admisséveis XWmst, onde os coeficientes fie são obtidos sequencialmente resolvendo o subproblema (5.13).
A prova desta proposicão é analoga à prova da Proposição 5.5.
No caso do conjunto Eo = 0, ou se todos os coeficientes fie correspondentes às variéveis fixas a zero forem nulos, então a desigualdade anterior é uma simples DCIL.
Exemplo 5.12.
Considere-se a DCI X01 &amp;lt;0 valida para o conjunto restrito
xEo = XWMST n {Xe : X02 = X13 = X14 = X23 = 0}
obtida no Exemplo 5.11. Para efetuar o levantamento das variéveis de Eo podemos começcar por calcular os coeficientes associados a cada uma das variaéveis fixas a zero e obtemos
@13 =	mÍn{-X01 : x G XWMST ,x13 = 1,x02	= x14	= x23 = 0} =	-1;
@23 =	min{-X01 + X13 : x G Xwmst,X23 =	1,xu	= X02 = 0} =	0;
@02 =	min{-X01 + X13 : x G Xwmst,X02 =	1,xu	= 0} = -1;
@14 =	min{-X01 + X13 + X02 : x G Xwmst,xu =	1} = -1.
Apos o calculo dos coeficientes das variaveis fixas a zero obtem-se a seguinte desigualdade
X01 - x02 - x 13 - x 14 &amp;lt;0.
De seguida para tornar mais forte a desigualdade anterior efetua-se o levantamento das variaveis de Ef = E \ (S U E0) = {{0, 3}, {0,4}, {1, 2}, {2, 4}, {3,4}}, usando o levantamento sequencial usual, ou seja, calculam-se da seguinte forma os coeficientes das variaveis a efetuar levantamento.
@24 =	min{-X01 + X13 + X02	+ X14	: x	G	Xwmst, X24	=	1}	= 0;
@03 =	min{-X01 + X13 + X02	+ xu	: x	G	Xwmst, X03	=	1}	= 0;
@04 =	min{-X01 + X13 + X02	+ X14	: x	G	Xwmst, X04	=	1}	= 0;
@34 =	min{-X01 + X13 + X02	+ X14	: x	G	Xwmst, X34	=	1}	= 0;
@12 =	min{-X01 + X13 + X02	+ X14	: x	G	Xwmst, X12	=	1}	= 0.
Como todos os coeficientes obtidos atraves do levantamento usual sõao nulos entõao, a DCILUL e dada por
X01 - X02 - X13 - X14 &amp;lt;0,
que e valida para o conjunto das soluções admissíveis XWMST e corta a solucao fracionaria (0,2 &gt; 0).
Observacão 4.
Note-se que no caso do Problema WMST podem ser obtidas desigualdades validas diferentes quando se deixam as variaveis livres ou quando se fixam variaveis a zero.
Exemplo 5.13.
Considere-se a DCI X01 + X04 + X12 &amp;lt;2 obtida no Exemplo 5.3. Ao efetuar o levantamento das variaveis X34 e X13, obtemos os seguintes coeficientes
Mi = min{2 — xoi — xo4 — xi2 : x G Xwmst, x34 = 1} = 0;
Ai3 = min{2 — xoi — xo4 — xi2 : x G Xwmst, xn = 1} = 0.
Apés o calculo dos coeficientes das variéveis x34 e xi3 obtém-se a seguinte desigualdade
x0i + x04 + xi2 &amp;lt;2.
No caso de fixarmos a variével xi3 = 0 obtemos a DCI x0i+x04+xi2 &amp;lt;2 vélida para o conjunto restrito XEo = XWmst n {xe : xi3 = 0}. Ao efetuarmos o levantamento das variéaveis x34 e xi3, obtemos os seguintes coeficientes
Mi = min{2 — xoi — xo4 — xi2 : x G Xwmst, xi3 = 0, x34 = 1} = 1;
Ai3 = min{2 — xoi — xo4 — xi2 — x34 : x G Xwmst,xi3 = 1} = —1;
Apéos o céalculo dos coeficientes das variéaveis a efetuar levantamento obtemos a desigualdade
x0i + x04 + xi2 + x34 — xi3 &amp;lt;2.
Assim, verificamos que ao deixar a variéavel xi3 livre ou ao fixéa-la a zero se obtêem diferentes desigualdades vélidas para XWmst.
5.5.3	Desigualdades Generalizadas de Cobertura Implícita Levantada (DGCIL)
Para obter Desigualdades Generalizadas de Cobertura Implécita Levantada fixam-se à priori dois conjuntos de variéveis: um conjunto de variéveis fixas a zero, que se designa por E0 e um conjunto de variaéveis fixas a um, que se designa por Ei. Seja XU o conjunto restrito definido da seguinte forma
XU = Xwmst n {x : xe = 0, e G Eo, xe = 1, e G Ei},
onde U = Eo U Ei e as variéveis e G Eo encontram-se fixas a zero e as variéveis e G Ei encontram-se fixas a um. Notamos que o conjunto XU ée uma restriçcaõo do conjunto xwmst .
De seguida vamos definir uma cobertura implécita para o conjunto restrito XU. Vamos assumir XU = 0.
Definição 5.8. Cobertura Implícita para o conjunto restrito Xu
O conjunto S C E \ U em que U = E0 U E1, cujas arestas de S U E1 não formam ciclos, e uma Cobertura Implícita para o conjunto restrito Xu, se para cada arvore de suporte T = (V, ET) tal que S C ET, E0 C ET e E1 C ET se verifica a seguinte desigualdade
W (T) =^2 we &gt; W.
Para verificar que S C E \ U é uma CI para o conjunto restrito Xu, construímos uma sub-arvore com as arestas do conjunto S e do conjunto E1 e, sucessivamente, adicionamos arestas de Ef = E\(S U U) à sub-arvore até formarmos uma arvore de suporte de peso mínimo, T, contendo as arestas dos conjuntos S e E1. No caso da érvore de suporte T nao verificar a restrição de peso, então S é uma CI para o conjunto restrito Xu.
Proposição 5.11.
Seja S C E \ U uma CI para o conjunto restrito Xu, então a Desigualdade de Cobertura Implícita
xe &amp;lt;|S| - 1
ees ée vaélida para o conjunto restrito Xu.
A prova desta proposicão é análoga à prova da Proposição 5.7.
Observação 5.
Exemplo 5.14.
Considere-se o Exemplo 2.1 de 5 nodos, onde os valores de cada variável na solução da relaxaçao linear (ver Figura 3.5) são os seguintes: x01 = 1; x04 = 0,2; x12 = 1; x13 = 0,8; x34 = 0,8 e x43 = 0,2 (restantes variáveis com valor nulo).
Seja E0 = {{0, 2}, {2, 3}, {1,4}} o conjunto de variaveis fixas a zero, as arestas de E0 pertencem à arvore de suporte de peso mánimo (ver Figura 2.3) e tomam o valor zero na solucao da relaxacão linear. Seja E1 = {{0,1}, {1, 2}} o conjunto de variaveis fixas a um. As arestas de E1 tomam o valor um na soluçao da relaxacão linear e nao pertencem a árvore de suporte de peso mínimo (ver Figura 2.3).
De seguida, ordenam-se as restantes arestas não fixas, ou seja, as arestas de E \ (E0 U E1). Considere-se, por exemplo, a seguinte ordenacão:
{0, 4}	{3, 4}	{1,3} {0, 3}	{2,4}-
Para formar a DCI para o conjunto restrito XU = XWMST C {xe : x01 = x12 = 1,x02 = x23 = x14 = 0} considere-se a aresta {0, 4} e com esta forma-se a arvore de suporte de peso mínimo da Figura 5.7, esta contám as arestas de E1 e não contám as arestas de E0.
	í -	1	9 - 1	8 15	7 &gt; 16	
C =		-	30	16	
			-	10	
				-	/
Figura 5.7: Arvore de suporte com custo 24 e peso 21.
Como W(T) = 21 &gt; 20, obteve-se uma árvore de suporte não admissível e S = {{0,4}} á uma CI para o conjunto restrito XU, entao a DCI obtida á x04 &amp;lt;0, a qual á valida para o conjunto restrito XU. Notamos que as arestas {0, 2}, {0, 4}, {1,3} e {1,4}, formam uma arvore de suporte com peso 14 e custo 47, portanto uma solução admissável de Xwmst, e na qual x04 = 1 o que evidencia o facto da desigualdade x04 &amp;lt;0 não ser valida para XWMST.
De uma forma genáerica para calcular, sequencialmente, os coeficientes das variáaveis de (E0 U E1 U Ef) \ R, onde Ef = E \ (S U E0 U E1) e R Ç E0 U E1 U Ef resolve-se o seguinte subproblema:
= min &amp;lt;|S| — 1 — xe I	e&amp;amp;S
e xe	^e(1 — xe) : x G X (t)(5.16)
eefín(E0uE/)	eefínEx	J
onde
X(t)	x
G XWMST : xe
1,e G
Ei \ (R U	= 0,e G Eo \ R,xt = 0 j*, (5.17)
t G Ei \ R;
X(t)	x
G XWMST : xe
1,e G
E1 \ R,xe = 0, e G
Eo \ (R U{t}),xt = 1}, (5.18)
t G Eo \ R;
X (t) =
{x G XwMST : xe = 1,
e G E1 \ R,xe = 0,
e G Eo \ R,xt = 1 j*,	(5.19)
t G Ef \ R.
Nestes casos, se X(t) = 0 atribuámos ao coeficiente o valor zero (fit = 0)- Para efetuar o chamado down-lifting, ou seja, o levantamento das variaveis fixas a um, usamos o conjunto definido em (5-17)- Neste caso, estamos a atribuir o valor zero à variável xt,t G E1 \ R da qual se esta a fazer o down-lifting- As variáveis de E1 (E1 \ (RU {t})) das quais ainda nãao efetuáamos o levantamento tomam o valor um e as variaáveis fixas a zero das quais ainda nao efetuamos o levantamento (E0 \ R) tomam o valor zero-
Para efetuar o levantamento das variáveis fixas a zero, isto á, o chamado up-lifting usamos o conjunto definido em (5-18)- Neste caso, estamos a atribuir o valor um a variavel xt,t G E0 \ R da qual se esta a fazer o up-lifting. As restantes variáveis fixas a zero das quais ainda não efetuamos o levantamento (E0 \ (R U {t})) atribuámos o valor zero e as variaveis fixas a um das quais ainda não efetuamos o levantamento (E1 \ R) atribuámos o valor um-
Para efetuar o levantamento das variáveis de Ef, usamos o conjunto definido em (5-19)- Neste caso, estamos a atribuir o valor um a variável xt,t G Ef \ R da qual se esta a fazer o levantamento- As variáveis fixas a um das quais ainda não efetuámos o levantamento (E1 \ R) atribuámos o valor um, e finalmente as variaveis fixas a zero das quais ainda nao efetuamos o levantamento (E0 \ R) atribuámos o valor zero-
Apés o levantamento de todas as variéveis do conjunto R obtemos uma Desigualdade Generalizada de Cobertura Implícita Levantada.
Proposicao 5.12.
Dada a DCI J2egSxe &amp;lt;|S| - 1 para o conjunto restrito XU, Ef = E \ (SU E0 U E1) e R Ç E0 U E1 U Ef , a seguinte desigualdade valida
y^xe +	x, +	&amp;amp;(1 - xe)&amp;lt;|S|- 1.
eES	eGfín(EoUEf)	e^R^E±
é chamada de Desigualdade Generalizada de Cobertura Implícita Levantada (DGCIL) e é vélida no conjunto das solucões admissíveis XWmst, onde os coeficientes &gt;, sõo obtidos sequencialmente resolvendo o subproblema (5.16).
A prova desta proposiçõo é anéloga a prova da Proposiçao 5.5.
As Desigualdades de Cobertura Implícita Levantada por Down-lifting e por Up-lifting sõo casos particulares das Desigualdades Generalizadas de Cobertura Implícita Levantada.
•	As DCILs obtâm-se quando E0 U E1 = 0 ou se todos os coeficientes das variéveis fixas a zero e a um forem nulos.
•	As DCILULs obtâm-se quando E0 = 0 ou quando todos os coeficientes das variéveis fixas a zero forem nulos.
•	E finalmente as DCILDLs obtâm-se quando E1 = 0 ou quando todos os coeficientes das variéveis fixas a um forem nulos.
Exemplo 5.15.
Considere-se a DCI x04 &amp;lt;0 valida para o conjunto restrito
XU = XwMST n {xe : xo1 = x12 = 1, x02 = x23 = ^14 = 0},
obtida no Exemplo 5.14. Para efetuar o levantamento das variáveis de E1 podemos comecar por calcular os coeficientes associados a cada uma das variáveis fixas a um e obtemos
^01 = min{ — x04 : x G XWMST ,x01 = 0,x12 = 1,x02 = x23 = x14 = 0} = —1 ^12 = min{1 — x01 — x04 : x G Xwmst,x12 = 0 x02 = x23 = xu = 0} = —1.
De seguida efetua-se o levantamento das variaveis de E0, ou seja, calculam-se, sequencialmente, os coeficientes destas variáveis da seguinte forma
^23 = min{2	—	x01	—	x04	—	#12	:	x	G Xwmst, x23	= 1, x02 = x04 = 0} =	0
^02 = min{2	—	x01	—	x04	—	#12	:	x	G Xwmst, x02	= 1, xw = 0} = 0
^14 = min{2	—	x01	—	x04	—	#12	:	x	G Xwmst, xw	= 1} = 0
Apás o cálculo	dos	coeficientes	das	variaveis fixas	a zero e a um obtém-se a seguinte
desigualdade
x01 + x04 + x 12 A 2.
De seguida para tornar mais forte a desigualdade anterior efetua-se o levantamento das variaveis de Ef = E \ (S U E0 U E1) = {{0, 3}, {1, 3}, {2, 4}, {3, 4}} usando o levantamento sequencial usual e os coeficientes calculam-se da seguinte forma:
A34 = min{2	—	x01	—	x04	—	#12 : x G Xwmst, x34 = 1} = 0
A13 = min{2	—	x01	—	x04	—	#12 : x G Xwmst, x^ = 1} = 1
A03 = min{2	—	x01	—	x04	—	#12 — #13 : x G Xwmst, #03 = 1}	=	0
&gt;21 = min{2	—	x01	—	x04	—	#12 — xi3 : x G Xwmst, x24 = 1}	=	0
A DGCIL é dada por
X01 + x04 + x12 + x 13 A 2,
que é vélida para o conjunto das soluções admisséveis XWMST e corta a solucõo fra-cionéria (2,2 &gt; 2).
Em Anexo apresentam-se todas as facetas de PWMST para o Exemplo 2.1 obtidas através do software PORTA (POlyhedron Representation Transformation Algorithm) [14]. Para cada uma das facetas obtidas pelo software foi feita a respetiva caracte-rizacçõao.
166
Capítulo 6
Algoritmos de Separação
Com o propéosito de usar classes de desigualdades vaélidas como planos de corte e de tornar este processo eficiente necessitamos de algoritmos de separacçãao, isto ée, precisamos de ter um conjunto de rotinas para gerar desigualdades vaélidas e detetar quando ée que elas sao violadas. Kaparis e Letchford [42, 43] apresentam um estudo muito completo sobre separação de desigualdades validas para o Problema Saco-mochila Binério.
Infelizmente os problemas de separaçcãao para Desigualdades de Cobertura, Desigualdades de Cobertura Levantada e Desigualdades Generalizadas de Cobertura Levantada são NP-diféceis (ver [17, 30, 44]).
Neste capétulo com o intuito de fortalecer as formulaçcãoes apresentadas no Capétulo 3, descrevemos algoritmos de separaçcãao para as classes de desigualdades vaélidas abordadas no Capétulo 5.
Na Secçao 6.1 comecamos por apresentar dois algoritmos heurísticos de separação genéericos. Num dos algoritmos ée introduzida uma desigualdade véalida, em cada iteracçãao, enquanto que no outro podem ser introduzidas véarias desigualdades véalidas numa iteraçcãao. Em cada uma das subsecçcoães seguintes apresentamos as particularidades dos algoritmos de separaçcãao que ée necessaério especificar para introduzir as desigualdades vélidas descritas no Capétulo 5. Na Seccão 6.1 apresentamos também um algoritmo heuréstico para determinacçãao dos coeficientes das variéaveis a efetuar levantamento. Na Seccçãao 6.2 começcamos por apresentar as experiêencias computacionais realizadas com os algoritmos de separaçcãao propostos, depois comparamos os véarios algoritmos apresentados. De seguida apresentamos os resultados computacionais dos melhores algoritmos de separaçcaão e por fim apresentamos uma séntese dos resultados computacionais obtidos neste capétulo.
6.1	Algoritmos de Separação Genéricos
Vamos começar por apresentar dois algoritmos de separação genéricos, os quais vão servir como base a todos os algoritmos de separaçao propostos ao longo deste capétulo.
Algoritmo de Separação Genérico 1 (Sepl)
Passo 1: Resolver a relaxação linear
Seja x* a solução da relaxação linear de uma formulacão para o Problema WMST.
Se x* for inteira, então STOP.
Seja Erl = {e : x* &gt; 0} o conjunto formado pelas arestas da solucão da relaxação linear com valor positivo.
Seja ORD = {O1,..., Onord} um conjunto de nord ordenacoes predefinidas. Considerar a primeira ordenação O1 e fazer k =1.
Passo 2: Ordenar as arestas da relaxação linear
Seja ERLOrdk a lista ordenada de arestas da solucao da relaxação linear de acordo com a ordenaçcãao de arestas k.
Passo 3: Obter uma desigualdade valida
Construir, caso seja possével, uma desigualdade vélida (DV).
Passo 4: Decisão sobre a inserção da desigualdade valida
Se a DV corta a solucao fracionaria x*, então
inserir a DV no modelo e voltar ao Passo 1.
Caso contréario,
Fazer k = k + 1 (passar à ordenação seguinte).
Se k &gt; nord, entaão
STOP.
Caso contréario,
voltar ao Passo 2.
No Passo 1 resolvemos a relaxação linear do Procedimento P-WMTZ+C descrito na Seccao 3.3. Se a solucao x* não for inteira obtemos um conjunto que denominamos de Erl, constituído pelas arestas com xe &gt; 0 na solucão da relaxacao linear, impomos um numero fixo de ordenaçães nord e estabelecemos a primeira ordenaçao de arestas (k = 1). Em seguida, no Passo 2 ordenamos as arestas desse conjunto de acordo com a ordenacão indicada k, formando a lista de arestas ERLOrdk• No Passo 3 temos de construir uma desigualdade válida, caso seja possível. Finalmente, no Passo 4 á avaliado se a desigualdade valida formada no Passo 3 corta a solucao fracionaria x* (solução da relaxacão linear obtida no Passo 1). Se a desigualdade válida cortar a solução fracionaria x*, será introduzida no modelo e voltamos ao Passo 1, onde resolvemos a nova relaxacçãao linear. Caso a desigualdade vaílida naão corte a solucçaão fracioníaria x*, ou não seja possível formar uma desigualdade valida no Passo 3, temos ainda de averiguar se já foram utilizadas todas as ordenaçães definidas inicialmente por nord. Em caso afirmativo, o algoritmo termina. No caso de existirem outras ordenaçcãoes para efetuar, voltamos ao Passo 2 e ordenamos as arestas do conjunto Erl por outra ordenacao k. Observe-se que outros critários de paragem podem ser impostos, por exemplo, podemos terminar o algoritmo quando se encontrarem um certo nuámero de relaxaçcoães lineares seguidas com valor igual ou impor a introducçãao de um certo nuámero de cortes.
De seguida propomos algumas formas de ordenar as arestas da relaxação linear com xe &gt; 0 para formar a lista de arestas ERLOrdk.
1.	OrdW: Ordenar por ordem decrescente de peso, we.
2.	OrdWX: Ordenar por ordem decrescente de valor de we x xe.
3.	OrdX: Ordenar por ordem decrescente de valor de xe.
4.
OrdKnap:
Ordenar por ordem decrescente de valor de
1 - Xe
We
5.	OrdFixW: Começar por ordenar por ordem decrescente de peso, we as arestas com xe = 1 e de seguida, ordenar as restantes arestas (0 &amp;lt;xe &amp;lt;1) tambám por ordem decrescente de peso, we.
6.	OrdFixWX: Comecar por ordenar por ordem decrescente de valor de we x xe as arestas com xe = 1 e de seguida, ordenar as restantes arestas (0 &amp;lt;xe &amp;lt;1) tambáem por ordem decrescente de we x xe.
No Algoritmo Sepl, iterativamente, inserimos uma desigualdade vélida no modelo e resolvemos uma nova relaxaçao linear, mas podemos querer introduzir nao uma, mas vérias desigualdades no modelo (se for possével) e so depois resolver a relaxacão linear. Assim no novo algoritmo proposto apenas alteramos os Passos 3 e 4.
Algoritmo de Separação Genérico 2 (Sep2)
Passo 3: Obter uma desigualdade válida
Construir, caso seja possével, uma desigualdade vélida (DV).
Fazer nDV = 0.
Passo 4: Decisão sobre a inserção da desigualdade valida
Fazer k = k + 1 (passar à ordenação seguinte).
Se a DV corta a soluçao fracionaria x*, então
inserir a DV no modelo.
udv = hdv + 1.
Se k &gt; nord, então
Se nDV &gt; 0, entao
voltar ao Passo 1.
Caso contraério,
STOP.
Caso contréario,
voltar ao Passo 2.
No Passo 3 para aléem de construirmos, caso seja possével, uma desigualdade véalida, vamos inicializar o numero de desigualdades vélidas (nDV = 0). No Passo 4 do Algoritmo Sep2 é avaliado se a desigualdade valida formada no Passo 3 corta a solução fracionéria x* (solução da relaxaçao linear obtida no Passo 1). Se a desigualdade valida cortar a solucao fracionaria x*, sera introduzida no modelo e aumenta-se em uma unidade o numero de desigualdades vélidas a introduzir no modelo. No caso de ainda não se terem testado todas as ordenaçães definidas inicialmente por nord, então voltamos
ao Passo 2 e ordenamos as arestas do conjunto ERL por outra ordenação k. Caso não existam mais ordenações disponíveis e existam desigualdades validas a inserir no modelo	&gt; 0), então volta-se ao Passo 1 para resolver a nova relaxação linear.
O algoritmo termina se não existirem mais ordenações disponíveis nem desigualdades válidas a inserir no modelo. Tal como referimos anteriormente para o Algoritmo Sepl podemos impor outros critários de paragem. Por exemplo, terminar o algoritmo quando se encontrarem um certo numero de relaxações lineares seguidas com valor igual ou quando um certo numero de cortes forem introduzidos no modelo.
Nas seccoes seguintes descrevemos para cada classe de desigualdades válidas apresentadas no Capítulo 5 os procedimentos a adotar no Passo 3 para a formação de uma desigualdade vaálida.
6.1.1	Algoritmo de Separação para as DC
Para descrever um algoritmo de separacão para as Desigualdades de Cobertura (DCs) precisamos de encontrar as sucessivas DCs que á possível obter no Passo 3 dos Algoritmos Sepl e Sep2. Assim, para descrever os algoritmos para introducão de DCs será necessário especificar o Passo 3.
Passo 3: Obter uma Desigualdade de Cobertura
Seja S = {}.
Fazer p =1 (inserir a primeira aresta de ERLOrdk no conjunto S).
Passo 3.1: Construir o conjunto S
Atualizar o conjunto S com as primeiras p arestas da lista ERLOrdk.
Passo 3.2: Verificar se S e Cobertura
Calcular WS	V e&amp;amp;s we-
Se WS &gt; W, entao
S áe uma Cobertura.
DC:	xe &amp;lt;|S| - 1.
Caso contréario,
Se p &amp;lt;#ERLOrdk, entao
p = p +1.
Voltar ao Passo 3.1.
Caso contréario,
nãao ée possével formar uma cobertura.
No Passo 3, para formar uma DC, temos de formar uma Cobertura S, para tal, adicionamos, sucessivamente, uma aresta da lista ERLOrdk ao conjunto S, até que a soma dos pesos das arestas contidas em S seja superior a W.
Note-se que no Passo 3.2, #ERLOrdk representa o numero de arestas da lista ERLOrdk.
Para exemplificar os algoritmos de separaçcãao propostos para as DCs usamos as seis ordenacães propostas (nord = 6) e a instância de 5 nodos do Exemplo 2.1.
Exemplo 6.1.
Consideremos o Exemplo 2.1. De seguida vamos descrever em detalhe a primeira iteraçcãao do Algoritmo Sep1 para o caso das DCs e os principais resultados das restantes iteraçoes encontram-se na Tabela 6.1.
Iteração 1:
Passo 1: O conjunto de arestas com xe &gt; 0 na solucão da relaxacao linear do Procedimento P-WMTZ+C é dado por ERL = {{0,1}, {0, 4}, {1, 2}, {1, 3}, {3,4}}, onde x01 = 1; x04 = 0,2; x12 = 1; x13 = 0,8; x34 = 0,8 e x43 = 0,2 (restantes variaveis com valor nulo).
Passo 2: Ordenando as arestas do conjunto ERL, por exemplo, por ordem decrescente de peso (OrdW) obtemos a seguinte lista de arestas ordenadas
ERLOrdw = [{0, 4}, {0,1}, {1, 2}, {3, 4}, {1, 3}].	(6.1)
Passo 3: Para formar a Cobertura S vamos adicionar, sucessivamente, uma aresta de ERLOrdW ao conjunto S da seguinte forma,
S = {{0, 4}} Ws =	wo4 = 7;
S = {{0,1}, {0, 4}}	Ws = wo4	+	woi = 7 + 6 = 13;
S = {{0,1}, {0, 4}, {1,2}} Ws	=	wo4 + woi + W12 =	13 +	6	=	19;
S = {{0, 1}, {0, 4}, {1,2}, {3, 4}}	Ws = w04 + w01 + w12 + w34 =	19 + 5 = 24 &gt; 20.
Como Ws = 24 &gt; 20 = W, S é uma Cobertura e podemos construir a correspondente DC
xoi + Xo4 + Xi2 + X34 &amp;lt;3.	(6.2)
Passo 4: Como a DC obtida corta a solução fracionaria (3,2 &gt; 3), então e introduzida no modelo e volta-se ao Passo 1.
A informação respeitante às restantes iteracoes encontra-se resumida na Tabela 6.1.
Iter.	Sepl-DC	
2	Passo 1	x*: xoi = 1; xo4 = 0,5; X12 = 1; X13 = 1 e X34 = 0,5 Custo = 25,5 e peso = 20
	Passo 2, 3 e 4	Ordenacao: OrdW DC: x01 + x04 + x12 + x34 &amp;lt;3. Não corta x* (3	3).
	Passo 2, 3 e 4	Ordenação: OrdWX DC: x01 + x04 + x12 + x34 &amp;lt;3. Nao corta x* (3	3).
	Passo 2, 3 e 4	Ordenacão: OrdX DC: x01 + x04 + x12 + x13 + x34 &amp;lt;4. Não corta x* (4	4).
	Passo 2, 3 e 4	Ordenação: OrdFixWX DC: x01 + x04 + x12 + x13 &amp;lt;3 Inserir, corta x* (3, 5 &gt; 3).
3	Passo 1	x*: x01 = 1; x03 = 0,125; x04 = 0,125; #12 = 1; #13 = 0,875 e x34 = 0,875 Custo = 25,75 e peso = 20
	Passo 2, 3 e 4	Ordenaçcaão: OrdW DC: x01 + x03 + x04 &amp;lt;2. Nao corta x* (1,25	2).
	Passo 2, 3 e 4	Ordenacçãao: OrdWX DC: x01 + x03 + x12 + x13 + x34 &amp;lt;4. Não corta x* (3,875	4).
	Passo 2, 3 e 4	Ordenaçcãao: OrdX DC: x01 + x03 + x12 + x13 + x34 &amp;lt;4. Nao corta x* (3,875	4).
	Passo 2, 3 e 4	Ordenacçãao: OrdFixWX DC: x01 + x03 + x12 + x13 + x34 &amp;lt;4. Não corta x* (3,875	4).
	Passo 2, 3 e 4	Ordenacçaão: OrdFixW DC: x01 + x03 + x04 + x12 &amp;lt;3. Nao corta x* (2,25	3).
	Passo 2, 3 e 4	Ordenaçao: OrdKnap DC: x03 + x04 + x13 + x34 &amp;lt;3. Nao corta x* (2	4).
Tabela 6.1: Principais resultados por iteração do Algoritmo Sepl para as DCs aplicado ao Exemplo
2.1.
Na Tabela 6.2 podemos observar as principais etapas do Algoritmo Sep2 para as DCs aplicado ao Exemplo 2.1. Na referida tabela apresentamos apenas as desigualdades que cortam a solucao x*.
Iter.	Sep2-DC	
1	Passo 1	x*: xoi = 1; xo4 = 0,2; X12 = 1; X13 = 0,8; X34 = 0,8 e X43 = 0,2 Custo = 25,4 e peso = 20
	Passo 2, 3 e 4	Ordenação: OrdW e OrdFixW DC: xoi + x04 + X12 + x34 &amp;lt;3 Inserir, corta x* (3,2 &gt; 3).
2	Passo 1	x*: xoi = 1; X04 = 0,5; X12 = 1; X13 = 1 e X34 = 0,5 Custo = 25,5 e peso = 20
	Passo 2, 3 e 4	Ordenação: OrdFixW e OrdFixWX DC: x01 + x04 + x12 + x13 &amp;lt;3 Inserir, corta x* (3,5 &gt; 3).
3	Passo 1	x*: x01 = 1; x03 = 0,125; x04 = 0,125; x12 = 1; x13 = 0,875 e x34 = 0,875 Custo = 25,75 e peso = 20
Tabela 6.2: Principais resultados por iteração do Algoritmo Sep2 para as DCs aplicado ao Exemplo
2.1.
Neste exemplo, com a aplicacçaão do Algoritmo Sep2 sãao adicionadas tambéem duas DCs, sendo estas as introduzidas no Algoritmo Sep1. Nas Iteraçao 1 e 2 foram omitidos os passos correspondentes as ordenacães que nao formam nenhuma DC.
Uma desvantagem da aplicação do Algoritmo Sep2 poderí ser o consumo de tempo em obter desigualdades jí obtidas, pois na Tabela 6.2 nas Iteraçães 1 e 2 sao obtidas a mesma DC por dois modos de ordenaçcaão de arestas diferentes.
A soluçao obtida neste algoritmo tem custo 25,75 e peso 20 e é igual a obtida pelo Algoritmo Sep1.
Podemos observar também que as coberturas correspondentes às DCs obtidas nos Algoritmos Sep1 e Sep2 sao minimais.
Proposicao 6.1.
Se S e uma Cobertura formada pelos Algoritmos Sep1 e Sep2 usando a ordenaçcõao OrdW, entõo S é Cobertura Minimal.
Demonstração.
Seja S uma Cobertura, com |S| = s e EOrdW = [e1, e2,..., es-1, es,..., et] a lista de arestas ordenadas por ordem decrescente de peso (OrdW), onde t e o numero de arestas da relaxaçcõao linear com soluçcõao positiva. Os pesos das arestas de Eordw verificam,
We1 &gt; We2 &gt; ... &gt; Wes-1 &gt; We, &gt; ... &gt; Wet.
Se considerarmos a sucessiva inclusõao de arestas em S obtemos:
S = {e1}	wei &amp;lt;W
S = {e1, e2}	We1 + We2 &amp;lt;W
S = {e1, e2,... es-1}	Wei + we2 + ... + w^ &amp;lt;W.
Como ainda nõo temos a cobertura formada, pois so temos s _ 1 arestas incluídas na cobertura entõao adicionamos a préoxima aresta da lista Eordw e obtemos
We1 + We2 + ... + Wes-1 + We, &gt; W,
o que é equivalente a ter ^2eSS We &gt; W, pelo que S é uma Cobertura.
Se removermos a aresta de menor peso, es, da cobertura ficamos com
V We &amp;lt;W,	(6.3)
eSS-{es}
e se removermos qualquer outra aresta e», com i = {1, 2,..., s _ 1}, sabemos que Wei	Wes, logo a desigualdade (6.3) é sempre verificada.
Assim S ée Cobertura Minimal.
□
Quando se utiliza uma das outras cinco ordenações propostas a cobertura formada pode nãao ser minimal.
Por exemplo, com a ordenação de arestas OrdWX,
ERLOrdWX = [{0, 1}, {1, 2}, {3, 4}, {1,3}, {0, 4}],
obtemos a cobertura S = {{0,1}, {1, 2}, {3,4}, {1,3}, {0, 4}}, a qual não é uma cobertura minimal, pois se removermos a aresta {1,3} do conjunto S o peso das restantes arestas é WS = 25 &gt; 20.
Note-se ainda que com diferentes sequências de ordenaçães ou utilizando um maior ou menor numero de ordenaçães podemos obter DCs diferentes e, consequentemente, levar à obtençao de diferentes limites inferiores para o valor étimo.
6.1.2	Algoritmo de Separação para as DCI
Para aplicar os Algoritmos Sep1 e Sep2 ao caso particular das Desigualdades de Cobertura Implécita (DCIs), temos de efetuar algumas alteracçoães ao Passo 3 descrito na Subsecção 6.1.1, pois as CI são baseadas numa estrutura em arvore.
Passo 3: Obter uma Desigualdade de Cobertura Implícita
Seja S = {}.
Fazer p =1 (inserir a primeira aresta de ERLOrdk no conjunto S).
Passo 3.1: Construir o conjunto S (sem ciclos)
Atualizar o conjunto S com as primeiras p arestas da lista ERLOrdk, desde que naão formem ciclos.
Passo 3.2: Verificar se S é Cobertura Implícita
Obter a aérvore de suporte de peso ménimo T, que inclui as p primeiras arestas de S.
Se W(T) &gt; W, entõo
S e uma CI.
DCI: Y.ees Xe&amp;lt;|S|- 1.
Caso contrario,
Se p &amp;lt;#ERLordk, entao
p = p +1.
Voltar ao Passo 3.1.
Caso contrario,
nõo e possiVel formar uma CI.
Para obter uma DCI, no Passo 3.1 atualizamos, sucessivamente, o conjunto S com as arestas de ERLOrdk , desde que naõo formem ciclos. Inicialmente o conjunto S comecça com uma aresta (p =1). A formaçõo da DCI é realizada no Passo 3.2, onde formamos uma arvore de suporte de peso mínimo com as arestas de S. Enquanto a árvore obtida verificar a restricçõao de peso e existirem arestas de ERLOrdk para inserir em S, voltamos ao Passo 3.1 e atualizamos o conjunto S adicionando mais uma aresta da lista ERLOrdk. No caso de naõo existirem mais arestas para inserir em S, entõao nõao ée possével formar uma CI. Caso a restriçcaõo de peso nõao seja verificada, S ée uma CI e temos a correspondente DCI.
De seguida exemplificamos os Algoritmos Sep1 e Sep2 para as DCIs usando as seis ordenacões propostas (nord = 6) e a instância de 5 nodos do Exemplo 2.1.
Exemplo 6.2.
Consideremos o Exemplo 2.1. De seguida apresentamos a explicaçõo detalhada da Iteracõo 1 do Algoritmo Sep1 para as DCIs e na Tabela 6.3 encontram-se os principais passos das restantes iteraçcoões.
Iteração 1:
Passo 1: O conjunto de arestas com Xe &gt; 0 na solucçõao da relaxacçaõo linear do Procedimento P-WMTZ+C é dado por ERL = {{0,1}, {0, 4}, {1, 2}, {1, 3}, {3,4}}, onde X01 = 1; X04 = 0,2; X12 = 1; X13 = 0,8; X34 = 0,8 e X43 = 0,2 (restantes variaéveis com valor nulo).
Passo 2: De seguida ordenamos as arestas do conjunto ERL, por exemplo, por ordem decrescente de peso e obtemos a seguinte lista de arestas ordenadas
ERLOrdW = [{0, 4}, {0,1}, {1, 2}, {3, 4}, {1, 3}].
Passo 3: Considerando a primeira aresta da lista ordenada ERLOrdW, formamos no Passo 3.1 o conjunto S = {{0,4}} (p = 1).
No Passo 3.2 construímos a árvore de suporte de peso mínimo que inclui esta aresta e obtemos a solução admissível da Figura 6.1 com peso 14.
	-	1	9	8 -	1	15	7 16	
C =		- 30	16	
		-	10	
			-	/
Figura 6.1: Arvore de suporte de peso mínimo incluindo a aresta {0,4} com custo 47 e peso 14.
Como a restrição de peso da arvore da Figura 6.1 nao á violada, voltamos ao Passo 3.1 e aumentamos parap = 2 o numero de arestas no conjunto S = {{0,1}, {0, 4}} e obtemos a seguinte árvore admissível com peso 18.
( -	19
- 1
C =
8	7 \
15 16
30	16
- 10
-
Figura 6.2: Árvore de suporte de peso mínimo incluindo as arestas {0,1} e {0,4} com custo 32 e peso 18.
A restricão de peso continua a ser verificada (ver Figura 6.2), o que nos leva a aumentar para p = 3 o numero de arestas em S. Desta forma, S = {{0,1}, {0, 4}, {1,2}} e obtemos uma soluçao nao admissível com peso 21 que se encontra representada na figura seguinte.
/- 1
C =
k
9	8	7	\
1	15	16
- 30	16
- 10
-
Figura 6.3: Arvore de suporte de peso mínimo incluindo as arestas {0,1}, {0,4} e {1, 2} com custo 24 e peso 21.
A restricao de peso nao é verificada (W(T) = 21 &gt; 20 = W), o que significa que foi encontrada a CI. Podemos assim construir a correspondente DCI,
Xoi + X04 + X12 &amp;lt;2.
Passo 4: Como a DCI obtida corta a solucão fracionaria x* (2,2 &gt; 2) á introduzida no modelo.
A informacão respeitante às restantes iterações encontra-se resumida na Tabela 6.3.
Iter.
Sepl-DCI
2	Passo 1	x*: xoi = 1; xo3 ~ 0,1667; X12 = 1; X13 ~ 0,8333 e X34 = 1 Custo = 25,8333 e peso = 20
	Passo 2, 3 e 4	Ordenaçao: OrdW DCI: x01 + x03 + x12 &amp;lt;2 Inserir, corta x* (2,1667 &gt; 2).
3	Passo 1	x*: x01 = 0,875; x02 = 0,125; x03 = 0,125; x04 = 0,125; x12 = 0,875; x13 = 0,75; x21 = 0,125; x34 = 0,875 e x43 = 0,125 Custo = 26,125 e peso = 20
	Passo 2, 3 e 4	Ordenação: OrdW DCI: x01 + x03 + x04 + x12 &amp;lt;3. Não corta x* (2,125	3).
	Passo 2, 3 e 4	Ordenacao: OrdFixW DCI: x02 + x12 + x13 + x34 &amp;lt;3. Não corta x* (2,875 3).
Tabela 6.3: Principais resultados por iteracão do Algoritmo Sepl para as DCIs aplicado ao Exemplo
2.1.
Neste algoritmo são introduzidas no modelo duas DCIs, uma na Iteração 1 e uma na Iteração 2 ambas utilizando a ordenação OrdW. Como não é possível obter mais nenhuma DCI na Iteração 3, dado que se percorreram todas as ordenaçães, então o algoritmo termina e a soluçao obtida tem custo 26,125 e peso 20. Note-se que na Iteraçao 3 foram omitidos os passos correspondentes às ordenaçães que não formam nenhuma DCI.
Na Tabela 6.4 podemos observar as principais etapas do Algoritmo Sep2 para as DCIs aplicado ao Exemplo 2.1.
Iter.
Sep2-DCI
1	Passo 1	x*: xoi = 1; xo4 = 0,2; X12 = 1; X13 = 0,8; X34 = 0,8 e X43 = 0,2 Custo = 25,4 e peso = 20
	Passo 2, 3 e 4	Ordenação: OrdW e OrdFixW DCI: x01 + x04 + x12 &amp;lt;2 Inserir, corta x* (2,2 &gt; 2).
2	Passo 1	x*: xoi = 1; X03 ~ 0,1667; X12 = 1; X13 « 0,8333 e X34 = 1 Custo = 25,8333 e peso = 20
	Passo 2, 3 e 4	Ordenaçao: OrdW DCI: x01 + x03 + x12 &amp;lt;2 Inserir, corta x* (2,1667 &gt; 2).
	Passo 2, 3 e 4	Ordenação: OrdFixW DCI: x01 + x03 + x12 + x34 &amp;lt;3 Inserir, corta x* (3,1667 &gt; 3).
3	Passo 1	x*: x01 = 0,875; x02 = 0,125; x03 = 0,125; x04 = 0,125; x12 = 0,875; x13 = 0,75; x21 = 0,125; x34 = 0,875 e x43 = 0,125 Custo = 26,125 e peso = 20
Tabela 6.4: Principais resultados por iteração do Algoritmo Sep2 para as DCIs aplicado ao Exemplo
2.1.
No Algoritmo Sep2 sao adicionadas três DCIs, sendo duas delas as introduzidas no Algoritmo Sep1.
Note-se que nas Iteraçães 1 e 2 foram omitidos os passos correspondentes às or-denaçães que não formam nenhuma DCI.
A soluçao obtida no Algoritmo Sep2 tem custo 26,125 e peso 20, sendo a mesma da obtida no Algoritmo Sep1.
6.1.3	Algoritmo de Separação para as DCIE
Passo 3: Obter uma Desigualdade de Cobertura Implícita Estendida
Passo 3.1: Obter uma DCI
Seja S = {}.
Fazer p =1 (inserir a primeira aresta de ERLOrdk no conjunto S).
Passo 3.1.1: Construir o conjunto S (sem ciclos)
Atualizar o conjunto S com as primeiras p arestas da lista ERLOrdk, desde que naão formem ciclos.
Passo 3.1.2: Verificar se S e Cobertura Implícita
Obter a arvore de suporte de peso mínimo T, que inclui as p primeiras arestas de S.
Se W(T) &gt; W, então
S ée uma CI.
DCI: EeeSxe &amp;lt;|S| — 1. Ir para o Passo 3.2.
Caso contréario,
Se p &amp;lt;#ERLOrdk, entao
p = p +1.
Voltar ao Passo 3.1.1.
Caso contréario,
naão ée possével formar uma CI.
Passo 3.2: Obter uma DCIE
Calcular Wmax = max{Wf : f E S}.
Obter o conjunto S1 = {e E E \ S : we &gt; wmax e S U {e} forma ciclo}. DCIE: ZeeS Xe + E . Xe&amp;lt;|S| — 1.
Quando no Passo 3.1 é obtida uma DCI, no Passo 3.2 temos apenas de obter o conjunto S'. Uma aresta pertence ao conjunto S' se não pertencer a S, se o seu peso for superior ou igual ao peso maéximo das arestas do conjunto S e, ainda, se formar ciclo com as arestas do conjunto S. Desta forma obtemos uma DCIE.
No caso de aplicarmos os Algoritmos Sep1 e Sep2 para as DCIEs ao Exemplo 2.1 não é possével obter nenhuma DCIE. Assim para exemplificar estes algoritmos no caso das DCIEs temos de recorrer a um outro exemplo.
Nas Tabelas 6.5 e 6.6 podemos observar as principais etapas dos Algoritmos Sep1 e Sep2 para as DCIEs aplicado ao Exemplo 5.4.
Iter.	Sepl-DCIE	
l	Passo l	x*: xoi = 1; xo4 = 0,2; X12 = 1; X13 = 0,8; X34 = 0,8 e X43 = 0,2 Custo = 25,4 e peso = 20
	Passo 2, 3 e 4	Ordenação: OrdW DCI: xoi + X04 + X12 &amp;lt;2 DCIE: x01 + x04 + x12 + x02 &amp;lt;2 Inserir, corta x* (2,2 &gt; 2).
2	Passo l	x*: x01 = 1; x03 ~ 0,1667; x12 = 1; x13 « 0,8333 e x34 = 1 Custo « 25,8333 e peso = 20
	Passo 2, 3 e 4	Ordenacçãao: OrdW DCI: x01 + x03 + x12 &amp;lt;2 Inserir, corta x* (2,1667 &gt; 2).
3	Passo 1	x*: x01 ~ 0,8571; x03 ~ 0,1429; x04 ~ 0,1429; x12 = 1; x13 « 0,7143; x31 « 0,1429; x34 « 0,8571 e x43 « 0,1429 Custo « 26,8571 e peso = 20
	Passo 2, 3 e 4	Ordenaçcaão: OrdW DCI: x03 + x04 &amp;lt;1. Nao corta x* (0,2857	1).
	Passo 2, 3 e 4	Ordenaçao: OrdFixW DCI: x03 + x04 + x12 &amp;lt;2. Não corta x* (1,2857	2).
	Passo 2, 3 e 4	Ordenaçao: OrdKnap DCI: x03 + x04 + x13 + x34 &amp;lt;3. Não corta x* (2,1429 3).
Tabela 6.5: Principais resultados por iteração do Algoritmo Sepl para as DCIEs aplicado ao Exemplo
5.4.
Neste algoritmo sãao introduzidas duas desigualdades véalidas, uma DCIE na Iteraçcãao 1 e uma DCI na Iteracão 2, ambas obtidas usando a ordenação OrdW. Para a DCI obtida na Iteracçãao 2 naão foi possével obter uma DCIE. Como naão ée possével na Iteraçcãao 3 obter mais nenhuma DCI ou DCIE, dado que se percorreram todas as ordenacçãoes, entao o algoritmo termina e a solução obtida tem custo 26,8571 e peso 20. Note-se que na Iteração 3 foram omitidos os passos correspondentes às ordenaçães que nao formam
nenhuma DCI e, consequentemente, nenhuma DCIE.
Iter.	Sep2-DCIE	
1	Passo 1	x*: xoi = 1; xo4 = 0,2; X12 = 1; X13 = 0,8; X34 = 0,8 e X43 = 0,2 Custo = 25,4 e peso = 20
	Passo 2, 3 e 4	Ordenacão: OrdW e OrdFixW DCI: xoi + X04 + X12 &amp;lt;2 DCIE: x01 + x04 + x12 + x02 &amp;lt;2 Inserir, corta x* (2,2 &gt; 2).
2	Passo 1	x*: x01 = 1; x03 ~ 0,1667; x12 = 1; x13 « 0,8333 e x34 = 1 Custo « 25,8333 e peso = 20
	Passo 2, 3 e 4	Ordenaçao: OrdW DCI: x01 + x03 + x12 &amp;lt;2 Inserir, corta x* (2,1667 &gt; 2).
	Passo 2, 3 e 4	Ordenacçaão: OrdFixW DCI: x01 + x03 + x12 + x34 &amp;lt;3 Inserir, corta x* (3,1667 &gt; 3).
	Passo 2, 3 e 4	Ordenacao: OrdKnap DCI: x03 + x12 + x13 + x34 &amp;lt;3. Nao Inserir (3	3).
3	Passo 1	x*: x01 ~ 0,8571; x03 ~ 0,1429; x04 ~ 0,1429; x12 = 1; x13 « 0,7143; x31 « 0,1429; x34 « 0,8571 e x43 « 0,1429 Custo « 26,8571 e peso = 20
	Passo 2, 3 e 4	Ordenaçcaão: OrdW DCI: x03 + x04 &amp;lt;1. Nao Inserir (0,2857	1).
	Passo 2, 3 e 4	Ordenaçcaão: OrdFixW DCI: x03 + x04 + x12 &amp;lt;2. Nao Inserir (1,2857	2).
	Passo 2, 3 e 4	Ordenaçcãao: OrdKnap DCI: x03 + x04 + x13 + x34 &amp;lt;3. Não Inserir (2,1429	3).
Tabela 6.6: Principais resultados por iteracão do Algoritmo Sep2 para as DCIEs aplicado ao Exemplo
5.4.
No Algoritmo Sep2 são adicionadas três desigualdades vélidas, sendo uma delas uma DCIE e duas delas DCIs. Note-se que nas Iteracães 1, 2 e 3 foram omitidos os passos correspondentes às ordenações que não formam nenhuma DCI e, consequentemente, nenhuma DCIE.
A soluçao obtida neste algoritmo tem custo 26,8571 e peso 20, sendo a mesma da obtida no Algoritmo Sep1.
6.1.4	Algoritmos de Separação para as DCIL
Para obter Desigualdades de Cobertura Implícita Levantada (DCILs) temos de especificar o Passo 3 de modo que depois de se obter uma DCI se venha a encontrar uma correspondente DCIL.
Passo 3: Obter uma Desigualdade de Cobertura Implícita Levantada
Passo 3.1: Obter uma DCI
Este passo é igual ao Passo 3.1 do Algoritmo para as DCIEs.
Passo 3.2: Obter uma DCIL
Calcular os coeficientes fie, e G R G E\S.
e = min &amp;lt;|S|- 1	xf ^^2 fifxf : x G XWmst, xe = 1 &gt; .
I	f&amp;amp;S	f&amp;amp;R	)
DCIL: EeeS xe + EeeR e x, &amp;lt;|S| - 1
No Passo 3.1, se for possível obter uma írvore de suporte de peso mínimo que contenha as arestas de S e não verifique a restricão de peso, obtemos uma DCI e no Passo 3.2 efetuamos o cílculo dos coeficientes para fazer o levantamento das variíveis do conjunto R de arestas que ainda não foram levantadas e que se pretendem levantar de modo a obter uma DCIL. Assim, para aplicar os algoritmos de separaçao ao caso das DCILs temos que ter em conta apenas a ordem de determinaçao dos coeficientes para efetuar o levantamento das variíveis. Recorde-se que as variaveis com xe &gt; 0, que estao na solução da relaxação linear encontram-se ordenadas pelas ordens propostas na Secçao 6.1. As restantes variíveis com xe = 0 na soluçao da relaxacao linear encontram-se por uma ordem arbitríria.
Ordem de Determinação dos Coeficientes no Levantamento das Variáveis
• Levantamento das Variáveis 1 (LV1)
Efetuar o levantamento apenas das variíveis com xe &gt; 0, que estão na solucao da relaxação linear de acordo com as ordenacães propostas na Seccão 6.1.
•	Levantamento das Variaveis 2 (LV2)
Efetuar o levantamento de todas as variéveis. Sendo as variaveis com xe &gt; 0, que estõo na soluçao da relaxacõo linear levantadas em primeiro lugar de acordo com as ordenacões propostas na Secçõo 6.1. As restantes variéveis sao levantadas numa ordem arbitraria.
•	Levantamento das Variaveis 3 (LV3)
Efetuar o levantamento de todas as variaveis. Sendo as variéveis com xe &gt; 0, que estao na soluçao da relaxaçao linear levantadas em primeiro lugar de acordo com as ordenacões propostas na Secçõo 6.1. As restantes variaveis sõo levantadas por ordem decrescente de peso.
Observe-se que de entre as n(n^—variaveis, podemos efetuar o levantamento de todas as variéveis que nao pertençam a Cobertura S, isto é, necessitamos de determinar no maximo n(n^—_ |S| coeficientes de variaveis para efetuar o seu levantamento. Para o célculo de forma sequencial dos coeficientes existem	) _ |S|^ ! maneiras
diferentes de efetuar o levantamento das variéveis. No caso do Exemplo 2.1, em que temos 5 nodos e uma cobertura com |S| = 3 (Exemplo 6.2), existem 7! = 5040 modos diferentes de efetuar o levantamento das variéveis, o que significa que dependendo da ordem de levantamento das variéveis também podem ser obtidas diferentes DCILs.
Note-se que no caso dos coeficientes de todas as variéveis a efetuar o levantamento serem nulos, nao temos uma DCIL, mas temos uma DCI, a qual poderé ser inserida no modelo, caso corte a solucao fracionaria, x*.
Caso a DCI contenha apenas uma aresta, a DCI correspondente é da forma xe &amp;lt;0. Neste caso não faz sentido efetuar o levantamento das variaveis, uma vez que o célculo dos coeficientes fif sera efetuado resolvendo o seguinte problema,
¡3f = min{—xe : x G XWMST,Xf = 1}.
Os posséveis valores destes coeficientes são —1 ou 0, mas como fif &gt; 0, então neste caso não é necessario determinar os coeficientes, pois estes são todos nulos.
Figura 6.4: Esquemas de obtenção de uma DCIL dada uma DCI.
Na Figura 6.4 podemos observar duas estratégias para a formação de DCILs. No Passo 3 do algoritmo de separação proposto para as DCILs, gera-se uma DCIL sempre que no Passo 3.1 é obtida uma DCI (Esquema 1 - DCIL-E1 da Figura 6.4). Evidenciamos no Esquema 2- DCIL-E2 da Figura 6.4 que podemos sé gerar uma DCIL apenas no caso da DCI obtida no Passo 3.1 cortar a soluçao fracionaria, x*. Caso esta não corte, nao é obtida nenhuma DCIL. Este facto pode ser vantajoso reduzindo o tempo de execução do algoritmo de separação.
Se o cálculo dos vários coeficientes das variáveis a fazer levantamento for efetuado usando um algoritmo exato pode demorar muito tempo, dado que á necessária a resoluçao de no máximo n(n +) — |S| subproblemas, no caso de se efetuar o levantamento de todas as variaveis.
Para diminuir o numero de subproblemas, não vamos efetuar o levantamento usual de variaveis nos seguintes casos:
•	Quando a aresta correspondente à variavel a efetuar levantamento pertencer à érvore de suporte de peso mínimo que contém as arestas do conjunto S;
•	Quando a variavel a efetuar levantamento não verificar a seguinte restriçao,
Wij + (n - 2)pmin &amp;lt;W,	(6.4)
onde pmin é o peso ménimo de entre todos os pesos dos arcos (i,j) G A.
Para explicar a razão da condiçao dada por (6.4), podemos pensar que nos varios subproblemas a solução obtida corresponde a uma árvore de suporte que verifica a restricao de peso, isto á, Z}eeET wexe &amp;lt;W. Como no caso do levantamento usual a aresta {i, j} correspondente à variável que se pretende efetuar o levantamento tem de estar na áarvore, entãao a variaável xij toma o valor um, pelo que obtemos wij + Z}ee^\ii-ij}} wexe &amp;lt;W. Assim ficam a faltar introduzir na arvore n — 2 arestas e admitindo que estas arestas a introduzir têm peso mínimo pmin obtemos a seguinte restriçao wij + (n — 2)pmin &amp;lt;W.
Para determinar os coeficientes Pe de forma sequencial vamos descrever um algoritmo aproximado, baseado em relaxaçcãao Lagrangeana que áe adaptado do Algoritmo Alg2 descrito na Seccão 4.4. Aproveitamos para descrever um algoritmo genárico que para aláem de efetuar o levantamento usual de variáaveis tambáem efetua os chamados down-lifting e up-lifting.
Calculo dos coeficientes das variáveis a efetuar levantamento
Vamos considerar que pretendemos efetuar o levantamento da variável xt. Seja
R Ç E0 U Ei U Ef o conjunto de variaveis que já foram sujeitas a levantamento, onde Ei á o conjunto de variaveis fixas a um, E0 á o conjunto de variaveis fixas a zero e Ef = E \ (E0 U Ei U S). Para calcular o coeficiente necessitamos de um algoritmo genárico aproximado que resolva o seguinte problema,
Pt = &amp;lt;|S| — 1 ^2 xe I	eeS
Pexe	y2 Pe(1 — xe): x G X (t),
e€ñn(EoUEf)	eeROEi	J
onde
X (t) =
x G XWMST : xe
1,
e G E1 \ R,xe = 0, e G Eo \ R,xt = 1
t G Ef \ R;
X(t)	x
t G Ei \ R;
X(t)	x
t G Eo \ R.
G XWMST : xe = 1
G XWMST : xe = 1
E1 \ (R u{t}),
E1 \ R,xe = 0,
xe = 0, e G Eo \ R,xt = 0 j&gt;
e G Eo \ (R u {t}),xt = 1 }
(6.5)
(6.6)
(6.7)
(6.8)
e
e
G
G
Recordamos que caso se utilize o conjunto definido por (6.6) estamos a efetuar o levantamento usual de variaveis, no caso de utilizarmos o conjunto definido por (6.7) estamos a efetuar o chamado down-lifting e no caso de utilizarmos o conjunto definido por (6.8) estamos a efetuar o chamado up-lifting. Para resolver o problema (6.5) temos que minimizar a função objetivo |S| — 1 — Eees xe — J2eeRn(-EoUE) Pexe — J2egRnE1 Pe(1 — xe). Tendo por base esta função objetivo vamos considerar uma matriz de custos modificados. Denotamos os custos modificados de cada arco (i, j) G A por cij. Como os custos dos arcos (i, j) G A são iguais aos custos das arestas {i, j} G E, para simplificar a notaçao, definimos apenas os custos modificados das arestas e = {i, j} do seguinte modo
|S 1 —	2 — Sf eRn®! Pf,	se	e	G	S;
|S 1 —	1 — pe — SfeRn®! pf,	se	e	G	R h	(Eo u	Ef);
|S| —	1 — Sfe(RnEi)\{e} pf,	se	e	G	R h	E1.
Inicialmente quando todos os coeficientes Pe das variaveis a efetuar levantamento forem nulos, pretende-se que o maior numero de arestas de S esteja na soluçcãao, pois queremos minimizar a função objetivo. Os custos modificados vão sendo sucessivamente alterados uma vez que dependem dos valores dos coeficientes das variaveis ja levantadas. Sempre que se determina um novo coeficiente os custos são alterados e têm em conta o novo valor obtido.
Para resolver o problema dado em (6.5) vamos usar a relaxação Lagrangeana. Assim, associamos a restricão de peso um multiplicador de Lagrange A (A &gt; 0) e adicionando o produto do multiplicador pela restricão de peso à função objetivo do problema (6.5) e obtemos o seguinte problema relaxado
Pt = min {h(S, R, A, P) : x G XL(t)} ,	(6.9)
onde
h(S,R,A,P) = —AW + |S | — 1 ^2 xe —	Pexe	Pe(1 — xe) + J2 Awexe,
eeS	eeRn(EoUEf)	eeRnEi	eeE
e o conjunto XL(t) é definido por um dos três conjuntos (6.6), (6.7) ou (6.8) com apenas uma alteração, em vez de x G Xwmst = XT h XK, apenas se tem de verificar que as solucoes pertencem ao conjunto formado pelas arvores de suporte, isto e, x G XT.
Os valores ponderados para cada arco (i, j)	A podem ser definidos do seguinte
modo
pij	cij + Awij,
onde o multiplicador de Lagrange, A (A &gt; 0) é dado por
A =
Cm (Ta) - Cm (Tm)
W (Tm ) - W (Ta )
(6.10)
sendo Ta uma árvore de suporte admissável e 7„ uma arvore de suporte nao admissável para o Problema WMST.
Antes da apresentaçao do algoritmo heurístico para calcular o coeficiente das va-riaveis a efetuar levantamento, temos de ter em conta que, dependendo do tipo de levantamento que se está a efetuar (levantamento usual, down-lifting ou up-lifting), á necessário definir alguns critérios para a construção das árvores de suporte.
Critérios para obter árvores
•	Critério de levantamento usual
A érvore de suporte tem de conter a aresta t.
•	Critério de down-lifting
A érvore de suporte não pode conter a aresta t, mas tem de conter as arestas de E1\R.
•	Critério de up-lifting
A arvore de suporte tem de conter a aresta t e nao conter as arestas de E0\R.
Deste modo a seguir encontra-se, de forma resumida, um algoritmo heurístico para calcular os coeficientes das variáveis a efetuar o levantamento. Notemos que de cada vez que a execução deste algoritmo é chamada encontramos o valor de um coeficiente A-
Algoritmo heurístico para o cálculo dos coeficientes das variáveis a efetuar levantamento (HCoef)
Passo 1: Inicializações
Passo 1.1: Obter um limite superior para
Obter, se possível, a árvore de suporte de peso mánimo, TWI, que verifica uma das três condições seguintes:
Se t	E	Ef,	então TwI	verifica o	Critério de levantamento usual.
Se t	E	Ei,	então TWI	verifica o	Critério de down-lifting.
Se t	E	Eo,	então TWI	verifica o	Critério de up-lifting.
Se TWI existir, entao
Se W(TWI) &gt; W, entao
f = 0, STOP.
Caso contréario,
T = T a — wi •
Se t E Ef e CM(Ta) &amp;lt;0, entao
f = 0, STOP.
Caso contréario,
f = 0, STOP.
Passo 1.2: Obter um limite inferior para ft
Obter, se possível, a árvore de suporte de custo modificado mínimo, TcI, que
verifica uma das três condicães seguintes:
Se t E Ef, entao TcI verifica o Critério de levantamento usual.
Se t E Ei, então TcI verifica o Critério de down-lifting.
Se t E Eo, entãao TcI verifica o Critéerio de up-lifting.
Se TcI existir, entao
Se W(TcI) &amp;lt;W, entao
TcI, é a arvore correspondente a solugao ótima.
A = Cm(Ta), STOP.
Caso contrório,
Caso contrário,
ft = 0, STOP.
Passo 2: Obter uma nova árvore
Calcular os valores ponderados pij = Cij + Xwij para cada arco (i, j) G A.
Obter, se possível, a arvore de suporte ponderada mínima, TPI, que verifica uma das três condicões seguintes:
Se t	G	Ef,	então	TPI	verifica o Critério	de	levantamento	usual.
Se t	G	Ei,	então	TpI	verifica o Critério	de	down-lifting.
Se t	G	E0,	então	TPI	verifica o Critério	de	up-lifting.
Calcular CM(TPI), W(TPI) e P(TPI).
Se TPI nao existir, entao
Pt = 0, STOP.
Passo 3: Atualização de limites
Se W(TPI) &amp;lt;W, entõo
atualizar o LS, isto é, se CM(TPI) &amp;lt;CM(Ta) substituir Ta por TPI.
Se t G Ef e CM(Ta) &amp;lt;0, entao
Pt = 0, STOP.
Caso contríario,
atualizar o LI, isto é, se CM(TPI) &gt; CM(Tp) substituir Tp por TPI.
Se Cm (Ta) = Cm (Tp), entõo
Pt = Cm (Ta), STOP.
Passo 4: Critério de paragem
Se |P(Ta) — P(TPI)| &amp;lt;tol, entõo
Ta é a arvore correspondente a soluçao aproximada.
Calcular Pt, usando a relaxacao Lagrangeana dada por (6.9), STOP.
Se t G Ef e Pt &amp;lt;0, entõo Pt = 0.
Caso contréario,
ir para o Passo 2.
Notamos que inicialmente todos os coeficientes e sao nulos. No Passo 1.1 é obtida a éarvore de suporte de peso ménimo que verifica determinado critéerio dependendo do procedimento de levantamento que se esta a efetuar (levantamento usual, down-lifting ou up-lifting), a qual se denota por TWI, onde CM(TWI) e W(TWI) são, respetivamente, o custo modificado e o peso da arvore TWI. Se esta arvore existir e se nao verificar a restriçao de peso, entao nao existe soluçao e o algoritmo termina, sendo = 0. Caso a restricão de peso seja verificada, então foi encontrado um limite superior (LS) para o custo modificado e Ta = TWI. Neste caso, se estivermos a efetuar o levantamento usual (t E Ej) e o custo modificado da arvore Ta for inferior ou igual a zero, entao = 0 e o algoritmo termina. No caso de naão ser possével formar uma éarvore TWI o algoritmo termina, sendo = 0.
No Passo 1.2 obtém-se a érvore de suporte de custo modificado mínimo que verifica determinado critéerio dependendo do procedimento de levantamento que se estéa a efetuar (levantamento usual, down-lifting ou up-lifting), a qual é designada por TCI, onde CM(TCI) e W(TCI) são, respetivamente, o custo modificado e o peso da érvore TCI. Se esta éarvore nãao verificar a restriçcãao de peso, entãao foi encontrado um limite inferior (LI) para o custo modificado e Tp = TCI. No caso de verificacão da restrição de peso significa que foi encontrada a soluçao otima e o algoritmo termina, sendo = CM (TCI). No caso de não ser possível formar uma érvore TCI o algoritmo termina, sendo = 0.
No Passo 2 calculam-se os valores ponderados pij para cada arco (i,j) E A. De seguida ée obtida a éarvore de suporte ponderada ménima que verifica determinado critéerio dependendo do procedimento de levantamento que se estí a efetuar (levantamento usual, down-lifting ou up-lifting), a qual é denotada por TPI, onde CM(TPI) e W(TPI) são, respetivamente, o custo modificado e o peso da érvore TPI. Assim podemos definir os valores ponderados P(TPI) = CM (TPI) + XW(TPI) para um A &gt; 0. No caso de nao ser possível formar uma érvore TPI o algoritmo termina, sendo = 0.
A éarvore TPI ée atualizada no Passo 3. No caso da restriçcaão de peso ser verificada e o custo modificado da érvore TPI nao ser superior ao custo modificado da érvore Ta, entao atualizamos o limite superior (LS) e subtituímos Ta por TPI, nesta situaçao temos ainda de averiguar no caso de estarmos a efetuar o levantamento usual (t E Ej) se o custo modificado que atualizéamos ée inferior ou igual a zero e neste caso o algoritmo termina com = 0. Caso a restriçao de peso seja violada e o custo modificado da érvore TPI nao for inferior ao custo modificado da érvore Tp, entao atualizamos o limite inferior (LI) e subtituímos Tp por TPI. Apos se ter efetuado a atualizacao dos limites podemos verificar se as duas érvores Ta e Tp têm os mesmos custos modificados e em
caso afirmativo o algoritmo termina com Pt = CM(Ta).
Os Passos 2 e 3 são executados ate que se verifique (Ta) - P(TpI)| &amp;lt;tol, e assim o algoritmo termina, sendo Ta a arvore correspondente a soluçao aproximada e Pt e obtido usando a relaxacao Lagrangeana dada por (6.9). No caso do coeficiente Pt ser um numero fracionario arredonda-se o seu valor para o inteiro mais proximo. Se estivermos a efetuar o levantamento usual de variaveis e se o coeficiente Pt for negativo, entao considera-se Pt = 0.
No exemplo que se segue aplicamos o Algoritmo Sep1 para as DCILs ao Exemplo 2.1 e exemplificamos tambem como se efetua o calculo de alguns coeficientes das variaveis a efetuar levantamento usando o Algoritmo HCoef.
Exemplo 6.3.
Dada a DCI, x01 + x04 + x12 &amp;lt;2 obtida na Iteração 1 do Exemplo 6.2. Podemos efetuar o levantamento das restantes variaveis recorrendo à ordenaçao que esta a ser utilizada. Assim a lista de arestas da soluçao da relaxacão linear é dada por ERLOrdW = [{0, 4}, {0,1}, {1, 2}, {3, 4}, {1, 3}]. Como as três primeiras arestas ja se encontram na DCI, então vamos fazer o levantamento das restantes arestas de ERLOrdW utilizando o Algoritmo HCoef para o calculo dos coeficientes das variaveis a efetuar levantamento.
Para exemplificar o funcionamento do Algoritmo HCoef vamos calcular, detalhadamente, e de forma sequencial dois coeficientes. No levantamento da variavel x34 calcula-se o coeficiente P34 do seguinte modo,
P34 = min{2 - x01 - x04 - #12 : x G Xwmst,x34 = 1}-
No Passo 1 do Algoritmo HCoef sãao obtidas as seguintes arvores,
Cm (Twi ) = 2 e W (TWI) = 14
Figura 6.5: Arvores de suporte TcI e TwI obtidas no Passo 1 do Algoritmo HCoef no calculo do coeficiente de levantamento usual ^34.
Ambas as arvores da Figura 6.5 contêm a aresta {3, 4} correspondente a variavel da qual se pretende efetuar o levantamento. A arvore TwI foi obtida no Passo 1.1 e como tem peso 14, verifica a restrição de peso, assim Ta = TWI. No Passo 1.2 e obtida a arvore TCI que nao verifica a restrição de peso, então TM = TCI. Deste modo obtemos um limite inferior e um limite superior para o coeficiente ^34, ou seja,
-1 &amp;lt;Ã4 &amp;lt;2.
No Passo 2 e obtida a arvore de suporte ponderada ménima que contem a aresta {3, 4} (ver Figura 6.6).
Cm (TPi ) = 0 e W (TP ) = 19
Figura 6.6: Arvore de suporte Tpi obtida no Passo 2 do Algoritmo HCoef no calculo do coeficiente de levantamento usual ^34.
No Passo 3 e atualizado o LS, pois CM(TPI) = 0 &amp;lt;2 = CM(Ta), mas como Cm(Ta) = 0, então ^34 = 0.
Para calcular o coeficiente ^13 resolve-se o seguinte problema
^13 = min{2 _ xo1 _ xo4 _ £12 : x G Xwmst,£13 = 1}.
Como a aresta {1,3} pertence a arvore de suporte de peso mínimo que contem as arestas de S (Figura 6.3), entao ^13 = 0.
Note-se que, no caso de aplicarmos o Levantamento de Variaveis LV1, nao se consegue obter nenhuma DCIL.
Para calcular os restantes coeficientes das variaveis que nõo pertencem a soluçõo da relaxacçõao linear temos de as ordenar, por exemplo, por ordem decrescente de peso (Levantamento de Variaveis LV3). Assim, como W03 &gt; w24 &gt; w23 &gt; W02 &gt; w14 vamos começcar por determinar o coeficiente da variavel xo3 resolvendo o seguinte problema
^03 = min{2 _ xo1 _ xo4 _ ^12 : x G Xwmst,xo3 = 1}.
Para determinar o coeficiente ^o3, no Passo 1 do Algoritmo HCoef sao obtidas as seguintes arvores,
Cm (T'WI) = 2 e W (T'WI) = 15
Figura 6.7: Arvores de suporte TcI e TwI obtidas no Passo 1 do Algoritmo HCoef no cálculo do coeficiente de levantamento usual ,d03.
Ambas as arvores da Figura 6.7 contêm a aresta {0, 3} correspondente a variavel da qual se pretende efetuar o levantamento. A arvore TWI foi obtida no Passo 1.1 e como tem peso 15, verifica a restrição de peso, assim Ta = TWI. No Passo 1.2 é obtida
a érvore TcI que nao verifica a restricõo de peso, entao T^ = TcI. Deste modo obtemos um limite inferior e um limite superior para o coeficiente @03, ou seja,
-1 &amp;lt;@03 &amp;lt;2.
No Passo 2 ée obtida a éarvore de suporte ponderada ménima que contéem a aresta {0, 3} (ver Figura 6.8).
Cm (TpI) = 0 e W(TpI) = 22
Figura 6.8: Primeira árvore de suporte Tpi obtida no Passo 2 do Algoritmo HCoef no calculo do coeficiente de levantamento usual ^03.
No Passo 3 ée atualizado o LI, pois
W(Tp,) = 22 &gt; 20 = W e Cm(TpI) = 0 &gt; -1 = Cm(TJ.
Assim temos que
0 &amp;lt;&amp;lt;2.
Volta-se ao Passo 2, onde ée obtida a nova éarvore de suporte ponderada ménima que contem a aresta {0, 3} e que se encontra representada na figura seguinte,
2.
8
Tpi:
Cm (TpI) = 1 e W (TPI) = 18
Figura 6.9: Segunda árvore de suporte TPI obtida no Passo 2 do Algoritmo HCoef no cálculo do coeficiente de levantamento usual ^03.
Agora no Passo 3 á atualizado o LS, pois
W(Tpi) = 18 &amp;lt;20 = W e Cm(Tp,) = 1 &amp;lt;2 = Cm(T«).
Assim temos que
0 &amp;lt;@03 &amp;lt;1.
Voltando ao Passo 3 obtém-se a mesma arvore de suporte da Figura 6.9. Como o critáerio de paragem do algoritmo áe verificado, entãao
@03 = 0,25 x 20 + 1 + 0,25 x 18 = 0,5.
Efetuando o arredondamento para o inteiro mais práximo obtemos
@03 = 1.
De seguida calculam-se os restantes coeficientes de forma sequencial usando tambám o Algoritmo HCoef.
@24 = min{2	—	Xoi — X04 — X03	—	X12	:	x	G Xwmst, X24	=	1}	=	0;
@23 = min{2	—	X01 — X04 — X03	—	X12	:	x	G Xwmst,X23	=	1}	=	0;
@02 = min{2	—	X01 — X04 — X03	—	X12	:	x	G Xwmst, X02	=	1}	=	0;
@14 = min{2	—	X01 — X04 — X03	—	X12	:	x	G Xwmst, X14	=	1}	=	0.
Logo, a DCIL obtida á dada por:
X01 + X04 + X12 + x03 &amp;lt;2.
Esta desigualdade corta a solução fracionária (2,2 &gt; 2). Após a introdução da DCIL no modelo obtóm-se a nova solução da relaxação linear do Procedimento P-WMTZ+C x01 = 1; x12 = 1; x13 = 1 e x34 = 1, com custo de 27 e peso 20. Como esta soluçao ó inteira obtivemos a soluçao otima da instância com apenas a introducão de um corte.
Se aplicarmos o Algoritmo Sep2 ao Exemplo de 5 nodos apenas se forma a DCIL obtida no Algoritmo Sep1.
Figura 6.10: Esquemas de obtenção de uma DCIL dada uma DCIE.
6.1.5	Algoritmo de Separação para as DCILDL
Para obter Desigualdades de Cobertura Implícita Levantada por Down-Lifting (DCILDLs) temos de alterar o Passo 3 de modo a obter uma CI válida para o conjunto restrito XE1 = XWMST C {x : Xf = 1, f E Ex} ea correspondente DCILDL.
Passo 3: Obter uma Desigualdade de Cobertura Implícita Levantada por Down-Lifting
Seja Ei o conjunto de variaveis fixas a um.
Passo 3.1: Obter uma DCI valida para o conjunto restrito X E
Seja S = {}.
Fazer p =1 (inserir em S, a primeira aresta de ERLOrdk tal que e / Ey).
Passo 3.1.1: Construir o conjunto S (sem ciclos)
Atualizar o conjunto S com as primeiras p arestas de ERLOrdk, desde que não formem ciclos e que não pertençam ao conjunto Ey.
Passo 3.1.2: Verificar se S e CI para o conjunto restrito X Ei
Obter a arvore de suporte de peso mínimo T, que inclui as p primeiras arestas de S e as arestas de Ey.
Se W(T) &gt; W, entao
S á uma CI para o conjunto restrito XE1. DCI:	xe &amp;lt;|S| — 1. Ir para o Passo 3.2.
Caso contrário,
Se p &amp;lt;#ERLordk, então
p = p +1.
Voltar ao Passo 3.1.1.
Caso contráario,
naão áe possável formar uma CI.
Passo 3.2: Obter uma DCILDL
Calcular os coeficientes fie, e E R Ç Ey U Ef.
/3e = min &amp;lt;|S| — 1 — ^Xt —	fax —	&amp;amp;(1 — Xt) : x E X(e),
I	tes	teRnEf	teRnEi	I
• e G Ef \ R
X(e) = {x G Xwmst : xt = 1,t G E1 \ R,xe = 1J;
• e G E1 \ R
X(e) = {x G Xwmst : xt = 1,t G E1 \ (R U {e}),x = 0^.
DCILDL: EeSS xe + ^2e&amp;amp;RnEf @exe + E-cRmE, @e(1 xe) &amp;lt;|S|	1-
Inicialmente no Passo 3 consideramos um conjunto de variaveis fixas a um, que designamos por E1, depois no Passo 3.1 obtemos uma DCI valida para o conjunto restrito X E
e no Passo 3.2 efetuamos o calculo dos coeficientes para fazer o levantamento das variaveis de E1 e de Ef = E \ (S U E1) e obter a DCILDL. Assim, para aplicar os algoritmos de separação ao caso das DCILDLs temos que ter em conta os três fatores que se seguem:
•	A escolha do conjunto de variaveis a fixar a um (conjunto E1);
•	A ordem dos procedimentos a adotar para efetuar o levantamento das variaveis;
•	A ordem de determinacão dos coeficientes para efetuar o levantamento das variaveis.
Escolha do Conjunto de Variáveis a Fixar a um, E1
Quando fixamos variaveis a um estamos a fazer com que essas variaveis façam parte da soluçao. Segundo Gu et. al. [29] devem-se selecionar as variaveis com valores mais elevados na solucão da relaxação linear. Assim, propomos os seguintes modos de escolha do conjunto E1:
•	Fixaçao de Variáveis D1 (FVD1)
Fixar a um as variaveis que têm valor um na solucão da relaxacão linear.
•	Fixaçao de Variáveis D2 (FVD2)
Fixar a um as variaveis que têm valor um na soluçao da relaxacão linear e que não pertencem a arvore de suporte de peso mínimo, Tw.
•	Fixação de Variáveis D3 (FVD3)
Fixar a um uma unica variável, a variável de menor peso com valor um na soluçao da relaxação linear e que nao pertence à érvore de suporte de peso ménimo, Tw.
Ordem de Determinação dos Coeficientes no Levantamento das Variáveis
•	Procedimento de Levantamento LD (PL-LD)
Primeiro efetuamos o levantamento sequencial usual e depois o down-lifting.
•	Procedimento de Levantamento DL (PL-DL)
Primeiro efetuamos o down-lifting e depois o levantamento sequencial usual.
Ordem de Determinação dos Coeficientes no Levantamento das Variáveis
Para efetuar o levantamento sequencial usual podemos usar as mesmas ordens propostas na Subsecçao 6.1.4. No down-lifting ordenamos as variéveis por ordem crescente de peso. Podemos efetuar primeiro o levantamento das variéveis com menor peso ou com maior peso.
Note-se que:
•	Quando o numero de variaveis a fixar a um for nulo (E1 = 0), nao se aplica o procedimento down-lifting e aplica-se apenas o procedimento de levantamento sequencial usual, se a DCI vélida para o conjunto restrito XE1 cortar a solucao fracionaria x*;
•	No caso da DCI vélida para o conjunto restrito XE1 conter apenas uma variével, então faz-se apenas o down-lifting, uma vez que se efetuarmos o levantamento sequencial usual os coeficientes são todos nulos.
Para exemplificar o Algoritmo HCoef vamos calcular um coeficiente down-lifting para o Exemplo 2.1.
Exemplo 6.4.
Dada a DCI, x04 &amp;lt;0 vélida para o conjunto restrito XE1 = XWMst A {xe : x01 = x12 = 1}. Para fazer o levantamento da variével x12 e calcular o coeficiente £12 temos de resolver o seguinte problema
£12 = min{-xo4 : x G Xwmst,xi2 = 0,xoi = !}•
Para determinar este coeficiente, no Passo 1 do Algoritmo HCoef sao obtidas duas érvores, as quais contêm a aresta {0,1} e nao contêm a aresta {1, 2} (ver Figura 6.11).
Cm (Tci ) = — 1 e W(TCI) = 24
Figura 6.11: Arvores de suporte TcI e TwI obtidas no Passo 1 do Algoritmo HCoef no cálculo do coeficiente down-lifting ^12 •
A érvore TwI foi obtida no Passo 1.1 e como tem peso 13, verifica a restriçao de peso, assim Ta = TWI. No Passo 1.2 é obtida a arvore TCI que não verifica a restriçao de peso, então TM = TCI. Deste modo obtemos um limite inferior e um limite superior para o coeficiente £12, ou seja,
-1 &amp;lt;£12 &amp;lt;0.
No Passo 2 ée obtida a éarvore de suporte ponderada ménima que contéem a aresta {0,1} e nao contém a aresta {1, 2} (ver Figura 6.12).
6
2
Tpi :
Cm (Tpi ) = -1e W (TPI) = 18
Figura 6.12: Arvore de suporte TPI obtida no Passo 2 do Algoritmo HCoef no cálculo do coeficiente down-lifting ^12-
No Passo 3 é atualizado o LS, pois
W(Tpi) = 18 N 20 = W e CM(TPI) = -1 = Cm(T«).
Assim temos que
P12 = Cm (Ta) = -1.
De seguida calculam-se os restantes coeficientes de forma sequencial usando também o Algoritmo HCoef.
Nas Tabelas 6.7 e 6.8 podemos observar as principais etapas do Algoritmo Sepl para as DCILDLs aplicado ao Exemplo 2.1, onde sao escolhidos dois conjuntos diferentes de fixacçõao de variaéveis.
Iter.	Sepl-DCILDL, FVD3	
	Passo 1	x*: xoi = 1; xo4 = 0,2; x42 = 1; x43 = 0,8; x^ = 0,8 e x^^ = 0,2 Custo = 25,4 e peso = 20
1	Passo 2, 3 e 4	Ordenacão: OrdW E1 = {{1, 2}} DCI: x01 + x04 N 1 DCILDL: x01 + x03 + x04 + x12 N 2 Inserir, corta x* (2,2 &gt; 2).
2	Passo 1	x*: x0i = 1; xi2 = 1; x43 = 1 e x34 = 1 Custo = 27 e peso = 20
Tabela 6.7: Principais resultados por iteração do Algoritmo Sepl para as DCILDLs com fixação de variáveis FVD3 aplicado ao Exemplo 2.1.
Iter.
Sepl-DCILDL, FVD2
1	Passo 1	x*: xoi = 1; xo4 = 0,2; X12 = 1; X13 = 0,8; X34 = 0,8 e X43 = 0,2 Custo = 25,4 e peso = 20
	Passo 2, 3 e 4	Ordenaçao: OrdW Ei = {{0,1}; {1, 2}} DCI: X04 &amp;lt;0 DCILDL: x0i + x04 + xi2 &amp;lt;2 Inserir, corta x* (2,2 &gt; 2).
2	Passo 1	x*: xoi = 1; xo3 ~ 0,1667; xi2 = 1; xi3 « 0,8333 e x34 = 1 Custo = 25,8333 e peso = 20
	Passo 2, 3 e 4	Ordenacão: OrdW Ei = {{0,1}; {1, 2}; {3,4}} DCI: xo3 &amp;lt;0 DCILDL: xoi + xo3 + xi2 &amp;lt;2 Inserir, corta x* (2,1667 &gt; 2).
3	Passo 1	x*: xoi = 0,875; xo2 = 0,125; xo3 = 0,125 xo4 = 0,125; xi2 = 0,875; xi3 = 0,75; x2i = 0,125; x34 = 0,875 e x43 = 0,125 Custo = 26,125 e peso = 20
	Passo 2, 3 e 4	Ordenaçao: OrdW Ei = {} DCI: xo1 + xo3 + xo4 &amp;lt;2. Não corta x* (1,125	2).
Tabela 6.8: Principais resultados por iteracão do Algoritmo Sepl para as DCILDLs com fixação de variáveis FVD2 aplicado ao Exemplo 2.1.
Da observaçao das Tabelas 6.7 e 6.8 podemos concluir que a utilização de diferentes formas de escolher o conjunto E1 podem levar à obtençao de diferentes DCILDLs. Nestes dois exemplos foi utilizado o mesmo procedimento de levantamento das variaveis, PL-LD. Utilizando a fixação de variaveis FVD2 (Tabela 6.8) foram introduzidas no modelo duas DCILDLs e naão foi obtida a soluçcãao otima, enquanto que utilizando a fixação de variaveis FVD3 (Tabela 6.7) so foi introduzida no modelo uma DCILDL, a qual levou a obtenção da solução otima com custo 27 e peso 19.
Caso se utilize o procedimento de levantamento das variaveis PL-DL e as fixaçcãoes de variaveis FVD2 e FVD3 obtêm-se os resultados dados na Tabela 6.7. Assim tambem se pode observar que a utilizacçãao de diferentes procedimentos de levantamento de variaveis pode levar à obtenção de diferentes DCILDLs.
Se aplicarmos o Algoritmo Sep2 ao Exemplo de 5 nodos apenas se forma a DCILDL obtida na Iteração 1 do Algoritmo Sep1 que se encontra na Tabela 6.7.
6.1.6	Algoritmo de Separação para as DCILUL
No caso de pretendermos obter Desigualdades de Cobertura Implécita Levantada por Up-Lifting (DCILULs) temos de alterar o Passo 3, da Seccão 6.1.5 para agora obter uma CI valida para o conjunto restrito XE° = Xwmst {x : Xj = 0, f E Eo} e a correspondente DCILUL. A principal diferença no Passo 3.1 deste algoritmo relativamente ao algoritmo para as DCILDLs é a alteração do conjunto Ex para o conjunto Eo. Deste modo temos de obter uma DCI valida para o conjunto restrito XEo e no Passo 3.1.2 a érvore de suporte de peso mínimo tem de conter as arestas de S, mas naão pode conter as arestas do conjunto Eo.
Passo 3: Obter uma Desigualdade de Cobertura Implícita Levantada por Up-Lifting
Seja Eo o conjunto de variéaveis fixas a zero.
Passo 3.1: Obter uma DCI valida para o conjunto restrito XE°
Seja S = {}.
Fazer p =1 (inserir em S, a primeira aresta de ERLOrdk tal que e / Eo).
Passo 3.1.1: Construir o conjunto S (sem ciclos)
Atualizar o conjunto S com as primeiras p arestas de ERLOrdk, desde que nãao formem ciclos e que naão pertençcam ao conjunto Eo.
Passo 3.1.2: Verificar se S é CI para o conjunto restrito XE°
Obter a aérvore de suporte de peso ménimo T, que inclui as p primeiras arestas de S e cujas arestas de Eo nao pertencam à arvore.
Se W(T) &gt; W, então
S é uma CI para o conjunto restrito XEo.
DCI: £eeSxe &amp;lt;|S| — 1. Ir para o Passo 3.2.
Caso contraério,
Se p &amp;lt;#ERLOrdk, entao
p = p +1.
Voltar ao Passo 3.1.1.
Caso contraério,
naão ée possével formar uma CI.
Passo 3.2: Obter uma DCILUL
Calcular os coeficientes fie, e G R Ç E0 U Ef.
&gt;, = min &amp;lt;|S| — 1 — xt	fitxt : x G X (e),
t^S	tGRn(EoUE f)
•	e G Ef \ R
X(e) = {x G Xwmst : xt = 0,t G Eo \ R,Xe = 1
•	e G Eo \ R
X(e) = {x G Xwmst : Xt = 0,t G Eo \ (R U {e}),xe = 1
DCILUL: ^eeS xe + Segfín(E0UEf) Pexe &amp;lt;|S 1 — 1-
Inicialmente no Passo 3 consideramos um conjunto de variáveis fixas a zero que designamos por Eo, depois no Passo 3.1 obtemos uma DCI válida para o conjunto restrito XE° e no Passo 3.2 efetuamos o calculo dos coeficientes para fazer o levantamento das variaveis de Eo e de Ef = E\(S U Eo) e obter a DCILUL. Assim, para aplicar os algoritmos de separação ao caso das DCILULs temos que ter em conta os três fatores que se seguem:
•	A escolha do conjunto de variáveis a fixar a zero (conjunto Eo);
•	A ordem dos procedimentos a adotar para efetuar o levantamento das variáveis;
•	A ordem de determinacão dos coeficientes para efetuar o levantamento das variáveis.
Escolha do Conjunto das Variáveis a Fixar a zero, Eo
Quando fixamos variaveis a zero estamos a eliminar a possibilidade dessas variáveis estarem na solucão.
•	Fixaçao de Variáveis U1 (FVU1)
Fixar a zero todas as variáveis cujas correspondentes arestas pertencem à árvore de suporte de peso mínimo Tw, e não tomam o valor um (tomam um valor inferior a um) na solução da relaxaçao linear.
•	Fixação de Variáveis U2 (FVU2)
Fixar a zero as variáveis cujas correspondentes arestas pertencem à arvore de suporte de peso mínimo Tw, e têm valor zero na solucao da relaxacao linear.
•	Fixação de Variáveis U3 (FVU3)
Fixar a zero uma unica variável, a de maior peso que tem valor inferior a um na solucao da relaxação linear e cuja correspondente aresta pertence à árvore de suporte de peso mínimo Tw.
•	Fixaçao de Variaveis U4 (FVU4)
Fixar a zero uma unica variável, a de maior peso que tem valor zero na solução da relaxacao linear e cuja correspondente aresta pertence à árvore de suporte de peso mínimo Tw.
Procedimentos a adotar para levantamento das variaveis
•	Procedimento de Levantamento LU (PL-LU)
Primeiro efetuamos o levantamento sequencial usual e depois o up-lifting.
•	Procedimento de Levantamento UL (PL-UL)
Primeiro efetuamos o up-lifting e depois o levantamento sequencial usual.
Ordem de Determinação dos Coeficientes no Levantamento das Variaveis
Para efetuar o levantamento sequencial usual podemos usar as mesmas ordens propostas na Subsecção 6.1.4. No up-lifting ordenamos as variaveis por ordem crescente de peso. Podemos testar se efetuamos primeiro o levantamento das variáveis com menor peso ou com maior peso.
Note-se que:
•	Quando o numero de variáveis a fixar a zero for nulo, ou seja, E0 = 0 não se aplica o procedimento up-lifting e aplica-se apenas o procedimento de levantamento sequencial usual, se a DCI válida para o conjunto restrito XE° cortar a solucao fracionaria x*.
• No caso da DCI vólida para o conjunto restrito XEo conter apenas uma varióvel, então faz-se apenas o up-lifting, uma vez que, se efetuarmos o levantamento sequencial usual os coeficientes são todos nulos.
Para exemplificar o Algoritmo HCoef vamos calcular dois coeficientes up-lifting para o Exemplo 2.1.
Exemplo 6.5.
Dada a DCI, x04 &amp;lt;0 valida para o conjunto restrito XEo = Xwmst A {xe : x02 = x13 = x14 = x23 = 0}. Para fazer o levantamento da varióvel x23 e calcular o coeficiente ^23 temos de resolver o seguinte problema
^23 = min{ — x04 : x ê XWMST ,x23 = 1, x02 = x13 = x14 = 0}-
Para determinar este coeficiente, no Passo 1.1 do Algoritmo HCoef ó obtida a órvore de suporte de peso mínimo que contém a aresta {2, 3} e não contém as restantes arestas de E0 (ver Figura 6.13).
Cm (Twi ) — 0 e W (TWI) — 21
Figura 6.13: Arvore de suporte TwI obtida no Passo 1.1 do Algoritmo HCoef no cálculo do coeficiente up-lifting ^23 •
Como W(TWI) — 21 &gt; 20 — W, então ^23 — 0.
Para calcular o coeficiente ^02 temos de resolver o seguinte problema
^02 — mm{-X)4 : x	Xwmst,xo2 — 1,xi3 — xi4 — 0}.
Para determinar este coeficiente, no Passo 1.1 do Algoritmo HCoef são obtidas duas árvores de suporte que contêm a aresta {0, 2} e nao contêm as arestas {1,3} e {1,4} (ver Figura 6.14).
Figura 6.14: Arvores de suporte TcI e TwI obtidas no Passo 1 do Algoritmo HCoef no cálculo do coeficiente up-lifting do2.
A árvore TwI foi obtida no Passo 1.1 e como tem peso 18, verifica a restriçao de peso, assim Ta = TwI. No Passo 1.2 á obtida a árvore TcI que não verifica a restrição de peso, então T^ = TCI. Deste modo obtemos um limite inferior e um limite superior para o coeficiente ^02, ou seja,
-1 &amp;lt;P02 &amp;lt;0.
No Passo 2 áe obtida a áarvore de suporte ponderada mánima que contáem a aresta {0, 2} e não contám as arestas {1, 3} e {1, 4} (ver Figura 6.15).
Figura 6.15: Arvore de suporte TPI obtida no Passo 2 do Algoritmo HCoef no calculo do coeficiente up-lifting ^02.
No Passo 3 e atualizado o LS, pois
W(Tpi) = 20 = W e Cm(Tpt) = —1 = Cm(Ta).
Assim temos que
@02 = Cm (Ta) = —1.
Os restantes coeficientes são tambem calculados de forma sequencial atraves do Algoritmo HCoef.
Nas Tabelas 6.9 e 6.10 podemos observar as principais etapas do Algoritmo Sep1 para as DCILULs aplicado ao Exemplo 2.1, onde são escolhidos dois procedimentos diferentes de levantamento de variaveis.
Iter.	Sepl-DCILUL, PL-UL	
1	Passo 1	x*: xoi = 1; xo4 = 0,2; X12 = 1; X13 = 0,8; X34 = 0,8 e X43 = 0,2 Custo = 25,4 e peso = 20
	Passo 2, 3 e 4	Ordenação: OrdW Eo = {{0, 2}; {1, 3}; {1,4}; {2, 3}} DCI: xoi + xo4 + xi2 &amp;lt;2 DCILUL: xo1 + xo3 + xo4 + x12 &amp;lt;2 Inserir, corta x* (2,2 &gt; 2).
2	Passo 1	x*: xoi = 1; X12 = 1; X13 = 1 e X34 = 1 Custo = 27 e peso = 20
Tabela 6.9: Principais resultados por iteraçao do Algoritmo Sepl para as DCILULs utilizando o procedimento de levantamento de variáveis PL-UL aplicado ao Exemplo 2.1.
Da observação das Tabelas 6.9 e 6.10 podemos concluir que a utilizaçao de diferentes procedimentos de levantamento das variaveis podem levar à obtenção de diferentes DCILULs. Nestes dois exemplos foram utilizadas as mesmas formas de escolher o conjunto E0. Utilizando o procedimento de levantamento das variaveis PL-LU (Tabela 6.10) foram introduzidas no modelo duas DCILULs e não foi obtida a solução ótima, enquanto que utilizando o procedimento de levantamento das variaveis PL-UL (Tabela 6.9) so foi introduzida no modelo uma DCILUL, a qual levou à obtenção da solução otima com custo 27 e peso 19. Note-se que tal como verificamos para o caso das DCILDLs, a utilizacão de diferentes formas de escolher o conjunto E0 pode levar a obtencçãao de diferentes DCILULs.
Iter.
Sepl-DCILUL, PL-LU
l	Passo 1	x*: xoi = 1; xo4 = 0,2; X12 = 1; X13 = 0,8; X34 = 0,8 e X43 = 0,2 Custo = 25,4 e peso = 20
	Passo 2, 3 e 4	Ordenaçao: OrdW Eo = {{0, 2}; {1, 3}; {1,4}; {2, 3}} DCI: X04 &amp;lt;0 DCILUL: _x02 + x04 _ x13 _ x14 &amp;lt;0. Nao corta x* (_0,6 0).
	Passo 2, 3 e 4	Ordenação: OrdWX E0 = {{0, 2}; {1, 3}; {1,4}; {2, 3}} DCI: x01 &amp;lt;0 DCILUL: x01  x02  x13  x14 &amp;lt;0 Inserir, corta x* (0,2 &gt; 0).
2	Passo 1	x*: x01 = 1; x04 = 0,5; x12 = 1; x13 = 1 e x34 = 0,5 Custo = 25,5 e peso = 20
	Passo 2, 3 e 4	Ordenacçaão: OrdW E0 = {{0,1}; {1, 2}; {2, 3}} DCI: x01 + x04 + x12 &amp;lt;2 DCILUL: x01  x02 + x03 + x04 + x12  x14 &amp;lt;2 Inserir, corta x* (2,5 &gt; 2).
3	Passo 1	x*: x01 « 0,8571; x02 « 0,1429; x04 « 0,2857 x12 « 0,8571; x13 « 0,7143; x21 « 0,1429; x34 « 0,7143; e x43 = 0,2857 Custo = 25,8571 e peso = 20
	Passo 2, 3 e 4	Ordenaçcaão: OrdW E0 = {{0, 2}; {1, 3}; {1,4}; {2, 3}} DCI: x04 &amp;lt;0 DCILUL: _x02 + x04 _ x13 _ x14 &amp;lt;0. Não corta x* (_0,5714	0).
	Passo 2, 3 e 4	Ordenaçao: OrdWX e OrdX E0 = {{0, 2}; {1, 3}; {1,4}; {2, 3}} DCI: x01 &amp;lt;0 DCILUL: x01 _ x02 _ x13 _ x14 &amp;lt;0. Não corta x* (0	0).
Tabela 6.10: Principais resultados por iteraçao do Algoritmo Sepl para as DCILULs utilizando o procedimento de levantamento de variáveis PL-LU aplicado ao Exemplo 2.1.
Se aplicarmos o Algoritmo Sep2 ao Exemplo de 5 nodos apenas se forma a DCILUL obtida na Iteração 1 do Algoritmo Sep1 que se encontra na Tabela 6.9.
6.1.7	Algoritmo de Separação para as DGCIL
Para obter Desigualdades Generalizadas de Cobertura Implícita Levantada (DGCILs) temos de alterar o Passo 3, dado nas Seccoes 6.1.5 e 6.1.6 de modo a usarmos dois conjuntos de variáveis fixas e obter uma DCI válida para o conjunto restrito XU = XWMST G {x : xe = 0, e G E0,xe = 1,e G Ex}, onde U = Eo U Ex e a correspondente DGCIL. A principal diferenca no Passo 3.1 deste algoritmo relativamente aos algoritmos aplicados as DCILDLs e às DCILULs á a alteração do conjunto de variaveis fixas, que neste caso passamos a ter dois conjuntos de variáveis fixas, o conjunto Eo de variáveis fixas a zero e o conjunto Ex de variáveis fixas a um. Deste modo temos que obter uma DCI valida para o conjunto restrito XU, onde no Passo 3.1.2 a arvore de suporte de peso mánimo tem de conter as arestas de S e as arestas do conjunto Ex, mas não pode conter as arestas do conjunto Eo.
Passo 3: Obter uma Desigualdade Generalizada de Cobertura Implícita Levantada
Seja Eo o conjunto de variaveis fixas a zero e Ex o conjunto de variaveis fixas a um.
Passo 3.1: Obter uma DCI valida para o conjunto restrito XU
Seja S = {}.
Fazer p = 1 (inserir em S, a primeira aresta de ERLOrdk tal que e G Eo U Ex).
Passo 3.1.1: Construir o conjunto S (sem ciclos)
Atualizar o conjunto S com as primeiras p arestas de ERLOrdk, desde que nãao formem ciclos e que nãao pertencçam ao conjunto Eo nem ao conjunto Ex .
Passo 3.1.2: Verificar se S e CI para o conjunto restrito XU
Obter a arvore de suporte de peso mánimo T, que inclui as p primeiras arestas de S e as arestas de Ex, mas cujas arestas de Eo nãao pertençcam à árvore.
Se W(T) &gt; W, então
S é uma CI para o conjunto restrito XU.
DCI: J2egSxe — |S| - 1- Ir para o Passo 3.2.
Caso contrério,
Se p &amp;lt;#ERLordk, entao
p = p +1.
Voltar ao Passo 3.1.1.
Caso contrério,
não é possível formar uma CI.
Passo 3.2: Obter uma DGCIL
Calcular os coeficientes 0e, e E R Ç Eo U Ei U Ef.
fie = min |S| — 1 — yxt — e E Ef \ R
X (e)	x
e E Eo \ R
X (e)	x
e E Ei \ R
X (e)	x
^txt -	^t(1 - xt) : x E X(e)
tes	teRn(EoUEy)
teRnEi
•&gt;
E XWMST : xt = 1
•&gt;
Ei
\ R,xt = 0,t E Eo \ R,xe = 1 j*;
E XWMST : xt = 1
E XWMST : xt = 1,
Ei
Ei
\ R,xt = 0,t E Eo \ (R U {e}),Xe =
\ (R U {e}),xt = 0,t E Eo \ R,Xe =
•)




t
t
t
E
E
E
t
DGCIL: EeSS xe + EeSRn(E0UEf) fiexe + EegRnEi fie(1 xe) — |S 1	1.
Inicialmente no Passo 3 consideramos dois conjuntos: um conjunto de variéveis fixas a zero que designamos por Eo, e outro de variaveis fixas a um que designamos por Ei. No Passo 3.1 obtemos uma DCI vélida para o conjunto restrito XU e no Passo 3.2 efetuamos o célculo dos coeficientes para fazer o levantamento das variéveis de Eo, de Ei e de Ef = E\(S U Eo U Ei) e obter a DGCIL. Assim, para aplicar os algoritmos de separaçao ao caso das DGCILs temos que ter em conta os três fatores que se seguem:
• A escolha dos conjuntos de variéveis a fixar a zero (conjunto Eo) e a fixar a um (conjunto Ei);
•	A ordem dos procedimentos a adotar para efetuar o levantamento das variaveis;
•	A ordem de determinação dos coeficientes para efetuar o levantamento das variéveis.
Escolha dos Conjuntos de Variaveis a Fixar a zero e a um, E0 e E1
Como estamos a fixar, simultaneamente, dois conjuntos de variéveis, estamos a fazer com que as variéveis fixas a um façam parte da soluçõo e as variéveis fixas a zero nõo façam parte da solucao.
Para escolha dos conjuntos E0 e E1 propomos efetuar uma combinaçõo das escolhas feitas nas duas subsecções anteriores.
Procedimentos a adotar para levantamento das variaveis
•	Procedimento de Levantamento DUL (PL-DUL)
Primeiro efetuamos o down-lifting, depois o up-lifting e por fim o levantamento sequencial usual.
•	Procedimento de Levantamento UDL (PL-UDL)
Primeiro efetuamos o down-lifting, depois o o levantamento sequencial usual e por fim o up-lifting.
•	Procedimento de Levantamento ULD (PL-ULD)
Primeiro efetuamos o up-lifting, depois o levantamento sequencial usual e por fim o down-lifting.
•	Procedimento de Levantamento DLU (PL-DLU)
Primeiro efetuamos o up-lifting, depois o down-lifting e por fim o levantamento sequencial usual.
•	Procedimento de Levantamento LDU (PL-LDU)
Primeiro efetuamos o levantamento sequencial usual, depois o down-lifting e por fim o up-lifting.
•	Procedimento de Levantamento LUD (PL-LUD)
Primeiro efetuamos o levantamento sequencial usual, depois o up-lifting e por fim o down-lifting.
Ordem de Determinação dos Coeficientes no Levantamento das Variáveis
Para efetuar o levantamento usual podemos usar as mesmas ordens propostas na Subseccao 6.1.4. No up-lifting e no down-lifting ordenamos as variéveis de cada conjunto E0 e E1 por ordem crescente de peso. Podemos testar se efetuamos primeiro o levantamento das variéveis com menor peso ou com maior peso em cada um dos conjuntos.
Note-se que:
•	Quando o numero de variaveis a fixar a zero for nulo, ou seja, E0 = 0 não se aplica o procedimento up-lifting e aplicam-se apenas os procedimentos de levantamento sequencial usual e de down-lifting. Se o numero de variéveis a fixar a um for nulo (E1 = 0) aplicam-se apenas os procedimentos up-lifting e levantamento sequencial usual;
•	Caso os dois conjuntos de variéveis sejam nulos sé se aplica o procedimento de levantamento sequencial usual;
•	No caso da DCI vélida para o conjunto restrito XU conter apenas uma variével, então faz-se up-lifting e down-lifting, uma vez que, se efetuarmos o levantamento sequencial usual em primeiro lugar os coeficientes são todos nulos.
Para calcular os coeficientes das variéveis a efetuar levantamento usa-se o algoritmo aproximado HCoef, descrito na Subsecção 6.1.4.
Exemplo 6.6.
Nas Tabelas 6.11 e 6.12 podemos observar as principais etapas do Algoritmo Sep1 para as DGCILs aplicado ao Exemplo 2.1, onde sõo escolhidos dois procedimentos diferentes de levantamento de variéaveis.
Iter.	Sepl-DGCIL, PL-DLU	
1	Passo 1	x*: xoi = 1; xo4 = 0,2; X12 = 1; X13 = 0,8; X34 = 0,8 e X43 = 0,2 Custo = 25,4 e peso = 20
	Passo 2, 3 e 4	Ordenacão: OrdW Eo = {{0, 2}; {1,4}; {2, 3}} Ei = {{0,1}; {1, 2}} DCI: X04 &amp;lt;0 DGCIL: x01 — x02 + 2x03 + x04 + x12 — x14 &amp;lt;2 Inserir, corta x* (0,2 &gt; 0).
2	Passo 1	x*: x01 = 1; x04 = 0,2; x12 = 1; x13 = 0,6; x14 = 0,2; x34 = 0,6 e x43 = 0,4 Custo = 25,6 e peso = 20
	Passo 2, 3 e 4	Ordenaçcãao: OrdW E0 = {{0, 2}; {2, 3}} E1 = {{0,1}; {1, 2}} DCI: x04 &amp;lt;0 DGCIL: x01 + x03 + x04 + x12 &amp;lt;2 Inserir, corta x* (2,2 &gt; 2).
3	Passo 1	x*: x01 ~ 0,8333; x02 ~ 0,1667; x04 ~ 0,1667 x12 ~ 0,8333; #13 « 0,8333; x21 ~ 0,1667; x34 « 0,8333; e x43 = 0,1667 Custo = 27 e peso = 19,33
Tabela 6.11: Principais resultados por iteração do Algoritmo Sepl para as DGCILs utilizando o procedimento de levantamento de variáveis PL-DLU aplicado ao Exemplo 2.1.
Iter.
Sep1-DGCIL, PL-DUL
1	Passo 1	x*: xoi = 1; xo4 = 0,2; xi2 = 1; xi3 = 0,8; X34 = 0,8 e X43 = 0,2 Custo = 25,4 e peso = 20
	Passo 2, 3 e 4	Ordenação: OrdW Eo = {{0, 2}; {1,4}; {2, 3}} Ei = {{0,1}; {1, 2}} DCI: X04 &amp;lt;0 DGCIL: x01 + x03 + x04 + x12 &amp;lt;2 Inserir, corta x* (2,2 &gt; 2).
2	Passo 1	x*: X01 = 1; X12 = 1; x43 = 1 e X34 = 1 Custo = 27 e peso = 20
Tabela 6.12: Principais resultados por iteração do Algoritmo Sepl para as DGCILs utilizando o procedimento de levantamento de variáveis PL-DLU aplicado ao Exemplo 2.1.
Da observação das Tabelas 6.11 e 6.12 podemos concluir, tal como visto para as DCILDLs e para as DCILULs, que utilizando diferentes procedimentos de levantamento de variáveis podemos encontrar diferentes DGCILs. Nestes dois exemplos foram utilizadas as mesmas formas de escolher os conjuntos E0 e Ei . Utilizando o procedimento de levantamento das variáveis PL-DLU (Tabela 6.11) foram introduzidas no modelo duas DGCILs e naão foi obtida a soluçcaão áotima, enquanto que utilizando o procedimento de levantamento das variáveis PL-DUL (Tabela 6.12) sá foi introduzida no modelo uma DGCIL, a qual levou à obtenção da solução otima com custo 27 e peso 19.
Note-se que tal como verificáamos para o caso das DCILDLs e das DCILULs, utilizando diferentes formas de escolher os conjuntos Eo e Ei pode levar a obtençao de diferentes DGCILs.
Se aplicarmos o Algoritmo Sep2 ao Exemplo de 5 nodos apenas se forma a DGCIL obtida na Iteração 1 do Algoritmo Sep1 que se encontra na Tabela 6.12.
Note-se que a desigualdade váalida
xoi + xo3 + xo4 + xi2 &amp;lt;2	(6.11)
que corta a soluçcãao da relaxaçcãao linear e que com a sua introduçcãao no modelo se consegue obter a soluçcãao áotima foi obtida em todas as desigualdades derivadas de levantamento de variaáveis.
Para obter a desigualdade (6.11) como uma DCIL primeiro obteve-se a DCI, x0i + x04 + xi2 &amp;lt;2 e o coeficiente fi03 = 1 foi obtido efetuando o levantamento usual.
Ao fixar o conjunto E1 = {{1,2}} obtemos também a desigualdade (6.11) como uma DCILDL, onde a DCI, x01 + x04 &amp;lt;1 é vélida para o conjunto restrito XE1 e o coeficiente ^12 = — 1 é obtido efetuando o down-lifting e o coeficiente ^03 = 1 efetuando o levantamento usual.
Ao fixar o conjunto E0 = {{0, 2}; {1, 3}; {1,4}; {2, 3}} obtemos a mesma desigualdade (6.11) como uma DCILUL, onde a DCI, x01 + x04 + x12 &amp;lt;2 e valida para o conjunto restrito XE° e o coeficiente o3 = 1 e obtido efetuando o levantamento usual.
No caso das DGCILs podemos obter a desigualdade (6.11) fixando por exemplo os conjuntos E0 = {{0, 2}; {1,4}; {2, 3}} e E1 = {{0,1}; {1, 2}}, a DCI, x04 &amp;lt;0 e valida para o conjunto restrito XEoUE1 e os coeficientes ^12 = — 1 e ^01 = —1 são obtidos efetuando o down-lifting e o coeficiente o3 = 1 efetuando o levantamento usual.
6.2	Experiencias e Resultados Computacionais
Nesta seccçãao descrevemos algumas experiêencias computacionais realizadas e apresentamos os resultados computacionais dos algoritmos heurísticos de separacao apresen
tados ao longo deste capítulo. Efetuamos tambám uma comparaçao entre os algoritmos de separacçãao com o objetivo de avaliar qual o mais eficiente. Neste sentido pretendemos avaliar a qualidade do valor do limite inferior obtido pela respetiva relaxaçcaão linear.
Assim, para avaliar o limite inferior obtido em cada um dos algoritmos calculamos o
O PT — LI
gap = —opt— x 100, onde LI é o valor do limite inferior obtido para o valor do custo e OPT á o valor átimo (d(WMST)) ou o melhor valor obtido pelo Procedimento
P-WMTZ+C do Capítulo 3.
Relativamente aos tempos de execução vamos analisar em termos médios os tempos usados para a obtencao do valor étimo ou de um limite superior para o valor do custo (tempos de execução da relaxacao linear conjuntamente com os tempos de execução do Algoritmo Branch and Bound).
6.2.1	Experiências realizadas com as DCs e as DCIs
Nas experiências computacionais realizadas com as DCs e com as DCIs foram utilizadas todas as ordenações propostas na Secção 6.1. No caso de se obterem dois valores da relaxacõo linear iguais com a mesma ordenação de arestas mudamos de ordenação.
Na Tabela 6.13 são apresentados os gaps médios, em percentagem, do limite inferior obtidos pelo Procedimento P-WMTZ+CL e por cada um dos Algoritmos Sepl e Sep2 para as DCs e para as DCIs e os respetivos desvios padrões. Note-se que os referidos gaps correspondem aos valores obtidos pelas respetivas relaxações lineares. Os tempos médios, em segundos, apresentados na Tabela 6.13, correspondem aos tempos de execução até obter o valor étimo ou um limite superior para o valor do custo (tempo de execuçao da relaxação linear + tempo de execuçao do Algoritmo Branch and Bound). Na mesma tabela encontram-se os desvios padroães correspondentes aos tempos.
		P-WMTZ+Cl	Sep1-DCs	Sep2-DCs	Sep1-DCIs	Sep2-DCIs
	10	22,292	19,747	19,747	19,451	19,467
Gap Medio (%)	20	9,874	9,627	9,627	9,552	9,562
	40	6,362	6,337	6,337	6,331	6,332
	60	4,830	4,815	4,815	4,810	4,812
	10	7,061	7,217	7,217	7,324	7,335
	20	4,380	4,388	4,388	4,431	4,427
agap	40	0,840	0,838	0,838	0,844	0,843
	60	0,863	0,863	0,863	0,861	0,861
	10	0,109	0,154	0,148	0,151	0,169
Tempo Médio (s)	20	1,350	1,274	1,287	1,372	1,956
	40	41,756	36,886	42,449	35,787	40,408
	60	517,422	553,105	932,913	1513,102	875,270
	10	0,042	0,034	0,043	0,045	0,039
tempo	20	0,867	0,513	0,372	0,947	1,488
	40	29,749	15,673	23,380	22,001	24,511
	60	338,821	407,218	1480,329	2300,852	992,761
Tabela 6.13: Comparação do Procedimento P-WMTZ+CL e dos Algoritmos Sepl e Sep2 nas DCs e nas DCIs nas instancias QC de 10 a 60 nodos.
Em termos de tempos médios de execução, o algoritmo de separação mais rápido
parece ser o Algoritmo Sep1, nas DCs e nas DCIs. No caso das DCIs, apenas em instaâncias de 60 nodos o tempo móedio do Algoritmo Sep1 óe superior ao tempo móedio do Algoritmo Sep2.
Tanto nas DCs como nas DCIs os gaps módios obtidos são muito identicos nos dois Algoritmos Sep1 e Sep2. Os gaps medios mais baixos são obtidos pelo Algoritmo Sep1 com as DCIs. Em qualquer um dos algoritmos os gaps módios são inferiores aos obtidos com o Procedimento P-WMTZ+CL. Os limites inferiores obtidos usando estes algoritmos de separaçao aumentam em 39 das 40 instâncias (de 10 a 60 nodos). Apenas numa das instancias (QC60-9) o limite inferior obtido ó igual ao obtido com o Procedimento P-WMTZ+CL. Os algoritmos para as DCIs são os que obtâm melhores limites inferiores. Deste modo, podemos afirmar que faz sentido fazer o levantamento de uma DCI para obtençcaão de desigualdades derivadas atravóes de procedimentos de levantamento usual.
Em termos móedios, naão se observa uma reduçcãao do tempo quando se aplicam os algoritmos heurísticos de separação comparativamente ao Procedimento P-WMTZ+CL. Podemos observar que hó melhorias de tempo em 32,5% das instancias de 10 a 60 nodos (13 instâncias em 40) no Algoritmo Sep1 para as DCIs.
6.2.2	Experiências Realizadas com as DCIEs
Nas experiâencias computacionais realizadas com as DCIEs tambóem foram utilizadas todas as ordenaçcoães propostas na Secçcaão 6.1. No caso de se obterem dois valores da relaxaçcãao linear iguais com a mesma ordenaçcaão de arestas mudamos de ordenaçcãao.
Na Tabela 6.14 sãao apresentados os gaps móedios, em percentagem, do limite inferior obtidos pelo Procedimento P-WMTZ+CL e por cada um dos Algoritmos Sep1 e Sep2 para as DCIEs e os respetivos desvios padroães. Note-se que os referidos gaps correspondem aos valores obtidos pelas respetivas relaxaçcoães lineares. Os tempos móedios, em segundos, apresentados na Tabela 6.14, correspondem aos tempos de execuçcaão atóe obter o valor óotimo ou um limite superior para o valor do custo (tempo de execuçcãao da relaxaçao linear + tempo de execucão do Algoritmo Branch and Bound). Na mesma tabela encontram-se os desvios padrãoes correspondentes aos tempos.
		P-WMTZ+Cl	Sep1-DCIEs	Sep2-DCIEs
	10	22,292	17,885	13,181
Gap Mádio(%)	20	9,874	9,511	8,995
	40	6,362	6,327	6,249
	60	4,830	4,802	4,782
	10	7,061	7,595	3,667
	20	4,380	4,445	4,001
agap	40	0,840	0,843	0,864
	60	0,863	0,853	0,845
	10	0,109	0,170	0,205
Tempo Medio (s)	20	1,350	1,601	1,669
	40	41,756	36,206	34,171
	60	517,422	897,147	657,020
	10	0,042	0,056	0,065
	20	0,867	1,090	0,857
^tempo	40	29,749	21,568	19,530
	60	338,821	1337,665	584,175
Tabela 6.14: Comparação do Procedimento P-WMTZ+CL e dos Algoritmos Sep1 e Sep2 nas DCIEs nas instâncias QC de 10 a 60 nodos.
Em termos de tempos medios, nas instâncias de 40 e 60 nodos o algoritmo de separação mais rápido para as DCIEs parece ser o Algoritmo Sep2, mas nas instâncias de 10 e 20 nodos o tempo medio do Algoritmo Sep2 e superior ao tempo medio do Algoritmo Sep1.
Quanto aos gaps medios obtidos são inferiores no Algoritmo Sep2. Em qualquer um dos algoritmos os gaps medios são inferiores aos obtidos com o Procedimento P-WMTZ+Cl. Os limites inferiores obtidos usando estes algoritmos heurísticos de separaçcaão aumentam em todas as instâancias (de 10 a 60 nodos).
6.2.3	Experiências Realizadas com as DCILs
De experiêencias computacionais realizadas com as DCILs, verificamos que se utilizarmos todas as ordenacoes propostas na Secção 6.1, pode-se tornar dispendioso do ponto vista computacional. Das véarias experiêencias computacionais efetuadas com combinaçcãoes das diferentes ordenaçcãoes verificamos que com algumas delas, em geral, obtemos as mesmas desigualdades. Assim, decidimos utilizar apenas trêes ordenaçcãoes: OrdW, OrdWX e OrdFixW. Começamos por obter uma desigualdade usando a ordenação de arestas OrdW, depois usamos a ordenação OrdWX e por fim a ordenação OrdFixW. No caso de se obterem dois valores da relaxação linear iguais com a mesma ordenaçcãao de arestas mudamos de ordenacçaão.
Quando tentamos encontrar uma CI formam-se vérias érvores de suporte. Sempre que estas aérvores verifiquem a restricçãao de peso podemos atualizar o limite superior para o custo (LSC) do Problema WMST. Quando se aplica o Algoritmo HCoef para determinar os vaérios coeficientes das variaéveis a efetuar levantamento tambéem se encontram véarias éarvores de suporte que verificam a restricçãao de peso, sendo assim tambéem podemos atualizar o limite superior para o custo do Problema WMST, desde que o custo obtido seja inferior ou igual a LSC. Assim os Algoritmos Sep1 e Sep2 podem terminar no caso do valor obtido na relaxaçcãao linear ser igual ao valor do LSC.
Os resultados computacionais que se apresentam para as duas estratéegias apresentadas na Seccão 6.1.4 usam o levantamento das variaveis LV2, dado que apos a realizaçao de vaérias experiêencias com as diferentes ordens de levantamento apresentadas na Secçcãao 6.1.6 este foi o que apresentou os melhores resultados.
Na Tabela 6.15 sãao apresentados os gaps méedios (em percentagem) do limite inferior obtidos pelo Procedimento P-WMTZ+CL e por cada um dos Algoritmos Sep1 e Sep2 para as DCILs e os respetivos desvios padrãoes. Note-se que os referidos gaps correspondem aos valores obtidos pelas respetivas relaxaçcãoes lineares. Os tempos méedios, em segundos, apresentados na Tabela 6.15, correspondem aos tempos de execução até obter o valor éotimo ou um limite superior para o valor do custo (tempo de execuçcãao da relaxação linear + tempo de execução do Algoritmo Branch and Bound). Na mesma tabela encontram-se os desvios padrãoes correspondentes aos tempos.
Os resultados computacionais apresentados na Tabela 6.15 para o Algoritmo Sep2 foram obtidos usando apenas a Estratéegia DCIL-E2, uma vez que esta estratéegia foi a que apresentou tempos méedios mais baixos para o Algoritmo Sep1.
Sepl
Sep2
		P-WMTZ+Cl	DCIL-E1	DCIL-E2	DCIL-E2
	10	22,292	6,671	9,632	3,910
Gap Médio (%)	20	9,874	0,088	0,096	0,084
	40	6,362	1,515	1,650	2,141
	60	4,830	0,546	0,596	0,984
	10	7,061	5,210	5,690	4,376
	20	4,380	0,277	0,276	0,264
agap	40	0,840	2,541	2,735	2,825
	60	0,863	1,725	1,715	2,034
	10	0,109	0,228	0,189	0,220
Tempo Medio (s)	20	1,350	1,579	1,087	2,000
	40	41,756	55,764	29,259	48,773
	60	517,422	209,591	154,743	375,455
	10	0,042	0,086	0,057	0,041
tempo	20	0,867	0,947	0,824	1,570
	40	29,749	50,803	27,386	37,153
	60	338,821	213,496	293,342	546,707
Tabela 6.15: Comparação do Procedimento P-WMTZ+CL e dos Algoritmos Sepl e Sep2 nas DCILs nas instâncias QC de 10 a 60 nodos.
Relativamente ao Algoritmo Sepl, a Estratégia DCIL-E1 é a que apresenta gap mais baixo, mas em relação ao tempo de execução este e superior ao da Estrategia DCIL-E2 (quase o dobro). Quando se forma uma DCI que não corta a solução da relaxaçcaão linear, obtemos na mesma a DCIL, logo estamos constantemente a resolver subproblemas para obter os coeficientes de levantamento e por vezes a DCIL encontrada não corta a soluçao da relaxação linear. Como podemos observar no Algoritmo Sep2, os gaps em instâncias de 10 e 20 nodos são melhores, mas depois em instâncias de 40 e 60 pioram comparativamente ao Algoritmo Sepl. Usando a Estrategia DCIL-E2, os tempos medios de execuçcaão do Algoritmo Sep2 sãao sempre mais elevados do que no Algoritmo Sep1.
Em qualquer um dos algoritmos, os gaps medios são inferiores aos obtidos com o Procedimento P-WMTZ+CL. Os limites inferiores obtidos usando estes algoritmos heurísticos de separação aumentam em todas as instâncias (de 10 a 60 nodos).
Em termos de tempos méedios verifica-se uma reducçãao em instâancias com 20 ou
mais nodos no Algoritmo Sep1 usando a Estratéegia DCIL-E2 quando comparado com o Procedimento P-WMTZ+CL. Podemos encontrar 60% das instancias de 10 a 60 nodos (24 instâncias em 40) em que os tempos de execuçõo do Algoritmo Sep1 usando a Estratéegia DCIL-E2 sõao inferiores aos tempos de execuçcõao obtidos com o Procedimento P-WMTZ+Cl .
Apés a realizacõo de experiâncias computacionais verificémos que as estratégias propostas na Secçõo 6.1.6 para levantamento de uma DCIE nõo vâm trazer melhorias nem nos gaps nem nos tempos médios de execucõo.
6.2.4	Experiências Realizadas com as DCILDLs
Se pensarmos em fixar a um o conjunto de variaveis que tâm valor um na soluçõo da relaxaçao linear do Procedimento P-WMTZ+C (fixaçõo de variéveis FVD1 da Subsecçcõao 6.1.5), em alguns exemplos, o nuémero de variéaveis a fixar a um pode ser muito grande (quase o mesmo nuémero que o das arestas da éarvore). Por exemplo, em instancias de 10 nodos fixam-se a um cerca de 8 variéveis, em instancias de 20 nodos cerca de 18 variéveis, em instâncias de 40 nodos cerca de 38 variaveis e em instâncias de 60 nodos cerca de 56 variéveis. Para evitar que o conjunto E1 seja demasiado grande vamos apresentar os resultados das quatro estratéegias seguintes.
Estrategia Down-Lifting 1 (DL-E1)
Escolha do conjunto E1: FVD2
Procedimento de levantamento das variaéveis: PL-LD
Estrategia Down-Lifting 2 (DL-E2):
Escolha do conjunto E1: FVD3.
Procedimento de levantamento das variéaveis: PL-LD.
Estrategia Down-Lifting 3 (DL-E3)
Escolha do conjunto E1: FVD2
Procedimento de levantamento das variéaveis: PL-DL
Estrategia Down-Lifting 4 (DL-E4):
Escolha do conjunto E1: FVD3
Procedimento de levantamento das variaéveis: PL-DL
As estratégias apresentadas para o Algoritmo Sepl diferem na escolha do conjunto de variaveis a fixar a um e na ordem dos procedimentos para levantamento das variéveis.
Na Tabela 6.16 são apresentados os gaps médios (em percentagem) do limite inferior obtidos pelo Procedimento P-WMTZ+CL e por cada um dos Algoritmos Sepl e Sep2 para as DCILDLs e os respetivos desvios padrães. Note-se que os referidos gaps correspondem aos valores obtidos pelas respetivas relaxaçães lineares. Os tempos médios, em segundos, apresentados na Tabela 6.16, correspondem aos tempos de execução até obter o valor otimo ou um limite superior para o valor do custo (tempo de execucão da relaxação linear + tempo de execução do Algoritmo Branch and Bound). Na mesma tabela encontram-se os desvios padrãoes correspondentes aos tempos.
Os resultados computacionais apresentados na Tabela 6.16 para o Algoritmo Sep2 foram obtidos usando apenas a Estratégia DL-E3, uma vez que esta estratégia se mostrou a mais eficiente em termos de tempos méedios e de gaps méedios para o Algoritmo Sep1.
		Sép1					Sep2
		P-WMTZ+Cl	DL-E1	DL-E2	DL-E3	DL-E4	DL-E3
	10	22,292	10,617	10,699	8,891	8,891	5,622
Gap Médio (%)	20	9,874	3,359	2,524	1,304	1,300	0,565
	40	6,362	5,713	4,114	0,940	1,263	1,035
	60	4,830	4,047	2,859	0,382	0,409	0,695
	10	7,061	6,964	6,274	6,151	6,151	5,773
	20	4,380	3,877	3,111	2,604	2,602	1,005
agap	40	0,840	1,480	1,471	2,217	2,295	2,254
	60	0,863	1,470	1,039	1,096	1,097	1,450
	10	0,109	0,208	0,220	0,195	0,198	0,251
Tempo Médio (s)	20	1,350	1,504	1,467	1,157	1,148	2,073
	40	41,756	51,654	65,114	27,474	30,176	40,378
	60	517,422	481,450	193,296	73,554	78,639	204,174
	10	0,042	0,078	0,086	0,070	0,069	0,055
^tempo	20	0,867	1,506	1,469	0,969	1,073	1,677
	40	29,749	36,275	65,476	34,029	35,130	45,521
	60	338,821	552,349	388,098	89,572	93,186	243,529
Tabela 6.16: Comparacão do Procedimento P-WMTZ+CL e dos Algoritmos Sep1 e Sep2 nas DCIL-
DLs nas instâncias QC de 10 a 60 nodos.
No Algoritmo Sep1 as Estratéegias DL-E3 e DL-E4 sãao as mais réapidas e estas sãao comparíveis em termos de tempo médio de execuçao. Quanto a qualidade das soluçães obtidas ée preferével utilizar a Estratéegia DL-D3, pois para instêancias de 40 e 60 nodos os gaps médios são inferiores aos obtidos através da Estratégia DL-E4. Os gaps médios obtidos pelo Algoritmo Sep2 para instências de 10 e 20 nodos são mais baixos que os obtidos pelo Algoritmo Sep1 usando a mesma estratégia, mas tendem a piorar em instêancias de 40 e 60 nodos. Em termos de tempo de execucçãao a Estratéegia DL-E3 do Algoritmo Sep1 apresenta melhores resultados quando comparada com a mesma estratéegia do Algoritmo Sep2.
Em qualquer um dos algoritmos os gaps médios são inferiores aos obtidos com o Procedimento P-WMTZ+CL. Os limites inferiores obtidos usando estes algoritmos heurísticos de separação aumentam em todas as instências (de 10 a 60 nodos).
Em termos de tempos méedios verifica-se uma reducçãao em instêancias com 20 ou mais nodos no Algoritmo Sep1 usando a Estratéegia DL-E3 quando comparado com o Procedimento P-WMTZ+CL. Podemos encontrar 65% das instancias de 10 a 60 nodos (26 instaências em 40) em que os tempos de execuçcaão do Algoritmo Sep1 usando a Estratéegia DL-E3 saão inferiores aos tempos de execucçaão obtidos com o Procedimento P-WMTZ+Cl .
6.2.5	Experiências Realizadas com as DCILULs
Para encontrar DCILULs realizaram-se várias experiencias efetuando combinaçães das diferentes formas de escolher o conjunto Eo com os vários procedimentos de levantamento das variáveis propostos na Subseccão 6.1.6, das quais apresentamos as quatro melhores:
Estratágia Up-Lifting 1 (UL-E1)
Escolha do conjunto Eo: FVU3
Procedimento de levantamento das variaveis: PL-LU
Estratégia Up-Lifting 2 (UL-E2):
Escolha do conjunto Eo: FVU4
Procedimento de levantamento das variaveis: PL-LU
Estratégia Up-Lifting 3 (UL-E3):
Escolha do conjunto Eo: FVU2
Procedimento de levantamento das variaveis: PL-UL
Estratégia Up-Lifting 4 (UL-E4):
Escolha do conjunto Eo: FVU4
Procedimento de levantamento das variaveis: PL-UL
As estratégias apresentadas para o Algoritmo Sepl diferem na escolha do conjunto de variéveis a fixar a zero e na ordem dos procedimentos de levantamento das variéveis.
Na Tabela 6.17 são apresentados os gaps médios (em percentagem) do limite inferior obtidos pelo Procedimento P-WMTZ+CL e por cada um dos Algoritmos Sepl e Sep2 para as DCILULs e os respetivos desvios padrães. Note-se que os referidos gaps correspondem aos valores obtidos pelas respetivas relaxaçães lineares. Os tempos médios, em segundos, apresentados na Tabela 6.17, correspondem aos tempos de execução até obter o valor otimo ou um limite superior para o valor do custo (tempo de execução da relaxaçao linear + tempo de execuçao do Algoritmo Branch and Bound). Na mesma tabela encontram-se os desvios padrãoes correspondentes aos tempos.
Os resultados computacionais apresentados na Tabela 6.17 para o Algoritmo Sep2 foram obtidos usando apenas a Estratéegia UL-E4, uma vez que esta estratéegia se mostrou a mais eficiente em termos de tempos méedios e de gaps méedios para o Algoritmo Sep1.
		P-WMTZ+Cl	UL-E1	UL-E2	UL-E3	UL-E4	UL-E4
	10	22,292	13,788	7,694	9,652	9,280	4,844
Gap Medio (%)	20	9,874	6,791	6,489	0,902	1,025	0,978
	40	6,362	4,103	3,701	2,119	2,101	2,041
	60	4,830	2,691	2,866	1,453	0,773	1,267
	10	7,061	3,621	4,400	3,889	4,275	4,475
	20	4,380	5,685	4,993	2,098	2,476	2,331
agap	40	0,840	2,128	1,885	2,807	2,782	2,715
	60	0,863	1,556	1,514	2,359	1,690	2,097
	10	0,109	0,203	0,229	0,289	0,262	0,273
Tempo Médio (s)	20	1,350	2,231	2,003	2,511	1,861	2,984
	40	41,756	89,639	114,625	72,127	54,137	72,101
	60	517,422	659,180	427,924	248,016	190,024	351,448
	10	0,042	0,093	0,053	0,078	0,091	0,100
&amp;amp; tempo	20	0,867	1,108	1,418	3,456	1,483	2,848
	40	29,749	88,168	175,842	86,058	43,831	55,188
	60	338,821	1093,039	526,810	254,598	239,052	330,918
Tabela 6.17: Comparação do Procedimento P-WMTZ+CL e dos Algoritmos Sepl e Sep2 nas DCI-
LULs nas instâncias QC de 10 a 60 nodos.
No Algoritmo Sep1, as Estratógias UL-E3 e UL-E4, em geral, são as que apresentam gaps mais baixos e os menores tempos móedios de execuçcãao.
No Algoritmo Sep2, os gaps módios obtidos para instâncias ató 40 nodos sao menores do que os obtidos pelo Algoritmo Sep1 usando a mesma estratógia, mas tendem a piorar em instâancias de 60 nodos. A nóvel de tempo de execuçcãao óe preferóvel aplicar a Estratóegia UL-E4 do Algoritmo Sep1.
Em qualquer um dos algoritmos os gaps móedios sãao inferiores aos obtidos com o Procedimento P-WMTZ+CL. Os limites inferiores obtidos usando estes algoritmos heurósticos de separaçcãao aumentam em todas as instâancias (de 10 a 60 nodos).
Em termos de tempos móedios verifica-se uma reducçãao em instâancias com 20 ou mais nodos no Algoritmo Sep1 usando a Estratóegia UL-E4 quando comparado com o Procedimento P-WMTZ+CL. Podemos encontrar 42,5% das instancias de 10 a 60 nodos (17 instâancias em 40) em que os tempos de execuçcãao do Algoritmo Sep1 usando a Estratóegia UL-E4 sãao inferiores aos tempos de execuçcaão obtidos com o Procedimento P-WMTZ+Cl .
6.2.6	Experiências Realizadas com as DGCILs
Depois de realizadas várias experiências computacionais com as diferentes combinações possíveis entre as escolhas dos conjuntos Eo e Ex e os diferentes procedimentos de levantamento das variaveis escolheram-se as três que apresentam melhores resultados para as DGCILs, as quais se encontram descritas a seguir.
Estratégia Generalizada 1 (GL-E1)
Escolha do conjunto Ex: FVD2 Escolha do conjunto Eo: FVU3 Procedimento de levantamento das variáveis: PL-DUL
Estratégia Generalizada 2 (GL-E2):
Escolha do conjunto Ex: FVD2 Escolha do conjunto Eo: FVU3 Procedimento de levantamento das variáaveis: PL-UDL
Estratégia Generalizada 3 (GL-E3)
Escolha do conjunto Ex: FVD2 Escolha do conjunto Eo: FVU3 Procedimento de levantamento das variaáveis: PL-ULD
As estratágias apresentadas para o Algoritmo Sepl diferem na escolha dos conjuntos de variáveis a fixar a zero e a um e na ordem dos procedimentos de levantamento de variáaveis.
Na Tabela 6.18 sõo apresentados os gaps médios (em percentagem) do limite inferior obtidos pelo Procedimento P-WMTZ+CL e por cada um dos Algoritmos Sepl e Sep2 para as DGCILs e os respetivos desvios padrões. Note-se que os referidos gaps correspondem aos valores obtidos pelas respetivas relaxações lineares. Os tempos médios, em segundos, apresentados na Tabela 6.18, correspondem aos tempos de execucõo até obter o valor otimo ou um limite superior para o valor do custo (tempo de execuçõo da relaxaçõo linear + tempo de execuçõo do Algoritmo Branch and Bound). Na mesma tabela encontram-se os desvios padrõoes correspondentes aos tempos.
Os resultados computacionais apresentados na Tabela 6.18 para o Algoritmo Sep2 foram obtidos usando apenas a Estratégia GL-E2, uma vez que esta estratégia se
mostrou a mais eficiente em termos de tempos mádios de execução para o Algoritmo Sep1.
		Sep1			Sep2	
		P-WMTZ+Cl	GL-E1	GL-E2	GL-E3	GL-E2
	10	22,292	7,533	9,477	8,009	6,493
Gap Mádio (%)	20	9,874	1,130	1,201	1,595	1,202
	40	6,362	1,940	2,119	3,570	2,020
	60	4,830	0,846	0,949	1,649	0,921
	10	7,061	5,907	5,853	4,665	3,939
	20	4,380	2,134	2,333	2,479	2,338
agap	40	0,840	2,713	2,771	1,730	2,659
	60	0,863	1,872	2,027	1,984	1,964
	10	0,109	0,374	0,292	0,389	0,299
Tempo Mádio (s)	20	1,350	2,178	2,052	2,086	2,828
	40	41,756	76,569	68,194	137,023	100,902
	60	517,422	456,713	339,516	445,974	369,289
	10	0,042	0,133	0,122	0,174	0,107
&amp;amp; tempo	20	0,867	2,766	3,211	3,091	2,650
	40	29,749	60,440	81,144	154,134	111,226
	60	338,821	532,450	473,387	495,796	410,294
Tabela 6.18: Comparação do Procedimento P-WMTZ+CL e dos Algoritmos Sep1 e Sep2 nas DG-
CILs nas instâncias QC de 10 a 60 nodos.
No Algoritmo Sep1, a Estratágia GL-E2 á a mais rápida e a Estratágia GL-E1 á a que obtám gaps mais baixos.
No Algoritmo Sep2, os gaps mádios obtidos para instancias de 10, 40 e 60 nodos são menores do que os obtidos pelo Algoritmo Sep1 usando a mesma estratágia. A nível de tempo de execuçao á preferível aplicar a Estratágia GL-E2 do Algoritmo Sep1.
Em qualquer um dos algoritmos os gaps médios são inferiores aos obtidos com o Procedimento P-WMTZ+CL. Os limites inferiores obtidos usando estes algoritmos heurísticos de separação aumentam em todas as instâncias (de 10 a 60 nodos).
Em termos de tempos máedios verifica-se uma reducçãao apenas em instaências de 60 nodos no Algoritmo Sep1 usando a Estratáegia GL-E2 quando comparado com o Procedimento P-WMTZ+CL. Podemos encontrar 50% das instancias de 10 a 60 nodos (20 instaências em 40) em que os tempos de execucçaão do Algoritmo Sep1 usando a
Estrategia GL-E2 sao inferiores aos tempos de execucão obtidos com o Procedimento P-WMTZ+Cl .
6.2.7	Comparação dos Algoritmos de Separação
Com o objetivo de comparar as melhores estratégias de separação obtidas nas subsecções anteriores elaboramos os gráficos das Figuras 6.16, 6.17 e 6.18. No grafico da Figura 6.16 comparamos os tempos de execução na obtenção do valor otimo ou de um limite superior para o valor do custo (tempo de execucao da relaxaçao linear + tempo de execucão do Algoritmo Branch and Bound) entre o Procedimento P-WMTZ+C e as melhores estrategias heurísticas de separação. No grafico da Figura 6.17 apresentam-se as percentagens de soluçcoães otimas obtidas com as melhores estrategias de separacçaão. Finalmente, no grafico da Figura 6.18 comparamos o numero de nodos usado no Algoritmo Branch and Bound entre o Procedimento P-WMTZ+C e as melhores estrategias heurísticas de separacão.
Figura 6.16: Percentagem de instâncias, em cada uma das melhores estratágias heurísticas de separaçao com tempo inferior ao tempo do Procedimento P-WMTZ+CL em instancias QC de 10 a 60 nodos.
As Estratéegias DCIL-E2 e DL-E3 sãao as que apresentam a maior percentagem de instêancias com tempo inferior ao tempo obtido na execucçaão do Procedimento P-WMTZ+C.
Figura 6.17: Percentagem de soluções ótimas obtidas com as melhores estratégias heurísticas de separação em instâncias QC de 10 a 60 nodos.
Em todas as estratégias heurísticas de separação apresentadas no grífico da Figura 6.17, a percentagem de soluçcãoes éotimas ée superior ou igual a 50%.
Figura 6.18: Percentagem de instâncias, em cada uma das melhores estratégias heurísticas de separação com o nUmero de nodos no Branch and Bound inferior ao nUmero usado pelo Procedimento P-WMTZ+C em instâncias QC de 10 a 60 nodos.
Podemos observar no gráfico da Figura 6.18 que as estratágias heurísticas de se-paraçao apresentadas usam um numero de nodos no Branch and Bound inferior ao numero de nodos no Branch and Bound usado pelo Procedimento P-WMTZ+C. As Estratágias DL-E3, GL-E1 e GL-E2 são as que apresentam uma maior percentagem de instêancias em que o nuámero de nodos no Branch and Bound áe inferior ao nuámero de nodos usados pelo Branch and Bound do Procedimento P-WMTZ+C.
Na Tabela 6.19 resumem-se os resultados computacionais mais relevantes referentes ao Procedimento P-WMTZ+CL e aos melhores algoritmos heurísticos de separaçao. Apresentam-se os gaps mádios (em percentagem) do limite inferior e os respetivos desvios padrães. Note-se que os referidos gaps correspondem aos valores obtidos pelas respetivas relaxaçcoães lineares.
Os tempos mádios, em segundos, apresentados na Tabela 6.19, correspondem aos tempos de execuçcãao atáe obter o valor áotimo ou um limite superior para o valor do custo (tempo de execuçcãao da relaxaçcãao linear + tempo de execuçcãao do Algoritmo Branch and Bound). Na mesma tabela encontram-se os desvios padroes correspondentes aos tempos.
236
			DCILs	DCILDLs	DCILULs		DGCILs	
		P-WMTZ+Cl	DCIL-E2	DL-E3	UL-E3	UL-E4	GL-E1	GL-E2
	10	22,292	9,632	8,891	9,652	9,280	7,533	9,477
Gap Médio (%)	20	9,874	0,096	1,304	0,902	1,025	1,130	1,201
	40	6,362	1,650	0,940	2,119	2,101	1,940	2,119
	60	4,830	0,596	0,382	1,453	0,773	0,846	0,949
	10	7,061	5,690	6,151	3,889	4,275	5,907	5,853
	20	4,380	0,276	2,604	2,098	2,476	2,134	2,333
agap	40	0,840	2,735	2,217	2,807	2,782	2,713	2,771
	60	0,863	1,715	1,096	2,359	1,690	1,872	2,027
	10	0,109	0,189	0,195	0,289	0,262	0,374	0,292
Tempo Médio (s)	20	1,350	1,087	1,157	2,511	1,861	2,178	2,052
	40	41,756	29,259	27,474	72,127	54,137	76,569	68,194
	60	517,422	154,743	73,554	248,016	190,024	456,713	339,516
	10	0,042	0,057	0,070	0,078	0,091	0,133	0,122
&amp;amp;tempo	20	0,867	0,824	0,969	3,456	1,483	2,766	3,211
	40	29,749	27,386	34,029	86,058	43,831	60,440	81,144
	60	338,821	293,342	89,572	254,598	239,052	532,450	473,387
	10	60	28	21	21	15	13	18
NA Médio de Nodos no B&amp;amp;B	20	1158	8	289	595	514	136	304
	40	28775	4828	2603	7874	6396	5763	7439
	60	171415	32697	2744	23751	7228	12236	14536
Tabela 6.19: Comparação do Procedimento P-WMTZ+CL e dos melhores algoritmos heurásticos de separacão nas instancias QC de 10 a 60 nodos.
Em relação ao gap médio mais baixo, podemos observar que nas instâncias de 10 nodos e obtido usando a Estratégia GL-E1, nas instâncias de 20 nodos e obtido usando a Estrategia DCIL-E2 e para 40 e 60 nodos usando a Estrategia DL-E3.
As Estrategias DCIL-E2 e DL-E3 são as mais rápidas. Em relacão à Estrategia DCIL-E2 apresenta tempos medios inferiores em instâncias de 10 e 20 nodos. A medida que o numero de nodos aumenta a Estrategia DL-E3 torna-se mais rápida (instâncias de 40 e 60 nodos).
Em relação ao numero de nodos no Branch and Bound tambem se obtem melhores resultados usando a Estrategia DL-E3.
6.2.8	Resultados Computacionais
Nesta subseccão vamos apresentar os resultados computacionais das duas melhores estrategias heurísticas de separação, isto é, das Estrategias DCIL-E2 e DL-E3 para instâncias Quase Caminhos de 80, 100 e 150 nodos. Para estas estratégias heurísticas de separação e para o Procedimento P-WMTZ+CL apresentamos na Tabela 6.20 os gaps médios (em percentagem) do limite inferior e os respetivos desvios padrães. Note-se que os referidos gaps correspondem aos valores obtidos pelas respetivas relaxacoes lineares.
Os tempos médios, em segundos, apresentados na Tabela 6.20, correspondem aos tempos de execuçcãao atée obter o valor éotimo ou um limite superior para o valor do custo (tempo de execução da relaxacão linear + tempo de execucão do Algoritmo Branch and Bound). Na mesma tabela encontram-se os desvios padrães correspondentes aos tempos.
		P-WMTZ+Cl	DCIL-E2	DL-E3
	80	3,778	0,643	0
Gap Médio (%)	100	3,192	0,254	0
	150	1,680	1,103	0,737
	80	0,884	1,356	0
agap	100	0,274	0,802	0
	150	0,360	0,775	0,994
	80	2535,069	422,553	74,436
Tempo Medio (s)	100	10596,601	1322,044	234,924
	150	10804,610	7437,602	4838,626
	80	2095,415	641,694	25,973
fyempo	100	645,980	3333,550	119,356
	150	1,819	4137,739	4669,236
	80	426456	47044	12
N.Q Médio de Nodos no B&amp;amp;B	100	1020861	35802	1
	150	322897	201438	116934
Tabela 6.20: Comparação do Procedimento P-WMTZ+CL e dos dois melhores algoritmos heurísticos de separação nas instancias QC de 80 a 150 nodos.
Em instâncias Quase Caminhos de 80 a 150 nodos, quando se aplica a Estratégia DCIL-E2 do Algoritmo Sep1 obtém-se 66,7% de instâncias com solução ótima (20 em 30 instancias). Com a aplicacão da Estratégia DL-E3 do Algoritmo Sep1 obtemos 86,67% (26 em 30 instancias). Os gaps médios mais baixos e os tempos médios mais baixos são obtidos usando a Estratégia DL-E3. A Estratégia DL-E3 reduz significativamente o numero de nodos no Branch and Bound. Assim, a Estratégia DL-E3 parece ser a mais eficiente.
Instâncias Aleatórias e Euclideanas
Para instâncias do grupo Aleatérias e Euclideanas, o Procedimento P-WMTZ+C é relativamente répido na obtenção do valor étimo para instancias com menos de 300 nodos no caso das instancias Aleatérias e com menos de 200 nodos no caso das instâncias Euclideanas. Em instancias de maiores dimensoes a relaxacão linear do Procedimento P-WMTZ+C é mais demorada do que a obtencão do valor otimo depois de entrar em Branch and Bound. Deste modo, em termos de tempo nao temos
vantagens em usar a introducçaão de desigualdades como planos de corte usando as estratégias heurísticas de separação. Foram efetuadas algumas experiências com algumas das instências Aleatórias e Euclideanas e verifica-se que quando se aplica a Estratégia DL-E3 das DCILDLs, o numero de nodos no Branch and Bound, em geral, diminui comparativamente ao numero de nodos no Branch and Bound obtido pelo Procedimento P-WMTZ+C.
6.2.9	Síntese dos Resultados Computacionais
Os melhores resultados são obtidos usando o Algoritmo Sep1, onde em cada iteração á introduzida apenas uma desigualdade válida.
A percentagem de soluçães átimas obtida em todas as intências á de 62,86% (44 em 70 instências) usando a Estratégia DCIL-E2 das DCILs e de 68,57% (48 em 70 instancias) usando a Estratágia DL-E3 das DCILDLs. Para instências Quase Caminhos de 10 a 60 nodos, de entre as várias estratágias usadas ao aplicar o Algoritmo Sep1, as duas melhores estratáegias de separaçcaão saão a Estratáegia DCIL-E2 e a Estratáegia DL-E3, as quais obtêem as soluçcãoes de melhor qualidade no menor tempo. Para instências de 80 a 150 nodos concluímos que a Estratágia DL-E3 das DCILDLs á a que apresenta os melhores resultados.
240
Capítulo 7
Método Feasibility Pump
A Heurística Feasibility Pump (FP) é uma sequencia de arredondamentos de soluções fracionéarias obtidas atravées da relaxaçcaõo linear que conduz, no caso do Problema WMST, a uma soluçao inteira admissével (caso exista alguma), em que o seu custo ée o valor éotimo ou um limite superior para o valor oétimo.
Quando se usam formulações, os solvers dos vérios pacotes de Otimizacõo tais como, o do software Xpress, em algumas instancias diféceis gastam muito tempo a determinar a primeira solucçaõo admissével. Por esse motivo, o desenvolvimento de méetodos heurésticos genéericos que interagem com pacotes de resoluçcõao têem mostrado grande im-portaência, do ponto de vista préatico, para encontrar uma primeira soluçcõao admissével em problemas diféceis.
O Método Feasibility Pump é um esquema heurístico bastante utilizado devido à sua rapidez e também à qualidade da primeira soluçao admissével encontrada. Foi proposto por Fischetti, Glover e Lodi [18] com o objetivo de encontrar soluções admisséveis (se existir alguma) para problemas genéericos de Programacçõao Linear Inteira Mista (MIP - Mixe.d-Inte.ger Linear Programming). Posteriormente, o método foi melhorado por Fischetti, Bertacco e Lodi [12] e por Achterberg e Berthold [2].
Neste capétulo apresentamos alguns conceitos importantes para a aplicacçõao do Méetodo Feasibility Pump e descrevemos uma Heuréstica Feasibility Pump baésica aplicada ao Problema WMST na Seccõo 7.1. Com o objetivo de melhorar a qualidade das soluções obtidas apresentamos, na Secçõo 7.2, uma versõo onde se altera a funçõo objetivo na Heuréstica Feasibility Pump aplicada ao Problema WMST. Na Secçcõao 7.3 apresentamos algumas extensoões do méetodo com o objetivo de melhorar o seu desempenho quando aplicado ao Problema WMST. De seguida, na Secçao 7.4 apresentamos
o comportamento da Heurística Feasibility Pump do ponto de vista geomátrico, no caso geral e no caso particular do problema em estudo. Na uáltima secçcãao começcamos por descrever e discutir algumas experiências computacionais realizadas. Posteriormente, apresentamos os resultados obtidos usando quatro estratágias Heurísticas Feasibility Pump e, por fim, comparamos as estratáegias heurásticas propostas, em termos de qualidade da soluçcãao admissável determinada e de tempo de execuçcãao, com a Heurástica do software Xpress aplicada ao nodo raiz utilizando a Formulacao WMTZ e tambám com a primeira soluçcaão inteira admissável obtida atraváes da Formulaçcãao WMTZ quando usa o procedimento Branch and Bound. Para terminar o capátulo apresentamos uma sántese dos resultados computacionais obtidos.
7.1 Heurística Feasibility Pum Basica Aplicada ao
Problema WMST
Para aplicar a Heurística Feasibility Pump Bésica ao Problema WMST, começamos por obter a soluçõo étima da relaxaçõo linear de uma formulaçõo para o Problema WMST, a qual designamos por x* G XL. Denotamos por C(x*), o custo da soluçao x* e por W(x*), o peso da soluçao x*. Caso a solucao x* seja inteira, entõo à soluçao x* G Xwmst corresponde a arvore de suporte Tx*.
Designamos por x o ponto que é obtido por arredondamento do ponto x da seguinte forma: xij = [xj], para todo o arco (i, j) G A, sendo [.] o operador escalar de arredondamento. No caso do operador de arredondamento para o inteiro mais príximo, o arredondamento de cada variéavel seria efetuado da seguinte forma:
_	1, se xij &gt; 0,5
xij = S
0, caso contréario
, (b j) G A-
Deste modo, todas as componentes xij, V(z, j) G A, de x sao inteiras e este ponto pode ser considerado uma soluçõo inteira. Denotamos por C(x), o custo da solucao x e por W(x), o peso da soluçao x. Em geral, a referida solucõo nõo é admissível, embora em alguns casos possa ser uma solucao inteira admissível. Caso a soluçõo x corresponda a uma érvore de suporte esta sera designada por Tx, e o custo seré denotado por C(Tx) e o peso por W (Tj).
Exemplo 7.1.
Consideramos as variíveis com solução positiva na solução da relaxação linear
(Exemplo 3.2),
x* : x01 = 1; x04 = 0,2; x12 = 1; x13 = 0,8; x34 = 0,8 e x43 = 0,2;
relativa a instância de 5 nodos obtida no Exemplo 2.1. Se efetuarmos o arredondamento para o inteiro mais proximo de todas as variíveis (com solução positiva), obtemos a solucçãao,
x = [x*] : x01 = 1; x04 = 0; x12 = 1; x13 = 1; x34 = 1 e x43 = 0.
A esta soluçao x corresponde a írvore de suporte Tx que se encontra representada na Figura 7.1.
	/ -	1	9 - 1	8 15	7 16	
C =		-	30	16	
			-	10	
	\			-	/
Figura 7.1: Arvore de suporte Tx com custo 27 e peso 19.
O peso desta írvore é W(Tx) = 19 &amp;lt;20 e o custo é C(T^) = 27. Logo, neste caso, a solução x é uma solucão inteira admissível e corresponde à solucao ítima desta instâancia de 5 nodos.
Suponhamos que obtemos o seguinte arredondamento,
x = [x*] : x01 = 1; x04 = 1; x12 = 1; x13 = 1; x34 = 0 e x43 = 0.
A esta solucão x corresponde a írvore de suporte Tx que se encontra representada na Figura 7.2.
	í -	1	9 - 1	8 15	7 &gt; 16	
C =		-	30	16	
			-	10	
				-	/
Figura 7.2: Arvore de suporte Tx com custo 24 e peso 21.
O peso desta árvore á W(Tx) = 21 &gt; 20 e o custo á C(Tx) = 24. Logo, neste caso, x e uma solucao inteira nao admissível, pois não verifica a restriçao de peso.
Na primeira situacao do Exemplo 7.1 a solucao x e inteira admissável (x G XWMST), pois á uma arvore de suporte que verifica a restricao de peso, isto á, W(Tx) &amp;lt;W. Na segunda situaçao do mesmo exemplo, a solucao x á inteira e corresponde a uma árvore de suporte, no entanto esta arvore não verifica a restrição de peso, isto á, W(Tx) &gt; W, pelo que nesta situação dizemos que x á uma solucão inteira nao admissável. Alám destes dois casos que observámos no Exemplo 7.1, tambám podem ocorrer mais dois casos, o caso em que a restricão de peso á verificada, mas a solução x não corresponde a uma árvore de suporte e o caso em que não se verifica a restricão de peso e x nao corresponde a uma árvore de suporte. Nestes dois ultimos casos a solucao x á inteira não admissável. Em resumo, a solução x é sempre inteira, e pode ou não ser admissável dependendo se satisfaz ou nao as restantes restricoes (ser arvore de suporte e verificar a restriçao de peso).
A funcao distancia entre um ponto x G XL e um ponto inteiro x pode ser definida pela norma L1 tal que,
X(x,x)=	\xij - xij|,	(7.1)
e pode ser reescrita da seguinte forma
A(x,x)=	xij +	(1 - xij).	(7.2)
(i,j)GA:xij =0	(i,j)eA:xij = 1
Como tal, a funçao não linear definida por (7.1) pode ser transformada na funcão linear definida por (7.2).
Dado um ponto inteiro x, o ponto x* G XL mais próximo de x pode ser determinado através da minimizacão de um novo problema, cujas restriçães são as mesmas do Problema WMST e apenas a função objetivo é alterada para
ã(x*) = min A(x*,x).
s.a. x* G XL.
Se a distancia for nula, isto e, se $(x*) = 0, entao x* e uma soluçao inteira admissível obtida para o Problema WMST. Por outro lado, se $(x*) &gt; 0 e for obtido um ponto x* G XL, então o novo ponto inteiro x mais préximo de x* é facilmente obtido por arredondamento de x*. Assim, a Heurística Feasibility Pump sugere que para encontrar uma soluçcaão inteira admissével para o Problema WMST se atualize, iterativamente, o par de pontos (x* ,x) com o objetivo de reduzir, tanto quanto possível, a sua distância X(x*,x).
De seguida apresentamos uma descrição resumida da Heurística Feasibility Pump Bésica Aplicada ao Problema WMST, posteriormente, explicamos de forma mais detalhada o seu funcionamento. Denote-se por TL o tempo limite imposto para executar a heurística e maxIter o numero máximo de iteraçães.
Heurística Feasibility Pump Básica Aplicada ao Problema WMST
Passo 1: Obter a solução da relaxação linear
Seja x* a solucçãao da relaxaçcaão linear de uma formulacçãao para o Problema WMST.
Se x* ée inteira, entaão
x* é a solução étima. STOP.
Caso contraério,
ir para o Passo 2.
Passo 2: Arredondar os valores da solução da relaxação linear
Seja x0 := [x*].
Passo 3: Critério de paragem e pumping cycle
k := 0.
Enquanto (tempo &amp;lt;TL e k &amp;lt;maxIter) fazer
k := k + 1.
Determinar x* resolvendo a relaxacõo linear:
$(x*) = min A(x*, xk-1)
s.a. x* G XL.
Se ^(x*) = 0, entõo
x* é uma soluçõo inteira admissível, STOP.
Caso contréario,
Se 3(i, j) G A : [xj] = xij 1, entõo
atualizar xk := [x*].
Caso contréario,
aplicar Mecanismo de Perturbaçao1.
A heurística inicializa no Passo 1 com um ponto inicial x* que é, em geral, a soluçao da relaxacao linear de uma formulaçao para o Problema WMST. Caso a solucao x* seja inteira (x* G XWMST), entao foi obtida a solucõo ótima e a heurística termina. Caso contrário, definimos no Passo 2 uma soluçõo inteira x obtida através do arredondamento da solucçaõo x*.
No Passo 3, enquanto o tempo limite TL e o numero míximo de iterações maxIter nõo forem excedidos, executamos uma iteracõo do Método Feasibility Pump, chamada pumping cycle. Em cada pumping cycle consideramos a soluçõo corrente x e, através da relaxacõo linear, encontramos o ponto x* G XL que esta mais próximo da solucao corrente x, minimizando assim a distância A(x*,x).
Se $(x*) = 0, isso significa que x* é uma soluçao inteira admissível (x* G Xwmst) e a heurística termina. Caso contrario, se pelo menos uma das componentes [xj] for diferente da respetiva componente xij obtida na iteracao anterior, substituímos x pelo arredondamento de x* de modo a reduzir ainda mais a distancia A(x*,x).
1Este Mecanismo de Perturbação será explicado detalhadamente mais adiante.
O principal problema na aplicacão deste método esté na possibilidade de depois de um certo numero de iteraçães o método poder entrar em ciclo. A ocorrência de ciclo deve-se ao facto de se encontrarem várias vezes a mesma sequência de pontos x* e x, o que leva a que a distância A(x*,x) não seja reduzida. De modo a contornar este problema, introduzimos um simples mecanismo de perturbacçãao (explicado mais adiante) na soluçcãao corrente, fazendo com que o processo de busca e convergêencia seja reiniciado a partir de uma nova soluçcãao x*.
O processo termina quando uma soluçcãao inteira for encontrada, ou quando o tempo limite ou o nuémero méaximo de iteracçãoes impostos forem excedidos.
Se o tempo limite ou o nuémero maéximo de iteraçcoães forem excedidos e naão houve sucesso em obter uma soluçao inteira admissével, a Heuréstica Fesibility Pump termina com falha.
7.2	Alteracao da Funcao Objetivo na Heurística
Feasibility Pump Aplicada ao Problema WMST
Com o ob jetivo de obter solucçãoes de melhor qualidade os autores Achterberg e Berthold [2] propãem uma modificação na Heurística Feasibility Pump original para os Problemas MIP. Tendo por base as ideias de Achterberg e Berthold [2] podemos adaptar esta pequena modificação para aplicar ao Problema WMST.
Na Heurística Feasibility Pump Bésica para o Problema WMST apresentada na Seccão 7.1, apenas se utiliza a funçao objetivo do Problema WMST na obtençao da primeira soluçao admissével x* E XL. Nas restantes iteraçães utiliza-se como funcao objetivo a funcão dada por (7.2). Nesta heurística modificada a primeira solução é obtida como na heuréstica anterior e nas restantes iteraçcãoes vamos usar uma funçcãao objetivo modificada que contenha tambéem informaçcãao da funçcãao objetivo do Problema WMST.
Assim, a funcçãao objetivo (7.2) ée substituéda por uma combinaçcãao linear convexa entre a funcão objetivo do Problema WMST ^2(i j)eA Cjxij = cTx e a funcao distância A(x,x), e passa a ser definida por,
Aa(x,x) := (1 — a)A(x,x) + a
T
c x,
(7.3)
onde ||c|| é a norma Euclideana do vetor dos custos e a G [0,1]. Deste modo, à medida que o numero de iteraçães aumenta, a influência da funcão objetivo do Problema WMST vai sendo, progressivamente, reduzida dando lugar à funçao objetivo (7.2) quando o valor de a = 0 é atingido. Deste modo, aumenta-se a probabilidade de convergência para soluçoes inteiras admisséveis de melhor qualidade.
O Passo 3 da heurística descrita na Secção 7.1 é alterado para:
Passo 3: Critério de paragem e pumping cycle
k := 0.
Atribuir um valor a ak e a ^.
Enquanto (tempo &amp;lt;TL e k &amp;lt;maxIter) fazer
k := k + 1.
Determinar x* resolvendo a relaxaçao linear:
b,l;(x*) = min Aafc(x*,xk-1)
s.a. x* G XL.
Se 'dak (x*) = 0, então
x* ée uma soluçcãao inteira admissével, STOP.
Caso contréario,
Se 3(i, j) G A : [x*] = xij 1, então atualizar xk := [x*].
Caso contraério,
Se xk = xk-1 e ak - ak-1 &amp;lt;õa, entao
aplicar Mecanismo de Perturbacçaão1 .
Guardar o par (xk, ak).
Atualizar ak = ^ak-1.
Os Passos 1 e 2 da heurística apresentada na Secção 7.1 mantêm-se inalterados.
No Passo 3, o valor de a é inicializado com a0 G [0,1] e é atribuédo um valor fixo a G]0,1[. A solucao x* é determinada usando a funcão objetivo (7.3) em vez da (7.2). xEste Mecanismo de Perturbação será explicado detalhadamente mais adiante.
O valor de a é geometricamente reduzido em cada iteraçao segundo o parâmetro fixo ou seja, ak = ^afc_i.
Note-se que se ak = 0, então Aafc (x,x) := A(x,x), o que corresponde a funcão objetivo utilizada na Heurística Feasibility Pump Basica Aplicada ao Problema WMST.
Em cada iteracão, o par (xk,ak) é guardado e o método pode entrar em ciclo se existirem duas iterações seguidas k - 1 e k, tais que, os correspondentes pares (xk_1,ak_1) e (Xk,ak) satisfazem xk = xk-1 e ak - ak-1 &amp;lt;õa, para um dado valor ôa G [0,1]. No caso do método entrar em ciclo também podemos aplicar os mecanismos de perturbação que serâo descritos mais adiante na Secção 7.3.
7.3	Extensões da Heurística Feasibility Pump para o Problema WMST
O interesse ao aplicarmos a Heurística Feasibility Pump ao Problema WMST é o de obter soluçães inteiras admissíveis de boa qualidade e de forma rápida. Assim, temos de ter em conta o modo de obtencão das sucessivas solucães x* G XL, os critérios a adotar para efetuar o arredondamento das variéaveis e os mecanismos de perturbaçcãao a aplicar.
7.3.1	Modo de Obtenção das Soluções x*
A soluçcãao inicial pode ser obtida atraváes da soluçcaão da relaxacçãao linear do Procedimento P-WMTZ+C apresentado na Seccão 3.3, pois foi aquele que apresentou os melhores resultados em termos de tempo de execucçãao para todos os grupos de instêancias em teste.
Em instaências grandes Aleatáorias e Euclideanas a relaxaçcãao linear do Procedimento P-WMTZ+C demora muito tempo na obtenção de uma solucão admissível (ver resultados computacionais do Capítulo 3), então se utilizarmos este procedimento a Heurística Feasibility Pump iria levar muito tempo para a obtençcaão de uma soluçcãao inteira ad-missável. Assim, para contornar este problema e reduzir o tempo de execuçcãao podemos
aplicar as seguintes estratéegias:
1.	Todas as solucães x* E XL sao obtidas recorrendo à relaxaçao linear da For-mulaçcaão WMTZ.
2.	A primeira soluçao x* E XL é obtida através da relaxacao linear da Formulacao WMTZ e durante cada pumping cycle usamos a relaxação linear do Procedimento P-WMTZ+C para obter as sucessivas solucoes x* E XL.
3.	A primeira solução x* E XL é obtida através da relaxacao linear do Procedimento P-WMTZ+C com um tempo limite na introduçcãao de cortes e durante cada pumping cycle usamos a relaxaçcaão linear da Formulacçaão WMTZ para obter as sucessivas solucoes x* E XL.
4.	Todas as solucães x* E XL são obtidas recorrendo a relaxacao linear do Procedimento P-WMTZ+C com um tempo limite na introduçcãao dos cortes.
Na primeira estratégia obtemos uma solucão x* E XL de forma répida, mas fraca. Usando o Procedimento P-WMTZ+C a solução x* E XL encontrada é de melhor qualidade, mas ée obtida de forma mais lenta. Para tentar diminuir o tempo de execuçcãao, na terceira estratéegia usamos o Procedimento P-WMTZ+C com tempo limitado na introduçao dos cortes para obtençao da soluçao inicial x* E XL e em cada pumping cycle usamos a Formulacao WMTZ para obter as sucessivas soluções x* E XL. Na uéltima estratéegia usamos sempre o Procedimento P-WMTZ+C com limite de tempo na introduçcaão dos cortes.
7.3.2	Critérios de Arredondamento das Variáveis
Observamos que um dos aspetos a ter em conta, em relaçcaão ao arredondamento das variéaveis, ée o facto de que se nãao efetuamos o arredondamento a algumas variaéveis, nem para zero nem para um, ficando elas com um valor fracionéario, a heuréstica termina quando obtiver uma soluçcaão admissével (naão necessariamente inteira). O que leva a concluir que para obter uma solucçãao inteira admissével temos de efetuar o arredondamento a todas as variéaveis. Notamos que se nãao efetuarmos o arredondamento a todas
as variaveis o valor obtido para o custo pode corresponder tanto a um limite superior como a um limite inferior.
Para o arredondamento das variaveis podemos estabelecer diferentes critérios. De seguida apresentamos alguns critérios gerais que se podem utilizar para efetuar o arredondamento das variéveis.
,(i,j) e A,
• Critério de Arredondamento 1 (A1)
_	11, se Xij &gt; a
Xij = S
[ 0, caso contrario
onde a constante a pode tomar valores no intervalo ]0,1[. Note-se que no caso de a = 0,5 temos o chamado arredondamento simétrico.
• Critério de Arredondamento 2 (A2)
se Xij &gt; b
se Xij &amp;lt;a , (i,j) e A, caso contrário
onde a constante a pode tomar valores no intervalo ]0; 0,5[ e a constante b no intervalo ]0,5; 1[. A constante p pode tomar apenas dois valores, isto é, p e {0,1}. Para obter o valor de p, geramos aleatoriamente um valor pij e [0,1]. Se pij &gt; 0,5, então p =1, caso contrario p = 0.
• Critério de Arredondamento 3 (A3)
~ í 1, se xij &gt; a ou ) e T
Xij =&amp;lt;	, , ■	, (i,j) e
0, caso contrario
7.3.3	Mecanismos de Perturbação
Os mecanismos de perturbação são utilizados sempre que todas as componentes xj ((i,j) G A) do novo xk coincidam com as componentes de xk_1, isto é, se em duas iteraçães consecutivas as solucães arredondadas são iguais. No caso do valor de d(x*) ser o mesmo em três iteraçães seguidas, tambem e utilizado o mecanismo de perturbação. Nestas duas situaçães temos de modificar algumas componentes xij ((i, j) G A), mesmo que aumente o valor da distância A(x*, x), de modo que o processo de busca e convergância seja reiniciado a partir de uma nova solucao x*.
Neste sentido, podemos utilizar os dois mecanismos que se seguem e que são idânticos aos utilizados em [18]:
•	Mecanismo de Perturbação 1 (P1):
Modificar apenas as variáveis x^ ((i, j) 6 A), tais que \xij — x^| &gt; a.
No caso de xij — Xj &gt; a, então modificar o valor de Xj = 0 para Xj = 1. Caso contrario, modificar para Xj = 0.
•	Mecanismo de Perturbação 2 (P2):
Para cada (i, j) 6 A, gerar um valor aleatorio pij 6 [—0,3; 0,7] e modificar apenas as variaveis Xj ((i, j) 6 A), tais que \xij — Xj| + maxfpj, 0} &gt; ã.
No caso de xij — xj + maxlpj, 0} &gt; ã, então modificar o valor de xj = 0 para xjj = 1. Caso contrario, modificar para x^ = 0.
O Mecanismo P1 pode ser considerado fraco pois, quando temos \xij — xj| = 0 ((i, j) G A) essas variaveis não são modificadas. Quanto ao Mecanismo P2, este pode ser considerado forte, uma vez que da a possibilidade tambem às variaveis tais que \xij — xj | = 0 ((i,j) G A) de serem modificadas, desde que max{pij, 0} &gt; ã. Assim, o conjunto de variaveis que podem ser trocadas no Mecanismo P2 e maior do que no Mecanismo P1.
Com a aplicação dos mecanismos de perturbação podem ser efetuadas muitas trocas e alterado o valor de todas as variaveis da solucão. Assim, para evitar que tal
aconteça, é necessario limitar tambem o nUmero de trocas. De acordo com
mos efetuar um numero inteiro de trocas pertencente ao intervalo
18], pode, onde M
M 3M
é um parâmetro fixo. Para encontrar este valor geramos um numero inteiro aleatírio no intervalo considerado.
7.4	Comportamento da Heurística Feasibility Pump
Do ponto de vista geométrico o comportamento da Heurística Feasibility Pump gera duas trajetórias de pontos x* e x, que se esperam ser convergentes. Uma trajetória satisfaz as restriçães da relaxação linear e pode ou não satisfazer as restricães de in-tegralidade. A outra trajetoria satisfaz as restriçães de integralidade, podendo ou nao satisfazer as restantes restriçães dadas por (3.2) e/ou a restriçao de peso, isto é, uma trajetíria é formada por uma sucessao de pontos x* G XL (que podem ser ou nao inteiros), enquanto que a outra trajetoria é formada por uma sucessão de pontos x inteiros (que podem ser ou nao admissíveis para o Problema WMST).
A distância A(x*, x) pode ser interpretada como a diferença entre os pontos x* G XL e x que tentamos reduzir efetuando o pumping cycle.
Como a cada ponto x* e x se faz corresponder um custo e um peso, também se pode interpretar a Heurística Feasibility Pump como duas trajetírias de custos e duas trajetírias de pesos que se esperam convergentes para um mesmo custo e um mesmo peso,
C(Tx*) = C(Tx) e W(Tx.) = W(Tx).
A heurística termina quando as duas sequâncias convergem ou quando o tempo ou o nuémero de iteracçoães imposto forem excedidos.
Nos três graficos que se seguem podemos observar geometricamente o comportamento da instância 80-7 do grupo de instâncias Quase Caminhos com valor W = 1000.
Trajetórias de Custos
C(z*)	— C(t)
Figura 7.3: Representação geométrica das duas trajetórias de custos (instância QC80-7).
Na Figura 7.3 encontram-se representadas as sucessoes de pontos relativos aos custos das duas sequências de solucoes x* e x. Observamos que as duas trajetorias de custos convergem apés oito iteracoes para o mesmo custo 3759.
Trajetórias de Pesos
H'(r‘)	— IV(Í)
Figura 7.4: Representaçao geometrica das duas trajetórias de pesos (instancia QC80-7).
Na Figura 7.4 encontram-se representadas as sucessões de pontos relativos aos pesos das duas sequências de soluções x* e x. Observamos que as duas trajetórias de pesos convergem apos 8 iterações para o mesmo peso 904.
Note-se que na Iteracõo 1 apenas existe custo e peso para a solucao x*, pois e a primeira solucõo obtida que corresponde à soluçõo otima da relaxaçõo linear e ainda nõo foi efetuado o primeiro arredondamento para obter x.
Neste grafico podemos observar ainda se as soluçoes x verificam a restricao de peso. Neste exemplo, o peso das sucessivas solucões x é sempre inferior ou igual a 1000. Observe-se que em outros exemplos as soluções x podem nõo verificar a restriçao de peso.
Notemos tambem que na Iteraçõo 5 observamos no grafico da Figura 7.3 que C(x*) = C(õ), mas atraves da observacao do grafico da Figura 7.4 podemos verificar que as solucoes nõo sao as mesmas, dado que W(x*) = W(x).
Entre cada um dos pontos x* e x esta associada uma distência A(x*,x), que se pretende minimizar, isto e, que se tenta reduzir a zero. No seguinte grafico podemos visualizar o comportamento da funcõo distancia ao longo das oito iterações na instancia 80-7 do grupo de instências Quase Caminhos.
Figura 7.5: Evolução da distância A(x*,x) ao longo das iterações (instância QC80-7).
No gráfico da Figura 7.5 observamos que a fungao distancia, iterativamente, se reduz
a zero, ao fim de oito iteraçcãoes. Note-se que séo a partir da Iteraçcãao 2 ée que se minimiza a distância. Neste exemplo, observamos a existência de três iteracoes seguidas com a mesma distância 6,00752 (Iteraçães 2, 3 e 4), o que leva a efetuarmos modificaçães nas variéaveis atravées da introduçcãao de um mecanismo de perturbacçãao e, devido a este facto, existe um crescimento do valor da função distância para 9 (Iteracão 5).
Nesta instêancia, a soluçcãao inteira admissével obtida ée uma éarvore de suporte de custo 3759 e peso 904, que não corresponde à solução otima da instância considerada, mas apresenta um gap de 0,21%.
7.5	Experiências e Resultados Computacionais
Nesta seccão, comecamos por descrever e discutir algumas experiências computacionais realizadas com as duas heurísticas propostas nas Secçães 7.1 e 7.2. De seguida, propomos quatro estratéegias heurésticas e apresentamos um exemplo comparativo entre as quatro estratéegias heurésticas propostas. Por fim, os resultados computacionais são comparados entre si, com a Heurística do software Xpress aplicada ao nodo raiz utilizando a Formulaçcãao WMTZ e com a primeira solucçãao inteira admissével obtida
pela Formulação WMTZ quando usa o procedimento de Branch and Bound.
Todos os testes foram efetuados num Intel(R) Core(TM)2 Duo CPU (T7100) 2.00 GHz processador e 4Gb de RAM e usou-se o software Xpress 7.3 (Xpress-Optimizer 23.01.03 e Xpress-Mosel 3.4.0) [1] para implementar todas as estratégias heurísticas.
Em todas as heurísticas é obtido um limite superior para o valor docusto^que pode ou nao ser o valor étimo. O gap correspondente é dado por gap = —qpt— X 100, onde LS é o valor do limite superior obtido para o valor do custo através da heurística
considerada e OPT é o valor étimo (ü(WMST)) ou o melhor valor encontrado até ao
momento.
7.5.1	Descrição das Experiências Computacionais Realizadas
Das experiências computacionais realizadas verificámos que as três primeiras estratégias de obtencao das soluções x* G XL (Subseccao 7.3.1) não apresentaram bons resultados nas instências Aleatérias e Euclideanas, pois ocorreram muitos casos em que as Heurísticas Feasibility Pump terminaram com falhas devido ao tempo limite imposto ou ao numero maximo de iteracoes ter sido excedido. E de referir ainda que nas instências Quase Caminhos qualquer uma destas estratégias apresentou bons resultados.
No arredondamento das variaveis, em relação ao Critério Al foram efetuadas experiências com vérios valores de a (a = 0,5; a = 0,6; a = 0,75 e outros) e verificémos que em todos os grupos de instâncias, os melhores resultados se obtêm com um valor de a = 0,5, ou seja, efetuando o arredondamento para o inteiro mais préximo. Com base nas experiências efetuadas observémos que quanto mais próximo do valor um estiver o valor de a, maior é o tempo de execucao e o gap. Este facto pode ser devido a que com o aumento da constante a, o numero de variéveis que se arredondam para o valor um diminui.
Apos experiências com vérios valores de a e de b (a g]0; 0,5[ e b g]0,5; 1[), o Critério A2 apresentou bons resultados com a = 0,4 e b = 0,6 para instancias Quase Caminhos. Nos grupos de instências Aleatorias e Euclideanas ocorrem muitos casos em que as Heurísticas Feasibility Pump terminaram com falhas devido ao tempo limite imposto ou ao numero méximo de iteraçoes ter sido excedido ou as soluçoes encontradas não serem de boa qualidade.
Em relaçao ao Critério A3 verificamos que é importante a escolha de uma arvore com custo proximo do custo da solução étima. Os melhores resultados obtêm-se utilizando a érvore de suporte que se designou por Tp, sendo esta arvore obtida através do Algoritmo Lagrangeano 2 da Subsecçao 4.4.
Em relacao à aplicaçao dos mecanismos de perturbacão foram testadas as seguintes estratégias:
• utilizar apenas um mecanismo de perturbação, ou o Mecanismo P1 ou o Mecanismo P2;
•	utilizar os dois mecanismos de perturbaçao de forma intercalada, isto é, em iterações émpares utilizar o Mecanismo P1 e em iteraçães pares o Mecanismo P2;
•	utilizar os dois mecanismos de perturbacão de forma aleatória, isto é, gerar um numero aleatorio p, entre 0 e 1. Se p &gt; 0,5, utilizar o Mecanismo P2, caso contrario, utilizar o Mecanismo P1.
A aplicação de qualquer uma destas combinaçães dos mecanismos de perturbação leva à obtençao de resultados satisfatórios, embora a utilização dos dois mecanismos P1 e P2 de forma aleatória seja melhor em termos de tempo de execução. Para utilizarmos estes dois mecanismos temos de escolher valores para os parâmetros a e 5. Das experiências computacionais realizadas com a e 5 no intervalo [0; 0,5], os parâmetros a = 0,01 e 5 = 0,4, apresentam os melhores resultados. Na Heurística FP com a funçao objetivo alterada, depois de efetuadas experiâncias com vérios valores de ao, p e 5a (ao, 5a g]0, 1[ e p G [0,1]), decidimos utilizar a0 = p = 0,1 e 5a = 0,05, para evitar a ocorrância de muitas falhas na heurística e tentar que o tempo não aumente muito em relação à Heurística FP Bésica.
Para a obtençao dos resultados computacionais em todas as heurísticas apresentadas, imposemos um limite de tempo TL = 10000 segundos e um numero méximo de iteraçães maxIter = 50. Para os restantes parâmetros decidimos utilizar a = 0,01; 5 = 0,4; a0 = p = 0,1 e 5a = 0,05.
Tendo por base as experiâncias computacionais descritas anteriormente, apresentamos de seguida quatro esquemas heurísticos cujos resultados computacionais serão apresentados na subsecção seguinte.
Heurística Feasibility Pump Básica 1 (FPB1)
•	A obtencao das solucões x* é efetuada recorrendo à relaxaçao linear do Procedimento P-WMTZ+C com um limite de tempo igual a 100 segundos na introdução dos cortes.
•	O critério de arredondamento utilizado é o Critério A1 com a = 0,5.
• O mecanismo de perturbação utilizado é o que combina os dois Mecanismos
P1 e P2 de forma aleatária com os parâmetros a = 0,01 e S = 0,4. Sá á permitido
efetuar um numero inteiro de trocas pertencente ao intervalo
M 3M
2' 2
com
M = 20.
Heurística Feasibility Pump Basica 2 (FPB2)
•	A obtencao das soluções x* é efetuada recorrendo à relaxação linear da For-mulaçao WMTZ.
•	O critério de arredondamento utilizado é o Critério A3 com a = 0,9 e a utilização da érvore de suporte T = Tp obtida através do Algoritmo Lagrangeano 2 da Subsecção 4.4.
•	O mecanismo de perturbaçao utilizado é o mesmo que na Heurística FPB1.
Heurística Feasibility Pump com Alteraçõo da Funçõo Objetivo 1 (FPO1)
Aplicar a Heurística FP com alteração da função objetivo proposta para o Problema WMST com os mesmos critérios adotados na Heurística FPB1.
Heurística Feasibility Pump com Alteracõo da Funçõo Objetivo 2 (FPO2)
Aplicar a Heurística FP com alteração da função objetivo proposta para o Problema WMST com os mesmos critérios adotados na Heurística FPB2.
7.5.2	Exemplos Comparativos das Heurísticas Feasibility Pump
De seguida apresentamos alguns gráficos (Figuras 7.6, 7.7 e 7.8), onde podemos observar o comportamento da função distância ao longo das várias iterações usando as quatro estratágias heurísticas propostas anteriormente. O gráfico da Figura 7.6 á relativo a instância 80-7 do grupo de instancias Quase Caminhos (QC80-7), o da Figura 7.7 á relativo a instância 80-5 do grupo de instâncias Aleatárias (R80-5) e o gráfico da Figura 7.8 refere-se à instância 80-3 do grupo de instâncias Euclideanas (E80-3).
Figura 7.6: Evolução da distância A(x*,x) ao longo das iterações na instância QC80-7 nas quatro estratégias heurísticas propostas.
Figura 7.7: Evolução da distância A(x*,x) ao longo das iteracoes na instância R80-5 nas quatro estratégias heurísticas propostas.
Figura 7.8: Evolucão da distância A(x* , x) ao longo das iteracoes na instancia E80-3 nas quatro estratégias heurísticas propostas.
Em qualquer um dos três grupos de instâncias, Quase Caminhos, Aleatárias e Eu-clideanas, as Heurásticas FPO1 e FPO2 necessitam de mais iteraçães para obter uma solucçaão inteira admissável.
Na Tabela 7.1 podemos consultar os valores obtidos para o custo e peso para as instências QC80-7, R80-5 e E80-3 em cada uma das Heurísticas FP propostas e ainda o respetivo gap.
QC80-7	R80-5	E80-3
	Custo	3769	34421	271898
FPB1	Peso	904	96953	70556
	Gap	0,48	3,33	3,59
	Custo	3751	33926	265002
FPB2	Peso	905	98144	70252
	Gap	0	1,84	0,96
	Custo	3759	34421	271898
FPO1	Peso	904	96953	70556
	Gap	0,21	3,33	3,59
	Custo	3751	33926	265002
FPO2	Peso	905	98144	70968
	Gap	0	1,84	0,96
Tabela 7.1: Comparação dos valores obtidos usando as quatro Heurésticas FP propostas.
Como podemos observar a negrito na Tabela 7.1, as Heurísticas FP onde se obtêm as solucões de melhor qualidade sõo as Heurísticas FPB2 e FPO2.
Na instêancia QC80-7, com a aplicaçcõao das Heurésticas FPB2 e FPO2 ée obtida a soluçcõao éotima com custo 3751 e peso 905.
Quanto às instências R80-5 e E80-3, em nenhuma das Heurísticas FP se consegue obter a soluçcõao oétima. Na instaência R80-5, a soluçcaõo mais préoxima da éotima ée obtida quando se aplicam as Heurísticas FPB2 e FPO2 com custo 33926 e peso 98144 e gap 1,84%. Na instência E80-3, o gap mais baixo (0,96%) também é obtido através das Heurésticas FPB2 e FPO2 com custo 265002 e peso 70968.
7.5.3	Resultados Computacionais
Nesta secção apresentamos os resultados computacionais das quatro estratégias Heurísticas Feasibility Pump descritas na secção anterior.
Para podermos efetuar uma comparaçcãao da qualidade da soluçcãao obtida e do tempo de execução, apresentamos também os resultados obtidos pela Heurística do software Xpress aplicada ao nodo raiz utilizando a Formulacao WMTZ (HXNR) e da primeira solucão inteira admissével obtida pelo solver do software Xpress através da Formulaçao WMTZ, quando usa o procedimento Branch and Bound (PSIABB).
Os testes são realizados para as 215 instâncias geradas (ver Secção 2.3).
De modo a facilitar a análise, em cada grupo de instancias, estas são separadas em 12 subgrupos, agrupadas por dimensãao. Para estudar a qualidade das soluçcãoes obtidas sao apresentados os gaps médios (em percentagem) e os respetivos desvios padroes e para estudar a rapidez são apresentados os tempos médios de execução (em segundos) e os respetivos desvios padrãoes.
Instâncias Quase Caminhos
Nas Heurésticas FPB2, FPO2 e HXNR ée possével encontrar soluçcaão inteira ad-missével em todas as instâncias Quase Caminhos (95 instâncias). No caso da Heuréstica HXNR, a referida soluçcãao ée sempre encontrada no nodo raiz.
Usando as Heurísticas FPB1 e FPO1 é possével encontrar solucão inteira admissével em 93 das instâncias, o que corresponde a 97,89% dos casos. Estas heurísticas falham apenas em 2 instâncias (na Heuréstica FPB1 as instancias são de 150 nodos e na Heuréstica FPO1 uma instâancia ée de 60 e a outra de 300 nodos). As falhas referidas devem-se ao nuémero méaximo de iteraçcãoes ter sido excedido.
Quanto à Heuréstica PSIABB, não foi possével obter solução inteira admissével em 5 instâncias (uma de 500 nodos e 4 de 1000 nodos), dado que excedeu o tempo limite imposto (10000 segundos).
No grífico da Figura 7.9 encontram-se representadas as percentagens de gaps nulos obtidas no grupo de instaâncias Quase Caminhos para as vaérias estratéegias heurésticas propostas.
Figura 7.9: Percentagem de gaps nulos nas diferentes heurísticas propostas nas instâncias QC.
Das estratéegias heurésticas apresentadas, a que tem maior percentagem de gaps nulos é a Heurística FPO1 com 33,68% dos casos (32 em 95 instancias), depois temos as Heurísticas FPB2 e FPO2 com 32,63% dos casos (31 em 95 instâncias), a seguir com 20% dos casos (19 em 95 instâncias) temos a Heurística FPB1, depois temos a Heurística PSIABB onde é possível encontrar 11,58% de gaps nulos (11 em 95 instancias) e por fim, através da Heurística HXNR temos 2,11% dos casos (2 em 95 instaâncias). Portanto, qualquer uma das estratéegias Heurésticas FP propostas apresenta maior percentagem de gaps nulos quando comparada com as Heurésticas HXNR e PSIABB.
Na Tabela 7.2 podemos observar os gaps médios, em percentagem, obtidos pelas Heurísticas HXNR, PSIABB, FPB1, FPB2, FPO1 e FPO2 e na Tabela 7.3 encontram-se os correspondentes desvios padroes.
N» Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	FPO2
10	46,949	15,080	15,311	7,138	11,723	7,138
20	23,121	3,591	1,293	0,574	1,293	0,574
40	23,925	3,479	1,687	0,579	0,675	0,579
60	12,949	2,683	0,135	0,022	0,150	0,022
80	9,798	1,491	0,207	0,058	0,134	0,058
100	7,147	1,048	0,117	0,665	0,077	0,665
150	8,684	1,574	1,151	0,773	0,518	0,773
200	3,777	0,457	0,564	1,180	0,076	1,180
300	3,050	0,185	0,607	1,204	0	1,204
400	8,974	0,427	0,663	0,895	0,143	0,895
500	3,894	0,343	0,845	1,063	0,264	1,063
1000	1,414	0,004a	0,459	1,414	0,030	1,414
Tabela 7.2: Gaps médios, em percentagem, obtidos pelas heurísticas propostas nas instâncias QC.
NA Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	FPO2
10	41,805	30,180	11,157	8,075	7,344	8,075
20	13,448	4,228	1,539	0,610	1,539	0,610
40	5,751	3,036	2,150	0,614	0,696	0,614
60	2,721	3,228	0,247	0,029	0,257	0,029
80	1,740	1,344	0,220	0,051	0,123	0,051
100	0,602	1,209	0,252	1,398	0,159	1,398
150	2,767	1,200	1,361	1,271	0,953	1,271
200	0,833	0,386	0,570	1,425	0,151	1,425
300	0,923	0,341	0,350	0,884	0	0,884
400	10,702	0,686	0,699	0,727	0,199	0,727
500	1,049	0,642	0,612	1,325	0,354	1,325
1000	0,430	_a	0,208	0,430	0,068	0,430
Tabela 7.3: Desvios Padrões dos gap obtidos pelas heurísticas propostas nas instancias QC.
aGap apenas da instância QC1000-5, pelo que, não foi possível calcular desvio padrão.
A fim de comparar a qualidade das soluções obtidas entre as Heurísticas FP propostas e a Heurística HXNR no grupo de instâncias Quase Caminhos, apresentamos o seguinte grafico.
Figura 7.10: Comparação dos gaps médios, em percentagem, entre as Heurísticas FP propostas e a Heurística HXNR nas instâncias QC.
Como as Heurísticas FPB2 e FPO2 apresentam os mesmos gaps médios, no gráfico acima apenas se apresentam os gaps médios correspondentes à Heurística FPB2. Através do gráfico da Figura 7.10 e das Tabelas 7.2 e 7.3 podemos observar que qualquer das Heurísticas FP apresenta soluções de melhor qualidade quando comparada com a Heurística HXNR. E possível vizualizar ainda, a formacõo de dois grupos: um formado pelas instâncias com menos de 100 nodos, onde as Heurísticas FPB2 e FPO1 encontram as soluçcoões de melhor qualidade e o outro formado pelas instâancias de 100 ou mais nodos, onde a Heurística FPO1 apresenta solucoes de melhor qualidade. Estes dois grupos podem ser denominados por grupo de instâancias pequenas e por grupo de instâancias grandes. Assim, à medida que aumenta a dimensõo do problema, a Heurística FPO1 í a estratíegia que apresenta soluçcõoes de melhor qualidade nas instâancias Quase Caminhos.
Na Tabela 7.4 podemos observar os tempos médios de execuçõo (em segundos) das vírias heurísticas propostas e na Tabela 7.5 encontram-se os respetivos desvios padroes.
N» Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	FPO2
10	0,010	0,090	0,028	0,011	0,066	0,019
20	0,018	0,603	0,138	0,031	0,329	0,084
40	0,062	3,623	0,506	0,117	1,495	0,291
60	0,145	4,413	1,165	0,290	6,114	0,722
80	0,300	13,504	3,070	0,554	8,251	1,505
100	0,629	27,912	5,936	0,970	14,475	2,511
150	2,070	68,741	68,904	3,008	45,251	7,520
200	10,331	121,789	53,847	7,894	104,922	18,130
300	11,420	388,644	297,539	40,857	641,356	69,166
400	50,293	1340,455	483,319	90,462	840,883	173,079
500	51,274	4594,168	823,763	268,782	1656,248	371,326
1000	498,721	9434,064	1707,616	1014,109	6244,978	1712,898
Tabela 7.4: Tempos medios, em segundos, obtidos pelas heurísticas propostas nas instâncias QC.
N» Nodos	HXNR	PSIBB	FPB1	FPB2	FPO1	FPO2
10	0,002	0,017	0,011	0,011	0,004	0,001
20	0,002	0,188	0,029	0	0,013	0,003
40	0,015	0,990	0,087	0,020	0,098	0,014
60	0,003	0,739	0,456	0,015	7,285	0,015
80	0,007	6,638	1,309	0,023	0,228	0,076
100	0,201	11,936	3,779	0,057	0,415	0,063
150	1,051	58,716	108,248	0,151	2,030	0,702
200	12,701	61,637	12,845	1,415	9,759	0,802
300	0,134	135,503	245,209	7,360	623,046	2,122
400	53,274	554,393	536,410	4,307	25,410	5,140
500	0,529	3561,055	401,203	75,996	45,706	11,036
1000	29,572	1952,226	533,252	88,882	782,108	369,810
Tabela 7.5: Desvios padrães dos tempos obtidos pelas heurísticas propostas nas instâncias QC.
Em termos de tempo de execuçõo, das quatro Heurísticas FP apresentadas a Heurística FPB2 e a mais rípida, depois temos a Heurística FPO2, a seguir a Heurística FPB1 e a mais lenta é a que apresenta soluções de melhor qualidade para instâncias de
100 a 500 nodos. Nas instâncias de 400 e 500 nodos, o tempo de execucão da Heurística FPO1 é superior a quatro vezes o tempo de execucão das Heurísticas FPB2 e FPO2 e superior ao dobro do tempo de execução da Heurística FPB1.
Neste grupo de instancias, a Heurística HXNR é a mais répida, embora apresente soluçcãoes de pior qualidade.
Atendendo a que a Heuréstica FPB2 ée a mais raépida das quatro estratéegias Heurésticas FP propostas, vamos compara-la com a Heurística HXNR (Figura 7.11) e com a Heuréstica PSIABB (Figura 7.12).
Diferença de Gap entre HXNR e FPB2
Figura 7.11: Diferenças médias de gaps, em percentagem, entre as Heurísticas HXNR e FPB2 nas instâncias QC.
Do gréfico da Figura 7.11 podemos observar que a diferença média de gap existente entre as Heurésticas HXNR e FPB2 ée bastante significativa, o que leva a inferir que, apesar da Heuréstica FPB2 gastar mais tempo de execuçcãao, consegue obter soluçcãoes de melhor qualidade quando comparada com a Heurística HXNR. E de notar que apenas numa instância (QC10-8) a Heurística HXNR encontra uma solução de melhor
qualidade comparativamente à Heurística FPB2.
Figura 7.12: Comparação dos gaps médios, em percentagem, entre as Heurísticas FPB2 e a PSIABB nas instancias QC.
Dado que os resultados das Tabelas 7.4 e 7.5 provam que a Heurística FPB2 í mais rápida do que a Heurística PSIABB e atendendo também a que, em termos de gap, se pode observar (Figura 7.12 e Tabelas 7.2 e 7.3) que, em instancias de 200 ou mais nodos, a qualidade das soluções da Heurística FPB2 diminui, faz todo o sentido usar esta heurística num esquema enumerativo para melhorar a solução inteira admissível obtida. A Heurística FPB2 apresenta melhores soluçães do que a Heurística PSIABB em 68,42% dos casos (65 em 95 instâncias) e tambím apresenta uma maior percentagem de gaps nulos (32,63%&gt;2,11%).
E de notar que em relacão às instâncias de 1000 nodos, o gap mídio da Heurística PSIABB í o mais baixo, mas esse valor sí corresponde à soluçao da instância QC1000-5, pois para as restantes instâncias de 1000 nodos e algumas instâncias de 500 nodos nao foi possível obter solução admissível no tempo imposto (10000 segundos).
Instâncias Aleatórias
Nas Heurísticas FPB2 e FPO2 í possível encontrar solução inteira admissível em
todas as instâncias Aleatárias (60 instâncias). No caso da Heurástica HXNR, em 2 instaências de 1000 nodos nãao áe possável, no tempo estabelecido, encontrar solucçãao inteira admissável e em 56 instâncias (93,33%) a referida soluçao inteira admissável á encontrada no nodo raiz. Apenas em 2 instâncias de 500 nodos á obtida a solução num nodo diferente do nodo raiz. Na Heurástica FPO1 á possável encontrar solucão inteira admissável em 52 das instâncias Aleatárias em teste, o que corresponde a 86,67% dos casos. Por exemplo, em todas as instâncias de 1000 nodos ocorre falha e esta deve-se ao tempo limite ter excedido. Na Heurástica FPB1 ocorrem 7 falhas, sendo assim, nesta heurástica á possável encontrar solução inteira admissável em 88,33% dos casos (53 em 60 instaâncias).
Quanto à Heurástica PSIABB não foi possável obter solução inteira admissável em 5 instâncias, sendo todas elas de 1000 nodos. O motivo da não obtencão de solução inteira admissável á devido ao limite de tempo imposto exceder os 10000 segundos.
No gráfico da Figura 7.13 encontram-se representadas as percentagens de gaps nulos obtidas no grupo de instancias Aleatárias para as varias estratágias heurísticas propostas.
Figura 7.13: Percentagem de gaps nulos nas diferentes heurísticas propostas nas instâncias R.
Das quatro Heurísticas FP estudadas, a que apresenta a maior percentagem de gaps nulos é a Heurística PSIABB, com 13,33% (8 em 60 instâncias). Com a aplicação das Heurísticas FPB2 e FPO2 encontram-se 6,67% de gaps nulos (4 em 60 instancias). Através das Heurísticas FPB1 e FPO1 não foi possível obter gaps nulos em nenhuma instância do grupo de instâncias Aleatorias. Com a Heurística HXNR apenas se encontram 1,67% de gaps nulos (1 em 60 instâncias).
Na Tabela 7.6 podemos observar os gaps mádios, em percentagem, obtidos pelas Heurísticas HXNR, PSIABB, FPB1, FPB2, FPO1 e FPO2 e na Tabela 7.7 encontram-se os correspondentes desvios padroes.
N» Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	F	PO2
10	86,769	4,723	10,798	3,840	10,798	3	840
20	51,009	9,647	15,113	5,285	15,113	5	285
40	324,918	35,041	12,448	2,743	12,448	2	743
60	537,160	7,289	10,238	1,312	10,238	1	312
80	522,234	8,817	1,802	1,505	1,802	1	505
100	639,715	44,725	10,514	0,547	5,119	0	547
150	1486,381	16,399	8,337	0,787	2,055	0	787
200	290,743	19,828	2,307	0,533	0,731	0	533
300	1061,546	14,129	10,043	0,239	6,512	0	239
400	759,847	12,353	5,747	0,145	2,751	0	145
500	261,209	26,000	15,072	0,220	14,056	0	220
1000	7235,841	_b	_b	0,071	_b	0	071
Tabela 7.6: Gaps médios, em percentagem, obtidos pelas heurésticas propostas nas instancias R.
NA Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	FPO2	
10	83,293	9,340	7,596	3,430	7,596	3	430
20	90,885	12,317	5,720	5,006	5,720	5	006
40	504,830	44,644	9,647	1,676	9,647	1	676
60	751,221	10,084	11,366	1,074	11,366	1	074
80	938,157	11,919	1,560	1,320	1,560	1	320
100	1043,844	34,460	16,675	0,264	5,262	0	264
150	2766,229	10,241	14,132	0,684	1,782	0	684
200	286,631	26,807	3,576	0,379	0,809	0	379
300	770,713	7,302	7,541	0,621	0,499	0	,621
400	497,208	4,803	4,986	0,098	2,017	0	098
500	371,192	52,175	10,800	0,136	15,155	0	136
1000	11549,122	_b	_b	0,081	_b	0	081
Tabela 7.7: Desvios Padroes dos gaps obtidos pelas heurésticas propostas nas instancias R.
bNão foi possével calcular o gap medio nem o desvio padrão dado que ocorreu falha para todas as instancias de 1000 nodos.
O gráfico da Figura 7.14 apresenta os gaps médios (em percentagem) obtidos pelas Heurísticas FP propostas.
Figura 7.14: Comparação dos gaps médios, em percentagem, entre as Heurísticas FP propostas nas instâncias R.
Notamos que no gráfico acima nao foram apresentados os gaps médios obtidos através da Heurística FPO2 dado que são iguais aos apresentados pela Heurística FPB2. Através do gráfico da Figura 7.14 e das Tabelas 7.6 e 7.7 podemos concluir que as soluçães de melhor qualidade são obtidas utilizando as Heurísticas FPB2 e FPO2. Note-se ainda que para as instâncias de 1000 nodos apenas foi apresentada no gráfico a barra correspondente à Heurística FPB2, pois devido à ocorrância de falha (exceder o tempo imposto) nãao foi possével obter um valor para o gap méedio das Heurésticas FPB1 e FPO1.
Os tempos médios de execucão (em segundos), das vérias heurésticas propostas encontram-se registados na Tabela 7.8 e os respetivos desvios padroes na Tabela 7.9.
N» Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	FPO2
10	0,025	0,265	0,118	0,009	0,228	0,025
20	0,075	0,484	0,184	0,031	0,390	0,059
40	0,177	3,054	0,515	0,115	1,872	0,249
60	0,556	3,888	1,370	0,274	4,493	0,624
80	1,389	8,867	1,735	0,543	9,246	1,186
100	2,868	19,438	6,253	1,211	19,741	2,649
150	10,592	59,744	41,051	4,979	132,372	10,034
200	18,483	127,362	87,119	12,521	194,213	23,432
300	62,829	310,566	809,338	39,647	1108,573	72,916
400	151,223	1181,846	633,165	92,527	1450,826	155,788
500	1313,775	1952,868	2965,244	311,440	3913,382	532,116
1000	5427,520	10042,940	10618,800	1724,168	11771,360	1463,854
Tabela 7.8: Tempos mádios, em segundos, obtidos pelas heurásticas propostas nas instâncias R.
NA Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	FPO2
10	0,021	0,091	0,187	0,009	0,214	0,008
20	0,089	0,094	0,169	0,001	0,076	0,007
40	0,181	0,818	0,178	0,008	0,191	0,011
60	0,233	1,328	0,982	0,014	0,167	0,025
80	1,042	3,352	0,954	0,045	0,340	0,047
100	1,152	11,567	2,284	0,352	2,305	0,904
150	4,695	30,560	20,621	1,175	119,473	2,670
200	5,497	92,635	51,493	2,555	55,060	6,311
300	19,978	166,714	1012,314	15,762	939,541	32,523
400	51,623	459,940	192,898	45,278	454,522	98,084
500	1482,344	1810,176	1083,116	31,912	1581,267	30,537
1000	4214,302	20,804	525,087	264,514	1056,622	159,162
Tabela 7.9: Desvios padrães dos tempos obtidos pelas heurísticas propostas nas instancias R.
Em termos de tempo médio de execução podemos afirmar que das quatro Heurésticas FP apresentadas, a Heuréstica FPB2 é a mais répida, depois temos a Heuréstica FPO2, a seguir a Heuréstica FPB1 e a mais lenta é a Heuréstica FPO1.
Ao compararmos os tempos de execucão da Heurística FPB2 com os tempos de execução da Heurística HXNR (Tabelas 7.8 e 7.9) observamos que a Heurística FPB2 apresenta tempos de execucão inferiores.
Nas instaâncias Aleatéorias a Heuréstica FP que ée mais réapida e obtéem soluçcãoes de melhor qualidade é, sem duvida, a Heurística FPB2.
Ao compararmos a Heuréstica FPB2 com a Heuréstica PSIABB, verificamos que esta apresenta soluçcoães de melhor qualidade em menor tempo, o que leva a concluir que a Heuréstica FPB2 pode ser usada num esquema enumerativo de modo a melhorar a soluçcaão obtida.
Instâncias Euclideanas
Na Heurística HXNR é possível encontrar solucão inteira admissível no nodo raiz em 60% dos casos (36 em 60 instâncias), nos restantes casos, em 3 instâncias de 1000 nodos nãao ée possével, no tempo estabelecido, encontrar soluçcãao inteira admissével e em 21 instâancias obtéem-se uma soluçcãao inteira admissével num outro nodo diferente do nodo raiz.
Nas Heurésticas FPB2 e FPO2 ée possével encontrar solucçãao inteira admissével em todas as 60 instâncias Euclideanas, mas nas Heurísticas, FPB1 e FPO1, isso não é possével em algumas instâancias, sendo de realçcar que em nenhuma delas se encontram soluçcoães inteiras admisséveis para as instaâncias de 500 e 1000 nodos, devido a exceder o tempo limite imposto. A Heuréstica FPB1 apresenta 80% de soluçcãoes inteiras admisséveis (48 em 60 instâancias) e a Heuréstica FPO1 75% (45 em 60 instâancias).
Quanto à Heurística PSIABB foi possível obter solução inteira admissível em 55 das 60 instâncias, isto é, em 91,67% dos casos. Ocorrem falhas em todas as instâncias de 1000 nodos devido ao limite de tempo imposto execeder os 10000 segundos.
No gráfico da Figura 7.15 encontram-se representadas as percentagens de gaps nulos obtidas no grupo de instancias Euclideanas para as varias estratágias heurísticas propostas.
Figura 7.15: Percentagem de gaps nulos nas diferentes heurésticas propostas nas instâncias E.
Atravós do grófico da Figura 7.15 podemos observar que das varias heurísticas propostas, as que apresentam a maior percentagem de gaps nulos sãao as Heurósticas FPB2 e FPO2, com 28,33% dos casos (17 em 60 instâncias), depois temos as Heurísticas PSIABB, FPB1 e FPO1 com 3,33% dos casos (2 em 60 instâncias) e por fim, temos a Heurística HXNR, onde apenas se encontra 1,67% de gaps nulos (1 em 60 instâncias).
Nas Tabelas 7.10 e 7.11 encontram-se os gaps mídios, em percentagem, e os respetivos desvios padrões das Heurísticas HXNR, PSIABB, FPB1, FPB2, FPO1 e FPO2.
N» Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	F	PO2
10	8,403	7,812	5,805	5,274	5,805	5	274
20	10,604	17,306	4,095	2,250	4,095	2	250
40	35,935	24,242	3,629	1,959	3,629	1	959
60	34,519	38,492	2,612	0,747	2,612	0	747
80	24,208	24,109	1,382	0,576	1,382	0	576
100	61,786	23,687	0,964	0,563	0,964	0	563
150	233,198	30,507	25,211	0,284	2,897	0	284
200	305,504	34,327	41,024	0,402	5,910	0	402
300	704,702	19,144	62,551	0,219	39,983	0	219
400	525,941	16,987	98,556	0	133,266		0
500	573,380	25,729	_c	0	_c		0
1000	1960,172	_c	_c	0	_c		0
Tabela 7.10: Gaps medios, em percentagem, obtidos pelas heurísticas propostas nas instancias E.
NA Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	FPO2	
10	8,221	9,465	3,329	3,493	3,329	3	493
20	14,241	19,424	4,028	2,685	4,028	2	685
40	45,006	14,753	2,539	0,390	2,539	0	390
60	15,882	13,610	2,256	0,708	2,256	0	708
80	12,182	12,210	1,394	0,428	1,394	0	428
100	86,493	11,118	1,062	0,662	1,062	0	662
150	279,136	16,628	17,206	0,194	2,266	0	194
200	315,907	27,172	18,747	0,195	1,867	0	195
300	483,672	4,060	22,101	0,163	25,940	0	163
400	466,805	5,088	11,418	0	12,070		0
500	745,813	16,562	_c	0	_c		0
1000	14,540	_c	_c	0	_c		0
Tabela 7.11: Desvios Padroes dos gaps obtidos pelas heurísticas propostas nas instâncias E.
cNão foi possível calcular o gap médio nem o desvio padrèo dado que ocorreu falha para todas as instâncias.
O gráfico da Figura 7.16 apresenta os gaps médios (em percentagem) obtidos pelas Heurísticas FP propostas.
Figura 7.16: Comparação dos gaps médios, em percentagem, entre as Heurísticas FP propostas nas instâncias E.
Através do gráfico da Figura 7.16 e das Tabelas 7.10 e 7.11 podemos verificar que as soluções de melhor qualidade são obtidas utilizando as Heurísticas FPB2 e FPO2. Observamos também que como os gaps medios obtidos através das Heurísticas FPB2 e FPO2 sao iguais, apenas apresentamos no gráfico acima uma destas heurísticas.
Qualquer uma das Heurísticas FP propostas apresenta gaps de melhor qualidade quando comparada com a Heurística HXNR. As solucães obtidas através da Heurística HXNR apresentam gaps extremamente elevados.
Os tempos médios de execuçao (em segundos) das varias heurísticas propostas encontram-se registados na Tabela 7.12 e os desvios padroes na Tabela 7.13.
N» Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	FPO2
10	0,081	0,889	0,037	0,013	0,078	0,016
20	1,086	3,014	0,119	0,031	0,452	0,072
40	5,213	9,083	0,880	0,115	2,746	0,281
60	10,611	12,982	3,320	0,287	7,604	0,664
80	152,247	156,859	12,439	0,540	21,497	1,283
100	74,225	104,205	42,819	1,102	59,754	2,695
150	11,260	110,573	240,824	2,299	246,808	5,370
200	77,320	252,359	444,323	4,945	507,809	11,707
300	151,588	1064,143	1480,574	18,866	1991,436	33,212
400	384,974	3403,522	6608,878	39,502	6556,432	77,788
500	1237,238	6089,540	10701,340	98,892	10422,740	150,658
1000	6556,780	10049,880	11551,760	1171,194	11315,420	1249,820
Tabela 7.12: Tempos mádios, em segundos, obtidos pelas heurísticas propostas nas instâncias E.
N» Nodos	HXNR	PSIABB	FPB1	FPB2	FPO1	FPO2
10	0,069	0,213	0,018	0,007	0,011	0
20	0,844	0,898	0,067	0,011	0,065	0,008
40	3,805	5,176	0,501	0,008	0,572	0,011
60	8,182	6,948	1,347	0,009	1,503	0,028
80	169,931	167,887	4,064	0,050	3,427	0,049
100	128,850	123,519	14,519	0,265	14,035	0,735
150	3,916	33,553	129,518	0,109	130,900	0,474
200	118,815	87,049	71,833	0,406	149,765	0,646
300	239,359	420,261	334,313	3,469	884,028	1,793
400	512,596	1663,865	2307,711	1,545	3520,799	8,077
500	1839,296	2653,828	293,686	20,967	326,293	7,509
1000	4868,197	48,077	674,723	136,915	991,950	145,128
Tabela 7.13: Desvios padrões dos tempos obtidos pelas heurísticas propostas nas instâncias E.
Em termos de tempo méedio de execuçcãao podemos afirmar que das quatro Heurésticas FP apresentadas, a FPB2 ée a mais réapida, depois temos a Heuréstica FPO2 e as Heurésticas FPB1 e FPO1 sãao as mais lentas.
Ao compararmos os tempos de execucçãao das Heuréstica FPB2 e HXNR (Tabelas 7.12 e 7.13) observamos que estes saão inferiores na Heuréstica FPB2. Eé de notar que o tempo de execucçãao da Heuréstica HXNR ée superior ao dobro do tempo de execuçcãao da Heuréstica FPB2.
No grupo de instâancias Euclideanas as Heurésticas FP que apresentam soluçcoães de melhor qualidade saão sem duévida as Heurésticas FPB2 e FPO2, sendo a Heuréstica FPB2 a que apresenta menores tempos de execucçaão.
Compararando a Heuréstica FPB2 com a Heuréstica PSIABB, esta apresenta soluçcãoes de melhor qualidade em menor tempo (a Heuréstica PSIABB apresenta tempos superiores a mais de 8 vezes o tempo de execuçcãao da Heuréstica FPB2), o que leva a concluir que a Heuréstica FPB2 pode ser usada num esquema enumerativo de modo a melhorar a solucçaão obtida.
7.5.4	Síntese dos Resultados Computacionais
Em todos os grupos de instaâncias verificéamos que a Heuréstica FPB2 encontra solucçãoes admisséveis de boa qualidade quando comparada com as restantes Heurésticas Feasibility Pump propostas. Esta tambéem apresenta uma boa qualidade quando comparada com a Heuréstica HXNR e com a Heuréstica PSIABB. Em termos de tempo computacional, nas instaâncias Aleatéorias e Euclideanas a Heuréstica FPB2 ée relativamente raépida quando comparada com qualquer heuréstica testada. No caso das instâancias Quase Caminhos, a mais réapida ée a Heuréstica HXNR, mas em termos de qualidade das soluçcãoes encontradas, esta nãao apresenta bons resultados quando comparada com qualquer uma das Heurésticas FP.
280
Capítulo 8
Método Local Branching
No caso do Problema WMST, o Método Local Branching é um esquema enumerativo que constríi uma sequência de soluçães inteiras admissíveis com valor decrescente de custos. O custo da ultima soluçao inteira admissível da sequância corresponde ao valor ítimo ou a um limite superior para o valor ítimo.
O método começa com uma solução inicial inteira admissível, depois é definida uma vizinhançca dessa solucçãao atravíes da introduçcãao no modelo de uma inequacçãao linear chamada de restricão local branching. A exploraçao da vizinhança é feita através da utilização do solver de um software de Otimizacão, como por exemplo, o Mosel do software Xpress. Caso a nova soluçao obtida tenha menor custo, então é atualizada a solucçãao e o procedimento de definiçcãao e exploracçãao ée executado novamente atée que nãao existam melhoramentos no valor do custo das soluçcãoes obtidas.
O Método Local Branching foi proposto por Fischetti e Lodi [19] para resolver Problemas de Programação Linear Inteira Mista (MIP - Mixed-Integer Linear Program) e é considerado um méetodo de melhoramento bastante eficiente na resoluçcãao de problemas de grande dimensaão.
Segundo Hassen et al. [34], o Local Branching é uma técnica MIP que foi planeada para ser um método exato, mas que atua como um método heurístico se um limite de tempo for definido e atingido antes que a soluçao otima do problema seja encontrada.
Assim, o Local Branching pode ser considerado tambéem um méetodo heuréstico que permite encontrar soluçcãoes inteiras admisséveis de boa qualidade e de forma réapida, mas com a desvantagem de nãao garantir a obtençcãao da soluçcãao éotima.
Neste capétulo mostramos a aplicaçcãao do Méetodo Local Branching ao Problema WMST. Na Secção 8.1 comecamos por introduzir alguns conceitos importantes para aplicaçcaão do Méetodo Local Branching e apresentamos um Algoritmo Local Branching
Clíssico para o Problema WMST. Na Secção 8.2 apresentamos algumas extensães do mítodo com o objetivo de melhorar o seu desempenho quando aplicado ao problema em estudo.
Na Secçao 8.3 referimos as diferenças existentes entre o Mítodo Feasibility Pump e o Mítodo Local Branching e fazemos uma abordagem geomítrica do comportamento do Mítodo Local Branching. Na Secção 8.4 descrevemos vírios algoritmos derivados do Algoritmo Local Branching Clássico descrito na Seccão 8.1. Por fim, na Secção 8.5, apresentamos e discutimos os resultados computacionais obtidos atravís da aplicação dos vírios algoritmos de Local Branching propostos e efetuamos um estudo comparativo entre o algoritmo Local Branching que apresentou os melhores resultados, para um grupo de instâncias teste e o Algoritmo Branch and Bound do Procedimento P-WMTZ+C. Para finalizar o capítulo apresentamos uma síntese dos resultados computacionais obtidos.
8.1 Local Branching Aplicado ao Problema WMST
Para aplicar o Método Local Branching ao Problema WMST, começamos por obter uma primeira solução inteira admissével que se denomina de soluçao de referência e que designamos por x G Xwmst, a qual pode ser obtida usando o solver de um software de Otimizaçao ou utilizando um método heuréstico. A solução inteira admissével x G XWMST corresponde uma arvore de suporte, com custo C(Tx) e peso W (Tx).
Tendo por base a solução de referência x e o facto das variaveis serem binérias, definem-se dois conjuntos de variaveis S = {(i,j) G A : Xj = 1}, designado de suporte binario de x, o qual é constituédo pelas variaveis que tomam o valor um na solução de
__C
N(x, k) = &amp;lt;x E Xwmst : A(x, x) =	(1 - xj) +	xj &amp;lt;k,
L	(i&gt;j)6s	(i,j)^sG	)
isto é, N(x, k) é o conjunto de soluções inteiras admissíveis (x G XWMST) que satisfazem a restrição adicional de local branching
A(x,x) :=	(1 - xij) + xij &amp;lt;k.
(i,j)€S	(i,j)^sC
(8.1)
Nesta restriçcãao linear, os dois termos do lado esquerdo contam o numero de variaveis binarias que trocam de valores (relativamente a x), do valor um para o valor zero e do valor zero para o valor um, respetivamente, esse numero total de trocas define uma vizinhança de tamanho k.
No Problema WMST, a cardinalidade do suporte binario S de qualquer solução inteira admissível e sempre constante e igual ao numero de variaveis unitarias da solução x, isto á, igual ao numero de arestas da correspondente arvore de suporte Tx.
Sempre que se efetua uma troca podemos, por exemplo, atribuir o valor zero a uma variavel que antes tinha valor um, mas para que o |S| seja constante á necessario tambáem atribuir o valor um a uma variáavel que antes tinha valor zero, o que resulta numa contabilizaçcãao dupla.
Para simplificar a restrição (8.1), podemos pensar em contabilizar apenas metade das trocas efetuadas, isto áe, contabilizar apenas as variáaveis com valor um na soluçcãao de referência. Deste modo a restricão (8.1) pode ser escrita da seguite forma,
A(x,x) :	y2 (1 — xij) &amp;lt;k'
(i,j)eS
D-
(8.2)
Um outro problema conhecido da literatura onde a cardinalidade do suporte binério é constante é o Problema do Caixeiro Viajante (TSP - Traveling Salesman Problem), onde a restricao (8.2) permite que no maximo k' arestas sejam trocadas de rota de referência x.
Como o proóprio nome sugere, a restriçcaão local branching pode ser usada como um critóerio de ramificaçcãao num esquema de enumeraçcãao do tipo Branch and Bound.
Dada uma soluçao de referência x, o espaço de solucães associado ao no corrente pode ser particionado em duas ramificaçcãoes:
(i) A(x,x) &amp;lt;k (ramo esquerdo) ou (ii) A(x,x) &gt; k + 1 (ramo direito).
A escolha do tamanho das vizinhanças, dado pelo parâmetro k, torna-se difícil, pois pode depender do tamanho e da estrutura das instâancias utilizadas. O valor de
k deverí ser suficientemente grande para que a vizinhanca N(x, k) contenha soluçães melhores que x mas, por outro lado, deverí ser pequeno o suficiente de forma a garantir que a vizinhanca N(x, k) seja explorada rapidamente. Em [19] são utilizados valores de k no intervalo [10, 20], os quais têm mostrado ser eficientes para Problemas MIP.
No esquema que se segue apresentamos de forma resumida as principais etapas da implementação do Mítodo Local Branching Clíssico aplicado ao Problema WMST.
Algoritmo Local Branching Clássico (ALBC) Aplicado ao Problema WMST
Passo 1: Obter uma solucão inteira admissível inicial
Fazer t := 1. Seja x = xl a solução de referência obtida atraves de um solver.
Passo 2: Introduzir a restrição local branching
t := t + 1.
Definir S = {(i,j) G A : xij = 1} e um valor de k inteiro e positivo.
Introduzir a restriçao local branching A(x,x) &amp;lt;k.
Obter a soluçao ítima x* da vizinhanca N(x, k) utilizando um solver.
Passo 3: Critério de paragem e obtenção de novas soluçães inteiras admissíveis
Se status de N(x,k) = “Optimum found”, então
Se C(Txt) &amp;lt;C(Tx), entao
atualizar x = x* e voltar a efetuar o Passo 2.
Caso contríario,
introduzir A(x,x) &gt; k + 1 e utilizar um solver para obter xk
Se C(Txt) &amp;lt;C(Tx), entao
atualizar x = xk
STOP.
No Passo 1, o solver de um software de Otimização é chamado e a execução do Algoritmo Branch and Bound de uma formulação para o Problema WMST é interrompida assim que seja encontrada uma primeira soluçao inteira admissível X G Xwmst, a qual í tomada como solucão de referância X = xt.
No Passo 2, e inserida uma nova restricão, A(X,Xt) &amp;lt;k, para reduzir o espaço de solucães XWMST e assim formar o novo espaço de soluções Xt = XWMST n N(Xt, k). O solver é entao chamado para encontrar a solucão otima da vizinhança N(Xt,k). No Passo 3, se a nova solucão encontrada Xt+1 for melhor do que a solucao Xt, isto e, se C(Txt+i) &amp;lt;C(Txt), então volta-se ao Passo 2, onde é inserida a nova restricao A(x,Xt+1) &amp;lt;k tendo como base a nova solucão de referância Xt+1. O novo espaço de soluçães para este subproblema passa a ser Xt+1 = (XWMST\Xt) N(xt+1, k) e o solver e chamado novamente para encontrar a solucao otima da vizinhança N(xt+1, k).
No caso de continuar a existir melhoria no custo das soluçcãoes obtidas, o procedimento de ramificação continua a ser executado. Apos l iteracães foram inseridas l restriçães local branching, sendo o novo espaço de soluçoes para o subproblema em questão Xi = (Xwmst\X1\X2\ ... \X1_1) n N(xl, k).
Se não for encontrada uma solucão de custo inferior ao custo da solucão de referância, então não e possível aplicar mais o metodo, sendo o solver chamado para explorar o restante espaco de pesquisa correspondente a ramificacao direita A(x, X) &gt; k + 1. Se o custo da solucçãao encontrada nesta exploraçcãao local for inferior ao custo da soluçcãao de referâencia, entãao íe atualizada a solucçaão de referâencia e conclui-se a enumeracçãao.
Exemplo 8.1.
Como exemplo de aplicação do Algoritmo ALBC ao Problema WMST apresentamos um esquema em írvore na Figura 8.1, onde í usado o Algoritmo ALBC na instância 10-8 do grupo de instancias Quase Caminhos com W = 1000. Para a restrição local branching considerou-se a desigualdade (8.2) com k' = 5 e utilizou-se a Formulacão WMTZ.
No nodo 1 e obtida atraves do solver do software Xpress, a soluçcãao de referâencia X = X1, com custo 659 e peso 991. Apos a introdução da restrição local branching, A(x,X1) &amp;lt;5, obteve-se no nodo 2 a soluçao X2. Como C(Tx2) = 605 &amp;lt;659 = C(Txi), então a solucao de referância X e atualizada para X2. No nodo 3 é adicionada a ramificação esquerda correspondente a introducao da restricão A(x,X2) &amp;lt;5 e obtida
no nodo 4 a mesma solução obtida no nodo 2. Como esta solução não tem custo inferior ao da soluçao de referência, então voltamos ao nodo 3 e inserimos a ramificação direita correspondente à restrição A(x,x2) &gt; 6 para explorar o restante espaço de pesquisa e assim concluir a enumeração no nodo 5 com uma solução que é atualizada, pois C(Tx4) = 577 &amp;lt;605.
Figura 8.1: Esquema de ramificação obtido usando o Algoritmo ALBC na instância QC10-8.
Assim, x = x4 é a solucão obtida e corresponde a uma érvore de suporte Tx que contém as arestas {0,1}; {0, 7}; {1, 2}; {2, 3}; {2,5}; {4, 6}; {6, 7}; {7, 8} e {8, 9}. A árvore Tx tem custo C(Tx) = 577 e peso W(Tx) = 999 e corresponde à solucao otima desta instêancia.
8.2	Extensões do Método Local Branching
Com os métodos exatos há a garantia de encontrar a solução ótima global. No entanto, à medida que a dimensão dos problemas aumenta, os tempos de execução também aumentam, revelando-se necessário o uso de métodos heurésticos.
Uma vantagem do uso de mátodos heurísticos comparativamente ao uso de mátodos exatos, reside no facto de ser possável obter solucões admissáveis muito rapidamente, mas por outro lado apesar de se obterem solucões de forma rápida existe a desvantagem de nao ser garantida a obtençõo da soluçõo átima.
Ao usarmos o Mátodo Local Branching como um mátodo exato, existe uma maior integracõo com o solver de um software de Otimizacõo, mas temos a desvantagem de desperdicar muito tempo computacional, particularmente, quando nenhuma soluçao melhor do que a soluçõo de referência á encontrada. Se for imposto um limite de tempo no Algoritmo Local Branching Clássico aplicado ao Problema WMST este passa a comportar-se como um máetodo heurástico.
Apresentamos, de seguida, algumas formas de melhorar o desempenho da Heurástica Local Branching.
8.2.1	Solução de Referência Inicial
A escolha da soluçao de referência inicial é muito importante. E usual considerar uma soluçõo inteira admissível inicial fornecida pelo solver. Contudo, em algumas instaências, obter uma soluçcõao inteira admissével inicial pode demorar muito tempo, pelo que podemos usar como soluçcõao de referêencia:
1.	A soluçao correspondente à arvore de suporte de peso mínimo Tw;
2.	A solucõo obtida através de um esquema Heurístico Feasibility Pump;
3.	A soluçõo correspondente a uma írvore de suporte que verifique a restriçõo de peso.
8.2.2	Mecanismos de Intensificação e de Diversificação
Estes dois mecanismos de intensificação e de diversificação utilizam-se quando a solucao nao melhora. No que segue, convem referir, que |_pJ converte o numero p no maior numero inteiro menor ou igual a p e [p1 converte o numero p no menor numero inteiro maior ou igual a p.
•	Mecanismo de Intensificação
Este mecanismo tem por objetivo reduzir o tamanho da vizinhança a ser explorada e, consequentemente, o tempo de pesquisa.
O lado direito da restricão A(x,x) &amp;lt;k e reduzido para [|J, ou seja, introduz-se a restrição A(x,x) &amp;lt;[2J e utiliza-se novamente o solver para encontrar uma nova solução.
•	Mecanismos de Diversificação
Estes mecanismos têm por objetivo aumentar o tamanho da vizinhança a ser explorada e, consequentemente, o tempo de pesquisa.
Começamos por aplicar um mecanismo de diversificação fraca e caso nenhuma soluçao melhor seja encontrada, aplicamos um mecanismo de diversificação mais forte.
— Mecanismo de Diversificaçao Fraca
O lado direito da restricão A(x,x) &amp;lt;k e aumentado em [11, ou seja, e introduzida a restricão A(x,x) &amp;lt;k + [11 e utilizamos novamente o solver para encontrar uma nova soluçao.
— Mecanismo de Diversificaçao Forte
O lado direito da restriçao A(x,x) &amp;lt;k e aumentado em 2 x [21, isto é, e introduzida a restricão A(x,x) &amp;lt;k + 2[11 e utilizamos novamente o solver para encontrar uma nova soluçao. Este mecanismo de diversificação e inspirado na tecnica Variable Neighborhood Search [47].
Ao aplicar este ultimo mecanismo, geralmente encontra-se uma solução pior que a melhor solucão conhecida, mas não muito distante dela.
Note-se que o mecanismo de diversificação forte sí é executado se o mecanismo de diversificacão fraca foi executado sem sucesso na iteração anterior.
8.2.3	Critérios de Paragem
Em alguns casos, e dependendo do valor do parâmetro k, o tempo de processamento do ramo esquerdo até encontrar a solucao ítima na vizinhanca N(x, k) é muito elevado. Assim, do ponto de vista heurístico é razoível impor à partida um critério de paragem no solver. Pode-se optar, por exemplo, pelos dois critérios seguintes:
•	explorar as vizinhanças até que a primeira solução inteira seja obtida;
•	impor um limite de tempo na exploraçao das vizinhanças.
Como são impostos critérios de paragem no solver quando se explora uma dada vizinhança pode acontecer uma das seguintes situacães:
1. A solucao obtida é otima
O solver resolveu o subproblema até encontrar a solução otima da vizinhança N(x, k). Nesta situação podem ocorrer os seguintes casos:
•	A solucão otima obtida é melhor do que a soluçao de referência
O solver conseguiu encontrar a solução otima x da vizinhança N(x, k), tal que, C(Txt) &amp;lt;C(Tx), então atualizamos a solucão de referência para a nova soluçao encontrada. Sem alterar o valor do parâmetro k, introduzimos a restricao A(x,x) &amp;lt;k.
•	A soluçao otima obtida nao e melhor do que a soluçao de referência O solver conseguiu encontrar a solucão otima xtj da vizinhanca N(x,k), tal que, C(Txt) &gt; C(Tx). Neste caso, o solver é chamado para explorar o restante espaco de pesquisa (introduçao da restricao A(x,x) &gt; k + 1 correspondente à ramificacão direita) e assim concluir a enumeração.
2.	A solucao obtida não é admissível
O solver nõo conseguiu encontrar uma soluçõo inteira admissível para o subproblema na vizinhança N(x, k).
3.	A solucao obtida é admiss ível
O solver resolveu o subproblema e encontrou uma soluçõo inteira admissível, mas nao corresponde a solucao otima da vizinhanca N(x, k). Nesta situacõo podem ainda ocorrer dois casos:
•	A solucão obtida é melhor do que a solucao de referência
O solver conseguiu encontrar na vizinhança N(x, k) uma soluçõo inteira admissível xú, tal que, C(Txt) &amp;lt;C(Tx), entao atualizamos a soluçao de referencia para a nova solucõo encontrada. Sem alterar o valor do parâmetro k, introduzimos a restriçao A(x,x) &amp;lt;k.
•	A solucão obtida nao e melhor do que a solucao de referência
O solver conseguiu encontrar na vizinhanca N(x, k) uma soluçõo inteira admissível xú, tal que, C(Txt) &gt; C(Tx). Neste caso podemos aplicar os mecanismos de intensificaçõo ou diversificaçõo de modo a reduzir ou a aumentar a vizinhança.
8.3	Local Branching versus Feasibility Pump
Na Heurística Feasibility Pump (FP), para a obtencõo da solucõo inicial é necessario recorrer ao solver de um software de Otimizacõo para obter x*, a soluçõo ítima da relaxaçõo linear de uma formulaçao para o Problema WMST, sendo esta depois arredondada de acordo com determinado critério e obtida assim uma soluçõo inteira x, que pode ou nõo ser admissível. Na Heurística Local Branching (LB) podemos recorrer inicialmente ao solver para resolver o Algoritmo Branch and Bound de uma formulacõo para o Problema WMST até que seja obtida uma primeira soluçõo inteira admissível, x, ou optar por uma das soluçoes de referância proposta na Subsecçõo 8.2.1. Enquanto que na Heurística LB a soluçõo inicial x é inteira e admissível, na Heurística FP a soluçao inicial x é inteira, mas pode ou nao ser admissível.
Em ambos os métodos utilizamos a função distância A(x,x) e pretendemos que esta seja pequena, isto é, na Heuréstica FP a funçao distância é utilizada como função objetivo que se pretende minimizar, enquanto que na Heurística LB é usada como restriçao, onde se pretende explorar uma vizinhança pequena (não permitindo que se efetuem muitas trocas) de tal forma que a vizinhança seja explorada rapidamente.
Quando em duas iteracoes consecutivas as solucães forem iguais, isto é, não houver melhoramento no custo das soluçães, na Heuréstica FP aplicam-se mecanismos de perturbacão e na Heuréstica LB aplicam-se mecanismos de intensificação e de diversi-ficacao.
Geometricamente, a Heuréstica FP define duas trajetórias de pontos que se esperam convergentes (ver Secçao 7.4), enquanto que a Heuréstica LB define apenas uma trajetória de pontos inteiros e admisséveis que se espera convergente para um ponto. A Heuréstica LB também se pode interpretar como uma trajetória de custos e uma trajetória de pesos que convergem para um custo C(Tx) e um peso W(Tx).
Nos gréficos das Figuras 8.2 e 8.3 podemos observar as trajetórias de custos e de pesos da instância 10-8 do grupo de instâncias Quase Caminhos.
Figura 8.2: Representação da trajetória de custos da instância QC10-8.
Figura 8.3: Representação da trajetória de pesos da instância QC10-8.
A trajetória de custos converge para o custo 577 e a trajetória de pesos converge para o peso 999. Assim ó obtida a soluçao otima que corresponde a uma órvore de suporte com custo C(Tx) = 577 e peso W(Tx) = 999.
Note-se que no caso da Heurística LB a sequência de custos obtida ó decrescente, pois só são atualizadas as solucões no caso de existir melhoramento. Na Heurística FP as duas sequências de custos podem não ter qualquer monotonia.
8.4	Descrição dos Algoritmos Local Branching para o WMST
Tendo por base o Algoritmo ALBC aplicado ao Problema WMST apresentado e
descrito detalhadamente na Secção 8.1, propomos cinco versões para testar e comparar.
Algoritmo Local Branching 1 (ALB1)
Este algoritmo é o apresentado na Secçao 8.1 com ligeiras modificações. Atendendo a que à medida que a dimensão do problema aumenta, o tempo de execuçao também
aumenta, haé a necessidade de impor um limite de tempo para a execuçcõao do algoritmo (TL). O facto de impor um limite de tempo, leva a que o Passo 3 do Algoritmo ALBC aplicado ao Problema WMST seja modificado, tomando a seguinte forma:
Passo 3: Critério de paragem e obtenção de novas soluções inteiras admissíveis
Se status de N(x, k) = “Optimum found”, entõo
Se C(Txt) &amp;lt;C(Tx), entõo
atualizar x = xú e voltar a efetuar o Passo 2.
Caso contréario,
introduzir A(x,x) &gt; k + 1 e utilizar um solver para obter xí
Se C(Txt) &amp;lt;C(Tx), entao
atualizar x = xí
STOP.
Caso contraério,
Se status de N(x, k) = “Unfeasible”, entõo
STOP.
Caso contréario,
Se status de N(x, k) = “Unfinished”, entõo
Se C(Txt) &amp;lt;C(Tx), entao
atualizar x = xú e voltar a efetuar o Passo 2.
Caso contréario,
introduzir A(x,x) &gt; k + 1 e utilizar um solver para obter xí
Se C(Txt) &amp;lt;C(Tx), entao
atualizar x = xí
STOP.
Se um limite total de tempo ée imposto para a execucçõao do algoritmo, significa que na uéltima vizinhançca a ser explorada pode acontecer que o solver tenha de parar
antes que uma solucão inteira admissável seja encontrada ou antes de ser provada a otimalidade na vizinhançca explorada. Estes casos que podem ocorrer encontram-se descritos na Subsecção 8.2.3.
Algoritmo Local Branching 2 (ALB2)
Neste algoritmo á tambám imposto um limite de tempo (igual ao do Algoritmo ALB1). São introduzidos mecanismos de intensificação e de diversificação e o solver á interrompido assim que se obtenha uma solução inteira admissável no Algoritmo Branch and Bound de uma formulação para o Problema WMST. Assim, á necessário modificar os Passo 2 e 3 do Algoritmo ALBC descrito na Seccão 8.1 que passam a ter a seguinte forma:
Passo 2: Introduzir a restrição local branching
t := t + 1.
Definir S = {(i,j) G A : xij = 1} e um valor de k inteiro e positivo.
Introduzir a restrição local branching A(x,x) &amp;lt;k.
Obter uma solucão inteira admissável x* da vizinhança N(x, k) utilizando o solver.
Passo 3: Critério de paragem e obtenção de novas soluçães inteiras admissíveis
Se status de N(x,k) = “Optimum found”, então
Se C(Txt) &amp;lt;C(Tx), entao
atualizar x = x* e voltar a efetuar o Passo 2.
Caso contráario,
introduzir A(x,x) &gt; k + 1 e utilizar um solver para obter x*.
Se C(Txt) &amp;lt;C(Tx), então
atualizar x = x*.
STOP.
Caso contraário,
Se status de N(x,k) = “Unfeasible”, então
aumentar k := k + 1 e aplicar o Mecanismo de Diversificação Forte.
Caso contréario,
Se status de N(x, k) = “Unfinished”, então
Se C(Txt) &amp;lt;C(Tx), entao
atualizar x = x1 e voltar a efetuar o Passo 2.
Caso contréario,
aplicar os Mecanismos de Intensificação e de Diversificacão.
Enquanto que no Passo 2 do Algoritmo ALBC procuramos obter a solucao átima da vizinhança, no Passo 2 deste algoritmo apenas procuramos encontrar a primeira solucao inteira admissível da vizinhança.
Os mecanismos de intensificaçao e de diversificação sao introduzidos quando nao é encontrada uma solução inteira admissível ou quando a solução obtida é inteira admissível e não e melhor do que a soluçao de referência. Os mecanismos de intensificação e de diversificação são aplicados como descrito na Subseccão 8.2.2. Primeiro tentamos aplicar o mecanismo de intensificacao, para reduzir o tempo de pesquisa. Se não se conseguir uma soluçcaão melhor, entãao aplicamos a diversificaçcãao fraca. O mecanismo de diversificação forte sé é aplicado no caso de na iteracão anterior se ter aplicado sem sucesso um mecanismo de diversificaçcãao fraca.
Algoritmo Local Branching 3 (ALB3)
Os Passos 2 e 3 foram implementados da mesma forma que os Passos 2 e 3 do Algoritmo ALB2. A solução de referência obtida no Passo 1 corresponde a primeira solução inteira admissével obtida pelo solver quando usa o procedimento Branch and Bound. Na obtencão das restantes soluçães inteiras admissíveis é imposto um limite de tempo na exploracão das vizinhanças (nodos de ramificação esquerdos).
Uma vantagem deste algoritmo em relaçao ao anterior é o facto de durante o tempo imposto para a exploracão ser possével encontrar soluções inteiras admissíveis de melhor qualidade, dado que cada vez que se chama o solver este não é interrompido assim que se obtéem a primeira soluçcãao inteira admissével, mas sim quando exceder o limite de
tempo imposto na exploração da vizinhança. Tal como nos Algoritmos ALB1 e ALB2 e ainda imposto um tempo limite total para a execuçao do algoritmo (TL).
Exemplo 8.2.
Para exemplificar a introduçcãao dos mecanismos de intensificaçcãao e de diversificaçcãao vamos aplicar o Algoritmo ALB3 à instância 10-10 do grupo de instancias Quase Caminhos com W = 1000. Para a restrição local branching considerou-se a desigualdade (8.2) com k' = 5 e utilizou-se a Formulação WMTZ.
No esquema em arvore da Figura 8.4 podemos observar que no nodo 1 e obtida a solucao de referância x = x1, com custo 782 e peso 872. Apos se ter introduzido a restricao A(x,x1) &amp;lt;5, obteve-se no nodo 2 a solucao x2. Como o custo desta soluçao e inferior ao custo da soluçao de referância (C(Tx2) = 662 &amp;lt;782 = C(Txi)), entao atualiza-se x = x2. No nodo 3 e adicionada a ramificação esquerda A(x,x2) &amp;lt;5 e a solucçaão obtida no nodo 4 naão melhora, o que leva a introduzir um mecanismo de intensificaçcaão. Entãao volta-se ao nodo 3 e adiciona-se a ramificaçcãao correspondente a A(x,x2) &amp;lt;2. Como a solucão obtida no nodo 5 continua a nao melhorar, então aplica-se um mecanismo de diversificacçaão fraca que corresponde a voltar ao nodo 3 e introduzir mais uma ramificação com a restricão A(x,x2) &amp;lt;7. Como a solucão obtida no nodo 6 tem custo inferior a C(Tx) = 662, então atualiza-se a soluçao de referância para x5. No ramo que liga o nodo 7 ao nodo 9 volta-se a aplicar o mecanismo de intensificacçaão dado que a restriçcãao que foi introduzida na ramificacçãao do nodo 7 para o nodo 8 nãao originou melhorias. Finalmente, a ligaçcaão do nodo 7 ao nodo 10 explora o restante espacço de pesquisa. A solucçãao tem custo 657 e peso 930.
Figura 8.4: Esquema de ramificação obtido usando o Algoritmo ALB3 na instância QC10-10.
Os próximos algoritmos que vamos apresentar apenas diferem do Algoritmo ALB3 no Passo 1, onde ó obtida uma solução de referência inicial sem recorrer ao solver.
Algoritmo Local Branching 4 (ALB4)
Para a obtençcãao da solucçãao de referêencia inicial usamos a soluçcaão inteira admissóvel obtida atravós da Heurística FPB2 apresentada no Capítulo 7. A escolha desta heurística deve-se ao facto de, em geral, ter apresentado soluçães de melhor qualidade num menor tempo (ver resultados computacionais do Capítulo 7). Com a aplicaçao deste algoritmo pretendemos melhorar a solução obtida atravós da Heurística FPB2. Em caso de falha da Heurística Feasibility Pump na obtençao de uma solução inteira admissível, usa-se
o solver para obter a primeira solucão de referência.
Algoritmo Local Branching 5 (ALB5)
A primeira solução de referência corresponde à arvore de suporte de peso mínimo Tw, a qual pode ser obtida através da aplicacao do Algoritmo de Prim [51].
8.5	Experiencias para Comparacão dos Algoritmos
Local Branching e Resultados Computacionais
Nesta secção apresentamos os resultados computacionais dos vários algoritmos Local Branching propostos para o Problema WMST. Começamos por efetuar um estudo comparativo entre os vários algoritmos Local Branching propostos com o objetivo de escolher o mais eficiente para o comparar com o algoritmo Branch and Bound do Procedimento P-WMTZ+C.
Todos os testes foram efetuados num Intel(R) Core(TM)2 Duo CPU (T7100) 2.00 GHz processador e 4Gb de RAM e usou-se o software Xpress 7.3 (Xpress-Optimizer 23.01.03 e Xpress-Mosel 3.4.0) [1] para implementar todos os algoritmos Local Branching.
Como em todos estes algoritmos á obtido um limite superior para o valor do custo, que pode ou não ser o valor átimo, o gap correspondente á dado por
LS - O PT gap = OPT
x 100,
onde LS é o valor do limite superior obtido para o valor do custo através da aplicação de um dos algoritmos Local Branching e OPT é o valor ítimo (â(W M ST)) ou o melhor valor encontrado atée ao momento.
8.5.1	Exemplo Comparativo dos Algoritmos Local Branching
Com o objetivo de comparar os diferentes algoritmos Local Branching descritos ao longo da Secção 8.4 elaborámos a Tabela 8.1, onde se apresentam os sucessivos custos e pesos obtidos em cada um dos algoritmos para a instância 10-8 do grupo de instâncias Quase Caminhos.
	ALB1		ALB2		ALB3		ALB4		ALB5	
Iter	Custo	Peso	Custo	Peso	Custo	Peso	Custo	Peso	Custo	Peso
0	659	991	659	991	659	991	637	821	793	650
1	605	985	665	985	605	985	629	872	577	999
2	605	985	609	981	605	985	605	985	577	999
3	577	999	653	875	577	999	605	985	577	999
4			605	985			577	999		
5			673	861						
6			605	985						
7			577	999						
Tabela 8.1: Comparação dos algoritmos Local Branching na instância QC10-8.
Os valores a negrito na Tabela 8.1 indicam que foi atualizada a solução de referância.
Na instância QC10-8 o valor do custo e do peso da soluçao de referância inicial íe igual nos Algoritmos ALB1, ALB2 e ALB3, pois nestes trâes algoritmos a soluçcãao inicial corresponde a primeira soluçao inteira admissível obtida pelo solver atravís da Formulaçcãao WMTZ quando usa o procedimento de Branch and Bound.
No Algoritmo ALB4 o valor do custo da soluçcaão de referâencia inicial íe melhor do que o obtido nos restantes algoritmos, dado que íe obtido atravíes da Heurística FPB2 apresentada no Capítulo 7, enquanto que o valor do custo da solução de referência inicial usada no Algoritmo ALB5 íe o de pior qualidade, pois corresponde ao valor do custo da íarvore de suporte de peso mínimo, mas logo na iteraçcãao seguinte consegue-se obter o valor íotimo. Nesta instaância todos os algoritmos convergem para o mesmo valor de custo e de peso, sendo o custo 577 e o peso 999 que corresponde a solução ítima da instâancia. Neste exemplo, o algoritmo que realiza um maior nuímero de iteraçcoães íe o Algoritmo ALB2.
8.5.2	Estudo Comparativo dos Algoritmos Local Branching
Nesta subsecção, para comparar os diferentes algoritmos Local Branching propostos apenas apresentamos os resultados computacionais de instâncias até 100 nodos dos grupos de instâncias Quase Caminhos, Aleatórias e Euclideanas (ver Seccão 2.3).
Para começar vamos descrever os parâmetros utilizados nos algoritmos. Em todos os algoritmos Local Branching propostos foi imposto um limite de tempo global na execuçao do algoritmo que corresponde a TL = 10800 segundos. Apés se efetuarem algumas experiâncias computacionais decidimos utilizar a restrição local branching dada pela expressão (8.2). Quanto aos valores de k testaram-se alguns valores no intervalo [10, 20]. No seguinte gréfico encontram-se os tempos médios de execuçao (em segundos) para instancias até 100 nodos de trâs valores de k'.
Figura 8.5: Tempos médios de execução, em segundos, obtidos usando o Algoritmo ALB4 para diferentes valores de k'.
Através do gráfico da Figura 8.5 podemos observar que a medida que o valor de k' aumenta, os tempos médios também aumentam para instâncias maiores ou iguais a 40 nodos. Realca-se ainda que se encontram solucoes de melhor qualidade quando k' = 5. Assim, em todos os Algoritmos LB com exceçao do Algoritmo ALB5 vamos utilizar o valor do parâmetro k =10 (k' = 5). No Algoritmo ALB5 foi escolhido inicialmente
n — 1
2
um k' =
A escolha deste valor deve-se ao facto do custo da correspondente
írvore de suporte de peso mínimo estar bastante afastada do valor étimo e ao serem
efetuadas poucas trocas pode nõo ser possível encontrar uma soluçao na vizinhanca considerada N(x, k).
Depois de realizadas algumas experiências, nos algoritmos onde se aplicam os me
canismos de intensificação e de diversificacão o numero de intensificacães ou diversi-
ficaçoes foi limitado a 5.
Nos Algoritmos ALB3, ALB4 e ALB5 foram impostos tempos (em segundos) para explorar as vizinhanças, os quais se encontram na seguinte tabela.
	N.° Nodos	10	20	40	60	80	100
ALB3	QC e R	1	2	5	10	20	40
	E	1	2	10	30	200	350
ALB4 e ALB5	QC e R	1	2	5	10	20	40
	E	1	2	10	15	20	50
Tabela 8.2: Tempo, em segundos, imposto na exploraçao das vizinhanças.
De seguida comparamos os algoritmos Local Branching propostos em cada um dos grupos de instâncias em separado para averiguar qual dos algoritmos é o mais eficiente.
Instâncias Quase Caminhos
No gráfico da Figura 8.6 podemos observar a percentagem de soluções ótimas obtidas no grupo de instâncias Quase Caminhos em cada um dos algoritmos Local Branching propostos para instâncias ate 100 nodos.
Figura 8.6: Percentagem de soluções ótimas obtidos pelos algoritmos Local Branching nas instâncias
QC.
Em todos os algoritmos com exceção do Algoritmo ALB2 obtêm-se percentagens elevadas de solucães otimas. Com a aplicacao do Algoritmo ALB1 as 60 instências testadas apresentam gap nulo. O Algoritmo ALB4 é o segundo a ter maior percentagem de soluçães otimas (95% que corresponde a 57 em 60 instências). Depois, temos o Algoritmo ALB3 com solucães otimas em 76,67% dos casos (46 em 60 instências). O Algoritmo ALB5 tambem apresenta uma boa percentagem de soluções otimas, 73,33%, que corresponde a 44 instêancias. O algoritmo com menor percentagem de soluçcãoes otimas e o Algoritmo ALB2 com apenas 38,33% dos casos (23 em 60 instancias).
Na Tabela 8.3 podemos visualizar os gaps medios, em percentagem, e os correspondentes desvios padrãoes e tambem os tempos medios de execuçcãao, em segundos, e os respetivos desvios padroes obtidos para os cinco algoritmos Local Branching propostos.
N» Nodos		ALB1	ALB2	ALB3	ALB4	ALB5
	10	0	0,338	0	0	0
	20	0	1,546	0,097	0	0
Gap Medio (%)	40	0	1,063	0,222	0,174	0,181
	60	0	0,761	0,043	0	0
	80	0	0,156	0,037	0	0,015
	100	0	0,424	0,160	0	0
	10	0	0,765	0	0	0
	20	0	3,752	0,306	0	0
	40	0	0,994	0,366	0,438	0,475
agap	60	0	0,640	0,092	0	0
	80	0	0,226	0,118	0	0,032
	100	0	0,551	0,280	0	0
	10	0,421	0,582	0,403	0,398	0,394
	20	3,750	4,663	3,491	2,368	3,035
Tempos Medio (s)	40	64,057	29,265	24,322	20,005	36,845
	60	2273,078	17,854	34,097	23,998	76,875
	80	3443,434	41,932	61,954	51,046	159,832
	100	9999,254	67,038	123,663	98,633	287,813
	10	0,092	0,212	0,053	0,143	0,191
	20	1,143	1,676	1,021	0,688	1,053
tempo	40	35,763	6,668	5,040	5,844	3,450
	60	3554,363	3,349	14,049	5,315	6,752
	80	3593,114	8,988	17,306	10,495	24,908
	100	0,418	16,523	19,429	19,435	25,297
Tabela 8.3: Comparação dos algoritmos Local Branching em termos de gaps médios (em percentagem) e de tempo medio de execução (em segundos) nas instâncias QC.
Os Algoritmos ALB1, ALB4 e ALB5 são os que apresentam gaps de melhor qualidade. Quanto aos Algoritmos ALB2 e ALB3 são os que apresentam os gaps de pior qualidade, embora relativamente baixos.
Quanto ao tempo de execuçao podemos observar que os Algoritmo ALB2 e ALB4 são os mais rópidos. O Algoritmo ALB1 apesar de ter gap nulo para todas as intências apresenta tempos médios bastante elevados quando comparado com os restantes algoritmos.
Instâncias Aleatórias
No gráfico da Figura 8.7 podemos observar a percentagem de soluções ótimas obtidas no grupo de instancias Aleatárias em cada um dos algoritmos Local Branching propostos para instancias atá 100 nodos.
Figura 8.7: Percentagem de soluções ótimas obtidas pelos Algoritmos Local Branching nas instâncias
R.
Da observação do gráfico, verifica-se que neste grupo de instâncias se encontram muitos gaps nulos. Com a aplicação do Algoritmo ALB1 as 30 instancias testadas apresentam gap nulo. O Algoritmo ALB4 á o segundo a ter maior percentagem de soluçães átimas, 93,33% que corresponde a 28 instancias. A seguir, temos o Algoritmo ALB3 com soluçães otimas em 86,67% das instancias (26 em 30 instancias). O Algoritmo ALB5 tambám apresenta uma boa percentagem de soluçães átimas, 76,67% que corresponde a 23 instancias. O algoritmo com menor percentagem de soluçcoães oátimas á o ALB2 com apenas 33,33% dos casos (10 em 30 instancias).
Na Tabela 8.4 podemos observar os gaps médios, em percentagem obtidos para cada um dos algoritmos Local Branching e os respetivos desvios padrães. Na mesma tabela sao tambám apresentados os tempos mádios de execução, em segundos, e os correspondentes desvios padrãoes.
N» Nodos		ALB1	ALB2	ALB3	ALB4	ALB5
	10	0	0	0	0,501	0
	20	0	2,280	0,039	0	0
Gap Médio	40	0	1,705	0,369	0	24,433
	60	0	0,525	0	0	2,817
	80	0	1,137	0,007	0	0,021
	100	0	11,614	1,255	0,010	37,293
	10	0	0	0	1,119	0
	20	0	3,535	0,087	0	0
	40	0	2,668	0,577	0	54,524
agap	60	0	0,637	0	0	6,300
	80	0	1,325	0,015	0	0,046
	100	0	12,036	1,225	0,023	74,585
	10	0,405	0,549	0,605	0,375	0,222
	20	2,683	4,733	2,818	2,346	2,209
Tempos Medio (s)	40	17,257	26,271	13,670	10,062	12,103
	60	18,891	20,321	20,037	13,473	15,001
	80	64,020	48,808	49,259	30,499	39,717
	100	1942,807	90,721	238,077	75,494	89,788
	10	0,164	0,373	0,343	0,166	0,089
	20	0,822	0,350	0,756	0,269	0,907
tempo	40	8,272	6,820	4,726	2,595	10,435
	60	6,074	4,764	10,700	3,962	11,722
	80	54,930	10,903	54,326	12,240	32,372
	100	2690,993	45,009	189,743	40,712	122,236
Tabela 8.4: Comparação dos algoritmos Local Branching em termos de gaps médios (em percentagem) e de tempo medio de execução (em segundos) nas instâncias R.
Os Algoritmos ALB1, ALB3 e ALB4 além de apresentarem as maiores percentagens de soluções étimas, também são os que apresentam os gaps de melhor qualidade. Quanto aos Algoritmos ALB2 e ALB5 são os que apresentam os gaps de pior qualidade.
O Algoritmo ALB4 apresenta tempos médios inferiores para instâncias com mais de 40 nodos e os Algoritmos ALB1 e ALB3 apresentam tempos médios mais elevados quando comparados com o Algoritmo ALB4.
Instâncias Euclideanas
No gráfico da Figura 8.8 apresentam-se as percentagens de soluções ótimas obtidas em cada um dos algoritmos Local Branching no grupo de instâncias Euclideanas para instâncias atá 100 nodos.
Figura 8.8: Percentagem de soluções ótimas obtidas pelos algoritmos Local Branching nas instâncias
E.
Os algoritmos que apresentam maior percentagem de soluções ótimas são o Algoritmo ALB1 com 83,33% das instancias (25 em 30 instâncias) e o Algoritmo ALB4 com 50% dos casos (16 em 30 instâncias). O Algoritmo ALB3 apresenta 40% de soluções ótimas que corresponde a 14 instâncias. No Algoritmo ALB5 obtóm-se 30% de soluções otimas, mas estas ocorrem apenas em instancias de 10 e 20 nodos (9 em 30 instâncias) e no Algoritmo ALB2 apenas se consegue obter a solucçõao óotima em 3 instâancias.
Na Tabela 8.5 sõo apresentados os gaps módios, em percentagem, obtidos para cada um dos algoritmos Local Branching propostos e os respetivos desvios padrões. Nesta tabela sõo tambóm apresentados os tempos módios de execuçõo, em segundos, acompanhados dos correspondentes desvios padroes.
N» Nodos		ALB1	ALB2	ALB3	ALB4	ALB5
	10	0	2,180	0,489	0	0
	20	0	2,875	1,451	0,103	1,705
Gap Médio (%)	40	0	4,416	1,975	0,121	2,234
	60	0	9,303	0,031	0,076	11,600
	80	0,281	9,154	0,460	0,085	34,397
	100	0,151	15,792	0,307	0,064	22,105
	10	0	3,356	0,547	0	0
	20	0	3,191	3,045	0,230	3,813
	40	0	3,194	1,976	0,268	3,485
agap	60	0	6,355	0,059	0,126	8,665
	80	0,409	3,426	0,655	0,153	29,054
	100	0,207	3,422	0,330	0,069	26,790
	10	0,885	2,278	2,686	2,689	0,705
	20	6,520	14,917	13,407	6,845	6,739
Tempos Médio (s)	40	88,598	63,845	75,011	29,515	43,164
	60	3802,020	62,197	241,641	28,979	75,451
	80	8084,062	476,787	1927,288	44,585	123,633
	100	9102,888	319,507	3471,078	132,123	232,832
	10	0,396	1,204	1,770	1,782	0,478
	20	2,841	2,271	3,942	3,258	3,214
^tempo	40	71,630	10,628	23,181	7,639	36,337
	60	4238,789	28,713	116,432	6,311	41,659
	80	4285,257	384,109	1396,524	6,020	8,949
	100	2006,389	272,925	1169,519	48,589	118,691
Tabela 8.5: Comparaçao dos algoritmos Local Branching em termos de gaps médios (em percentagem) e de tempo medio de execução (em segundos) nas instâncias E.
Os gaps de melhor qualidade são obtidos nos Algoritmos ALB1, ALB3 e ALB4. Sendo os Algoritmos ALB2 e ALB5 os que apresentam os gaps de pior qualidade. A medida que o numero de nodos aumenta, os gaps obtidos nos Algoritmos ALB2 e ALB5 parecem ser de pior qualidade.
O Algoritmo ALB4 e o mais rápido, pois apresenta tempos medios de execução inferiores a qualquer um dos outros algoritmos Local Branching para instâncias maiores do que 20 nodos. Os Algoritmos ALB1 e ALB3 apesar de terem gaps medios baixos apresentam tempos medios de execução bastante elevados quando comparados com os
tempos méedios de execuçcãao do Algoritmo ALB4.
S íntese da Comparação dos vários Algoritmos Local Branching
Dos cinco algoritmos Local Branching apresentados podemos verificar que em todos os grupos de instâncias, o Algoritmo ALB4 se mostrou o mais eficiente, apresentando uma percentagem de solucões étimas em 83,33% das instâncias testadas (100 em 120 instâncias) e soluções muito préximas das étimas nos restantes casos. Este algoritmo foi também considerado o mais répido.
8.5.3	Resultados Computacionais
Para avaliar o desempenho da Heurística Local Branching vamos comparar, em todas as instâancias, os resultados obtidos pelo Algoritmo ALB4 com os obtidos pelo Algoritmo Branch and Bound do procedimento de introduçao de cortes P-WMTZ+C (Secçao 3.3), o qual serí designado por ABB-P-WMTZ+C.
Nas Tabelas 8.6, 8.7, 8.8, 8.9, 8.10, 8.11 e 8.12, a primeira coluna refere-se à de-signaçõo da instância, as três colunas seguintes contêm o tempo de execuçõo (tABB, em segundos), o valor íotimo ou o melhor valor do limite superior obtido (LS ABB) e o gap (em percentagem) e sõao referentes ao Algoritmo ABB-P-WMTZ+C. As cinco colunas seguintes contâm informaçõo sobre o Algoritmo ALB4, uma refere-se à soluçõo de referância obtida inicialmente pela Heurística FPB2 apresentada no Capítulo 7 (LS Inic.), a seguir temos a soluçõo obtida apís a aplicaçõo do Algoritmo ALB4 (LS LB), depois temos o tempo de execucõo (tLB, em segundos), a seguir o gap e para finalizar os dados referentes ao Algoritmo ALB4 temos o nuímero de iteraçcõoes (Iter.). Por fim, a uíltima coluna apresenta a razõao entre os tempos de execuçcõao do Algoritmo ABB-P-WMTZ+C e do Algoritmo ALB4. Em todas as tabelas, a sigla NFA significa que o limite superior nunca foi atualizado, e neste caso nõao foi obtida uma soluçcõao inteira admissível.
	ABB-P-WMTZ+C				ALB4				
Instancia	tABB	LS ABB	Gap	LS Inic.	LS LB	tLB	Gap	Iter.	tABB/tLB
QC10-1	0,08	168	0	173	168	0,48	0	4	0,16
QC10-2	0,22	364	0	385	364	0,37	0	3	0,58
QC10-3	0,09	375	0	426	375	0,41	0	3	0,23
QC10-4	0,11	364	0	366	364	0,31	0	3	0,35
QC10-5	0,09	581	0	641	581	0,27	0	3	0,35
QC10-6	0,11	179	0	179	179	0,30	0	2	0,37
QC10-7	0,08	439	0	439	439	0,23	0	2	0,33
QC10-8	0,13	577	0	637	577	0,44	0	3	0,29
QC10-9	0,06	263	0	330	263	0,73	0	5	0,09
QC10-10	0,09	657	0	672	657	0,44	0	3	0,21
QC20-1	0,92	1581	0	1584	1581	1,98	0	2	0,46
QC20-2	1,08	1463	0	1473	1463	2,86	0	3	0,38
QC20-3	1,11	1364	0	1376	1364	2,90	0	3	0,38
QC20-4	0,70	674	0	678	674	1,92	0	3	0,37
QC20-5	0,61	547	0	547	547	1,59	0	2	0,38
QC20-6	1,42	930	0	936	930	2,18	0	2	0,65
QC20-7	3,57	1118	0	1118	1118	1,93	0	2	1,85
QC20-8	1,25	320	0	321	320	1,75	0	2	0,71
QC20-9	1,80	621	0	634	621	3,79	0	4	0,47
QC20-10	0,80	1446	0	1451	1446	2,78	0	3	0,29
QC40-1	29,78	1909	0	1940	1909	17,24	0	4	1,73
QC40-2	49,46	913	0	914	913	16,86	0	4	2,93
QC40-3	34,68	1155	0	1158	1156	29,89	0,09	6	1,16
QC40-4	88,17	776	0	778	778	13,93	0,26	3	6,33
QC40-5	25,79	2008	0	2009	2008	16,84	0	4	1,53
QC40-6	28,50	1436	0	1446	1436	17,90	0	4	1,59
QC40-7	101,52	1728	0	1731	1728	22,90	0	5	4,43
QC40-8	17,24	1922	0	1922	1922	13,88	0	3	1,24
QC40-9	14,57	1642	0	1662	1642	20,89	0	5	0,70
QC40-10	27,00	786	0	797	797	29,71	1,40	6	0,91
Tabela 8.6: Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias QC de 10 a 40 nodos.
Instancia	ÍABB	LS ABB	Gap	LS Inic.	LS LB	ÍLB	Gap	Iter.	tABB /ÍLB
QC60-1	473,32	1619	0	1620	1619	30,91	0	4	15,31
QC60-2	610,76	2944	0	2944	2944	16,89	0	2	36,17
QC60-3	554,47	3462	0	3462	3462	20,89	0	3	26,54
QC60-4	1250,20	2144	0	2144	2144	20,84	0	3	59,98
QC60-5	214,40	2994	0	2994	2994	20,88	0	3	10,27
QC60-6	201,09	1785	0	1785	1785	19,95	0	3	10,08
QC60-7	783,40	2092	0	2093	2092	30,83	0	4	25,41
QC60-8	414,74	1486	0	1487	1486	26,99	0	3	15,37
QC60-9	603,67	2442	0	2443	2442	30,77	0	4	19,62
QC60-10	66,16	2138	0	2138	2138	21,04	0	3	3,14
QC80-1	4605,26	1769	0	1769	1769	36,71	0	2	125,44
QC80-2	3618,29	3318	0	3320	3318	51,92	0	3	69,69
QC80-3	2102,42	1661	0	1662	1661	54,86	0	4	38,32
QC80-4	731,77	4759	0	4759	4759	43,82	0	3	16,70
QC80-5	1423,68	1283	0	1284	1283	55,87	0	3	25,48
QC80-6	7280,10	2686	0	2690	2686	62,86	0	4	115,82
QC80-7	1915,78	3751	0	3751	3751	31,81	0	2	60,23
QC80-8	393,61	1959	0	1960	1959	53,18	0	3	7,40
QC80-9	1255,06	2382	0	2385	2382	63,62	0	4	19,73
QC80-10	2024,72	1962	0	1963	1962	55,81	0	3	36,28
QC100-1	10801,10	5410	0	5596	5410	126,88	0	4	85,13
QC100-2	10800,90	4539	0	4539	4539	86,74	0	3	124,52
QC100-3	10800,80	2840	0	2840	2840	86,13	0	3	125,40
QC100-4	10800,60	4153	0	4153	4153	89,20	0	3	121,08
QC100-5	10801,00	3723	0	3723	3723	86,24	0	3	125,25
QC100-6	10800,80	4666	0	4815	4666	126,72	0	4	85,23
QC100-7	10800,70	4981	0	4981	4981	85,87	0	3	125,78
QC100-8	10801,10	5213	0	5214	5213	126,69	0	4	85,26
QC100-9	10800,90	4240	0	4240	4240	85,91	0	3	125,73
QC100-10	8758,11	2086	0	2086	2086	85,95	0	3	101,90
Tabela 8.7: Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instancias QC de 60 a 100 nodos.
Instancia	ÍABB	LS ABB	Gap	LS Inic.	LS LB	tLB	Gap	Iter.	tABB/tLB
QC150-1	10802,40	9251	0	9251	9251	141,78	0	3	76,19
QC150-2	10802,60	5365	0	5366	5365	223,62	0	5	48,31
QC150-3	10806,30	1987	0	2026	1987	211,99	0	4	50,98
QC150-4	10806,40	8173	0	8372	8173	212,55	0	4	50,84
QC150-5	10803,30	5768	0	5957	5768	202,20	0	4	53,43
QC150-6	10805,80	5616	0	5616	5616	138,78	0	3	77,87
QC150-7	10805,80	5138	0	5138	5138	141,19	0	3	76,53
QC150-8	10802,60	7146	0	7146	7146	138,82	0	3	77,82
QC150-9	10807,00	5801	0	5803	5801	204,03	0	4	52,97
QC150-10	10803,90	8094	0	8094	8094	146,13	0	3	73,94
QC200-1	10811,00	8949	0	8949	8949	197,84	0	3	54,64
QC200-2	10816,90	10462	0	10564	10462	292,60	0	4	36,97
QC200-3	10818,00	14814	0	15327	14814	481,79	0	7	22,45
QC200-4	10815,10	12639	0	12824	12639	597,70	0	7	18,09
QC200-5	10806,50	10437	0	10437	10437	208,33	0	3	51,87
QC300-1	10864,10	5562	0	5680	5562	442,19	0	4	24,57
QC300-2	10825,50	26842	0	27006	26842	944,77	0	9	11,46
QC300-3	10857,70	28018	0,02	28012	28012	679,32	0	6	15,98
QC300-4	10866,30	6602	0	6696	6602	686,95	0	6	15,82
QC300-5	10921,10	11383	0	11595	11595	689,94	1,86	6	15,83
QC400-1	10860,00	7138	0	7282	7138	1796,03	0	8	6,05
QC400-2	10938,60	16336	0	16475	16336	1398,10	0	6	7,82
QC400-3	10915,90	6623	0	6685	6623	1606,16	0	7	6,80
QC400-4	10873,30	7168	0	7216	7168	1409,06	0	6	7,72
QC400-5	11059,50	22095	0	22095	22095	1418,17	0	6	7,80
QC500-1	10924,50	14513	0	14667	14513	3429,02	0	6	3,19
QC500-2	11079,30	32723	0,45	32575	32575	4204,46	0	6	2,64
QC500-3	11270,60	25041	0	25876	25041	3501,10	0	7	3,22
QC500-4	11033,50	37829	0	38020	37829	3535,20	0	6	3,12
QC500-5	10979,10	29198	0,01	29315	29194	3451,37	0	6	3,18
QC1000-1	11690,10	NFA	—	77132	75948	9883,74	0	9	1,18
QC1000-2	12766,60	NFA	—	33224	32704	10002,10	0	9	1,28
QC1000-3	11872,10	NFA	—	51310	50127	9909,95	0	8	1,20
QC1000-4	12109,60	NFA	—	57844	57844	7963,73	0	6	1,52
QC1000-5	11505,10	96038	0	97438	96213	9509,04	0,18	8	1,21
Tabela 8.8: Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias QC de 150 a 1000 nodos.
Instancia	ÍABB	LS ABB	Gap	LS Inic.	LS LB	ÍLB	Gap	Iter.	ÍABB /ÍLB
R10-1	0,062	19304	0	19949	19304	0,219	0	3	0,28
R10-2	0,234	20759	0	20759	20759	0,171	0	2	1,37
R10-3	0,046	15222	0	15603	15603	0,499	2,503	3	0,09
R10-4	0,219	19552	0	21378	19552	0,515	0	3	0,43
R10-5	0,374	29405	0	30586	29405	0,469	0	3	0,80
R20-1	1,014	32055	0	32705	32055	2,216	0	3	0,46
R20-2	1,919	32340	0	32655	32340	2,558	0	3	0,75
R20-3	0,452	33366	0	34872	33366	2,465	0	3	0,18
R20-4	0,657	31835	0	33500	31835	2,558	0	4	0,26
R20-5	1,623	30040	0	34149	30040	1,935	0	3	0,84
R40-1	4,509	27601	0	28230	27601	9,766	0	3	0,46
R40-2	3,681	39903	0	41165	39903	13,277	0	3	0,28
R40-3	5,725	28096	0	29522	28096	11,762	0	3	0,49
R40-4	2,573	28469	0	28588	28469	8,970	0	3	0,29
R40-5	4,18	32022	0	32912	32022	6,536	0	3	0,64
R60-1	4,509	39507	0	40078	39507	10,390	0	3	0,43
R60-2	6,069	30675	0	30956	30675	12,262	0	3	0,49
R60-3	6,928	31328	0	31399	31328	13,356	0	3	0,52
R60-4	7,27	44299	0	45659	44299	20,265	0	4	0,36
R60-5	5,026	33088	0	33387	33088	11,092	0	3	0,45
R80-1	15,194	33196	0	33571	33196	22,277	0	3	0,68
R80-2	16,177	45697	0	46030	45697	52,089	0	3	0,31
R80-3	12,416	39223	0	40640	39223	24,087	0	3	0,52
R80-4	11,169	49269	0	49374	49269	27,316	0	3	0,41
R80-5	16,288	33313	0	33926	33313	26,724	0	3	0,61
R100-1	12,9	26575	0	26742	26575	110,965	0	4	0,12
R100-2	28,799	1939	0	1951	1940	101,438	0,052	3	0,28
R100-3	23,103	2257	0	2273	2257	21,138	0	3	1,09
R100-4	16,803	10300	0	10372	10300	66,115	0	3	0,25
R100-5	21,812	3763	0	3766	3763	77,816	0	3	0,28
R150-1	120,09	2265	0	2281	2265	205,487	0	5	0,58
R150-2	97,233	32853	0	33070	32864	119,189	0,033	3	0,82
R150-3	49,048	32838	0	32873	32838	126,974	0	3	0,39
R150-4	67,835	29144	0	29708	29708	311,634	1,935	6	0,22
R150-5	141,153	13103	0	13172	13103	113,324	0	3	1,25
Tabela 8.9: Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias R de 10 a
150 nodos.
	ABB-P-WMTZ+C					ALB4			
Instancia	ÍABB	LS ABB	Gap	LS Inic.	LS LB	ÍLB	Gap	Iter.	ÍABB /ÍLB
R200-1	162,058	38935	0	39358	38935	190,902	0	3	0,85
R200-2	133,637	39161	0	39237	39190	335,644	0,074	5	0,40
R200-3	618,244	4216	0	4236	4217	322,948	0,024	5	1,91
R200-4	477,987	13503	0	13600	13503	355,444	0	5	1,34
R200-5	161,012	14638	0	14666	14638	291,675	0	4	0,55
R300-1	2696,66	40936	0	41062	40956	821,275	0,049	7	3,28
R300-2	2280,974	44684	0	44748	44748	714,641	0,143	6	3,19
R300-3	733,738	41486	0	41704	41704	705,510	0,525	6	1,04
R300-4	1007,47	14795	0	14826	14804	744,381	0,061	7	1,35
R300-5	1112,231	13656	0	13881	13661	651,648	0,037	6	1,71
R400-1	2607,21	100652	0	100754	100754	1496,020	0,101	6	1,74
R400-2	3506,99	14449	0	14486	14486	1367,210	0,256	6	2,57
R400-3	2249,23	16428	0	16457	16457	1350,430	0,177	6	1,67
R400-4	2231,39	14915	0	14915	14915	1305,650	0	6	1,71
R400-5	2547,54	42765	0	42846	42846	1512,790	0,189	6	1,68
R500-1	5425,43	46254	0	46421	46421	2969,630	0,361	6	1,83
R500-2	12598,78	48269	0	48385	48273	2004,380	0,008	4	6,29
R500-3	10318,92	53763	0	53944	53944	2998,650	0,337	6	3,44
R500-4	10075,06	46892	0	46942	46892	1583,560	0	3	6,36
R500-5	7708,52	47654	0	47681	47654	2232,740	0	5	3,45
R1000-1	20451,42	NFA	—	4812	4812	10999,400	0	5	1,86
R1000-2	13308,52	105880	0,150	105721	105721	10991,700	0	5	1,21
R1000-3	19643,35	29176	0	29191	29191	10075,100	0,051	3	1,95
R1000-4	18787,51	57917	0	57987	57987	10851,500	0,121	5	1,73
R1000-5	15992,69	101608	0	101796	101796	11125,800	0,185	5	1,44
Tabela 8.10: Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias R de 200 a 1000 nodos.
Instâancia	tABB	LS ABB	Gap	LS Inic.	LS LB	tLB	Gap	Iter.	tABB/tLB
E10-1	0,09	39983	0	43179	39983	2,64	0	4	0,04
E10-2	0,03	36919	0	39701	36919	1,00	0	4	0,03
E10-3	0,09	35208	0	35208	35208	5,66	0	6	0,02
E10-4	0,17	26287	0	28252	26287	1,73	0	4	0,10
E10-5	0,16	41242	0	42631	41242	2,42	0	3	0,06
E20-1	0,61	53456	0	56494	53456	7,89	0	5	0,08
E20-2	0,17	89486	0	89486	89486	12,04	0	6	0,01
E20-3	1,59	60017	0	62793	60017	5,29	0	4	0,30
E20-4	0,81	56543	0	56784	56543	5,18	0	5	0,16
E20-5	1,28	60426	0	60737	60737	3,82	0,515	3	0,33
E40-1	6,41	98041	0	99458	98041	22,23	0	4	0,29
E40-2	7,08	109750	0	111660	109750	29,22	0	3	0,24
E40-3	4,74	129062	0	131866	129068	22,90	0,005	3	0,21
E40-4	5,66	125203	0	128282	125955	32,39	0,601	5	0,17
E40-5	4,09	116579	0	118884	116579	40,84	0	6	0,10
E60-1	11,75	171935	0	175244	171944	34,45	0,005	4	0,34
E60-2	11,36	175895	0	176782	175895	36,21	0	3	0,31
E60-3	7,85	158736	0	158869	158869	20,81	0,084	3	0,38
E60-4	10,62	181475	0	182212	181475	27,02	0	4	0,39
E60-5	20,22	160581	0	161895	161052	26,41	0,293	4	0,77
E80-1	29,89	253121	0	255889	253187	36,71	0,026	4	0,81
E80-2	29,27	289283	0	289563	289312	50,36	0,010	4	0,58
E80-3	61,28	262485	0	265002	262531	48,03	0,018	4	1,28
E80-4	42,79	257653	0	258593	258575	48,20	0,358	4	0,89
E80-5	42,35	271514	0	272509	271549	39,62	0,013	4	1,07
E100-1	78,61	13353	0	13421	13361	113,07	0,060	4	0,70
E100-2	98,70	30933	0	30969	30933	93,96	0	4	1,05
E100-3	166,30	14035	0	14054	14044	85,66	0,064	4	1,94
E100-4	102,98	34434	0	34551	34495	190,69	0,177	6	0,54
E100-5	135,39	24768	0	25192	24773	177,23	0,020	5	0,76
E150-1	340,16	16386	0	16418	16388	145,13	0,012	4	2,34
E150-2	502,74	16589	0	16604	16590	168,75	0,006	4	2,98
E150-3	791,48	17313	0	17341	17313	178,85	0	4	4,43
E150-4	560,61	16725	0	16795	16734	207,46	0,054	5	2,70
E150-5	730,79	15709	0	15796	15710	205,33	0,006	5	3,56
Tabela 8.11: Comparacão entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instancias E de 10 a
150 nodos.
Instancia	ÍABB	LS ABB	Gap	LS Inic.	LS LB	ÍLB	Gap	Iter.	ÍABB /ÍLB
E200-1	1529,04	20425	0	20472	20439	402,12	0,069	6	3,80
E200-2	2801,89	18888	0	19027	18890	241,72	0,011	4	11,59
E200-3	1558,63	20911	0	20978	20925	288,27	0,067	5	5,41
E200-4	1078,38	20177	0	20245	20177	235,56	0	4	4,58
E200-5	2558,41	19592	0	19668	19593	402,56	0,005	6	6,36
E300-1	10040,98	24996	0	25077	24996	875,38	0	4	11,47
E300-2	16316,11	26276	0	26303	26290	1358,79	0,053	6	12,01
E300-3	9070,20	24802	0	24840	24812	1139,88	0,040	5	7,96
E300-4	14695,34	25781	0	25897	25784	1160,76	0,012	5	12,66
E300-5	11720,18	25241	0	25257	25244	1490,32	0,012	6	7,86
E400-1	27871,23	32985	11,128	29723	29682	1447,26	0	5	19,26
E400-2	68388,10	32577	13,933	28536	28536	2513,43	0,126	6	27,21
E400-3	21454,16	37056	21,094	30601	30601	2510,20	0	6	8,55
E400-4	19547,89	33652	12,196	29994	29994	2560,37	0	6	7,63
E400-5	18255,85	33376	9,530	30472	30472	2520,09	0	6	7,24
E500-1	30927,90	41192	24,681	33048	33038	4523,01	0	7	6,84
E500-2	30892,30	NFA	—	33619	33558	3872,91	0	6	7,98
E500-3	31087,70	NFA	—	33823	33823	4706,75	0	6	6,60
E500-4	14224,57	NFA	—	32382	32382	4765,20	0	6	2,99
E500-5	30922,60	NFA	—	34509	34509	4785,43	0	6	6,46
E1000-1	31034,00	NFA	—	49045	49045	10825,90	0	4	2,87
E1000-2	31048,30	NFA	—	47061	47061	10818,20	0	4	2,87
E1000-3	30967,00	NFA	—	48947	48947	10852,80	0	4	2,85
E1000-4	31112,40	NFA	—	48981	48981	10830,30	0	4	2,87
E1000-5	31194,80	NFA	—	48172	48172	10838,10	0	4	2,88
Tabela 8.12: Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias E de 200 a 1000 nodos.
Instâncias Quase Caminhos
Nas instâncias Quase Caminhos com o Algoritmo ALB4 são obtidos 94,74% de gaps nulos, o que corresponde a 90 instancias em 95 testadas. Em 7 instâncias, o valor do custo da solução obtida através do Algoritmo ALB4 é de melhor qualidade comparativamente ao valor do custo da solução obtida através do Algoritmo ABB-P-WMTZ+C (os custos dessas instâncias encontram-se a negrito na Tabela 8.8).
Com o Algoritmo ALB4 foi sempre possível encontrar um limite superior para o valor do custo, enquanto que através do Algoritmo ABB-P-WMTZ+C não foi possível, no tempo imposto, obter um limite superior para o valor do custo em quatro instâancias de 1000 nodos (QC1000-1, QC1000-2, QC1000-3 e QC1000-4).
Em 63,16% das instâncias (60 em 95 instâncias) atraves da aplicacão do Algoritmo ALB4 é obtida uma solução de melhor qualidade do que a obtida através da Heurística FPB2. Das 35 instâncias onde não há melhoramento ao aplicar o Algoritmo ALB4, em 32 instâncias usando a Heurística FPB2 jé era possével obter a soluçao étima.
Os tempos de execução do Algoritmo ALB4 são inferiores aos tempos de execuçao do Algoritmo ABB-P-WMTZ+C em 77,89% das instâncias (74 instâncias em 95). Os tempos de execuçcãao do Algoritmo ALB4 sãao inferiores na instâancia QC20-7, em quase todas as instaâncias de 40 nodos e em todas as instâancias com mais de 40 nodos.
Instâncias Aleatorias
Nas instancias Aleatérias com o Algoritmo ALB4 são obtidos 65% de gaps nulos, o que corresponde a 39 instâancias em 60 testadas. Em apenas 2 instâancias, o valor do custo da solucçãao obtida atravées do Algoritmo ALB4 ée de melhor qualidade comparativamente ao valor do custo da solucçãao obtida atravées do Algoritmo ABB-P-WMTZ+C (os custos dessas instâncias encontram-se a negrito na Tabela 8.10).
Com o Algoritmo ALB4 foi sempre possével encontrar um limite superior para o valor do custo, enquanto que atravées do Algoritmo ABB-P-WMTZ+C nãao foi possével, no tempo imposto, obter um limite superior para o valor do custo numa instâancia de 1000 nodos (R1000-1).
As soluçcãoes obtidas atravées da aplicaçcãao do Algoritmo ALB4 sãao de melhor qualidade comparativamente às soluçães obtidas através da Heurística FPB2 em 73,33% das instâancias (44 em 60 instâancias). Nas instaâncias onde nãao héa melhoramento (17 instâancias) ao aplicar o Algoritmo ALB4, em 4 delas usando a Heuréstica FPB2 jéa era
possóvel obter a soluçao ótima (R10-2, R400-4, R1000-1 e R1000-2).
Os tempos de execução do Algoritmo ALB4 são inferiores aos tempos de execução do Algoritmo ABB-P-WMTZ+C em 41,67% das instências (25 em 60 instências). Os tempos de execuçao do Algoritmo ALB4 são inferiores nas instências R10-2, R100-3, R150-5, R200-3 e R200-4 e em todas as instêancias com mais de 200 nodos.
Instâncias Euclideanas
Nas instências Euclideanas com o Algoritmo ALB4 são obtidos 53,33% de gaps nulos, o que corresponde a 32 instêancias em 60 testadas. Podemos observar que em 15 instaências, o valor do custo da soluçcaão obtida atravóes do Algoritmo ALB4 óe de melhor qualidade comparativamente ao valor do custo da soluçcaão obtida atravóes do Algoritmo ABB-P-WMTZ+C (os custos dessas instancias encontram-se a negrito na Tabela 8.12).
Com o Algoritmo ALB4 foi sempre possóvel encontrar um limite superior para o valor do custo, enquanto que atravóes do Algoritmo ABB-P-WMTZ+C naão foi possóvel, no tempo imposto, obter um limite superior para o valor do custo em 9 instêancias, sendo estas de 500 e 1000 nodos. Em todas as instências de 400 nodos e numa de 500 nodos os limites superiores obtidos atravóes do Algoritmo ABB-P-WMTZ+C naão sãao de boa qualidade dado que os gaps obtidos são bastante elevados.
As soluçcãoes obtidas atravóes da aplicaçcãao do Algoritmo ALB4 saão de melhor qualidade comparativamente as solucães obtidas através da Heurística FPB2 em 71,67% das instêancias (43 em 60 instêancias). Nas instaências onde nãao haó melhoramento (17 instêancias), ao aplicar o Algoritmo ALB4, em 12 delas usando a Heuróstica FPB2 jóa era possóvel obter a solucçãao óotima.
Os tempos de execuçcãao do Algoritmo ALB4 sãao inferiores aos tempos de execuçcãao do Algoritmo ABB-P-WMTZ+C em 56,67% das instências (34 em 60 instências). Os tempos de execucçãao do Algoritmo ALB4 sãao inferiores nas instaências E80-3, R80-5, R100-2 e R100-3 e em todas as instêancias com mais de 100 nodos.
8.5.4	Síntese dos Resultados Computacionais
De todos os algoritmos Local Branching propostos verificémos através da Subseccão 8.5.2 que em todos os grupos de instâncias até 100 nodos, o Algoritmo ALB4 se mostrou
o mais eficiente.
Em 61,86% das instâncias (133 em 215 instancias), os tempos obtidos através da utilização do Algoritmo ALB4 sao inferiores aos tempos obtidos através do Algoritmo ABB-P-WMTZ+C. Verificamos também que para instâncias Quase Caminhos com mais do que 40 nodos, instâncias Aleatórias com mais do que 200 nodos e instâncias Euclideanas com mais do que 100 nodos, o Algoritmo ALB4 é mais rápido do que o Algoritmo ABB-P-WMTZ+C e as solucães encontradas são de boa qualidade, pois são obtidos 75,34% de gaps nulos (162 em 215 instâncias). Com a aplicação do Algoritmo ALB4 obtêm-se melhoramentos em 68,37% das instâncias (147 em 215 instâncias) comparativamente a aplicação da Heurística FPB2.
Capítulo 9
Considerações Finais
Ao longo desta tese abordáamos váarios máetodos para resolver o Problema WMST, entre os quais o mátodo Branch and Bound e Branch and Cut atravás do uso de formulaçcãoes e procedimentos de introduçcãao de cortes usando separaçcãao, os máetodos de relaxacçãao linear e Lagrangeana, máetodos de geraçcaão e introduçcãao de desigualdades válidas nas formulações usando separacão e por fim os mátodos Feasibility Pump e Local Branching.
No Capátulo 3 começámos por apresentar e comparar do ponto vista computacional vaárias formulacçãoes para o Problema WMST. Das vaárias comparaçcoães efetuadas resulta que, para os trâes grupos de instaâncias em estudo: Quase Caminhos, Aleatáorias e Euclideanas, o procedimento com introdução de cortes, que se aplica para fortalecer a formulacão baseada nas desigualdades WMTZ (Procedimento P-WMTZ+C), á o que apresenta melhores resultados na obtençcãao da soluçcãao oátima ou de uma soluçcãao admissável para o valor oátimo. Para todas as formulaçcãoes apresentadas no Capátulo 3, obtiveram-se tambáem os valores da relaxaçcãao linear. Os limites inferiores de melhor qualidade sao os obtidos atravás da relaxaçao linear do Procedimento P-WMTZ+C.
Uma outra forma de encontrar limites inferiores e superiores para o valor átimo do Problema WMST, foi apresentada no Capátulo 4 com a implementaçcãao de algoritmos baseados em relaxaçcaão Lagrangeana. Os Algoritmos Alg2, Alg5, Alg6 e Alg7 mostraram-se bastante eficientes em todos os grupos de instâancias, pois com a aplicaçcãao destes algoritmos foi possável obter, rapidamente, algumas solucçãoes áotimas e outras muito proáximas das oátimas. Podemos dizer que os valores obtidos pela relaxaçcãao La-grangeana dos Algoritmos Alg2, Alg5 e Alg6, em geral, sãao iguais aos valores obtidos
pela relaxação linear do Procedimento P-WMTZ+C apresentado no Capítulo 3. O Algoritmo Alg7, onde são incluídas desigualdades válidas í o que apresenta melhores limites inferiores.
No Capítulo 5 foram apresentadas apenas classes de desigualdades validas e no Capítulo 6 foram apresentados algoritmos heurísticos de separaçao para gerar e introduzir as desigualdades vílidas do Capítulo 5 nas formulaçães apresentadas no Capítulo 3 de modo a fortalecê-las. De experiências computacionais realizadas com os vírios algoritmos heurísticos de separaçao, num grupo de instências teste, resulta que os algoritmos que utilizam a introdução das Desigualdades Implícita Levantada e das Desigualdades Implícita Levantada por Down-Lifting sao os que apresentam os melhores resultados. Verificou-se ainda que ao testar instências de maior dimensao o procedimento de geraçao e introdução de Desigualdades Implícita Levantada por Down-Lifting íe o melhor para utilizacçãao na praítica.
Com o objetivo de obter soluçães inteiras admissíveis para o Problema WMST apresentímos no Capítulos 7 heurísticas Feasibility Pump. Nas instências Aleatírias e Euclideanas, a Heurística FPB2 í a que encontra soluçães admissíveis de melhor qualidade e mais rapidamente quando comparada com as restantes Heurísticas Fesibility Pump propostas e tambím quando comparada com a Heurística do Xpress aplicada ao nodo raiz utilizando a Formulação WMTZ (HXNR) e com a primeira solução inteira admissível obtida pelo solver do software Xpress atravís da Formulacão WMTZ, quando usa o procedimento Branch and Bound (PSIABB). No caso das instências Quase Caminhos, a mais rápida í a Heurística HXNR, mas em termos de qualidade das soluçcãoes encontradas, esta naão apresenta bons resultados quando comparada com a Heurística FPB2.
Um outro mítodo heurístico tratado no Capítulo 8 e bastante eficiente para ins-têancias de maiores dimensoães íe baseado no Míetodo Local Branching. De todos os algoritmos Local Branching propostos verificaímos que em todos os grupos de instêancias, o Algoritmo que se mostrou o mais eficiente foi o ALB4. Este algoritmo utiliza como solucçãao de referêencia inicial a soluçcaão inteira admissível obtida atravíes da Heurística FPB2. Quando comparamos o Algoritmo ALB4 com o Algoritmo Branch and Bound do procedimento de introdução de cortes P-WMTZ+C verificamos que em mais de metade das instancias (133 em 215 instancias) os tempos obtidos atravís da utilização
do Algoritmo ALB4 são inferiores aos tempos obtidos através do Algoritmo Branch and Bound do procedimento de introdução de cortes P-WMTZ+C. Como a Heurística Local Branching é uma heurística de melhoramento, podemos observar que com a aplicação do Algoritmo ALB4 ocorrem melhoramentos em mais de metade das instâncias (147 em 215 instâncias) comparativamente à aplicação da Heurística FPB2.
E de observar que os métodos Feasibility Pump e Local Branching e os algoritmos Lagrangeanos sãao normalmente mais raépidos do que o uso de méetodos Branch and Bound atravées das formulaçcãoes e os méetodos de planos de corte e daé mais adequados para resolver problemas de instâancias maiores, no entanto nãao garantem a obtençcaão da soluçcaão éotima e a qualidade das soluçcãoes, em geral, nãao ée tãao boa.
Em trabalhos futuros tencionamos desenvolver algoritmos heurésticos para obtençcãao dos coeficientes de levantamento usual, down-lifting e up-lifting mais rápidos, de modo a tornar os algoritmos heurísticos de separacão mais rápidos. Muitos outros métodos de resolução do Problema WMST ficaram por aplicar e poderão ser aplicados futuramente.
322
Anexos
Facetas do conjunto PWmst para uma instância de 5 nodos
Neste anexo apresentamos todas as facetas de Pwmst obtidas através do software PORTA para a instancia de 5 nodos dada no Exemplo 2.1. Para cada uma das desigualdades também indicamos uma possével forma de obtenção.
(1)	Xoi +X02	+X03	+X04	+X12	+X13	+X14	+^23	+^24	+X34	= 4
Restriçcãao de cardinalidade.
(2)	-2X02	-X04	-X12	-2X13	-2X14	-2X23	~^24	-X34	&amp;lt;-4
DCILUL (Fixação a zero).
Equivalente a: x01 - x02 + x03 - x13 - x14 - x23 &amp;lt;0.
Escolha das variéveis a fixar: x02 = x13 = x14 = x23 = 0.
Estas arestas formam a éarvore de suporte de peso ménimo.
DCI: x01 &amp;lt;0.
Corta o PL. Valor de PL = 25.5.
(3)	-2x02 +x03	- 3x13 - 3x14 - 2x23 -x24 -x34 &amp;lt;-4
DGCIL (Fixaçao a zero e a um).
Escolha das variéaveis a fixar: x14 = x24 = 1 e x02 = x13 = x23 = x34 = 0. DCI: x03 &amp;lt;0.
Corta o PL. Valor de PL = 27 = OPT.
(4)	-x02	-x03	-x04	-x12	-x13	-x14	-x23	-x24	-x34	&amp;lt;-3
Equivalente a: x01 &amp;lt;1.
(5)	— X02	— X04	— X12	- X13	—2X14	— X23	— X24	— X34	&lt;	—3
DCILUL (Fixaçõo a zero).
Equivalente a: x0i + x03 — xi4 &amp;lt;1.
Escolha das variaveis a fixar: xi4 = 0.
Esta aresta pertence a órvore de suporte de peso mínimo.
DCI: X01 + X03 &amp;lt;1.
(6)	—X02	—X04	—2xi3	—2xi4	— X23	— X24	—X34	&lt;	—3
DCILUL (Fixaçõo a zero).
Equivalente a: x01 + x03 + x12 — x13 — x14 &amp;lt;1.
Escolha das varióaveis a fixar: X13 = X14 = 0.
Estas arestas pertencem à arvore de suporte de peso mínimo.
DCI: xw + x03 &amp;lt;1.
Corta o PL. Valor de PL = 25.5.
(7)	—2x02	—x04	— xi2	— xi3	— xi4	—2x23	—x24	—x34	&amp;lt;—3
DCILUL (Fixaçao a zero).
Equivalente a: x01 — x02 + x03 — x23 &amp;lt;1.
Escolha das varióaveis a fixar: x02 = x23 = 0.
Estas arestas pertencem à órvore de suporte de peso mínimo.
DCI: x0i + x03 &amp;lt;1.
(8)	—x02	— 2xi3 — 2xi4 —2x23 —x24 —x34 &amp;lt;—3
DCILUL (Fixaçõo a zero).
Equivalente a: x01 + x03 + x04 + x12 — x13 — x14 — x23 &amp;lt;1.
Escolha das varióaveis a fixar: x13 = x14 = x23 = 0.
Estas arestas pertencem todas à arvore de suporte de peso mónimo.
DCI: x0i + x03 &amp;lt;1.
Corta o PL. O valor do PL = 27 = OPT.
(9)	—2x02 +x03	— 2xi3 — 2xi4 —2x23 —x24 —x34 &amp;lt;—3
DGCIL (Fixaçao a zero e a um).
Escolha das varióaveis a fixar: xi4 = x24 = 1 e x02 = xi3 = x23 = x34 = 0.
DCI: x03 &amp;lt;0.
Corta o PL. Valor de PL = 27 = OPT.
Note-se que nas desigualdades (2) e (8) se escolhem as mesmas varióveis para
se fixar a zero e a um, mas a ordem do calculo dos coeficientes e feita de forma diferente.
(10)	-X02	+X03	-X04	-2X13	-3X14	-^23	-^24	-X34	&amp;lt;-3
DGCIL (Fixação a zero a um).
Equivalente a: x01 + 2x03 + x12 - x13 - 2x14 &amp;lt;1.
Escolha das variaveis a fixar: x12 = 1 e x03 = x13 = x14 = 0. DCI: x01 &amp;lt;0.
Corta o PL. Valor de PL = 25.5.
(11)	-2x02 +x03	-2x13 -3x14 -x23 -x24 -x34 &amp;lt;-3
DGCIL (Fixaçcãao a zero e a um).
Escolha das variaveis a fixar: x13 = x34 = 1 e x02 = x14 = x23 = x24 = 0. DCI: x03 &amp;lt;0.
Corta o PL. Valor de PL = 25.8.
(12)	-x02	-x12 -x13 -x14 -x23 -x24	&amp;lt;-2
DCIE.
Equivalente a: x01 + x03 + x04 + x34 &amp;lt;2.
DCI: x01 + x04 + x34 &amp;lt;2.
Corta o PL. Valor de PL = 25.5.
(13)	-x02	-x13 -x14 -x23 -x24 -x34 &amp;lt;-2
DCIL.
Equivalente a: x01 + x03 + x04 + x12 &amp;lt;2.
DCI: x01 + x04 + x12 &amp;lt;2.
Corta o PL. Valor de PL = 27 = OPT.
(14)	-x02	-x03	-x12	-x13	-x23	-x24	-x34	&lt;	-2
Restrição de eliminacao de subcircuito / Clique.
Equivalente a: x01 + x04 + x14 &amp;lt;2.
(15)	-x02	-x04	-x12	-x13	-x44	-x23	-x34	&lt;	-2
DCI.
Equivalente a: x01 + x03 + x24 &amp;lt;2.
(16)	— X02	— X04 — X12	- X14 — X23 — X24 — X34 &amp;lt;—2
Restrição de eliminacao de subcircuito / Clique.
Equivalente a: x01 + x03 + x13 &amp;lt;2.
(17)	—X03 —X04	—X13 —X14 — X23 —X24 —X34 &amp;lt;—2
Restriçcãao de eliminacçaão de subcircuito / Clique.
Equivalente a: x01 + x02 + x12 &amp;lt;2.
(18)	—X02	—2X13 — X14 —X23	—X34 &amp;lt;—2
DCILUL (Fixação a zero).
Equivalente a: x01 + x03 + x04 + x12 — x13 + x24 &amp;lt;2. Escolha das variéveis a fixar: x13 = 0.
DCI: X01 + X03 + X04 &amp;lt;2.
(19)	—X04	—X13 —2xi4 —X23 —X24 —X34 &amp;lt;—2
DGCIL (Fixaçao a zero e a um).
Equivalente a: x01 + x02 + x03 + x12 — x14 &amp;lt;2. Escolha das variéaveis a fixar: X12 = X02 = 1 e X14 = 0.
DCI: x03 &amp;lt;0.
(20)	—x02 +x03 —x04	— xi3 —2xM —x23 —x24 —x34 &amp;lt;—2
DGCIL (Fixaçao a zero e a um).
Escolha das variaéveis a fixar: x14 = 1 e x02 = x04 = x13 = x23 = x24 = x34 = 0. DCI: x03 &amp;lt;0.
(21)	—x02 +x03	— 2xi3 — 2xi4 —x23 —x24	&amp;lt;—2
DGCIL (Fixaçcaão a zero e a um).
Escolha das variéaveis a fixar: x14 = 1 e x02 = x13 = x23 = x24 = 0. DCI: x03 &amp;lt;0.
Corta o PL. Valor de PL = 25.5.
(22)	— x02 +x03	— 2x13 — 2x14 — x23	—x34 &amp;lt;—2
DCILDL (Fixaçcãao a zero e a um).
Escolha das variéaveis a fixar: x14 = 1 e x02 = x13 = x23 = x34 = 0. DCI: x03 &amp;lt;0.
(23)	— 2x02	+x03	— x13	— 2x14	—x23	— x24	—x34	&lt;	— 2
DCILUL (Fixação a zero).
Equivalente a: x01 — x02 + 2x03 + x04 + x12 — x14 &amp;lt;2. Escolha das variaveis a fixar: x02 = x03 = x14 = 0.
Apenas as arestas {0, 2} e {1,4} pertencem a árvore de suporte de peso mínimo, a aresta {0, 3} nao pertence, mas pertence à soluçao admissível considerada inicialmente.
DCI: X01 + X04 + X12 &amp;lt;2.
Corta PL. O valor do PL = 25.6.
(24)	—X02	— X13 —X14	&amp;lt;— 1
DCE.
Equivalente a: x01 + x03 + x04 + x12 + x23 + x24 + x34 &amp;lt;3.
DC: X01 + X12 + X23 + X34 &amp;lt;3.
Corta PL. Valor de PL = 25.5.
(25)	—X02	— X12	—X23 —X24	&amp;lt;— 1
Restriçao de eliminacão de subcircuito / Corte do 2 / Clique. Equivalente a: x01 + x03 + x04 + x13 + x14 + x34 &amp;lt;3.
(26)	—X02	— X13	—X23	—X34 &amp;lt;— 1
DCE.
Equivalente a: x01 + x03 + x04 + x12 + x14 + x24 &amp;lt;3. DC: X01 + X03 + X14 + X24 &amp;lt;3.
(27)	—X03	— X13	—X23	—X34 &amp;lt;— 1
Restriçcãao de eliminacçãao de subcircuito / Corte do 3 / Clique. Equivalente a: x01 + x02 + x04 + x12 + x14 + x24 &amp;lt;3.
(28)	—x04	—x14	—x24 —x34 &amp;lt;— 1
Restriçcãao de eliminacçãao de subcircuito / Corte do 4 / Clique. Equivalente a: x01 + x02 + x03 + x12 + x13 + x23 &amp;lt;3.
(29)	— X13 — X14 —X23 —X24	&amp;lt;— 1
DCE.
Equivalente a: x01 + x02 + x03 + x04 + x12 + x34 &amp;lt;3.
DC: xoi + x02 + x04 + x34 &amp;lt;3.
Corta PL. Valor de PL = 25.5.
(30)	-xi3 -xi4 -x23	-x34 &amp;lt;-1
DCE.
Equivalente a: x0i + x02 + x03 + x04 + xi2 + x24 &amp;lt;3.
DC: x0i + x02 + x03 + x24 &amp;lt;3.
(31)	-xo2 +xo3	-xi3 -xi4 -x23 -x24	&amp;lt;-1
Desigualdade de Cobertura Levantada.
Equivalente a: x0i + 2x03 + x04 + xi2 + x34 &amp;lt;3.
DC: x0i + x04 + xi2 + x34 &amp;lt;3.
Corta PL. Valor de PL = 25.5.
(32)	-x02 +x03	-xi3 -xi4 -x23	-x34 &amp;lt;-1
DGCIL (Fixaçao a zero e a um).
Escolha das variáaveis a fixar: xi4 = 1 e x02 = xi3 = x23 = x34 = 0. DCI: x03 &amp;lt;0.
(33)	-x02 +x03 +x04	-2xi3 -2xi4 -x23	&amp;lt;-1
DGCIL (Fixaçcaão a zero e a um).
Escolha das va	riáav	eis	a fixar	: xi3 = x04 = 1 e x02 = xi4 = x23 = 0
DCI: x03 &amp;lt;0.				
(34)	-x02			&lt;	0
Equivalente a:	x02	&gt;	0.	
(35)	-x03			&lt;	0
Equivalente a:	x03	&gt;	0.	
(36)	-x04			&lt;	0
Equivalente a:	x04	&gt;	0.	
(37)	-xi2			&lt;	0
Equivalente a:	xi2	&gt;	0.	
(38)	-x	i3		&lt;	0
Equivalente a: x13 &gt; 0.
(39)	— x14	&amp;lt;0
Equivalente a: x14 &gt; 0.
(40)	—X23	&amp;lt;0
Equivalente a: x23 &gt; 0.
(41)	—X24	&amp;lt;0
Equivalente a: x24 &gt; 0.
(42)	—X34 &amp;lt;0 Equivalente a: x34 &gt; 0.
(43)	+X03	—X13 —X14	&amp;lt;0
DCILUL (Fixação a zero).
Escolha das variaveis a fixar: x13 = x14 = 0.
Estas arestas pertencem à árvore de suporte de peso mánimo. DCI: x03 &amp;lt;0.
(44)	+X04	— X13 — X14 —X23	&amp;lt;0
DCILUL (Fixação a zero).
Escolha das variaveis a fixar: x13 = x14 = x23 = 0. Estas arestas pertencem à árvore de suporte de peso mánimo. DCI: x04 &amp;lt;0.
(45)	—X02 +X03 +X04	— X13 — X14	&amp;lt;0
DCILUL (Fixação a zero).
Escolha das variáveis a fixar: x02 = x13 = x14 = 0. Estas arestas pertencem à árvore de suporte de peso mánimo. DCI: x04 &amp;lt;0.
(46)	—X02 +X03	+X12 — X13 — X14 —^23	&amp;lt;0
DCILUL (Fixação a zero).
Escolha das variáveis a fixar: x02 = x13 = x14 = x23 = 0. Estas arestas pertencem à árvore de suporte de peso mánimo. DCI: x12 &amp;lt;0.
Corta PL. Valor de PL = 25.5.
(47)	-X02 +X03	+X12	-2X14	-X24 -X34 &amp;lt;0
DCILUL (Fixação a zero).
Escolha das variíveis a fixar: x02 = x14 = x24 = x34 = 0.
As arestas {0, 2} e {1, 4} pertencem a arvore de suporte de peso mínimo, mas as arestas {2, 4} e {3, 4} não pertencem.
DCI: X12 &amp;lt;0.
(48)	+X34 &amp;lt;1
(49)	+X24	&amp;lt;1
(50)	+X23	&amp;lt;1
(51)	+X14	&amp;lt;1
(52)	+X13	&amp;lt;1
(53)	+X12	&amp;lt;1
(54)	+X04	&amp;lt;1
(55)	+X03	&amp;lt;1
(56)	+X02	&amp;lt;1
(57)	-X02 +X03 +X04	&amp;lt;1
DCILUL (Fixaçcãao a zero).
Escolha das variíaveis a fixar: X02 = 0.
Esta aresta pertence a írvore de suporte de peso mínimo. DCI: X03 + X04 &amp;lt;1.
(58)	+X03	+X12	-X14	&amp;lt;1
DCILUL (Fixação a zero).
Escolha das variíaveis a fixar: X14 = 0.
Esta aresta pertence a arvore de suporte de peso mínimo. DCI: X03 + X12 &amp;lt;1.
(59)	+Xo3 +X04	— X13 — X14	+X34 &amp;lt;—3
DCILUL (Fixação a zero).
Escolha das variáveis a fixar: x13 = x14 = x34 = 0.
As arestas {1,3} e {2, 4} pertencem a arvore de suporte de peso mánimo.
DCI: x04 + x24 &amp;lt;1.
(60)	+X03 +X04	—X13 — X14	+X24	&amp;lt;1
DCILUL (Fixação a zero).
Escolha das variaveis a fixar: x13 = x14 = 0.
Estas duas arestas pertencem à arvore de suporte de peso mánimo. DCI: X04 + X24 &amp;lt;1.
(61)	+X23 +X24 +X34 &amp;lt;2 Restriçao de eliminacao de subcircuito / Clique.
(62)	+X13 +X14	+X34 &amp;lt;2
Restriçcãao de eliminacçaão de subcircuito / Clique.
(63)	+X12	+X14	+X24	&amp;lt;2
Restriçcãao de eliminacçaão de subcircuito / Clique.
(64)	+X12 +X13	+X23	&amp;lt;2
Restriçcãao de eliminacçãao de subcircuito / Clique.
(65)
+x03	+x12
+x34 &amp;lt;2
DCI.
(66)	+X03	+X12	+X24	&amp;lt;2
DCI.
(67)	+X03 +X04	+X24	&amp;lt;2
DCI.
(68)	+X03 +X04	+X23	&amp;lt;2
DCI.
(69)	+X02	+X04
+X24	&amp;lt;2
Restricão de eliminacao de subcircuito / Clique.
(70)	+x02 +x03	+x23	&amp;lt;2
Restricçãao de eliminacçaão de subcircuito / Clique.
(71)	+x03 +x04 +x12 +x13	+x23	&amp;lt;3
DCE.
DC: x03 + x04 + xi3 + x23 &amp;lt;3.
(72)	+xi2 +xi3 +xi4 +x23 +x24 +x34 &amp;lt;3 Restricçãao de eliminacçãao de subcircuito / Corte do nodo 0 / Clique.
(73)	+x02 +x03 +x04	+x23 +x24 +x34 &amp;lt;3
Restriçcãao de eliminacçãao de subcircuito / Corte do nodo 1 / Clique.
(74)	+x02	+x03	+x04	+xi2	+xi3	+xi4	+x23	+x24	+x34	&amp;lt;4
Esta desigualdade é equivalente a seguinte: x0i &gt; 0.
Notação Utilizada
G = (V, E)	Grafo completo nao orientado.
V	Conjunto de nodos do grafo nao orientado G, V = {0,1,..., n — 1}.
E	Conjunto de arestas do grafo nao orientado G, E = {e = {i, j}, i, j G V, i = j}.
ce	Custo associado à aresta e G E.
we	Peso associado a aresta e G E.
Et	Conjunto de arestas de T = (V, ET) írvore de suporte no grafo G.
C(T)	Custo da arvore de suporte T.
W(T)	Peso da arvore de suporte T.
W Valor estabelecido para o limite de peso da restricao saco-mochila. tf(WMST)	Valor otimo do Problema WMST.
H	Matriz de pesos.
C	Matriz de custos.
Tc	Arvore de suporte	de	custo	mínimo.
Tw	Arvore de suporte	de	peso	mínimo.
Tp	Arvore de suporte ponderada mínima.
G = (V, A) Grafo completo orientado.
A Conjunto de arcos do grafo orientado G, A = {(i, j), i G V, j G V\{0}, i = j}. Cij	Custo associado ao arco (i, j) G A.
Wij	Peso associado ao arco (i, j) G A.
pij	Valor ponderado associado ao arco (i, j) G A, sendo combinaçao linear de cij
e wij .
P(T)	Valor ponderado da arvore de suporte T.
A(SbS2)	Conjunto de arcos com um extremo em S1 e outro extremo em S2.
Xwmst	Conjunto das solucoes admissíveis do Problema WMST.
XL	Conjunto das soluçães admissíveis da relaxação linear do Problema WMST.
XT	Conjunto das solucães admissíveis do Problema MST.
XK	Conjunto das solucoes admissíveis do problema saco-mochila binario.
dk	Direcão na iteração k.
sk Tamanho do passo na iteracão k.
A e v Multiplicadores de Lagrange.
tol Tolerância usada no critério de paragem dos algoritmos Lagrangeanos.
LI	Limite inferior.
LS	Limite superior.
PWMST	Invélucro convexo do conjunto XWMST.
E0	Conjunto de variaveis	fixas	a	zero.
E1	Conjunto de variéveis	fixas	a	um.
ce	Custo modificado associado à aresta e G E.
TL Tempo limite imposto.
maxIter Numero maximo de iteracoes a realizar na Heurística Feasibility Pump.
x Solucao obtida por arredondamento.
A(x,x)	Distância entre os pontos x e x.
x	Soluçao de referância.
S	Suporte binario de x.
N(x, k)	Vizinhanca k-OPT de x, onde k é o numero de variaveis binarias que
podem trocar de valor.
A(x,x) &amp;lt;k Restricao Local Branching, onde k eo numero de variaveis binarias que podem trocar de valor.
LpJ	Converte o numero p no maior numero inteiro menor ou igual a p.
Tp!	Converte o numero p no menor numero inteiro maior ou igual a p.
[p]	Converte o numero p no valor inteiro mais próximo de p.
&amp;amp;gap, &amp;amp; tempo	Desvio padrao do gap e do tempo, respetivamente.
OPT Valor otimo ($(WMST)) ou um valor do limite superior para o valor do custo.
336
Siglas Utilizadas
Siglas em Geral
E Grupo de instancias Euclideanas. Pag. 15.
MIP Programacao Linear Inteira Mista. Pag. 241.
MST Arvore de Suporte de Custo Mínimo. Pag. 7.
MSTP	Arvore de Suporte Ponderada Mínima. Pag. 13.
MSTw	Arvore de Suporte de Peso Mínimo. Pag. 11.
NFA Limite superior nunca foi atualizado. Pag. 308.
PLI Programaçao Linear Inteira. Pag. 19.
QC Grupo de instâncias Quase Caminhos. Pag. 16.
R Grupo de instancias Aleatorias. Pag. 16.
TSP Problema do Caixeiro Viajante. Pag. 27.
WMST Problema da Arvore de Suporte de Custo Mínimo com Restricoes de
Peso. Pag. 1.
Formulações para o Problema WMST
CS Formulaçao de Cortes. Pag. 23.
CSL	Relaxacao linear da Formulação de Cortes. Pag. 23.
ES Formulacao de Eliminacao de subcircuitos. Pag. 22.
ESl Relaxaçao linear da Formulaçao de Eliminacõo de subcircuitos. Pag. 23.
MF Formulaçao de Fluxos. Pag. 24.
MFL Relaxaçao linear da Formulaçao de Fluxos. Pag. 26.
MTZ Formulaçõo Miller-Tucker-Zemlin. Pag. 27.
mtzl Relaxaçao linear da Formulaçõo Miller-Tucker-Zemlin. Pag. 28.
MTZli Formulacao derivada da MTZ com a restricao (3.22) substituóda pela Desigualdade Levantada i, i = 1,2, 3, 4. Pag. 29.
MTZliL	Relaxacõo linear da Formulaçao derivada da MTZ com a restriçõo
(3.22) substituída pela Desigualdade Levantada i, i = 1, 2, 3, 4. Pag. 31.
P-CS Procedimento de Introducao de Cortes usando a Formulacõo CS. Pag. 42.
P-CSl Relaxacõo linear do Procedimento de Introducõo de Cortes usando a Formulaçcõao CS. Pag. 42.
P-MTZ+C Procedimento de Introducao de Cortes usando a Formulacõo MTZ. Pag. 42.
P-MTZ+Cl Relaxacçaõo linear do Procedimento de Introduçcaõo de Cortes usando a Formulaçcõao MTZ. Pag. 42.
P-WMTZ+C Procedimento de Introducao de Cortes usando a Formulaçao WMTZ. Pag. 42.
P-WMTZ+Cl	Relaxaçõo linear do Procedimento de Introduçao de Cortes
usando a Formulacõo WMTZ. Pag. 42.
WE	Formulacao de Fluxo com Especificacao de Pesos. Pag. 36.
WEl Relaxacao linear da Formulaçõo de Fluxo com Especificaçao de Pesos. Pag. 38.
WMSTa	Formulaçao genérica do Problema WMST com a restricao de peso
relaxada. Pag. 75.
WMST-Cav	Formulacõo genórica do Problema WMST com a restriçao de peso
e uma desigualdade vóalida relaxadas. Pag. 98.
WMTZ Formulaçao de Peso Miller-Tucker-Zemlin. Pag. 31.
wmtzl	Relaxação linear da Formulaçao de Peso Miller-Tucker-Zemlin. Pag.
33.
WMTZli Formulacao derivada da WMTZ com a restriçao (3.33) substituída pela Desigualdade Levantada i, i = 1, 2, 3, 4. Pag. 34.
WMTZliL Relaxacao linear da Formulacão derivada da WMTZ com a restricão (3.33) substituída pela Desigualdade Levantada i, i =1,2, 3, 4. Pag. 35.
Desigualdades para o Problema WMST
CI Cobertura Implícita. Pag. 138.
DC Desigualdade de Cobertura. Pag. 135.
DCE Desigualdade de Cobertura Estendida. Pag. 141.
DCI Desigualdade de Cobertura Implícita. Pag. 139.
DCIE	Desigualdade de Cobertura Implícita Estendida. Pag. 143.
DCIL	Desigualdade de Cobertura Implícita Levantada. Pag. 145.
DCILDL Desigualdade de Cobertura Implícita Levantada por Down-Lifting.
Pag. 153.
DCILUL Desigualdade de Cobertura Implícita Levantada por Up-Lifting. Pag.
158.
DGCIL Desigualdade Generalizada de Cobertura Implícita Levantada. Pag.
164.
Algoritmos e Heurísticas para o Problema WMST
ABB-P-WMTZ+C Algoritmo Branch and Bound do procedimento de introdução de cortes P-WMTZ+C. Pag. 308.
ALagB Algoritmo Lagrangeano Base para o Problema WMST. Pag. 78.
ALBC	Algoritmo Local Branching Clássico para o Problema WMST. Pag. 284.
ALB1	Algoritmo Local Branching 1 (ALBC com limite de tempo). Pag. 292.
ALB2	Algoritmo Local Branching 2 (ALB1 com mecanismos de Intensificaçao
e de Diversificacão e interrupcão do solver assim que se obtenha uma solução inteira admissível no Algoritmo Branch and Bound usando a Formulaçao WMTZ). Pag. 294.
ALB3 Algoritmo Local Branching 3 (ALB2 com limite de tempo na exploracao das vizinhancas). Pag. 295.
ALB4 Algoritmo Local Branching 4 (solucao de referência inicial é obtida pela Heurística FPB2). Pag. 297.
ALB5 Algoritmo Local Branching 5 (solucão de referência inicial é a solucao da correspondente érvore ). Pag. 298.
Algl Algoritmo Lagrangeano 1 (baseado no calculo dos valores ponderados da forma pij = (1 - Yk)wij + YkCj). Pag. 85.
Alg2 Algoritmo Lagrangeano 2 (baseado no calculo dos valores ponderados da forma pij = Akwij + cj). Pag. 87.
Alg3	Algoritmo Lagrangeano 3 (baseado no Método do subgradiente). Pag. 88.
Alg4	Algoritmo Lagrangeano 4 (baseado na técnica de pesquisa binaria). Pag.
90.
Alg5 Algoritmo Lagrangeano 5 (baseado na comparaçao de valores da funçao Lagrangeana). Pag. 92.
Alg6 Algoritmo Lagrangeano 6 (baseado na convexidade da funcao
Lagrangeana). Pag. 96.
Alg7 Algoritmo Lagrangeano 7 (baseado na introduçao de desigualdades validas). Pag. 98.
DCIL-E1	Estratégia que a partir de uma DCI obtém uma DCIL. Pag. 188.
DCIL-E2	Estratégia que só obtém a DCIL se a DCI cortar a solucao da
relaxacçãao linear. Pag. 188.
DL-Ei Estratégia Down-Lifting i, i = 1, 2, 3, 4 (usada nos algoritmos de separacão para o caso das DCILDLs). Pag. 226.
FP Heurística Feasibility Pump. Pag. 241.
FPB1	Heurística Feasibility	Pump	Básica 1. Pag.	258.
FPB2	Heurística Feasibility	Pump	Básica 2. Pag.	259.
FPO1	Heurística Feasibility	Pump	com Alteraçao	da Funcão	Objetivo 1. Pag.
259.
FPO2 Heurística Feasibility Pump com Alteraçao da Funcão Objetivo 2. Pag. 259.
GL-Ei Estratígia Generalizada i, i =1, 2, 3 (usada nos algoritmos de separaçao para o caso das DGCIL). Pag. 231.
Hcoef Algoritmo heurístico baseado em relaxaçao Lagrangeana para o calculo dos coeficientes das variíveis a efetuar levantamento. Pag. 191.
HXNR Heurística do Xpress Aplicada ao nodo raiz utilizando a Formulaçao WMTZ. Pag. 263.
LB Heurística Local Branching. Pag. 290.
OrdFixW Ordenacão de arestas (ordem decrescente de peso, we, primeiro as arestas com xe = 1 e depois as restantes arestas (0 &amp;lt;xe &amp;lt;1)). Pag. 169.
OrdFixWX Ordenação de arestas (ordem decrescente de valor de we x xe, primeiro as arestas com xe = 1 e depois as restantes arestas (0 &amp;lt;xe &amp;lt;1)). Pag. 169.
OrdKnap Ordenação de arestas (ordem decrescente de valor de (1 — xe)/we). Pag. 169.
OrdW Ordenacao de arestas (ordem decrescente de peso, we). Pag. 169.
OrdWX Ordenaçao de arestas (ordem decrescente de valor de we x xe). Pag. 169.
OrdX Ordenacao de arestas (ordem decrescente de valor de xe). Pag. 169.
PSIABB Primeira solucao inteira admissível obtida pelo solver do Xpress atravís da Formulaçao WMTZ, quando usa o procedimento Branch and Bound. Pag. 263.
Sepl Algoritmo de Separacão Genírico 1 (Inserçao de uma desigualdade vílida
no modelo por iteraçao). Pag. 168.
Sep2 Algoritmo de Separacão Genárico 2 (Inserção de varias desigualdades válidas no modelo por iteração). Pag. 170.
UL-Ei Estratégia Up-Lifting i, i =1, 2, 3, 4 (usada nos algoritmos de separaçao para o caso das DCILULs). Pag. 228.
Outras Siglas
Ai Critário de Arredondamento i, i = 1, 2, 3 (Heurística FP). Pag. 251.
FVDi	Fixaçao de Variaveis Di, i = 1, 2, 3 (nas DCILDLs). Pag. 202.
FVUi	Fixacao de Variaveis Ui, i = 1,2, 3, 4 (nas DCILULs). Pag. 208.
LVi Levantamento das Variaveis i, i =1, 2, 3 (nas DCILs). Pag. 186.
Pi Mecanismo de Perturbacao i, i = 1,2 (Heurística FP). Pag. 252.
PL-DL Procedimento de Levantamento DL (primeiro efetua-se o down-lifting e depois o levantamento usual). Pag. 203.
PL-DLU Procedimento de Levantamento DLU (primeiro efetua-se o down-lifting, depois o levantamento usual e por fim o up-lifting). Pag. 216.
PL-DUL Procedimento de Levantamento DUL (primeiro efetua-se o down-lifting, depois o up-lifting e por fim o levantamento usual). Pag. 216.
PL-LD Procedimento de Levantamento LD (primeiro efetua-se o levantamento usual e depois o down-lifting). Pag. 203.
PL-LDU Procedimento de Levantamento LDU (primeiro efetua-se o levantamento usual, depois o down-lifting e por fim o up-lifting). Pag. 216.
PL-LU Procedimento de Levantamento LU (primeiro efetua-se o levantamento usual e depois o up-lifting). Pag. 209.
PL-LUD Procedimento de Levantamento LUD (primeiro efetua-se o
levantamento usual, depois o up-lifting e por fim o down-lifting). Pag. 217.
PL-UDL Procedimento de Levantamento UDL (primeiro efetua-se o up-lifting, depois o down-lifting e por fim o levantamento usual). Pag. 216.
PL-UL Procedimento de Levantamento LU (primeiro efetua-se o up-lifting e depois o levantamento usual). Pag. 209.
PL-ULD Procedimento de Levantamento ULD (primeiro efetua-se o up-lifting, depois o levantamento usual e por fim o down-lifting). Pag. 216.
344
Lista de Figuras
2.1	Arvore de suporte de custo ménimo........................................... 10
2.2	Árvore de suporte com custo 27 e peso 19.................................... 10
2.3	Árvore de suporte de peso ménimo............................................ 13
2.4	Árvore de suporte ponderada mínima (pj = 0,5wj + 0,5cj para	todos	os	(i,	j)	G	A).	14
2.5	Árvore de suporte ponderada mínima (pj = Wj + 0,2cj para todos os	(i,	j)	G	A).	.	15
3.1	Exemplo com o valor das variéveis de fluxo na Formulação MF................. 26
3.2	Exemplo do calculo das posiçães dos nodos na érvore......................... 28
3.3	Exemplo do calculo dos estados dos pesos dos nodos na arvore................ 32
3.4	Exemplo com o valor das variaveis de fluxo na Formulaçao WE................. 37
3.5	Solução otima da relaxaçao linear obtida pelas Formulaçães ES, MF, WE, MTZll e
WMTZl2............................................................................. 39
3.6	Representaçcaão da soluçcãao da relaxacçaão linear da Formulaçcaão WMTZ............ 43
3.7	Representaçcãao da soluçcaão da relaxaçcãao linear da Formulaçcãao WMTZ apéos a in-
troduçao do corte 1................................................................ 44
3.8	Representaçcãao da soluçcãao da relaxaçcãao linear da Formulaçcãao WMTZ apéos a in-
troduçao do corte 2................................................................ 45
3.9	Tempos médios, em segundos, necessarios para a obtencão do valor étimo da For-
mulação MTZ com as varias desigualdades levantadas em instâncias de 10, 20 e 40 nodos.............................................................................. 51
3.10	Tempos médios, em segundos, necessarios para a obtençao do valor ótimo da For-mulaçcãao WMTZ com as véarias desigualdades levantadas em instâancias de 10, 20 e
40 nodos. ......................................................................... 54
3.11	Comparação das percentagens de tempo médio de execução (em segundos) da re-
laxacão linear e do Algoritmo Branch and Bound do Procedimento P-WMTZ+C em instancias R....................................................................... 69
3.12	Comparaçcãao das percentagens de tempo méedio de execuçcaão (em segundos) da re-
laxacão linear e do Algoritmo Branch and Bound do Procedimento P-WMTZ+C em instancias E.................................................................... 70
3.13	Comparaçao das percentagens de tempo médio de execução (em segundos) da re-
laxacão linear e do Algoritmo Branch and Bound do Procedimento P-WMTZ+C em instâancias QC.................................................................. 70
3.14	Relação entre os valores obtidos pela relaxaçao linear das diferentes formulaçães e
procedimentos de introduçcãao de cortes. ....................................... 71
4.1	Representação grafica de $(WMSI\) em funcão do valor de A....................... 76
4.2	Representacão geométrica dos pesos e dos custos das arvores Tc e Tw............. 81
4.3	Representação geométrica dos pesos e dos custos das érvores Tc e Tw e da reta w = W
com W(Tw) &gt; W................................................................... 82
4.4	Representação geométrica dos pesos e dos custos das érvores Tc e Tw e da reta w = W
com W(Tc) &amp;lt;W................................................................... 83
4.5	Representação geometrica dos pesos e dos custos das arvores Tc e Tw e da reta
w = W, onde W (Tw)&amp;lt;W&lt;W (Tc).................................................... 83
4.6	Comparacão dos tempos de execução em instancias QC para diferentes valores de p.	107
4.7	Comparação dos GapR médios, em percentagem, entre os Algoritmos Alg6 e Alg7
nas instaâncias QC............................................................. 113
4.8	Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instancias QC). 116
4.9	Numero médio de arvores de suporte obtidas pelos Algoritmos Alg5 e Alg6 nas
instaâncias QC................................................................. 118
4.10	Comparação dos GapR médios, em percentagem, entre os Algoritmos Alg6 e Alg7
nas instancias R............................................................... 119
4.11	Tempos méedios, em segundos, obtidos pelos algoritmos Lagrangeanos (instâancias R). 122
4.12	Nuémero méedio de aérvores de suporte obtidas pelos Algoritmos Alg5 e Alg6 nas
instancias R................................................................... 124
4.13	Comparaçao dos GapR médios, em percentagem, entre os Algoritmos Alg6 e Alg7
nas instancias E............................................................... 125
4.14	Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instâncias E). 128
4.15	Nuémero méedio de éarvores de suporte obtidas pelos Algoritmos Alg5 e Alg6 nas
instâncias E................................................................... 130
5.1	Representacao das arestas da Cobertura S4 no grafo..............................137
5.2	Arvore de suporte com custo 24 e peso 21........................................140
5.3	Desigualdade de Cobertura e Desigualdade de Cobertura Implícita........................140
5.4	Ciclos formados com as arestas da Cobertura Implícita S do Exemplo 5.3.................144
5.5	Arvore de	suporte	com custo 24 e peso 21.........................................152
5.6	Arvore de	suporte	com custo 28 e peso 22.........................................157
5.7	Arvore de	suporte	com custo 24 e peso 21.........................................162
6.1	Arvore de	suporte	de peso mínimo incluindo	a aresta {0,4}	com custo	47 e	peso	14.	179
6.2	Arvore de	suporte	de peso mínimo incluindo	as arestas	{0,1}	e	{0,4}	com	custo	32
e peso 18............................................................................. 179
6.3	Arvore de suporte de peso mínimo incluindo as arestas {0,1}, {0,4} e {1, 2} com
custo 24 e peso 21.................................................................... 180
6.4	Esquemas de obtencão de uma DCIL dada uma DCI..........................................188
6.5	Arvores de suporte TcI e TwI obtidas no Passo 1 do Algoritmo HCoef no calculo do
coeficiente de levantamento usual ^34..................................................196
6.6	Arvore de suporte TPI obtida no Passo 2 do Algoritmo HCoef no cálculo do coeficiente
de levantamento usual J34............................................................. 196
6.7	Arvores de suporte TcI e TwI obtidas no Passo 1 do Algoritmo HCoef no cálculo do
coeficiente de levantamento usual ft03.................................................197
6.8	Primeira árvore de suporte TPI obtida no Passo 2 do Algoritmo HCoef no cálculo do
coeficiente de levantamento usual ft03.................................................198
6.9	Segunda arvore de suporte TPI obtida no Passo 2 do Algoritmo HCoef no calculo do
coeficiente de levantamento usual ft03.................................................199
6.10	Esquemas de obtençao de uma DCIL dada uma DCIE........................................200
6.11	Arvores de suporte TCI e TWI obtidas no Passo 1 do Algoritmo HCoef no calculo do
coeficiente down-lifting fi12..........................................................204
6.12	Arvore de suporte TPI obtida no Passo 2 do Algoritmo HCoef no calculo do coeficiente
down-lifting ^12.......................................................................205
6.13	Arvore de suporte TWI obtida no Passo 1.1 do Algoritmo HCoef no calculo do coefi-
ciente up-lifting /323.................................................................210
6.14	Arvores de suporte TCI e TWI obtidas no Passo 1 do Algoritmo HCoef no cálculo do
coeficiente up-lifting ^02.............................................................211
6.15	Arvore de suporte TPI obtida no Passo 2 do Algoritmo HCoef no calculo do coeficiente
up-lifting JO2.........................................................................211
6.16	Percentagem de instâncias, em cada uma das melhores estratégias heurísticas de se-paracão com tempo inferior ao tempo do Procedimento P-WMTZ+CL em instancias
QC de 10 a 60 nodos...............................................................233
6.17	Percentagem de soluçães étimas obtidas com as melhores estratégias heurísticas de
separacão em instancias QC de 10 a 60 nodos.......................................234
6.18	Percentagem de instancias, em cada uma das melhores estrategias heurísticas de separaçcaão com o nuémero de nodos no Branch and Bound inferior ao nuémero usado
pelo Procedimento P-WMTZ+C em instancias QC de 10 a 60 nodos......................234
7.1	Arvore de suporte Tx com custo 27 e peso 19.......................................243
7.2	Arvore de suporte Tx com custo 24 e peso 21.......................................244
7.3	Representacão geométrica das duas trajetérias	de custos	(instancia	QC80-7).	. . .	254
7.4	Representação geométrica das duas trajetórias	de pesos	(instância	QC80-7)........ 254
7.5	Evoluçao da distância A(x*,x) ao longo das iteracães (instância QC80-7).......... 255
7.6	Evolucao da distância A(x*, x) ao longo das iteracoes na instancia QC80-7 nas quatro
estrategias heurísticas propostas.................................................260
7.7	Evolucão da distancia A(x*, x) ao longo das iteracoes na instancia R80-5 nas quatro
estrategias heurísticas propostas.................................................261
7.8	Evolucão da distancia A(x*, x) ao longo das iteracoes na instancia E80-3 nas quatro
estrategias heurísticas propostas.................................................261
7.9	Percentagem de gaps nulos nas diferentes heurésticas propostas nas instâancias QC. .	264
7.10	Comparacão dos gaps médios, em percentagem, entre as Heurísticas FP propostas e
a Heurística HXNR nas instancias QC...............................................266
7.11	Diferenças medias de gaps, em percentagem, entre as Heurísticas HXNR e FPB2 nas
instâancias QC................................................................... 268
7.12	Comparacão dos gaps médios, em percentagem, entre as Heurísticas FPB2 e a PSI-
ABB nas instâncias QC.............................................................269
7.13	Percentagem de gaps nulos nas diferentes heurésticas propostas nas instaâncias R. . .	270
7.14	Comparacçãao dos gaps méedios, em percentagem, entre as Heurésticas FP propostas
nas instâncias R..................................................................272
7.15	Percentagem de gaps nulos nas diferentes heurésticas propostas nas instaâncias E. . .	275
7.16	Comparacçãao dos gaps méedios, em percentagem, entre as Heurésticas FP propostas
nas instâncias E..................................................................277
8.1	Esquema de ramificacão obtido usando o Algoritmo ALBC na instancia QC10-8. . .	286
8.2	Representacão da trajetoria de custos da instância QC10-8.........................291
8.3	Representaçao da trajetória de pesos da instância QC10-8......................292
8.4	Esquema de ramificação obtido usando o Algoritmo ALB3 na instância QC10-10.	.	297
8.5	Tempos médios de execucao, em segundos, obtidos usando o Algoritmo ALB4 para
diferentes valores de k'......................................................300
8.6	Percentagem de soluções étimas obtidos pelos algoritmos Local Branching nas instancias
QC........................................................................... 302
8.7	Percentagem de solucães otimas obtidas pelos Algoritmos Local Branching nas instâncias
R.............................................................................304
8.8	Percentagem de solucães étimas obtidas pelos algoritmos Local Branching nas instâncias
E.............................................................................306
350
Lista de Tabelas
3.1	Comparação	dos	valores obtidos usando as Formulações MTZL	e WMTZL............... 33
3.2	Comparaçao	das	formulaçòes usando um exemplo de 5 nodos......................... 39
3.3	Comparaçao	das	formulaçães usando um exemplo de 10 nodos........................ 47
3.4	Comparação	dos	valores da relaxação linear da Formulação MTZ com	as	várias de-
sigualdades levantadas em instancias de 10 nodos................................... 49
3.5	Comparação dos valores da relaxação linear da Formulação MTZ com as várias desigualdades levantadas em instâncias de 20 nodos.................................... 50
3.6	Comparação dos valores da relaxação linear da Formulaçao WMTZ com as várias
desigualdades levantadas em instancias de 10 nodos................................. 52
3.7	Comparacão dos valores da relaxacão linear da Formulaçao WMTZ com as várias
desigualdades levantadas em instâncias de 20 nodos................................. 53
3.8	Comparacão dos tempos mádios (em segundos) e dos desvios padrões necessários
para a obtençcãao do valor da relaxacçaão linear nas Formulaçcãoes MTZ e WMTZ em instâncias QC...................................................................... 55
3.9	Comparação dos tempos mádios (em segundos) e dos desvios padrães necessários
para a obtençcãao do valor da relaxaçcãao linear nas Formulaçcãoes MTZ e WMTZ em instancias R....................................................................... 56
3.10	Comparação dos tempos médios (em segundos) e dos desvios padrães necessários
para a obtencçãao do valor da relaxaçcaão linear nas Formulaçcãoes MTZ e WMTZ em instancias E....................................................................... 56
3.11	Comparacão das formulaçães em instancias QC de 10 e 20 nodos...................... 58
3.12	Comparaçao das formulacoes em instancias QC de 40, 60 e 80 nodos.................. 60
3.13	Comparaçao dos Procedimentos P-CS e P-WMTZ+C em termos de tempo medio de
execuçcãao (em segundos) da relaxaçcãao linear em instâancias QC de 10, 20, 40, 60 e 80 nodos.............................................................................. 61
3.14	Comparacão das formulaçoes em instancias R de 10 nodos............................ 62
3.15	Comparacão das formulaçoes em instancias R de 40, 60, 80 e 100 nodos.............. 64
3.16	Comparação das formulações em instâncias E de 10 nodos....................................... 65
3.17	Comparação das formulações em instancias E de 20, 40, 60 e 80 nodos......................... 66
3.18	Tempos médios, em segundos, e respetivos desvios padrões obtidos com a aplicaçao do Procedimento P-WMTZ+C na obtençao do valor otimo ou de um limite superior
para o valor otimo em cada grupo de instancias............................................... 68
4.1	Resultados	da	aplicacão do Algoritmo Algl para o	exemplo	de 5	nodos.. 86
4.2	Resultados	da	aplicação do Algoritmo Alg2 para o	exemplo	de 5	nodos.. 87
4.3	Resultados	da	relaxação Lagrangeana aplicando o	Algoritmo Alg3 para diferentes
valores de p................................................................................. 89
4.4	Resultados	da	aplicacao do	Algoritmo Alg4	para o exemplo de 5 nodos........... 91
4.5	Resultados	da	aplicaçao do	Algoritmo Alg5	para obtençao	do intervalo	[lk,uk].	.	.	95
4.6	Resultados	da	aplicaçao do	Algoritmo Alg6	para obtenção	do intervalo	[lk,uk].	.	.	97
4.7	Comparacão dos algoritmos	Lagrangeanos no Exemplo 2.1..................................... 105
4.8	Valores de p utilizados no Algoritmo Alg3 nas instâncias Aleatórias e Euclideanas de
10 a 100 nodos. ............................................................................ 107
4.9	Valores de p utilizados no Algoritmo Alg3 nas instâancias Aleatoérias e Euclideanas de
150 a 1000 nodos. .......................................................................... 107
4.10	Comparaçcãao das duas estratéegias de inicializaçcãao do Algoritmo Alg5 em instaâncias
QC.......................................................................................... 108
4.11	Percentagens de gaps nulos obtidas através do LS nos varios algoritmos por cada
grupo de instaâncias. ...................................................................... 110
4.12	Percentagens de GapLS que sao inferiores aos GapR nos varios algoritmos por cada
grupo de instaâncias. ...................................................................... 111
4.13	Gaps médios, em percentagem, obtidos pelos algoritmos Lagrangeanos nas instâncias
QC.......................................................................................... 114
4.14	Desvios Padrães dos gap obtidos pelos algoritmos Lagrangeanos nas instâncias QC. 115
4.15	Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instancias QC). 117
4.16	Desvios padrães dos tempos obtidos pelos algoritmos Lagrangeanos (instancias QC). 117
4.17	Gap méedios, em percentagem, obtidos pelos algoritmos Lagrangeanos nas instâancias R.120
4.18	Desvios Padrães dos gap obtidos pelos algoritmos Lagrangeanos nas instâncias R. .	121
4.19	Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instancias R). 123
4.20	Desvios padrães dos tempos obtidos pelos algoritmos Lagrangeanos (instâncias R). .	123
4.21	Gap medios, em percentagem, obtidos pelos algoritmos Lagrangeanos nas instâncias E. 126
4.22	Desvios Padroes dos gap obtidos pelos algoritmos Lagrangeanos nas instancias E. .	127
4.23	Tempos médios, em segundos, obtidos pelos algoritmos Lagrangeanos (instâncias E). 129
4.24	Desvios padrões dos tempos obtidos pelos algoritmos Lagrangeanos (instancias E). .	129
6.1	Principais resultados por iteraçõo do Algoritmo Sepl para as DCs aplicado ao Exem-
plo 2.1........................................................................... 174
6.2	Principais resultados por iteraçõo do Algoritmo Sep2 para as DCs aplicado ao Exem-
plo 2.1........................................................................... 175
6.3	Principais resultados por iteraçõo do Algoritmo Sepl para as DCIs aplicado ao Exem-
plo 2.1. ........................................................................ 181
6.4	Principais resultados por iteraçao do Algoritmo Sep2 para as DCIs aplicado ao Exem-
plo 2.1. ........................................................................ 182
6.5	Principais resultados por iteraçõo do Algoritmo Sepl para as DCIEs aplicado ao
Exemplo 5.4....................................................................... 184
6.6	Principais resultados por iteraçõo do Algoritmo Sep2 para as DCIEs aplicado ao
Exemplo 5.4....................................................................... 185
6.7	Principais resultados por iteraçao do Algoritmo Sepl para as DCILDLs com fixacõo
de variaveis FVD3 aplicado	ao Exemplo 2.1........................................205
6.8	Principais resultados por iteraçõo do Algoritmo Sepl para as DCILDLs com fixaçõo
de variaveis FVD2 aplicado ao Exemplo 2.l..........................................206
6.9	Principais resultados por iteraçõo do Algoritmo Sepl para as DCILULs utilizando o
procedimento de levantamento de variaveis PL-UL aplicado ao Exemplo 2.l............212
6.10	Principais resultados por iteraçao do Algoritmo Sepl para as DCILULs utilizando o
procedimento de levantamento de variéveis PL-LU aplicado ao Exemplo 2.l............213
6.11	Principais resultados por iteraçao do Algoritmo Sepl para as DGCILs utilizando o
procedimento de levantamento de variaéveis PL-DLU aplicado ao Exemplo 2.l. . . .	218
6.12	Principais resultados por iteraçõo do Algoritmo Sepl para as DGCILs utilizando o
procedimento de levantamento de variaéveis PL-DLU aplicado ao Exemplo 2.l. . . .	219
6.13	Comparaçõo do Procedimento P-WMTZ+CL e dos Algoritmos Sepl e Sep2 nas DCs
e nas DCIs nas instâncias QC de l0 a 60 nodos......................................221
6.14	Comparaçõo do Procedimento P-WMTZ+CL e dos Algoritmos Sepl e Sep2 nas
DCIEs nas instâncias QC de l0 a 60 nodos...........................................223
6.15	Comparaçõo do Procedimento P-WMTZ+CL e dos Algoritmos Sepl e Sep2 nas
DCILs nas instancias QC de l0 a 60 nodos...........................................225
6.16	Comparaçõo do Procedimento P-WMTZ+CL e dos Algoritmos Sepl e Sep2 nas
DCILDLs nas instâncias QC de l0 a 60 nodos.........................................227
6.17	Comparação do Procedimento P-WMTZ+CL e dos Algoritmos Sep1 e Sep2 nas DCI-
LULs nas instâncias QC de 10 a 60 nodos................................................230
6.18	Comparacão do Procedimento P-WMTZ+CL e dos Algoritmos Sep1 e Sep2 nas DG-
CILs nas instancias QC de 10 a 60 nodos................................................232
6.19	Comparaçao do Procedimento P-WMTZ+CL e dos melhores algoritmos heurísticos
de separacao nas instâncias QC de 10 a 60 nodos........................................236
6.20	Comparaçao do Procedimento P-WMTZ+CL e dos dois melhores algoritmos heurísticos
de separacao nas instâncias QC de 80 a 150 nodos.......................................238
7.1	Comparacao dos valores obtidos usando as quatro Heurísticas FP propostas...............262
7.2	Gaps médios, em percentagem, obtidos pelas heurísticas propostas nas instâncias QC. 265
7.3	Desvios Padroes dos gap obtidos pelas heurísticas propostas nas instâncias QC. . .	265
7.4	Tempos méedios, em segundos, obtidos pelas heurésticas propostas nas instâancias QC. 267
7.5	Desvios padrãoes dos tempos obtidos pelas heurísticas propostas nas instaâncias QC. .	267
7.6	Gaps mídios, em percentagem, obtidos pelas heurísticas propostas nas instancias R. 271
7.7	Desvios Padrães dos gaps obtidos pelas heurísticas propostas nas instâncias R. . .	271
7.8	Tempos míedios, em segundos, obtidos pelas heurísticas propostas nas instâancias R. 273
7.9	Desvios padroães dos tempos obtidos pelas heurísticas propostas nas instâancias R. .	273
7.10	Gaps míedios, em percentagem, obtidos pelas heurísticas propostas nas instaâncias E. 276
7.11	Desvios Padrãoes dos gaps obtidos pelas heurísticas propostas nas instâancias E. . . .	276
7.12	Tempos míedios, em segundos, obtidos pelas heurísticas propostas nas instâancias E. 278
7.13	Desvios padrãoes dos tempos obtidos pelas heurísticas propostas nas instaâncias E. .	278
8.1	Comparaçao dos algoritmos Local Branching na instancia QC10-8..........................299
8.2	Tempo, em segundos, imposto na exploracao das vizinhanças..............................301
8.3	Comparaçao dos algoritmos Local Branching em termos de gaps mídios (em percentagem) e de tempo mídio de execução (em segundos) nas instâncias QC.............303
8.4	Comparação dos algoritmos Local Branching em termos de gaps mídios (em percentagem) e de tempo mídio de execucao (em segundos) nas instancias R..............305
8.5	Comparação dos algoritmos Local Branching em termos de gaps mídios (em percentagem) e de tempo míedio de execuçcãao (em segundos) nas instaâncias E. ....... 307
8.6	Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instancias QC de
10 a 40 nodos......................................................................... 309
8.7	Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias QC de
60 a 100 nodos. ...................................................................... 310
8.8	Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias QC de
150 a 1000 nodos...........................................311
8.9	Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias R de 10
a 150 nodos................................................312
8.10	Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias R de 200
a 1000 nodos...............................................313
8.11	Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias E de 10
a 150 nodos................................................314
8.12	Comparação entre os Algoritmos ALB4 e ABB-P-WMTZ+C nas instâncias E de 200
a 1000 nodos...............................................315
356
Bibliografia
[1]	FICO Xpress Optimization Suite. www.fico.com/xpress.
[2]	T. Achterberg and T. Berthold. Improving the feasibility pump. Discrete Optimization, 4(1):77-86, 2007.
[3]	V. Aggarwal, Y.P. Aneja, and K.P. Nair. Minimal spanning tree subject to a side constraint. Computers and Operations Research, 9(4):287-296, 1982.
[4]	A. Agra, A. Cerveira, C. Requejo, and E. Santos. On the weight-constrained minimum spanning tree problem. In Proceedings of the International Network Optimization Conference, volume 6701 of Lecture Notes in Computer Science, pages 156-161, 2011.
[5]	R.K. Ahuja, T.L. Magnanti, and J.B. Orlin. Network flows. In G.L. Nemhauser, A.H.G. Rinnooy Kan, and M.J. Todd, editors, Optimization, Handbooks in Operations Research and Management Science, Vol. 1. Elsevier Science Publishers, North-Holland, Amsterdam, The Netherlands, 1989.
[6]	R.K. Ahuja, T.L. Magnanti, and J.B. Orlin. Network Flows: Theory, Algorithms, and Applications. Prentice-Hall, New York, 1993.
[7]	L. Amado and P. Barcia. New polynomial bounds for matroidal knapsacks. European Journal of Operations Research, 95(1):201-210, 1996.
[8]	K.A. Andersen, K. Jornsten, and M. Lind. On bicriterion minimal spanning trees: An approximation. Computers and Operations Research, 23(12):1171-1182, 1996.
[9]	R. Andrade, A. Lucena, and N. Maculan. Using lagrangian dual information to generate degree constrained spanning trees. Discrete Applied Mathematics, 154(5):703-717, 2006.
[10]	E. Balas. Facets of knapsack polytope. Mathematical Programming, 8(1):146—164, 1975.
[11]	E. Balas and E. Zemel. Facets of knapsack polytope from minimal covers. SIAM Jounal on Applied Mathematics, 34(1):119—148, 1978.
[12]	L. Bertacco, M. Fischetti, and A. Lodi. A feasibility pump heuristic for general mixed-integer problems. Discrete Optimization, 4(1):63-76, 2007.
[13]	D. Blokh and G. Gutin. An approximation algorithm for combinatorial optimization problems with two parameters. Australasian Journal of Combinatorics, 14:157-164, 1996.
[14]	T. Christof and G. Reinelt. PORTA POlyhedron Representation Transformation Algorithm. http://typo.zib.de/opt-long_projects/Software/Porta/.
[15]	M. Desrochers and G. Laporte. Improvements and extensions to the Miller-Tucker-Zemlin subtour elimination constraints. Operations Research, 10(1):27-36, 1991.
[16]	D. Eppstein. Finding the k smallest spanning trees. BIT Numerical Mathematics, 32(2):237-248, 1992.
[17]	C. E. Ferreira, A. Martin, and R. Weismantel. Solving multiple knapsack problems by cutting planes. SIAM Journal Optimization, 6(3):858-877, 1996.
[18]	M. Fischetti, F. Glover, and A. Lodi. The feasibility pump. Mathematical Programming, 104(1):91-104, 2005.
[19]	M. Fischetti and A. Lodi. Local branching. Mathematical Programming, 98(1-3):23-47, 2003.
[20]	L.R. Ford and D.R. Fulkerson. Flows in Networks. Princeton University Press, 1962.
[21]	M.R. Garey and D.S. Johnson. Computers and Intractability: A Guide to the Theory of NP-Completeness. W.H. Freeman, New York, 1979.
[22]	R.E. Gomory. Some polyhedra related to combinatorial problems. Linear Algebra and its Applications, 2(4):451-558, 1969.
[23]	L. Gouveia. A 2n constraint formulation for the capacitated minimal spanning tree problem. Operations Research, 43(1):130—141, 1995.
[24]	L. Gouveia. Using the Miller-Tucker-Zemlin constraints to formulate a minimal spanning tree problem with hop constraints. Computers and Operations Research, 22(9):959-970, 1995.
[25]	L. Gouveia. Multicommodity flow models for spanning trees with hop constraints. European Journal of Operational Research, 95(1):178-190, 1996.
[26]	L. Gouveia and T. Magnanti. Network flow models for designing diameter-constrained minimum-spanning and Steiner trees. Networks, 41(3):159-173, 2003.
[27]	L. Gouveia and P. Martins. The capacitated minimum spanning tree problem: revisiting hop-indexed formulations. Computers and Operations Research, 32(9):2435-2452, 2005.
[28]	L. Gouveia and C. Requejo. A new lagrangean relaxation approach for the hop-constrained minimum spanning tree problem. European Journal of Operational Research, 132(3):539-552, 2001.
[29]	Z. Gu, G.L. Nemhauser, and M.W.P. Savelsbergh. Lifted cover inequalities for 0-1 integer programs: Computation. INFORMS Journal on Computing, 10(4):427-437, 1998.
[30]	Z. Gu, G.L. Nemhauser, and M.W.P. Savelsbergh. Lifted cover inequalities for 0-1 integer programs: Complexity. INFORMS Journal on Computing, 11(1):117-123, 1999.
[31]	H.W. Hamacher and G. Ruhe. On spanning tree problems with multiple objectives. Annals of Operations Research, 52(4):209-230, 1994.
[32]	P.L. Hammer, E.L. Johnson, and U.N. Peled. Facets of regular 0-1 polytopes. Mathematical Programming, 8(1):179-206, 1975.
[33]	G. Handler and I. Zang. A dual algorithm for the constrained shortest path problem. Networks, 10(4):293-309, 1980.
[34]	P. Hansen, N. Mladenovic, and D. Urosevic. Variable neighborhood search and local branching. Computers and Operations Research, 33(10):3034-3045, 2006.
[35]	R. Hassin and A. Levin. An efficient polynomial time approximation scheme for the constrained minimum spanning tree problem using matroid intersection. SIAM Journal on Computing, 33(2):261-268, 2004.
[36]	M. Held, P. Wolfe, and H.P. Crowder. Validation of subgradient optimization. Mathematical Programming, 6(1):62-88, 1974.
[37]	S.T. Henn. Weight-constrained minimum spanning tree problem. Master’s thesis, Department of Mathematics, University of Kaiserslautern, Kaiserslautern, Germany, 2007.
[38]	S.P. Hong, S.J. Chung, and B.H. Park. A fully polynomial bicriteria approximation scheme for the constrained spanning tree problem. Operations Research Letters, 32(3):233-239, 2004.
[39]	B.A. Julstrom and G.R. Raidl. Edges sets: an effective evolutionary coding of spanning trees. IEEE Transactions on Evolutionary Computation, 7(3):225-239, 2003.
[40]	A. Juttner. On resource constrained optimization problems. In fth Japonese-Hungarian Symposium on Discrete Mathematics and its Applications, pages 3-6, 2005.
[41]	A. Juttner, B. Szviatovszki, I. Mecs, and Z. Rajko. Lagrange relaxation based method for the QoS routing problem. In Proceedings of the IEEE INFOCOM -The conference on Computer Communications, volume 2, pages 859-868. IEEE Computer and communications Societies, 2001.
[42]	K. Kaparis and A.N. Letchford. Local and global lifted cover inequalities for the 01 multidimensional knapsack problem. European Journal of Operational Research, 186(1):91-103, 2008.
[43]	K. Kaparis and A.N. Letchford. Separation algorithms for 0-1 knapsack polytopes. Mathematical Programming, 124(1-2):69-91, 2010.
[44]	D. Klabjan, G.L. Nemhauser, and C. Tovey. The complexity of cover inequality separation. Operations Research Letters, 23(1-2):35 - 40, 1998.
[45]	T. Magnanti and L. Wolsey. Optimal trees. In M.O. Ball, T.L. Magnanti, C.L. Monma, and G.L. Nemhauser, editors, Network Models, Handbooks in Operations
Research and Management Science, Vol. 7. Elsevier Science Publishers, North-Holland, 1995.
[46]	C.E. Miller, A.W. Tucker, and R.A. Zemlin. Integer programming formulation and travelling salesman problems. Journal of the Association for Computing Machinery, 7(4):326-329, 1960.
[47]	N. Mladenovic and P. Hansen. Variable neighborhood search. Computers and Operations Research, 24(11):1097-1100, 1997.
[48]	S.C. Narula and C.A. Ho. Degree-constrained minimum spanning tree. Computers and Operations Research, 7(4):239-249, 1980.
[49]	G.L. Nemhauser and L.A. Wolsey. Integer and Combinatorial Optimization. John Wiley &amp;amp; Sons, New York, 1988.
[50]	D. Pisinger. Where are the hard knapsack problems? Computers and Operations Research, 32(9):2271-2284, 2005.
[51]	R.C. Prim. Shortest connection networks and some generalizations. Bell Systems Technical Journal, 36(6):1389-1401, 1957.
[52]	G.R. Raidl, S. Pirkwieser, and J. Puchinger. A Lagrangean decomposi-tion/evolutionary algorithm hybrid for the knapsack constrained maximum spanning tree problem. Studies in Computational Intelligence, 153:69-85, 2008.
[53]	R.M. Ramos, S. Alonso, J. Sicilia, and C. Gonzalez. The problem of the optimal biobjective spanning tree. European Journal of Operational Research, 111(3):617-628, 1998.
[54]	R. Ravi and M.X. Goemans. The constrained minimum spanning tree problem. In Proceedings of the Scandinavian Workshop on Algorithm Theory, volume 1097 of Lecture Notes in Computer Science, pages 66-75, 1996.
[55]	C. Requejo, A. Agra, A. Cerveira, and E. Santos. Formulations for the weight-constrained minimum spanning tree problem. In Proceedings of the International Conference on Numerical Analysis and Applied Mathematics, volume 1281 of AIP Conference Proceedings, pages 2166-2169, 2010.
[56]	C. Requejo and E. Santos. Greedy heuristics for the diameter-constrained minimum spanning tree problem. Journal of Mathematical Sciences, 161(6):930-943, 2009.
[57]	C. Requejo and E. Santos. Lagrangean based algorithms for the weight constrained minimum spanning tree problem. In Proceedings of the VII ALIO-EURO -Workshop on Combinatorial Optimization, pages 38-41, 2011.
[58]	A.W. Shogan. Constructing a minimal-cost spanning tree subject to resource constraints and flow requirements. Networks, 13(2):169-190, 1983.
[59]	N.Z. Shor. Minimization Methods for Non-Differentiable Functions. SpringerVerlag, Berlin, 1985.
[60]	F. Sourd and O. Spanjaard. A multiobjective branch-and-bound framework: application to the biobjective spanning tree problem. INFORMS Journal on Computing, 20(3):472-484, 2008.
[61]	S. Steiner and T. Radzik. Computing all efficient solutions of the biobjective minimum spanning tree problem. Computers and Operations Research, 35(1):198-211, 2008.
[62]	L.A. Wolsey. Faces for linear inequalities in 0-1 variables. Mathematical Programming, 8(1):165-178, 1975.
[63]	L.A. Wolsey. Integer Programming. John Wiley &amp;amp; Sons, 1998.
[64]	Y. Xiao, K. Thulasiraman, G. Xue, and A. Juttner. The constrained shortest path problem: Algorithmic approaches and an algebraic study with generalization. AKCE International Journal of Graphs and Combinatorics, 2(2):63-86, 2005.
[65]	G. Xue. Primal-dual algorithms for computing weight-constrained shortest paths and weight-constrained minimum spanning trees. In Proceedings of the IEEE International Performance, Computing, and Communications Conference, pages 271 -277. IEEE Communications Society, 2000.
[66]	T. Yamada, K. Watanabe, and S. Kataoka. Algorithms to solve the knapsack constrained maximum spanning tree problem. International Journal of Computer Mathematics, 82(1):23-34, 2005.</field>
	</doc>
</add>