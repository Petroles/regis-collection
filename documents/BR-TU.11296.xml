<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.11296</field>
		<field name="filename">16574_Costa_LuisAugustoNagasaki_M.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">
 

 

UNIVERSIDADE ESTADUAL DE CAMPINAS 

FACULDADE DE ENGENHARIA MECÂNICA  

E INSTITUTO DE GEOCIÊNCIAS 

PROGRAMA DE PÓS-GRADUAÇÃO EM  

CIÊNCIAS E ENGENHARIA DE PETRÓLEO 

 

 

LUÍS AUGUSTO NAGASAKI COSTA 

 

 

APLICAÇÃO DE REDES NEURAIS 

ARTIFICIAIS NO PROCESSO DE AJUSTE 

DE HISTÓRICO 
 

 

 

 

 

 

CAMPINAS 

2012

 



i 

 

UNIVERSIDADE ESTADUAL DE CAMPINAS 

FACULDADE DE ENGENHARIA MECÂNICA  

E INSTITUTO DE GEOCIÊNCIAS 

PROGRAMA DE PÓS-GRADUAÇÃO EM  

CIÊNCIAS E ENGENHARIA DE PETRÓLEO 

 

 

 

 

 

 

APLICAÇÃO DE REDES NEURAIS 

ARTIFICIAIS NO PROCESSO DE AJUSTE 

DE HISTÓRICO 
 

 

 

 

Autor: Luís Augusto Nagasaki Costa 

Orientador: Pesq. Dr. Célio Maschio 

Co-orientador: Prof. Dr. Denis José Schiozer 

 

 

Curso: Ciências e Engenharia de Petróleo 

Área de Concentração: Reservatórios e Gestão 

 

 

Dissertação de mestrado acadêmico apresentada à Comissão de Pós Graduação em Ciências e 

Engenharia de Petróleo da Faculdade de Engenharia Mecânica e Instituto de Geociências, como 

requisito para a obtenção do título de Mestre em Ciências e Engenharia de Petróleo. 

 

 

 

 

 

Campinas, 2012 

SP – Brasil. 



ii 

 

 

 

FICHA CATALOGRÁFICA ELABORADA PELA 

BIBLIOTECA DA ÁREA DE ENGENHARIA E ARQUITETURA - BAE - UNICAMP 

 

 

 

 

    C823a 

 

Costa, Luís Augusto Nagasaki 

     Aplicação de redes neurais artificiais no processo de 

ajuste de histórico / Luís Augusto Nagasaki Costa. --

Campinas, SP: [s.n.], 2012. 

 

     Orientador: Célio Maschio.  

     Coorientador: Denis José Schiozer. 

     Dissertação de Mestrado - Universidade Estadual de 

Campinas, Faculdade de Engenharia Mecânica. 

 

     1. Inteligência artificial.  2. Redes neurais.  3. 

Algoritmos genéticos.  4. Engenharia de reservatório.  5. 

Amostragem.  I. Maschio, Célio.  II. Schiozer, Denis 

José.  III. Universidade Estadual de Campinas. 

Faculdade de Engenharia Mecânica.  IV. Título. 

 

 

Título em Inglês: Application of artificial neural networks in the history 

matching process 

Palavras-chave em Inglês: Artificial intelligence, Artificial neural networks, 

Genetic algorithms, Oil reservoir engineering, 

Sampling 

Área de concentração: Reservatórios e Gestão 

Titulação: Mestre em Ciências e Engenharia de Petróleo 

Banca examinadora: Dirceu Bampi, Alexandre Campane Vidal 

Data da defesa: 24-05-2012 

Programa de Pós Graduação: Engenharia Mecânica 

 
 
 

 

 

 

 

 

 

 

 

 



iii 

 

 



iv 

 

 

 

 

 

 

 

 

 

 

 

 



 

 

v 

 

DEDICATÓRIA 

Dedico esse trabalho aos meus pais Gilvan e Eunice e a minha namorada Marcela, que me 

incentivaram a realizar o curso de mestrado e com seus exemplos de persistência e espírito 

batalhadores me serviram de modelo em toda a minha caminhada. 



 

 

vii 

 

AGRADECIMENTOS 

Ao meu orientador, Pesq. Dr. Célio Maschio e ao meu co-orientador Prof. Dr. Denis José 

Schiozer pela competência, paciência e generosidade e por acreditarem neste trabalho. 

Aos meus colegas de trabalho aos quais convivi durante o mestrado e proporcionaram um bom 

ambiente para estudos e desenvolvimento. 

Aos pesquisadores, colaboradores e funcionários do UNISIM, pelo suporte e colaboração. 

Aos professores e funcionários do DEP pela ajuda direta ou indireta na realização deste 

trabalho. 

À PETROBRAS pela concessão de bolsa de estudo, ao CEPETRO (Centro de estudos de 

Petróleo) e ao UNISIM pelo suporte financeiro. 

Aos meus pais Gilvan e Eunice, e minha namorada Marcela, pelo constante incentivo e apoio. 

A todos os meus amigos; os de Assis, os de Campinas e aos que conheci em Ilha Solteira, que 

direta ou indiretamente me proporcionaram bons momentos durante o mestrado. 



 

 

ix 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

“Ninguém pode fazer você se sentir inferior sem o seu consentimento.” 

“Faça o que o seu coração dizer que está certo – você será criticado pela sua atitude 

seja ela qual for.” 

Eleanor Roosevelt



 

 

xi 

 

RESUMO 

 

COSTA, Luís Augusto Nagasaki. Aplicação de Redes Neurais Artificiais no Processo de Ajuste 

de Histórico. Campinas: Faculdade de Engenharia Mecânica, Universidade Estadual de 

Campinas, 2012. 145 p. Dissertação de Mestrado. 

 

O processo de ajuste de histórico consiste em uma das etapas mais importantes envolvendo 

estudos de reservatórios, pois com o modelo de simulação ajustado pode-se realizar previsões de 

produção com maior confiabilidade e avaliar diferentes estratégias de produção de forma a obter 

maior recuperação final com menor custo. Porém, esse processo traz consigo diversas 

dificuldades, sendo uma delas a não unicidade das soluções, ou seja, vários modelos podem 

igualmente proporcionar resultados satisfatórios dependendo do objetivo de estudo. Além disso, o 

reservatório pode possuir diversas heterogeneidades e não linearidades entre atributos do 

reservatório e valores de produção e pressão, o que também contribui para aumentar a 

complexidade do problema. Através dos diversos trabalhos já publicados comprovou-se que cada 

caso possui diferentes características, de forma que uma metodologia aplicada com sucesso a um 

determinado caso pode não ser aplicável a outro e vice e versa. Dessa maneira, estudos nessa área 

devem ser realizados e atualizados constantemente.  

O grande desafio em problemas envolvendo ajuste de histórico está relacionado à redução 

do número de simulações necessárias para alcançar ajustes satisfatórios de acordo com o objetivo 

proposto. Entre as diversas técnicas que podem ser encontradas na literatura para tal propósito, 

uma que chama atenção é a aplicação de metamodelos gerados através de Redes Neurais 

Artificiais. Os metamodelos, uma vez gerados, são capazes de fornecer os resultados muito mais 

rápido que o simulador, pois se tratam de modelos simplificados. As RNA, por sua vez, são 

estruturas capazes de captar com eficiência as não linearidades entre entradas e saídas de um 

dado problema. Assim, os metamodelos gerados por RNA possuem características que os tornam



 

 

xiii 

 

promissores para serem utilizados como substitutos do simulador em etapas do ajuste que 

demandam maior esforço computacional.  

Deste modo, nesse trabalho foi avaliada a aplicação de metamodelos gerados por RNA no 

processo de ajuste de histórico, principalmente no que se refere à influência que a qualidade do 

conjunto de entrada exerce sobre o desempenho do metamodelo gerado e com relação à 

confiabilidade da utilização do metamodelo como substituto do simulador para casos práticos, 

com características mais próximas da realidade. Os resultados mostraram que a ferramenta, 

apesar dos erros envolvidos, por se tratar de um modelo simplificado, pode ser utilizada como 

ferramenta auxiliar ao simulador de escoamento no processo de ajuste de histórico. Não é 

recomendada a sua utilização como substituta do simulador no processo inteiro, porém, pode 

contribuir em etapas do processo que não requerem grande precisão dos resultados. Para a 

confiabilidade dos resultados, é necessário validar a resposta (encontrada por meio do 

metamodelo) usando o simulador de reservatórios. 

 

 Palavras-Chave 

Ajuste de histórico, inteligência artificial, redes neurais artificiais, simulação numérica de 

reservatórios, algoritmo genético, técnicas de amostragem, otimização.

 

 

 



 

 

xv 

 

ABSTRACT 

COSTA, Luís Augusto Nagasaki. Application of Artificial Neural Networks in the History 

Matching Process. Campinas: Faculdade de Engenharia Mecânica, Universidade Estadual de 

Campinas, 2012. 145 p. Dissertação de Mestrado. 

 

The history matching process is one of the most important stages involving studies of 

reservoirs, because with the adjusted reservoir model, the production forecasts can be done with 

higher reliability and different production strategies can be evaluated to obtain greater final 

recovery associated with less costs. However, this process have several problems associated, one 

being the multiple solution, meaning that different models provide satisfactory results, depending 

on the objective of the study. Furthermore, the reservoir in study can have different 

heterogeneities and nonlinearities between reservoir attributes and values of production and 

pressure, which also contributes to increase the complexity. Various published work showed that 

each case has different characteristics, so that a methodology that was applied successfully in one 

case, may not be efficient in another and vice-versa. Thus, studies in this area should be 

developed and updated constantly. 

The great challenge in problems involving history matching is related to reducing the 

number of simulations required to achieve satisfactory adjustments in accordance with the 

proposed objective. Among several procedures for this purpose, the application of proxy models 

generated through artificial neural networks (ANN) can be cited. The proxy models, once 

generated, are able to calculate the results much faster than the simulator due to the fact that they 

are simplified models. The ANN are structures capable of efficiently capture nonlinearities 

between inputs and outputs of a given problem. Thus, these proxy models have characteristics 

that make them promising for use as substitute of simulator in stages that require greater 

computational effort. 

Thereby, in this work the application of proxy models generated through ANN in the 

history matching process was evaluated, primarily regarding to the influence of the input quality 

in the proxy performance and the reliability of the use of proxy models as substitutes of the



 

 

xvii 

 

simulator in a realistic reservoir model. The results showed that the tool, despite the errors 

involved, because it is simplified model, can be used as auxiliary tool to the flow simulator in the 

process of history matching. It is not recommended to use as a substitute in the whole process, 

however, can contribute in the process stages that do not require great precision. For reliable 

results, it is necessary to validate the response (found through the proxy) using the reservoir 

simulator. 

 

 Key Words 

History matching, artificial intelligence, artificial neural networks, reservoir numeric 

simulation, genetic algorithm, sampling techniques, optimization. 



 

 

xix 

 

SUMÁRIO 

 

1 INTRODUÇÃO ............................................................................................................ 1 

1.1 Motivação .............................................................................................................. 5 

1.2 Objetivos ................................................................................................................ 5 

1.3 Organização da Dissertação ................................................................................... 6 

2 CONCEITOS E FUNDAMENTAÇÃO TEÓRICA ..................................................... 9 

2.1 Ajuste de histórico de produção ............................................................................. 9 

2.1.1 Etapas do ajuste ............................................................................................. 11 

2.1.2 Complexidade do ajuste ................................................................................ 12 

2.1.3 Tipos de ajuste: manual, automático e assistido ............................................ 14 

2.1.4 Qualidade do ajuste ....................................................................................... 15 

2.1.5 Otimização dos valores dos atributos do reservatório ................................... 17 

2.1.6 Utilização de metamodelos gerados por redes neurais artificiais no processo 

de ajuste de histórico ............................................................................................................. 18 

2.2 Redes neurais artificiais ....................................................................................... 18 

2.2.1 Redes neurais biológicas ............................................................................... 19 

2.2.2 Neurônio artificial.......................................................................................... 20 

2.2.3 Função de transferência (de ativação) ........................................................... 21 

2.2.4 Arquitetura ..................................................................................................... 21 

2.2.5 Escolha da arquitetura da rede ....................................................................... 23 

2.2.6 Treinamento de redes neurais artificiais ........................................................ 24 

2.2.6.1 Algoritmo de retro propagação (backpropagation) ................................... 25



 

 

xxi 

 

2.2.6.2 Variações do algoritmo de Retro propagação ........................................... 26 

2.2.6.3 Capacidade de generalização de uma rede neural artificial....................... 26 

2.3 Algoritmo genético .............................................................................................. 27 

2.4 Técnicas de amostragem ...................................................................................... 31 

2.4.1 Box Behnken ................................................................................................. 32 

2.4.2 Hipercubo Latino ........................................................................................... 35 

2.4.3 Sequência de Sobol ........................................................................................ 36 

2.5 Comentário sobre as técnicas de amostragem ..................................................... 37 

3 REVISÃO BIBLIOGRÁFICA .................................................................................... 39 

3.1 Ajuste de histórico ............................................................................................... 39 

3.2 Aplicação de redes neurais artificiais e metamodelos ......................................... 41 

3.3 Metamodelos gerados por redes neurais artificiais no processo de ajuste de 

histórico  ............................................................................................................................. 42 

4 METODOLOGIA ....................................................................................................... 47 

4.1 Metodologia geral do trabalho ............................................................................. 47 

4.2 Metodologia específica - procedimento de ajuste ................................................ 49 

4.2.1 Treinamento das redes neurais artificiais ...................................................... 50 

4.2.2 Aplicação de metamodelos no processo de ajuste de histórico ..................... 51 

5 APLICAÇÃO .............................................................................................................. 53 

5.1 Casos analíticos .................................................................................................... 53 

5.1.1 Premissas e considerações ............................................................................. 53 

5.1.2 Caso 1A ......................................................................................................... 54 

5.1.3 Caso 1B ......................................................................................................... 55 

5.1.4 Caso 1C ......................................................................................................... 56



 

 

xxiii 

 

5.1.5 Caso 1D ......................................................................................................... 56 

5.2 Casos de reservatório ........................................................................................... 57 

5.2.1 Premissas e considerações ............................................................................. 57 

5.2.2 Reservatório utilizado .................................................................................... 58 

5.2.3 Caso 2A ......................................................................................................... 59 

5.2.4 Caso 2B ......................................................................................................... 59 

5.3 Geração dos conjuntos de entrada para treinamento............................................ 60 

5.4 Treinamento das redes neurais artificias .............................................................. 65 

5.5 Otimização ........................................................................................................... 66 

6 RESULTADOS E DISCUSSÃO ................................................................................ 69 

6.1 Caso 1A ................................................................................................................ 69 

6.1.1 Passo 1: Definição do conjunto de treinamento ............................................ 69 

6.1.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho 

dos metamodelos gerados ...................................................................................................... 70 

6.1.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo 

encontrado  ....................................................................................................................... 72 

6.2 Caso 1B ................................................................................................................ 73 

6.2.1 Passo 1: Definição do conjunto de treinamento ............................................ 73 

6.2.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho 

dos metamodelos gerados ...................................................................................................... 75 

6.2.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo 

encontrado  ....................................................................................................................... 78 

6.2.4 Passo 4: Retreinamento ................................................................................. 78 

6.3 Caso 1C ................................................................................................................ 81



 

 

xxv 

 

6.3.1 Passo 1: Definição do conjunto de treinamento ............................................ 81 

6.3.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho 

dos metamodelos gerados ...................................................................................................... 83 

6.3.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo 

encontrado  ....................................................................................................................... 87 

6.4 Caso 1D ................................................................................................................ 90 

6.4.1 Passo 1: Definição do conjunto de treinamento ............................................ 90 

6.4.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho 

dos metamodelos gerados ...................................................................................................... 91 

6.4.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo 

encontrado  ....................................................................................................................... 94 

6.5 Comentários dos casos analíticos ........................................................................ 96 

6.6 Caso 2A ................................................................................................................ 99 

6.6.1 Passo 1: Definição do conjunto de treinamento ............................................ 99 

6.6.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho 

dos metamodelos gerados .................................................................................................... 102 

6.6.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo 

encontrado  ..................................................................................................................... 104 

6.6.4 Passo 4: Retreinamento ............................................................................... 106 

6.7 Caso 2B .............................................................................................................. 110 

6.7.1 Análise de sensibilidade .............................................................................. 110 

6.7.2 Passo 1: Definição do conjunto de treinamento .......................................... 112 

6.7.3 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho 

dos metamodelos gerados .................................................................................................... 114



 

 

xxvii 

 

6.7.4 Passo 3: Otimização utilizando o metamodelo e validação do mínimo 

encontrado  ..................................................................................................................... 119 

6.7.5 Passo 4: Retreinamento ............................................................................... 123 

6.8 Comentários gerais dos casos de reservatório. .................................................. 127 

7 CONCLUSÕES E SUGESTÕES PARA TRABALHOS FUTUROS ...................... 131 

REFERÊNCIAS BIBLIOGRÁFICAS ............................................................................... 137 

APÊNDICE ........................................................................................................................ 143 

I. Capacidade de extrapolação da rede neural artificial – Caso 2A....................... 143 

II. Melhor configuração de rede neural artificial obtida – Caso 2B ....................... 144



 

 

xxix 

 

LISTA DE FIGURAS 

Figura 2.1 – Fluxograma básico a ser seguido para realização do ajuste de histórico. 

(ERTEKIN et al., 2001, p.351). .................................................................................................... 11 

Figura 2.2 – Exemplo da não unicidade (múltiplas soluções) no problema de ajuste. ........ 14 

Figura 2.3 – Comparação do corte de água simulado com o histórico (Modificação de 

ERTEKIN et al., 2001, p.357). ...................................................................................................... 16 

Figura 2.4 – Esquema simplificado de um neurônio biológico. .......................................... 19 

Figura 2.5 – Esquema básico de neurônio artificial (HAGAN et al., 1996, p.2-3). ............ 20 

Figura 2.6 – Função de transferência do tipo linear (a) e tangente hiperbólica (b). ............ 21 

Figura 2.7 – Ilustração de uma rede neural de 3 camadas (HAGAN et al., 1996, p.2-11). . 22 

Figura 2.8 – Rede multicamadas na forma abreviada (HAGAN et al., 1996, p.2-12)......... 23 

Figura 2.9 – Fluxograma básico do algoritmo de RP........................................................... 25 

Figura 2.10 – Estrutura básica de um AGC. ........................................................................ 28 

Figura 2.11 – Exemplo de um indivíduo formado por um vetor de bits (a), ilustração dos 

processos de recombinação (b) e mutação (c). .............................................................................. 29 

Figura 2.12 – Ilustração do algoritmo de Roleta Russa. ...................................................... 29 

Figura 2.13 – Método de BB na forma gráfica para 3 fatores, discretizados em 3 níveis 

(FERREIRA et al., 2007, p.183). .................................................................................................. 34 

Figura 2.14 – Exemplo de discretização de uma distribuição normal em 7 intervalos. 

(MASCHIO et al., 2009, p.3) ........................................................................................................ 35 

Figura 2.15 - Figura ilustrativa da amostragem por HL, para distribuição normal (a) e 

uniforme (b). .................................................................................................................................. 36 

Figura 2.16 – Exemplo de amostragem pela Sequência de Sobol. ...................................... 37 

Figura 3.1 – Exemplo do indicador de qualidade de ajuste com relação ao Caso Base. ..... 44



 

 

xxxi 

 

Figura 4.1 - Fluxograma descrevendo as etapas utilizadas para realização da metodologia 

geral do trabalho. ........................................................................................................................... 47 

Figura 4.2 – Fluxograma que descreve os passos seguidos pelo procedimento de ajuste 

adotado nesse trabalho. .................................................................................................................. 49 

Figura 5.1 – Superfície de resposta para o Caso 1A. ........................................................... 54 

Figura 5.2 – Superfície de resposta para o Caso 1B. ........................................................... 55 

Figura 5.3 – Superfície de resposta para o Caso 1C. ........................................................... 56 

Figura 5.4 – Superfície de resposta para o Caso 1D. ........................................................... 57 

Figura 5.5 - Modelo de reservatório (permeabilidade horizontal – md). ............................. 58 

Figura 6.1 – Amostragem no espaço do conjunto de treinamento de 25 pontos; HL (a) e SS 

(b) – Caso 1A. ................................................................................................................................ 70 

Figura 6.2 – Superfícies de resposta e conjunto de teste, para os metamodelos gerados com 

HL25 (a) e HL50 (b) – Caso 1A. Pontos em azul: erro médio menor que 1% e pontos em 

vermelho: erro médio maior ou igual a 1%. .................................................................................. 71 

Figura 6.3 – Visualização dos erros ponto a ponto para os metamodelos gerados com HL25 

(a) e HL50 (b) pontos – Caso 1A. ................................................................................................. 72 

Figura 6.4 – Amostras de 25 pontos, do HL (a) e da SS (b)  para treinamento – Caso 1B. 74 

Figura 6.5 - Amostras de 50 pontos, do HL (a) e da SS (b) para treinamento – Caso 1B. .. 74 

Figura 6.6 – Superfícies de resposta dos metamodelos gerados com 25 pontos do HL (a) e 

da SS (b) – Caso 1B. ...................................................................................................................... 75 

Figura 6.7 - Superfícies de resposta dos metamodelos gerados com HL25 (a), HL50 (b), 

HL100 (c) pontos e da função analítica (d) – Caso 1B. ................................................................ 77 

Figura 6.8 – Conjunto de treinamento e novos limites (a) e superfície de resposta do 

metamodelo gerado (b), relativos ao retreinamento – Caso 1B. ................................................... 79 

Figura 6.9 - Conjunto de treinamento para HL25 (a) e SS25 (b) - Caso 1C. ....................... 81



 

 

xxxiii 

 

Figura 6.10 – Conjunto de treinamento para HL50 (a) e SS50 (b) - Caso 1C. .................... 82 

Figura 6.11 - Superfícies de resposta dos metamodelos gerados com HL25 (a) e SS25 (b) 

pontos  -  Caso 1C. ........................................................................................................................ 83 

Figura 6.12 - Superfícies de resposta dos metamodelos gerados com HL50 (a) e SS50 (b) 

pontos  -  Caso 1C. ........................................................................................................................ 84 

Figura 6.13 - Superfícies de resposta dos metamodelos gerados com HL100 (a) e SS100 (b) 

pontos  -  Caso 1C. ........................................................................................................................ 85 

Figura 6.14 - Superfícies de resposta dos metamodelos gerados com HL25 (a), HL50 (b), 

HL100 (c) pontos e da função analítica (d) – Caso 1C. ................................................................ 86 

Figura 6.15 - Mínimos globais, representados pelos pontos em azul (a); e critério de 

vizinhança adotado para identificação de mínimos de interesse (b) – Caso 1C. ........................... 88 

Figura 6.16 – Conjunto de treinamento para HL25 (a) e SS25 (b) pontos – Caso 1D. ....... 91 

Figura 6.17 - Superfícies de resposta dos metamodelos gerados com HL25 (a) e SS25 (b) 

pontos  -  Caso 1D ......................................................................................................................... 92 

Figura 6.18 - Superfícies de resposta dos metamodelos gerados com HL25 (a), HL50 (b), 

HL100 (c) pontos e da função analítica (d) – Caso 1D. ................................................................ 93 

Figura 6.19 – Conjunto de treinamento de HL100 (a) e SS100 (b) pontos – Caso 1D........ 95 

Figura 6.20 – Pontos de treinamento, relativos aos atributos porosidade da fácies 2 e 

transmissibilidade da falha 3 para os conjuntos HL25 (a) e HL50 (b) pontos - Caso 2A. .......... 100 

Figura 6.21 – Histograma dos valores de saída para os conjuntos de treinamento HL25 e 

HL50 pontos – Caso 2A. ............................................................................................................. 102 

Figura 6.22 – Gráfico de dispersão (crossplot) entre saída do simulador e saída do 

metamodelo, gerado com HL25 (a), HL50 (b) e HL100 (c) – Caso 2A; pontos em azul: pontos de 

treinamento e pontos em vermelho: pontos de teste. ................................................................... 103 

Figura 6.23 – Curva de produção de água do campo do Caso base, histórico e metamodelos 

gerados com HL25, HL50 e HL100 pontos – Caso 2A............................................................... 105



 

 

xxxv 

 

Figura 6.24 - Curva de produção de água do campo do Caso base, histórico e metamodelos 

gerados com HL50, HL100 pontos e HL50 após retreinamento – Caso 2A. .............................. 108 

Figura 6.25 – Análise de sensibilidade para o afastamento da produção de água do poço 

PROD4 (a) e média aritmética (b) – Caso 2B. ............................................................................ 110 

Figura 6.26 – Gráfico de dispersão dos pontos de treinamento entre os atributos Kz2 e Kr2, 

relativo aos conjuntos HL100 (a) e HL250 (b) pontos – Caso 2B. ............................................. 112 

Figura 6.27 - Gráficos de dispersão dos pontos de treinamento entre os atributos Kz2 e Kr2, 

referente aos conjuntos HL396 (a) e BB396 (b) – Caso 2B. ....................................................... 113 

Figura 6.28 - Gráficos de dispersão (crossplot) para o poço PROD2 – PROD_AS – Caso 

2B. ............................................................................................................................................... 116 

Figura 6.29 - Gráficos de dispersão (crossplot) para o poço PROD3 – PROD_AS – Caso 

2B. ............................................................................................................................................... 117 

Figura 6.30 – Coeficiente de correlação linear em gráfico de barras; grupo de barras da 

esquerda: resultados do treinamento; grupo de barras da direita: resultados do teste – Caso 2B.

 ..................................................................................................................................................... 118 

Figura 6.31 – Simulação dos mínimos encontrados com a otimização utilizando os  

metamodelos para os poços PROD1 (a), PROD2 (b), PROD3 (c) e PROD4 (d) – PROD_AS – 

Caso 2B. ...................................................................................................................................... 121 

Figura 6.32 - Simulação dos mínimos encontrados com a otimização utilizando os 

metamodelos para os poços PROD5 (a), PROD6 (b), PROD7 (c) e PROD8 (d) – PROD_AS – 

Caso 2B. ...................................................................................................................................... 122 

Figura 6.33 – Simulação dos mínimos encontrados com a otimização utilizando os 

metamodelos para os poços PROD1 (a), PROD2 (b), PROD3 (b) e PROD4 (b) – retreinamento – 

Caso 2B. ...................................................................................................................................... 125 

Figura 6.34 – Simulação dos mínimos encontrados com a otimização utilizando os 

metamodelos para os poços PROD5 (a), PROD6 (b), PROD7 (b) e PROD8 (b) – retreinamento – 

Caso 2B. ...................................................................................................................................... 126



 

 

xxxvii 

 

LISTA DE TABELAS 

Tabela 2.1 – Método de BB na forma matricial para 3 fatores, discretizados em 3 níveis. . 33 

Tabela 5.1 – Atributos incertos para o caso 2A. .................................................................. 59 

Tabela 5.2 – Atributos incertos para Caso 2B. .................................................................... 60 

Tabela 5.3 – Atributos que mais influenciam os poços. ...................................................... 62 

Tabela 5.4 – Principais parâmetros utilizados pelo AG. ...................................................... 67 

Tabela 6.1 – Coeficientes de correlação linear, erro médio e mínimos determinados através 

da otimização utilizando os metamodelos - Caso 1A. ................................................................... 73 

Tabela 6.2 – Coeficientes de correlação linear, erro médio e mínimos determinados através 

da otimização utilizando os metamodelos - Caso 1B. ................................................................... 78 

Tabela 6.3 – Definição dos novos limites para retreinamento – Caso 1B. .......................... 79 

Tabela 6.4 - Resultados obtidos com o retreinamento – Caso 1B. ...................................... 80 

Tabela 6.5 - Coeficientes de correlação linear, erro médio e mínimos determinados através 

da otimização utilizando os metamodelos - Caso 1C. ................................................................... 87 

Tabela 6.6 - Mínimos de interesse - Caso 1C. ..................................................................... 89 

Tabela 6.7 - Coeficientes de correlação linear, erro médio e mínimos determinados através 

da otimização utilizando os metamodelos - Caso 1D. ................................................................... 94 

Tabela 6.8 – Frequência de ocorrência dos valores de saída para os conjuntos de 

treinamento, HL25, HL50 e HL100 pontos – Caso 2A. .............................................................. 101 

Tabela 6.9 – Correlação linear entre saída do simulador e do metamodelo (afastamento da 

produção de água, do modelo de simulação com relação ao histórico), relativos aos conjuntos de 

treino e teste – Caso 2A. .............................................................................................................. 104 

Tabela 6.10 – Afastamento obtido com o mínimo encontrado na otimização, quando 

simulado com o metamodelo e com o simulador – Caso 2A. ..................................................... 104



 

 

xxxix 

 

Tabela 6.11 – Definição dos atributos para novo treinamento – Caso 2A. ........................ 107 

Tabela 6.12 – Coeficientes de correlação linear do retreinamento; mínimo obtido com a 

otimização e simulação do mínimo com o simulador – Caso 2A. .............................................. 107 

Tabela 6.13 - Relação da distância relativa dos atributos de treinamento com o histórico – 

Caso 2A ....................................................................................................................................... 109 

Tabela 6.14 – Análise de sensibilidade do poço PROD4 e da média dos oito poços. ....... 111 

Tabela 6.15 – Coeficientes de correlação linear dos metamodelos gerados – PROD_AS – 

Caso 2B. ...................................................................................................................................... 115 

Tabela 6.16 – Valores de afastamento e indicador de qualidade (%), obtidos com a 

simulação do mínimo (x10
6
) – PROD_AS – Caso 2B. ............................................................... 120 

Tabela 6.17 - Coeficientes de correlação linear – PROD_AS – Caso 2B – retreinamento.

 ..................................................................................................................................................... 123 

Tabela 6.18 – Valores de afastamento gerados com a simulação dos mínimos obtidos com a 

otimização – PROD_AS – Retreinamento – Caso 2B. ................................................................ 124 



 

 

xli 

 

LISTA DE NOMENCLATURAS 

Abreviações 

AG – Algoritmo Genético 

AGC – Algoritmo Genético Clássico 

BB - Box Behnken 

FO – Função Objetivo 

HL – Hipercubo Latino 

LMS - Least Mean Square 

LM - Levenberg-Marquardt 

RNA – Redes Neurais Artificiais 

RP – Retro propagação 

SS – Sequência de Sobol 

 

 

 

 

 

 

 

 



 

 

1 

 

1 INTRODUÇÃO 

A simulação numérica de reservatórios é amplamente utilizada por profissionais ligados à 

área de gerenciamento de reservatórios, uma vez que permite realizar estudos sobre reservatórios 

complexos (com falhas, fraturas, geometrias complexas, heterogeneidades etc.) e aplicação de 

diferentes estratégias de produção (injeção de água, vapor, polímeros etc.), sendo fundamental no 

apoio à tomada de decisões. O objetivo principal do estudo de reservatórios é a previsão de 

comportamentos futuros, o que possibilita a realização de testes de diferentes estratégias de 

produção de modo a se obter o melhor desempenho possível do reservatório considerando 

aspectos econômicos e técnicos. 

O modelo de simulação é construído a partir da caracterização geológica e de fluidos, 

realizando simplificações até que sua utilização com o simulador seja viável. Nessa etapa 

diversas informações do reservatório são perdidas. Além disso, são muitas as incertezas acerca 

dos parâmetros. Os procedimentos de obtenção dos dados do reservatório demandam custos 

elevados e são poucas as informações diretas obtidas (dados de poços), sendo a maioria estimada, 

correlacionada, ou não obtida.  

Portanto, o modelo de simulação obtido nessa fase necessita de uma calibração para que 

represente de forma confiável o comportamento observado no reservatório real e possa ser 

utilizado para previsão de produção. Esse processo de calibração do modelo é chamado de ajuste 

de histórico. 

O objetivo do ajuste de histórico é minimizar uma função objetivo (FO) que representa a 

qualidade do ajuste mediante cálculo da diferença entre dados observados no campo real e dados 

obtidos através do modelo de simulação.  O procedimento consiste basicamente na variação dos 

valores dos atributos incertos do reservatório (permeabilidades, porosidade, transmissibilidade 

etc.) iterativamente, até que um valor de FO aceitável seja alcançado.   

A importância desse processo reside no fato de que o modelo, uma vez ajustado, tem mais 

confiabilidade para ser utilizado na previsão de produção do reservatório. Porém, a obtenção de 



 

 

2 

 

um modelo aceitável não é uma tarefa fácil, devido a algumas características que o problema de 

ajuste de histórico possui, listadas abaixo: 

? É do tipo inverso: a resposta (dados de produção) é conhecida, mas as variáveis de 

entrada (propriedades do reservatório) são desconhecidas; 

? É, em geral, não linear: a resposta pode variar de forma não linear com as variáveis 

de entrada; 

? Pode ocorrer inconsistência nos dados: devido a alguns métodos de medição serem 

realizados de forma indireta. Por exemplo, esquema de rateio para medição da 

produção dos poços de petróleo; 

? Pode ocorrer insuficiência nos dados: principalmente para casos com pouco 

histórico de produção, em que os dados não são suficientes para calibrar o modelo; 

? Pode envolver inúmeros parâmetros: quanto maior o número de parâmetros 

envolvidos maior é a complexidade do problema. Tipicamente estes parâmetros são 

a porosidade, a permeabilidade (horizontal, vertical ou relativa), a 

transmissibilidade de falhas, saturações iniciais etc. Se o reservatório for 

heterogêneo pode possuir várias fácies
1
, o que também contribui para o aumento do 

número de parâmetros. 

? Pode assumir múltiplas soluções: diferentes combinações de parâmetros podem 

resultar em ajustes aceitáveis. 

Desse modo, o processo torna-se complexo e, dependendo do caso, o tempo demandado 

para realizar o ajuste pode ser grande. Na maioria dos casos tal processo é realizado de forma 

manual, pelo procedimento de tentativa e erro. Porém, com o aumento do número de parâmetros 

esse tipo de ajuste torna-se ineficaz, uma vez que a probabilidade de ocorrência de erros e a 

limitação da busca no espaço de soluções também aumentam. A vantagem é que a experiência do 

profissional pode levar a soluções de forma mais eficiente. Nesse contexto, foi desenvolvido o 

ajuste automático, que consiste na utilização de algoritmos para realizar todo o processo de 

ajuste. Porém, esse tipo de ajuste também se mostrou ineficiente, uma vez que, diversas 

                                                 
1
 Característica de um tipo de rocha que reflete sua origem e a diferencia de outros tipos ao seu redor. O termo fácies 

(em inglês, facies) é utilizado tanto para o singular quanto para o plural.  

Fonte: http://www.glossary.oilfield.slb.com/search.cfm, acesso em 01/06/2012, às 22h21min. 

 

http://www.glossary.oilfield.slb.com/search.cfm


 

 

3 

 

particularidades existem para cada tipo de problema e a definição de um algoritmo capaz de 

realizar ajustes de forma independente torna-se complicado. Para aproveitar a grande capacidade 

de processamento dos algoritmos automáticos e, ao mesmo tempo, utilizar a experiência de um 

profissional para guiar o processo, surgiu o ajuste de histórico assistido. Com isso, partes do 

processo, que exigem grande esforço computacional, passam a ser automatizadas e a presença de 

um profissional especializado ajuda na escolha de algoritmos e metodologias. 

A parte do processo que demanda maior esforço computacional é a etapa em que se realiza 

a varredura do espaço de soluções (etapa de otimização), necessitando normalmente de um 

grande número de simulações. Nessa área, a utilização de metamodelos (proxies) surge como 

opção interessante, uma vez que o metamodelo gerado pode ser utilizado no lugar do simulador 

em partes do processo, possibilitando a redução do número de simulações necessárias para 

alcançar ajustes aceitáveis. O metamodelo consiste, basicamente, em um modelo definido 

segundo funções matemáticas ou estatísticas que representam um dado padrão de saída para um 

dado padrão de entrada. 

Existem diversas técnicas disponíveis para geração de metamodelos. Segundo Zubarev 

(2009), o modelo de regressão polinomial obtido por planejamento estatístico é bastante utilizado 

na indústria de petróleo devido a sua fácil compreensão, flexibilidade e eficiência computacional. 

Outra ferramenta que pode ser utilizada para geração de metamodelos é a Rede Neural Artificial 

(RNA), utilizada em diversas áreas e bastante difundida em análise de risco na área de petróleo. 

Segundo Maschio et al. (2008), as RNA são estruturas capazes de captar, de forma eficiente, as 

não linearidades em problemas tipicamente encontrados nos processos envolvendo simulação de 

reservatórios, o que constitui a maior motivação para utilização dessa técnica para o problema de 

ajuste de histórico.  

Para geração de metamodelos utilizando RNA faz-se necessário treinar a rede para que ela 

seja capaz de reproduzir o comportamento do problema desejado. Para tanto, existem fatores 

importantes que devem ser considerados no processo de treinamento. A definição do conjunto de 

treinamento em específico é fundamental, pois a rede aprende através de exemplos e, por conta 

disso, não é capaz de representar com confiabilidade regiões do espaço de soluções para a qual 

não foi treinada. 



 

 

4 

 

Um fator importante na aplicação de metamodelos gerados por RNA no processo de ajuste 

de histórico, é que o procedimento de amostragem deve ser realizado utilizando o menor número 

possível de simulações. Esse aspecto ganha maior importância com o aumento da complexidade 

do problema (aumento do número de variáveis), uma vez que o número de simulações 

necessárias para amostragem de todas as combinações possíveis dos parâmetros cresce 

exponencialmente e se torna inviável. Assim, para definição do conjunto de treinamento deve-se 

atentar primeiramente à distribuição eficaz das amostras de forma a cobrir todo o espaço de busca 

dos parâmetros e, em segundo lugar, o espaço deve ser coberto com eficiência, ou seja, uma 

região deve conter uma quantidade suficiente de amostras (exemplos), de forma que a rede possa 

aprender o padrão de comportamento da superfície de resposta da região. 

Uma técnica bastante utilizada para este propósito é o planejamento estatístico, que 

segundo Risso et al. (2006) é o método mais adequado a ser aplicado para reduzir o número de 

simulações de reservatório e vem se mostrando uma boa técnica auxiliar em processos de 

desenvolvimento e gerenciamento de campos de petróleo, sendo sua principal aplicação voltada à 

geração de metamodelos.  

A fim de analisar a influência dos pontos de treinamento no aprendizado da RNA, foram 

abordadas três técnicas com diferentes características para geração dos conjuntos de treinamento, 

sendo uma delas o planejamento Box Behnken (BB). Além dele foi utilizado o Hipercubo Latino 

(HL), que é um método estatístico para gerar distribuições de parâmetros de forma a honrar as 

características da distribuição original, e a Sequência de Sobol (SS), que consiste em uma 

sequência de baixa discrepância, construída com intuito de obter melhor distribuição dos 

parâmetros no espaço.  Uma introdução básica a respeito das técnicas será apresentada no tópico 

de fundamentação teórica. 

    Uma vez treinada a RNA (chamada então de metamodelo), ela estará pronta para ser 

utilizada no processo de otimização. A ferramenta aplicada para realizar a otimização foi o 

Algoritmo Genético (AG), amplamente utilizado para determinação de mínimos globais, por ser 

eficiente na realização da varredura do espaço de busca dos parâmetros. Uma introdução básica 

sobre seus conceitos também será abordada no capítulo da fundamentação teórica. 



 

 

5 

 

Estudos já mostraram que metamodelos gerados por RNA podem ser utilizados como 

substitutos do simulador em casos mais simples de reservatório, porém, ainda não existem muitos 

estudos para casos mais complexos. Assim, o presente trabalho visa avaliar o desempenho dos 

metamodelos gerados por RNA no processo de ajuste de histórico, buscando analisar a influência 

dos dados de entrada na qualidade do modelo final e, desse modo, o potencial de aplicação da 

metodologia para casos com características reais.  

1.1 Motivação 

Para casos simples, as RNA são capazes de representar o problema proposto sem maiores 

dificuldades. Contudo, à medida que a complexidade do problema aumenta os erros envolvidos 

no processo de treinamento da rede também tendem a aumentar e critérios mais robustos para 

definição de confiabilidade para utilização da ferramenta tornam-se necessários. Caso contrário, o 

problema será mal representado e resultados equivocados podem ser gerados. Assim sendo, a 

avaliação da ferramenta faz-se necessária. 

Há diversas aplicações de RNA na indústria de petróleo, em particular na área de análise de 

risco, e poucas aplicações na área de ajuste de histórico. Porém, devido à semelhança no modo de 

aplicação da ferramenta entre as duas áreas, acredita-se que esta possui características 

importantes que a tornam promissoras para serem utilizadas na área de ajuste de histórico.  

Em adição aos fatores citados acima, a principal motivação para realização desse trabalho 

surgiu do trabalho de Maschio et al. (2008), que realizaram estudos para aplicação da técnica em 

casos de reservatórios sintéticos e ressaltaram a necessidade de aprimoramento do processo de 

treinamento de redes neurais e geração dos metamodelos. 

1.2 Objetivos 

O objetivo principal desse trabalho consiste em avaliar o potencial de aplicação de 

metamodelos gerados a partir de RNA no problema de ajuste de histórico em casos práticos. 

Através de casos analíticos de duas variáveis aos quais possibilitam uma análise visual, são 

avaliadas as características e limitações da ferramenta e, posteriormente, através de um caso 



 

 

6 

 

sintético de reservatório com características reais, o real potencial de aplicação da ferramenta em 

casos complexos será avaliado.  

Os objetivos específicos são: 

1) Avaliar a influência do conjunto de treinamento, variando o tipo de amostragem e o 

número de pontos amostrados, no desempenho dos metamodelos gerados. 

2) Avaliar formas de utilização do metamodelo em conjunto com o simulador no processo 

de ajuste de histórico para identificar de que maneira pode-se aplicar a ferramenta para 

melhorar a eficiência do processo. 

Para realizar o processo de ajuste de histórico e testar diferentes tipos de dados de entrada, 

foi necessário recorrer a diferentes técnicas de amostragem para gerar os conjuntos de entrada, e 

de uma ferramenta de otimização, para realizar a busca no espaço de soluções, sendo essas etapas 

necessárias para alcançar o objetivo final (são complementares ao estudo). Portanto, realizar um 

estudo aprofundado a respeito dessas técnicas não faz parte dos objetivos. 

1.3 Organização da Dissertação 

Esse trabalho foi estruturado em sete capítulos. No capítulo um fez-se uma breve 

introdução ao tema escolhido. 

No capítulo dois é realizada a fundamentação teórica, em que são mostrados os conceitos 

básicos necessários ao entendimento da aplicação das ferramentas utilizadas nesse trabalho. São 

abordados os temas de ajuste de histórico, redes neurais artificiais, algoritmo genético e técnicas 

de amostragem. 

No capítulo três é realizada uma breve revisão bibliográfica, expondo os principais 

trabalhos que serviram de base para montar a metodologia e aplicar a ferramenta. São abordados 

principalmente trabalhos relacionados aos temas de ajuste de histórico e redes neurais artificiais. 

O capítulo quatro consiste na modelagem da metodologia. O presente trabalho foi realizado 

em duas etapas, primeiro seguindo uma metodologia geral, modelada com o intuito de deixar 

claro os objetivos do estudo e escolher os casos de acordo com esses objetivos, e posteriormente, 

seguindo uma metodologia específica descrevendo o procedimento de ajuste adotado. 



 

 

7 

 

O capítulo cinco mostra os casos de estudo escolhidos para buscar alcançar os objetivos 

propostos. 

Os resultados da aplicação do procedimento de ajuste adotado aos casos escolhidos são 

mostrados no capítulo seis. Nesse capítulo observações e discussões acerca dos resultados são 

realizadas. 

Para finalizar, no capítulo sete são listadas as conclusões que se pôde chegar com os 

experimentos e sugestões futuras para melhorar os resultados e análises. 





 

 

9 

 

2 CONCEITOS E FUNDAMENTAÇÃO TEÓRICA 

O foco principal desse trabalho é estudar o desempenho de metamodelos gerados por redes 

neurais artificiais (RNA) no processo de ajuste de histórico, sendo que as técnicas de amostragem 

e otimização aparecem como ferramentas auxiliares, utilizadas para viabilizar a aplicação da 

metodologia e, portanto, complementares aos estudos realizados nesse trabalho. Logo, dar-se-á 

maior enfoque na fundamentação dos temas de ajuste de histórico e RNA e, a respeito das 

técnicas de amostragem e otimização, será feita apenas uma breve contextualização. 

2.1 Ajuste de histórico de produção 

Uma das áreas de maior importância na indústria de petróleo é a de estudo de reservatórios, 

pois influencia diretamente na definição de estratégias de produção e no planejamento 

econômico. Segundo Aziz e Settari (1979), o objetivo principal de um estudo de reservatórios é a 

previsão do comportamento futuro e a determinação de meios para aumentar a recuperação final. 

Grande parte do planejamento envolvido nessa fase de estudos é realizada segundo resultados 

obtidos através da simulação numérica, procedimento que permite realizar previsões e estudar 

diferentes estratégias, possibilitando encontrar o melhor custo benefício, que leva à maior 

recuperação final da jazida em estudo. Segundo Consentino (2001), a etapa mais importante, e 

que também demanda maior tempo dentro da simulação numérica de reservatórios, é a de ajuste 

de histórico. 

O modelo de simulação utilizado para estudos de reservatórios é construído a partir da 

caracterização geológica e de fluidos e são realizadas simplificações para possibilitar sua 

aplicação através do simulador de escoamento. Nessas etapas de simplificação, diversas 

informações são perdidas. Além disso, devido ao alto custo para obtê-las, alguns processos de 

medição acabam sendo realizados de forma indireta, gerando incertezas. Dessa maneira, o 

modelo de simulação obtido na fase de caracterização necessita de ajuste para que represente o 



 

 

10 

 

mais próximo possível o comportamento observado no reservatório real e possa ser utilizado para 

previsão de produção. Segundo Aziz e Settari (1979) mesmo com o modelo ajustado, a 

confiabilidade para previsão decresce com o tempo, sendo assim, interessante ‘atualizar’ o estudo 

de simulação realizado após certo período, efetuando novos ajustes dos parâmetros com dados 

adicionais de histórico. A esse processo de ajuste e validação do modelo de simulação aos dados 

históricos dá-se o nome de ajuste de histórico. 

Nesse processo, os atributos que descrevem o reservatório (permeabilidade, porosidade, 

transmissibilidade das falhas etc.) são modificados e os dados de produção e pressão são 

comparados com o histórico. Através de um processo iterativo, os valores desses atributos são 

alterados até que o valor de uma função objetivo (FO) aceitável seja obtido. Essa função, 

caracterizada pela diferença entre dados observados no campo real e dados obtidos através da 

simulação do modelo de simulação, geralmente possui a forma descrita na Equação 2.1 (Ertekin 

et al., 2001, p.350). 

  ?[   (             )
 
]

 

   

 Equação 2.1 

em que   representa o número total de amostras,    representa o peso atribuído,        representa 

o dado observado e        representa o dado simulado. A FO é calculada com base nos dados de 

produção e pressão. Porém, segundo Maschio (2006), outras informações podem ser adicionadas 

ao processo, como dados de sísmica (por exemplo, mapas de saturação e pressão) e dados 

provenientes de testes e de perfilagem de poços. 

Segundo Consentino (2001), o ajuste de histórico é um procedimento de validação de um 

modelo, em que o desempenho passado do reservatório é simulado e comparado com os dados 

observados. Quando diferenças são encontradas realizam-se modificações nos parâmetros de 

entrada. O objetivo final, portanto, é minimizar as diferenças nos dados dinâmicos reduzindo as 

incertezas dos dados estáticos. 

 



 

 

11 

 

2.1.1 Etapas do ajuste 

Em busca de um ajuste final aceitável, Ertekin et al. (2001) propôs um procedimento 

iterativo básico a ser seguido, ilustrado na Figura 2.1. 

 

Figura 2.1 – Fluxograma básico a ser seguido para realização do ajuste de histórico. (ERTEKIN 

et al., 2001, p.351). 

Segundo fluxograma da Figura 2.1, a primeira etapa para se realizar um ajuste é definir os 

objetivos do ajuste. Essa etapa é importante, pois influencia nas próximas. Por exemplo, se o 

objetivo for um estudo preliminar sabe-se que não é necessário obter grandes precisões nos 

resultados e é possível chegar a respostas mais rapidamente. 

A segunda etapa é dependente dos objetivos envolvidos no processo, recursos alocados pela 

companhia, prazos de entrega e disponibilidade dos dados.  

1. Definição dos objetivos do ajuste

2. Definição do método a ser utilizado

3. Determinação do dado de produção histórico a ser ajustado e 

definição de critérios que descrevam a qualidade do ajuste

6. Comparação dos resultados com os dados definidos na Etapa 3

7. Alteração dos dados do reservatório da Etapa 4 dentro dos 

limites

8. Continuar as Etapas 5 a 7 até que o critério estabelecido na 

Etapa 3 seja alcançado

5. Simulação do modelo com os melhores dados de entrada 

disponíveis

4. Definição das variáveis a serem ajustadas e seus limites de 

variação



 

 

12 

 

A terceira etapa depende da disponibilidade, da qualidade dos dados de produção e do 

objetivo do estudo da simulação.  

Na quarta etapa, os parâmetros escolhidos devem ser aqueles em que há maiores incertezas, 

porém, que influenciam mais sobre o desempenho do reservatório. Engenheiros de reservatório, 

geólogos e equipe de operadores, que conhecem bem o campo em estudo, devem trabalhar em 

conjunto para o sucesso desta etapa. 

Na quinta etapa os dados disponíveis são simulados para posterior comparação do modelo 

com o histórico e medição de sua qualidade. 

Na sexta etapa é realizada a comparação dos resultados obtidos com a simulação do modelo 

e o histórico. Os tipos de resultados a serem comparados dependem dos critérios definidos na 

Etapa 3. 

Na sétima etapa, caso haja necessidade de ajuste, os atributos incertos do reservatório, 

definidos na Etapa 4, são alterados de forma a minimizar a diferença calculada na Etapa 6. 

Por fim, a oitava etapa consiste em repetir as etapas cinco a sete até o modelo de simulação 

representar de forma aceitável o histórico. Uma vez ajustado o modelo com o histórico, ele pode 

ser utilizado com maior confiabilidade em previsões de comportamento.  

2.1.2 Complexidade do ajuste 

Esse procedimento de ajuste, no entanto, possui características intrínsecas a ele que o 

tornam complexo. Trata-se, segundo Consentino (2001), de um problema do tipo inverso, em que 

se conhecem os valores de saída (dados de produção), porém não se conhecem os parâmetros de 

entrada (atributos do reservatório) e depende, basicamente, da qualidade e da quantidade de 

dados disponíveis do reservatório em estudo, dos recursos alocados para o projeto e, 

eventualmente, da experiência e da atitude pessoal do engenheiro que trabalha no modelo. 

O problema relacionado à qualidade e à quantidade dos dados disponíveis decorre do fato 

de que algumas medições são realizadas indiretamente (por exemplo, esquema de rateio para 

medição da produção dos poços de petróleo), consequência do alto custo para obtenção dessas 



 

 

13 

 

informações. Pode haver, também, casos com pouco histórico de produção disponível em que os 

dados não são suficientes para ajustar o modelo. 

Dependendo do modelo, o número de parâmetros envolvidos pode ser alto (aumentam com 

a complexidade do problema). Tipicamente, estes parâmetros são a porosidade, permeabilidade 

(horizontal, vertical ou relativa), transmissibilidade de falhas, saturações residuais etc. Se o 

reservatório for heterogêneo pode possuir várias fácies, o que também contribui para o aumento 

do número de parâmetros. 

Além dos fatores supracitados, outro aspecto a ser considerado na fase de ajuste de 

histórico, segundo Consentino (2001) é a não unicidade dos resultados, ou seja, o fato de ajustes 

igualmente satisfatórios poderem ser obtidos por diferentes descrições de reservatório. Isso 

provém do fato de que a simulação numérica é um sistema matemático complexo, tipicamente 

com apenas algumas variáveis conhecidas (propriedades dos fluidos, produções etc.) e, 

possivelmente, milhares de variáveis desconhecidas (porosidades, permeabilidade de todos os 

blocos do modelo, etc.). Do ponto de vista matemático esse fato gera infinitos números de 

soluções. 

Um exemplo da não unicidade é mostrado na Figura 2.2, a qual mostra o gráfico da 

produção de água versus o tempo de uma jazida de petróleo. Os pontos em azul representam o 

histórico; a curva sólida em vermelho representa o Caso base (modelo desajustado); a curva 

tracejada em verde representa o Ajuste 1 e a curva tracejada em azul representa o Ajuste 2. 



 

 

14 

 

 

Figura 2.2 – Exemplo da não unicidade (múltiplas soluções) no problema de ajuste. 

No gráfico da Figura 2.2 tanto o modelo resultante do Ajuste 1 quanto o modelo resultante 

do Ajuste 2 fornecem respostas com o mesmo grau de afastamento em relação ao histórico e, 

dependendo da precisão exigida no processo, ambos podem ser aceitos como resposta ao 

problema. 

Segundo Ertekin et al. (2001) não há como fugir do problema da não unicidade dos 

resultados, porém, utilizar o máximo de dados de produção disponível e ajustar somente os dados 

menos conhecidos do reservatório dentro dos limites aceitáveis podem resultar em melhores 

ajustes.  

2.1.3 Tipos de ajuste: manual, automático e assistido 

Devido às características destacadas no Subitem 2.1.2, o processo pode se tornar complexo 

e, dependendo do caso, o tempo demandado para realizar o ajuste pode ser grande. Na maioria 

dos casos este processo é realizado de forma manual, pelo procedimento de tentativa e erro. 

Porém, uma grande desvantagem desse tipo de ajuste, segundo Schiozer et al. (2009), é o fato de 

ele exigir grande esforço do profissional envolvido, o que leva à limitação no número de 

simulações e consequente investigação insatisfatória do espaço de soluções (possibilidades e 

0 1000 2000 3000
0

50

100

150

200

250

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

 

 

Histórico

Caso base

Ajuste 1

Ajuste 2



 

 

15 

 

combinações dos atributos incertos dos modelos de simulação). Em contrapartida, possui a 

vantagem de contar com a experiência do profissional, podendo levar a uma redução do número 

de simulações, identificando melhores soluções e maneiras de se chegar aos resultados 

(economizar excluindo análises desnecessárias) mais rapidamente. Segundo Aziz e Settari 

(1979), devido ao fato das equações de fluxo serem resolvidas de forma aproximada e diversas 

considerações serem realizadas durante o desenvolvimento do modelo, o julgamento de um 

profissional da área com experiência e conhecimento torna-se importante para interpretar os 

resultados e auxiliar no processo. 

Com o intuito de diminuir as desvantagens do ajuste manual, foi desenvolvido o ajuste 

automático, que segundo Schiozer et al. (2009) consiste na utilização de algoritmos de 

otimização responsáveis por minimizar uma Função Objetivo (FO), representativa da qualidade 

do ajuste, sendo responsável por realizar todo o processo de forma independente. Contudo, esse 

tipo de ajuste não se mostrou eficiente devido à grande variedade de problemas com 

características distintas.  

Nesse contexto surge o ajuste assistido, a fim de integrar as vantagens provenientes do 

ajuste manual e automático. Dessa forma, partes do processo passam a ser automatizadas, 

aumentando a confiabilidade (melhor avaliação do espaço de soluções), e partes são realizadas 

pelo profissional, identificando características importantes do problema (identificação dos 

parâmetros envolvidos no ajuste, divisão de um problema maior em problemas menores para 

solucionar o problema em etapas, identificação de melhores metodologias a serem aplicadas a 

cada caso etc.) para procurar simplificar e melhorar algumas etapas, tarefa que não é possível ser 

realizada em um processo automático. 

2.1.4 Qualidade do ajuste 

A questão da definição de critérios que indicam quando um modelo pode ser considerado 

ajustado é importante, pois influencia na determinação da metodologia e consequentemente no 

tempo dispendido para sua aplicação. Segundo Ertekin et al. (2001) não há um padrão para 

definição de quando um modelo está bem ajustado, pois este varia de empresa para empresa, de 



 

 

16 

 

pessoa para pessoa dentro da companhia ou de projeto para projeto pelo mesmo indivíduo. O 

importante é que o ajuste seja condizente com o objetivo do estudo.  

Um exemplo desse aspecto é mostrado através do gráfico da Figura 2.3, que mostra a curva 

do corte de água (fw) versus o tempo, em que são mostradas a curva do histórico de corte de água 

(curva tracejada) e a simulação do corte de água (curva sólida). 

 

Figura 2.3 – Comparação do corte de água simulado com o histórico (Modificação de ERTEKIN 

et al., 2001, p.357). 

No gráfico da Figura 2.3, se o objetivo for realizar previsão de produção de água a fim de 

lidar com o avanço de água, então, o ajuste é aceitável, pois a tendência no final da curva está 

bem ajustada. Porém, se o objetivo é identificar localizações de poços ou futuras zonas a perfurar, 

então a qualidade não é boa, pois o modelo está subestimando o corte de água do poço. 

Estudos de reservatórios têm mostrado que existem diversos mínimos locais nos modelos 

de simulação (desde reservatórios em fase inicial de produção a reservatórios maduros). Esse 

fator dificulta a definição de critérios, pois a presença de diversos mínimos locais pode fazer com 

que se encontrem diversos modelos parecidos. 

Consentino (2001) atenta para o fato de que “o problema da não unicidade apenas nos 

permite concluir que a descrição do reservatório encontrado é apenas uma entre várias outras 

possibilidades que não contradizem os dados disponíveis” (CONSENTINO, 2001, p.273). Dessa 

maneira, o modelo de simulação ajustado deverá ser capaz de capturar os principais mecanismos 

que governam a produção do campo, porém, nunca será capaz de prever todas as possíveis 

fw

Tempo (Anos)

Simulação do corte
de água

His tórico de corte de
ág ua



 

 

17 

 

exceções para as regras gerais de depleção e deslocamento de fluidos no reservatório, devendo, 

portanto, ser considerado como um modelo probabilístico, o qual fornece uma estimativa 

confiável da produção futura do campo. 

Devido à complexidade do problema, mesmo em posse de grande quantidade de dados de 

histórico pode-se fracassar no processo de ajuste e, nesse caso, segundo Aziz e Settari (1979), 

pode ser um indicativo de que alguma aproximação considerada no desenvolvimento do modelo 

deva ser revista (estrutura geológica, comportamento PVT, extensão do reservatório, presença de 

aquífero etc.), ou pode significar falta de precisão dos resultados (inconsistência nos dados).  

2.1.5 Otimização dos valores dos atributos do reservatório  

Dentro do processo de ajuste, a etapa que demanda maior esforço computacional e também 

em pesquisa e desenvolvimento, segundo Schiozer et al. (2009), é a de otimização dos valores 

dos atributos do reservatório, a fim de ajustar o modelo de simulação com o histórico. Isso 

ocorre, pois com o aumento do número de atributos incertos, o espaço de soluções torna-se cada 

vez maior, o que dificulta a varredura de todo o espaço. Além disso, por se tratar de um problema 

do tipo inverso, o número de múltiplas soluções também aumenta com o aumento do número de 

atributos.  

Dessa maneira, ênfase maior tem sido dada para realização de estudos comparativos e 

desenvolvimento de novas metodologias para aplicação nessa área. Outro aspecto que leva à 

necessidade de melhorias constantes na área de otimização está relacionado ao fato de que cada 

caso possui particularidades, ou seja, uma ferramenta que serve para um determinado caso pode 

não servir para outro. 

Dentre as alternativas, um procedimento interessante, difundido na área de análise de risco 

e que possui aplicação crescente na área de ajuste de histórico é a utilização de metamodelos 

(proxies). 

 



 

 

18 

 

2.1.6 Utilização de metamodelos gerados por redes neurais artificiais no processo de 

ajuste de histórico 

Um metamodelo consiste basicamente em um modelo, definido segundo funções 

matemáticas ou estatísticas, o qual apresenta um dado padrão de saída para um dado padrão de 

entrada.  

Uma característica importante dos metamodelos é que, uma vez gerados, eles simulam os 

resultados rapidamente e, por conta disso, são bastante promissores para serem utilizados como 

substitutos do simulador. Segundo Avansi (2008), os metamodelos, apesar de serem modelos 

simplificados e com menor confiabilidade nos resultados, podem substituir a simulação numérica 

em situações que demandam muitas simulações e não é necessária grande precisão. 

Existem diferentes ferramentas disponíveis para geração de metamodelos. Segundo 

Zubarev (2009) o modelo de regressão polinomial é bastante utilizado na indústria de petróleo 

devido a sua fácil compreensão, flexibilidade e eficiência computacional. Outra ferramenta 

utilizada para geração de metamodelos é a Rede Neural Artificial (RNA), utilizada em diversas 

áreas, sendo bastante difundida em análise de risco na área de petróleo. Segundo Maschio et al. 

(2008), as RNA são estruturas capazes de captar de forma eficiente as não linearidades em 

problemas tipicamente encontrados nos processos envolvendo simulação de reservatórios, o que 

constitui a maior motivação para utilização dessa técnica para o problema de ajuste de histórico.  

Sendo assim, o Subitem 2.2 a seguir irá mostrar os principais conceitos para compreensão 

do funcionamento básico de uma RNA. A teoria relacionada à RNA é ampla e, por conta disso, 

serão mostrados apenas os aspectos relevantes ao presente trabalho. 

2.2 Redes neurais artificiais 

As tarefas realizadas pelo ser humano no dia a dia, como respiração, pensamento, leitura 

etc. são comandadas pelo cérebro, composto por uma grande quantidade de neurônios 

(aproximadamente 10
11

), interconectados com outros milhares, formando, assim, as redes neurais 

biológicas. Parte da estrutura da rede neural do cérebro é formada antes do nascimento do ser 

humano e parte é modificada ao longo da vida.  



 

 

19 

 

Acredita-se que todas as funções neurais, tais como a memória, são armazenadas nos 

neurônios e nas conexões entre eles. O aprendizado é visto como o estabelecimento, perda ou 

modificação de conexões. A partir desse conceito surge a inspiração para criação das redes 

neurais artificias.  

Utilizando neurônios artificiais (versão extremamente simplificada de um neurônio 

biológico) estrutura-se a rede neural artificial. Apesar de terem capacidade infinitamente inferior 

do que a do cérebro humano, as RNA podem ser treinadas para realizar inúmeros tipos de tarefas. 

2.2.1 Redes neurais biológicas 

O neurônio pode ser dividido basicamente em três partes principais: os dendritos, o corpo 

celular e o axônio. A Figura 2.4 mostra um esquema simplificado de um neurônio biológico. 

 

Figura 2.4 – Esquema simplificado de um neurônio biológico
2
. 

Os sinais oriundos de outros neurônios são receptados pelos dendritos e enviados ao corpo 

celular, responsável por processar todas as informações receptadas e o axônio envia o sinal 

processado para outros neurônios. O contato entre o axônio de um neurônio e o dendrito de outro 

                                                 
2
 Retirada do site http://www.din.uem.br/~jmpinhei/IA-CC/08Redes%20Neurais%20Artificiais.pdf. Acesso em 27 

de Abril de 2011 às 15h20. 

http://www.din.uem.br/~jmpinhei/IA-CC/08Redes%20Neurais%20Artificiais.pdf


 

 

20 

 

é chamado de sinapse. A disposição dos neurônios e as intensidades das sinapses dos neurônios, 

determinadas por processos químicos complexos, estabelecem as funções das redes neurais.  

2.2.2 Neurônio artificial 

Um exemplo ilustrativo de um neurônio artificial é mostrado na Figura 2.5.  

 

Figura 2.5 – Esquema básico de neurônio artificial (HAGAN et al., 1996, p.2-3). 

No neurônio da Figura 2.5, a entrada escalar p é multiplicada pelo peso w formando o 

produto w?p, sendo um dos elementos de entrada do neurônio. Além dessa entrada existe outra 

chamada de auxiliar, de valor “1”, que é multiplicada pelo peso auxiliar chamado “bias” (ou 

offset) b. Os valores são então somados, resultando no valor n, geralmente referenciado 

efetivamente como entrada do neurônio, que então passa pela função de transferência (ou de 

ativação) f, que, por sua vez, gera a saída escalar do neurônio a. 

Fazendo uma analogia com o neurônio biológico, o peso w representa a força da sinapse, o 

corpo celular é representado pelo somador e pela função de transferência e a saída a representa o 

sinal mandado ao axônio. A saída do neurônio é calculada pela Equação 2.2 (Hagan et al., 1996, 

p.2-3):  

   (     ) Equação 2.2 

em que os escalares w e b são ajustáveis. 

? fp
an

b

1

w

Entradas Neurônio

)( bwpfa ??



 

 

21 

 

2.2.3 Função de transferência (de ativação) 

Existem diversas funções de transferência que podem ser utilizadas para calcular a saída de 

um neurônio. Para problemas de aproximação de função, as mais utilizadas são as do tipo 

sigmoide e linear. A Figura 2.6 mostra a função do tipo linear (a) e a do tipo tangente hiperbólica 

(b).  

 

(a)                                                                        (b) 

Figura 2.6 – Função de transferência do tipo linear (a) e tangente hiperbólica (b). 

A Figura 2.6 mostra como a função varia em relação ao parâmetro de modelagem x. Os 

limites de variação para o parâmetro utilizado foi de -1 a 1 para a função da Figura 2.6 (a) e -3 a 3 

para a função da Figura 2.6 (b), tal que os limites de variação da resposta F(x) varie de -1 a 1. 

2.2.4 Arquitetura 

Tipicamente um neurônio possui mais de uma entrada. Além disso, geralmente, as redes 

possuem diversos neurônios e podem ter mais de uma camada. A Figura 2.7 mostra um exemplo 

de uma rede neural artificial com três camadas. 

 

-1 -0.5 0 0.5 1
-1

-0.5

0

0.5

1

x

F
(x

)

Linear

-2 0 2
-1

-0.5

0

0.5

1

x

F
(x

)

Tangente hiperbólica



 

 

22 

 

 

Figura 2.7 – Ilustração de uma rede neural de 3 camadas (HAGAN et al., 1996, p.2-11). 

Quanto à arquitetura, a rede da Figura 2.7 é do tipo direta ou feedforward (a saída de um 

neurônio da i-ésima camada não pode ser utilizada como entrada para neurônios de camada 

menor ou igual a i), múltiplas camadas (três) e completamente conectada (cada entrada é ligada a 

todos os neurônios da camada seguinte).  

Quanto à nomenclatura utilizada, o índice sobrescrito refere-se à camada, o índice subscrito 

da esquerda representa o neurônio de destino e o da direita representa a entrada de onde o sinal 

provém. Assim, a rede em questão possui R entradas, S
1
 neurônios na primeira camada, S

2
 

neurônios na segunda camada e S
3
 neurônios na terceira camada. Cada elemento do vetor de 

entrada (p) é conectado aos neurônios da primeira camada através da matriz de pesos (W). Cada 

neurônio possui uma entrada auxiliar, na qual possui um peso auxiliar (bi), chamado de bias, um 

somador, uma função de transferência e uma saída (ai). A terceira camada, que gera a saída da 

rede, é chamada de camada de saída. As outras camadas são chamadas ocultas ou intermediárias 

(hidden layer).  

A rede da Figura 2.7 também pode ser apresentada na forma abreviada, conforme mostra a 

Figura 2.8 abaixo: 

?

?

?

?

?

?

? f
3

?

?

f
3

f
3

.

.

.

1

1

1

1

1 1

1

1

1

1

1
b

1

2
b

1
1

S
b

1
p

2
p

R
p

1

1
n

1

2
n

1
1

S
n

2
1

S
b

2

2
b

2

1
b

2

1
n

2

2
n

2
2

S
n

3

1
n

3

2
n

3
3

S
n

3

1
a

3

2
a

3
3

S
a

3
3

S
b

3

2
b

3

1
b

1

1
a

1

2
a

1
1

S
a

2

1
a

2

2
a

2
2

S
a

1

1,1
w

1

,
1

RS
w

2

1,1
w

2

,
12

SS
w

3

1,1
w

2

,
23

SS
w

.

.

.
.
.
.

.

.

.

Entradas 1ª camada 2ª camada 3ª camada

? ?1111 bpWfa ??? ? ?21222 baWfa ??? ? ?32333 baWfa ???
? ?? ?? ?3211122333 bbbpWfWfWfa ???????

f 
1
 

f 
1
 

f 
1
 f 

2
 

f 
2
 

f 
2
 



 

 

23 

 

 

Figura 2.8 – Rede multicamadas na forma abreviada (HAGAN et al., 1996, p.2-12).   

2.2.5 Escolha da arquitetura da rede 

Algumas variáveis da rede são determinadas pela especificação do problema proposto, 

como por exemplo, o número de entradas e saídas da rede. Se o problema em estudo possui 

quatro parâmetros incertos e um valor de saída, então, o número de neurônio nas camadas de 

entrada e saída serão quatro e um, respectivamente. A função de transferência a ser utilizada pode 

ser escolhida segundo a característica desejada no sinal de saída da rede. Por exemplo, se deseja 

ter valores -1 ou 1 na saída, a função de transferência escolhida deve ser do tipo degrau unitário. 

As entradas auxiliares fornecem variáveis extras à rede. Segundo Hagan et al. (1996), 

“pode-se esperar que redes com entradas auxiliares sejam mais poderosas do que redes sem” 

(HAGAN et al., 1996 p.2-12). Por exemplo, se as entradas p forem todas zero, a presença das 

entradas auxiliares impede que a entrada n para a função de transferência seja zero.  

Quanto ao número de camadas de neurônios a ser empregado, a maior parte dos problemas 

utilizam de 2 a 3 camadas.  Segundo Hagan et al. (1996), “Uma rede com duas camadas e tendo 

função de transferência do tipo sigmoide nas camadas intermediárias e do tipo linear na saída 

pode ser treinada para aproximar inúmeras funções arbitrariamente bem. Redes de camadas 

únicas não” (HAGAN et al., 1996 p.2-12). Silva e Oliveira (2004) sugerem que a utilização de 

um grande número de camadas ocultas não é recomendável, uma vez que elas recebem uma 

estimativa do erro produzido na camada de saída e, quanto mais distante a camada oculta estiver 

W
1

b
1

 f 
1+

1

S
1
x R

S
1
x 1

S
1
x 1

n
1

R
1
x 1

p

R

W
2

b
2

 f 
2+

1

S
2
xS

1

S
2
x 1

n
2

a
1

S
1
x 1

S
2
x 1

S
1

S
2

W
3

b
3

 f 
3+

1

S
3
x S

2

S
3
x 1

n
3

a
2

S
3
x 1

S
3

S
2
x 1

a
3

S
3
x 1

Entrada 1ª camada 2ª camada 3ª camada

? ?1111 bpWfa ??? ? ?21222 baWfa ??? ? ?32333 baWfa ???
? ?? ?? ?3211122333 bbbpWfWfWfa ???????



 

 

24 

 

da camada de saída, menos precisa é a estimativa do erro. Assim, uma camada é o suficiente para 

problemas menores e, para problemas maiores, duas camadas devem ser suficientes. 

Quanto ao número de neurônios das camadas ocultas, segundo Silva e Oliveira (2004) o 

valor é escolhido de forma empírica, porém deve-se atentar para não utilizar nem valores de mais 

(leva a memorização – overfitting) nem de menos (a rede não será capaz de aprender os padrões 

desejados). Um procedimento existente para determinação do número de neurônios, segundo os 

autores, consiste em utilizar um número de sinapses dez vezes menor do que o número de 

exemplos utilizados para treinamento.  

Portanto, infelizmente, não existe nenhuma teoria ou regra a ser seguida para determinação 

da quantidade de camadas e neurônios a serem utilizados, sendo na maioria dos casos definidos 

de forma empírica. 

2.2.6 Treinamento de redes neurais artificiais 

O processo de treinamento consiste em utilizar uma regra de aprendizado e realizar 

modificações (ajustes) nos valores dos pesos, até que os níveis de discrepância entre os resultados 

gerados na saída da rede e os padrões apresentados (exemplos de como a rede deve se comportar, 

ou seja, conjunto de saídas desejadas) sejam aceitáveis. Assim, o objetivo do treinamento é fazer 

com que a rede seja capaz de reproduzir um padrão de comportamento desejado quando 

apresentado certo padrão de entrada. No processo chamado supervisionado, são apresentados 

padrões de entradas e saídas desejadas (target), e os valores dos pesos da rede são ajustados 

através de um algoritmo de aprendizado. Ao final, se o treinamento for bem sucedido, a rede será 

capaz de reproduzir o mesmo padrão de saída todas as vezes que novas entradas forem 

apresentadas a ela. 

Existem diversas regras utilizadas para aprendizado supervisionado, sendo uma delas 

baseada na otimização de uma função de desempenho, que mede a qualidade de generalização da 

rede. É nessa regra que se baseia o algoritmo de retro propagação, bastante utilizado em diversos 

problemas. A técnica de treinamento utilizada nesse trabalho é a de Levenberg-Marquardt (LM) 

com regularização Bayesiana, que é uma variação do método de Retro propagação (RP).  



 

 

25 

 

2.2.6.1 Algoritmo de retro propagação (backpropagation)  

As etapas básicas do algoritmo de retro propagação (RP) são ilustradas no fluxograma da 

Figura 2.9. 

 

Figura 2.9 – Fluxograma básico do algoritmo de RP. 

Inicialmente é fornecido à rede as entradas e saídas desejadas (exemplos de como deseja 

que a rede se comporte). As entradas são propagadas através das camadas da rede e as respectivas 

saídas são geradas. Essas saídas são comparadas com as saídas desejadas e os erros entre elas são 

calculados. Caso o valor do erro obtido não esteja de acordo com o objetivo, os valores dos pesos 

da rede são alterados de forma a reduzir esse valor. Para tanto, utiliza-se a regra da cadeia para 

retro propagar o valor do erro, partindo da camada de saída até chegar à camada de entrada, 

possiblitanto a atualização dos pesos de acordo com o erro obtido. Após atualização dos pesos 

inicia-se nova iteração, propagando as entradas pela rede e calculando novamente o erro.  

Uma observação importante sobre o  algoritmo, já mencionada anteriormente, é que, ao 

usar a regra da cadeia, cada camada oculta recebe uma estimativa do erro da camada subsequente, 

de forma que, quanto maior for o número de camadas, maior será a incerteza do valor do erro que 

a camada de entrada receberá. Uma abordagem mais completa do algoritmo pode ser encontrada 

em Hagan et al. (1996). 

Apresentação 

dos padrões:

{p1,t1},...,{pn,tn}

Rede Neural Artificial
Saídas:

{a1,...,an}

Saídas 

desejadas:

{t1,...,tn}

Computação do 

erro:

E=[(t-a)
T
·(t-a)]

Atualização dos pesos

Critérios de 

convergência 

alcançados?

Não

Sim

Início

Propagação direta

(Feedforward)

Retro propagação do erro

(Backpropagation) Fim

via algoritmo de treinamento

  Propagação das entradas 

 através dos pesos da rede



 

 

26 

 

2.2.6.2 Variações do algoritmo de Retro propagação  

O algoritmo de RP, apesar de ter revolucionado as pesquisas de RNA, segundo Hagan et al. 

(1996) “é muito lento e ineficaz para muitas aplicações práticas” (HAGAN et al., 1996, p.12-1). 

Segundo Hagan e Menhaj (1994), desde que o algoritmo se popularizou, surgiram diversas 

metodologias para acelerar sua convergência, sendo a incorporação de métodos numéricos ao 

algoritmo padrão uma dessas vertentes. O algoritmo de Levenberg-Marquardt (LM), uma 

variação do método de Newton
3
, é utilizado para minimização da soma quadrada de funções não 

lineares. Trata-se de uma característica importante que se enquadra muito bem no contexto de 

RNA, em que o desempenho é medido pela soma ou média do quadrado do erro. Por esse motivo, 

esse algoritmo foi escolhido para ser aplicado ao presente trabalho. Hagan e Menhaj (1994) 

publicaram um artigo no qual o algoritmo é aplicado a alguns problemas de aproximação de 

funções e, segundo os autores, é muito eficiente para aplicação em redes que tenham até algumas 

centenas de pesos. O desenvolvimento desse algoritmo pode ser encontrado em Hagan et al. 

(1996).  

2.2.6.3 Capacidade de generalização de uma rede neural artificial 

Um dos maiores problemas que ocorrem durante o processo de treinamento de uma RNA é 

a memorização (overfitting) dos dados. Em tais situações, a rede acaba memorizando as saídas ao 

invés de aprender o padrão de geração para poder generalizar para outras entradas. Como 

resultado, a rede produz saídas diferentes do padrão desejado quando são apresentadas entradas 

que não foram utilizadas para treinamento.   

Dois métodos utilizados para melhorar a capacidade de generalização de uma RNA são o 

método de regularização e de parada prematura (early stopping), descritos suscintamente a 

seguir. 

O método de parada prematura consiste em dividir o conjunto de treinamento em três 

subconjuntos: treinamento, validação e teste. O primeiro conjunto é utilizado para atualização dos 

pesos, ou seja, aplicação do algoritmo de aprendizagem. O segundo conjunto é utilizado durante 

                                                 
3
 A teoria referida pode ser encontrada no livro de Hagan et al., 1996. 



 

 

27 

 

o treinamento para monitorar o desempenho da rede. Se o erro de validação começar a subir 

enquanto o erro de treinamento continua diminuindo é sinal de que está ocorrendo memorização 

dos resultados. Nessa hora o treinamento é interrompido. O terceiro conjunto é utilizado após o 

treinamento para testar a capacidade de generalização da rede.  

Já o método de regularização consiste em modificar a função de desempenho. O método 

bayesiano, em particular, utiliza informações adicionais para cálculo dessa função, que assume a 

forma mostrada na Equação 2.3 (Foresse e Hagan, 1997, p.1). 

            Equação 2.3 

em que    representa a soma do quadrado do erro entre saída desejada e gerada pela rede,    

representa a soma do quadrado dos pesos da rede e   e   são parâmetros da função objetivo. 

Basicamente considera-se que os pesos da rede são variáveis aleatórias com uma determinada 

distribuição de probabilidades, de forma que os parâmetros   e   estejam atrelados a eles, e, seus 

valores são, então, estimados utilizando técnicas estatísticas. A descrição do método bayesiano de 

regularização pode ser encontrada no trabalho de Foresse e Hagan (1997) e no livro de Bishop 

(1995). 

2.3 Algoritmo genético 

Ao gerar o metamodelo, que no caso de RNA nada mais é do que uma rede treinada, ele 

está pronto para ser utilizado no lugar do simulador no processo de otimização. Nesse trabalho 

foi utilizado o algoritmo genético (AG) para esse processo. 

O AG consiste em uma metodologia de otimização baseada no mecanismo de seleção 

natural proposto pela teoria de Darwin, na qual diz que indivíduos mais adaptados ao meio 

sobrevivem e contribuem para propagação das gerações. Assim, as características dos indivíduos 

mais fortes vão se propagando para as futuras gerações, enquanto que, características 

desfavoráveis vão se tornando menos frequentes. Proposto por Holland
4
 em 1975, inicialmente 

foi desenvolvido e aplicado em máquinas com intuito de encontrar explicações para os processos 

                                                 
4
 John Henry Holland é conhecido por ter criado os algoritmos genéticos. 



 

 

28 

 

adaptativos em sistemas naturais. Porém, devido ao seu grande potencial em varrer espaços 

multidimensionais, passou a ser amplamente empregado em problemas de otimização.  

No AG um indivíduo é constituído pelo seu cromossomo, o qual representa uma possível 

resposta ao problema (conjunto de variáveis). O processo de evolução ocorre alterando-se os 

valores de cada gene (variável) do cromossomo.  

O funcionamento básico do algoritmo consiste em, a partir de uma população inicial de 

indivíduos (cromossomos), realizar operações de recombinação (crossover), mutação e seleção 

em um processo iterativo de modo que, a cada geração (iteração), a população gere indivíduos 

mais aptos (melhores soluções) ao ambiente (problema). 

No início o AG era padronizado e seguia, em geral, o mesmo procedimento, sendo 

denominado de Algoritmo Genético Clássico (AGC). A estrutura apresentada na Figura 2.10 

representa as principais etapas a serem realizadas em um AGC. 

 

Figura 2.10 – Estrutura básica de um AGC. 

Nesse algoritmo (AGC), cada indivíduo da população é composto por um vetor de bits, 

conforme mostra a Figura 2.11 (a), e representam possíveis respostas ao dado problema. 

Início

Fim

1. Cria População inicial

2. Avaliação da população 

(cálculo do fitness)

3. Seleção

5. Mutação

4. Recombinação 

(Crossover)

  6. Condições de 

   parada atingidas?

Sim 

Não



 

 

29 

 

 

Figura 2.11 – Exemplo de um indivíduo formado por um vetor de bits (a), ilustração dos 

processos de recombinação (b) e mutação (c). 

Para iniciar o algoritmo, é gerado um conjunto de indivíduos para compor a população 

inicial. Em seguida, a população é avaliada a fim de encontrar os indivíduos mais fortes. A cada 

indivíduo é atribuído um valor, determinado através da função de fitness, na qual representa o 

quão distante a solução gerada pelo indivíduo está do valor desejado. Após a avaliação ocorre a 

seleção dos indivíduos para serem submetidos aos operadores genéticos (recombinação e 

mutação). No AGC é utilizado o algoritmo da Roleta Russa (Roulette Wheel) para o processo de 

seleção, ilustrado na Figura 2.12. 

 

 

Figura 2.12 – Ilustração do algoritmo de Roleta Russa
5
. 

                                                 
5
 Retirada do site ftp://ftp.dca.fee.unicamp.br/pub/docs/vonzuben/ia707_01/topico6_01.pdf Acesso em 28 de Maio 

de 2011, às 13h44. 

0 1 1 0 1 1 1 1 1 0

(a)

0 1 1 0 1 1 1 1 1 0

1 1 1 0 1 0 0 0 1 1

0 1 1 0 1 0 0 0 1 1

1 1 1 0 1 1 1 1 1 0

(b)

0 1 1 0 1 1 1 1 1 0

0 1 1 1 1 1 1 1 0 0

(c)

novo indivíduo 2

indivíduo

novo indivíduo

indivíduo 1

indivíduo

indivíduo 2

novo indivíduo 1

nº Fitness Graus
1 0 0 0 1 1 0 0 1 0 1 0 1 0 6.0 180
2 0 1 0 1 0 0 1 0 1 0 1 0 1 3.0 90
3 1 0 1 1 1 1 0 1 0 0 1 0 1 1.5 45
4 1 0 1 0 0 1 0 1 0 1 0 0 1 1.5 45

Cromossomo

 

1

2
3

4

0.25

0

1
0.5

0.75

ftp://ftp.dca.fee.unicamp.br/pub/docs/vonzuben/ia707_01/topico6_01.pdf


 

 

30 

 

O algoritmo da Roleta Russa, mostrada na Figura 2.12, consiste em atribuir um valor de 

probabilidade de seleção a cada indivíduo, proporcional ao seu valor de fitness e, a partir daí, os 

indivíduos são selecionados de forma aleatória de acordo com a probabilidade.  

Aos indivíduos selecionados são aplicados os operadores genéticos. O operador de 

recombinação é realizado pelo método de recombinação de um ponto, em que os cromossomos 

de dois indivíduos são cortados em um ponto específico e, então, os dois pedaços são trocados, 

conforme mostra a Figura 2.11 (b). No AGC ainda pode ocorrer mutação em que, com uma 

probabilidade baixa, um indivíduo pode sofrer alteração em seu gene, conforme mostra a Figura 

2.11 (c).  

Os indivíduos, após a realização dos mecanismos de reprodução (seleção, recombinação e 

mutação), compõem a nova população para a próxima geração. Caso as informações desejadas 

não estejam contidas dentro dos indivíduos dessa nova população, ou seja, se as condições de 

parada não forem satisfeitas, inicia-se novamente o processo de reprodução. Um ciclo completo 

do processo de reprodução (etapas de 2 a 6 do fluxograma da Figura 2.10) consiste em uma 

geração. 

A desvantagem do AGC é que o procedimento de reprodução acaba possibilitando a perda 

do melhor indivíduo da população. Além disso, a codificação de valores em binário torna-se 

complicada com aumento da precisão dos dados. Para tentar superar essas desvantagens, 

algoritmos modificados têm sido utilizados, com mecanismos alternativos de seleção/reprodução 

e codificação dos indivíduos da população em número reais.  

Um exemplo de modificação no processo de reprodução e seleção consiste em gerar uma 

subpopulação a partir da população atual, utilizando operadores genéticos (recombinação e 

mutação), avaliar e organizar essa subpopulação e realizar nova seleção dentro dela para compor 

a próxima geração.  

O AG é uma ferramenta bastante utilizada para problemas de otimização devido a suas 

características particulares, que o diferenciam dos algoritmos de busca e otimização tradicionais. 

Conforme pôde ser observado na introdução, o AG realiza busca sobre uma população de pontos, 

ao invés de um ponto, de forma paralela e independente. Outra característica importante da 



 

 

31 

 

ferramenta é que ela não requer informações de derivadas, sendo necessário fornecer apenas o 

valor da função objetivo (fitness).  

2.4 Técnicas de amostragem 

Um ponto crítico que merece destaque no processo de treinamento de RNA é a questão dos 

dados de entrada (dados de treinamento), pois a qualidade do metamodelo está diretamente ligada 

a eles (Zubarev, 2009). Como as RNA aprendem através de exemplos, se não forem expostos os 

pontos relevantes e necessários que descrevem a superfície de resposta a qual se deseja modelar, 

a estrutura gerada muito provavelmente não irá realizar representações satisfatórias nessas 

regiões onde ocorre falta de informação.  

Essa observação traz a tona uma importante característica das RNA para representação de 

um simulador de escoamento. A RNA tende a suavizar (atenuar) o formato da superfície de 

resposta quando pouca informação lhe é fornecida. Sendo assim, em regiões onde a superfície 

possui muitas irregularidades e pouca informação a respeito, essa característica se torna mais 

importante. 

Adicionalmente, em problemas de ajuste de histórico, na prática, o tempo demandado para 

realizar uma simulação pode ser muito grande e, portanto, a utilização do menor número de 

pontos possível para realizar o processo se torna importante. Nesse contexto, pode-se dizer que 

para a metodologia de ajuste a ser adotada nesse trabalho, que é a aplicação de metamodelos 

gerados a partir de RNA no problema de ajuste de histórico, a técnica utilizada para amostrar os 

pontos de treinamento das RNA é de suma importância. 

Segundo Mckay et al. (1979) quando se pretende modelar algum fenômeno do mundo real 

através de simulação computacional, um problema que surge é saber quais valores devem ser 

utilizados como entrada. Essa incerteza acerca dos parâmetros é modelada tratando-os como 

variáveis aleatórias. O comportamento da saída é obtido realizando-se experimentos numéricos a 

partir da amostragem das variáveis de entrada, com distribuição de probabilidades conhecida. 

Existem diversas técnicas de amostragem na literatura, com o propósito de amostrar o 

espaço de busca dos parâmetros utilizando quantidades reduzidas de amostras. 



 

 

32 

 

A ideia original do trabalho consistiu em comparar as técnicas do Hipercubo Latino e Box 

Behnken para gerar os dados de entrada e os metamodelos a serem utilizados em casos práticos 

de reservatório. A escolha dessas duas técnicas se deu pelo fato de existirem trabalhos publicados 

da área de análise de risco em que elas foram aplicadas com sucesso.  

A técnica do HL possibilita gerar qualquer quantidade de amostras que se desejar. No 

entanto, no planejamento BB um conjunto pré-determinado de pontos é selecionado (segundo 

uma metodologia particular) dentre todas as possíveis combinações das variáveis de modelagem 

do problema, ou seja, a técnica não tem a flexibilidade que o HL fornece para escolha da 

quantidade de amostras. Por conta disso, para poucas variáveis, a quantidade de pontos 

amostrados é pequena, não sendo interessante utilizar a técnica nesses casos.  

Para aplicação da metodologia foram escolhidos, inicialmente, casos analíticos de duas 

variáveis a serem estudados antes de um caso prático de reservatório. Com isso, fez-se necessária 

a escolha de outra técnica de amostragem para aplicar a metodologia nesses casos preliminares. 

Através de uma rápida pesquisa bibliográfica decidiu-se utilizar a Sequência de Sobol por se 

tratar de uma sequência que gera um bom espaçamento entre as variáveis no espaço, sendo uma 

alternativa interessante em relação ao método de Monte Carlo. Portanto, foram comparadas em 

um primeiro momento as técnicas do HL e SS, e em um segundo momento as técnicas do HL e 

BB. Uma breve introdução dessas três técnicas é realizada nos itens subsequentes. 

2.4.1 Box Behnken 

Aliar um bom espaçamento entre pontos no espaço com menor número de simulações 

possível é uma tarefa complicada quando envolve grande quantidade de parâmetros. Nesse 

contexto, o planejamento estatístico tem sido empregado a fim de gerar dados de entrada com 

qualidade. Segundo Risso (2007) apud Montgomery (1996) a técnica consiste basicamente na 

utilização de métodos estatísticos e matemáticos para modelagem de problemas nos quais as 

funções-objetivo são influenciadas por vários atributos com a finalidade de otimizar a resposta.  

Dessa maneira, a etapa de amostragem dos dados de entrada é realizada de forma planejada, 

utilizando técnicas estatísticas. Segundo Mason et al. (2003), a utilização do planejamento 

estatístico permite que informações sejam obtidas de forma eficiente nas regiões de interesse. 



 

 

33 

 

A técnica possui diversas aplicações na indústria de petróleo. Como exemplo pode-se citar 

o planejamento do tipo Box Behnken (BB), utilizado por Risso (2006) em conjunto com o 

método de superfície de resposta para estudar o tratamento de atributos na análise de risco. No 

processo de ajuste de histórico Lima (2009) utilizou metamodelos gerados por planejamento 

estatístico para realizar o ajuste. Esse método possibilita realizar uma boa amostragem com 

número bastante reduzido de amostras em situações em que o número de fatores (parâmetros) é 

elevado. 

Supondo que se tenha   fatores (ou variáveis), discretizados em três níveis. O modelo 

fatorial    é um modelo contendo todas as combinações possíveis de   fatores (variáveis) nesses 

três níveis. O método de amostragem BB é formado selecionando valores do modelo    fatorial 

completo segundo uma metodologia particular, detalhada em Box e Behnken (1960). Os três 

níveis são normalizados de tal forma que se tenha apenas valores 1, -1 e 0.  

Os pontos resultantes formam uma matriz na qual as linhas representam o número de 

simulações e as colunas representam o número de fatores. A Tabela 2.1 mostra um modelo de 

três fatores.  

Tabela 2.1 – Método de BB na forma matricial para 3 fatores, discretizados em 3 níveis. 

Experimento X1 X2 X3 Experimento X1 X2 X3 

1 -1 -1 0 9 0 -1 -1 

2 1 -1 0 10 0 1 -1 

3 -1 1 0 11 0 -1 1 

4 1 1 0 12 0 1 1 

5 -1 0 -1 C 0 0 0 

6 1 0 -1 C 0 0 0 

7 -1 0 1 C 0 0 0 

8 1 0 1     

 

O método de planejamento estatístico foi proposto originalmente para ser utilizado na 

modelagem de experimentos de laboratório, em que erros de experimento e medição estão 

presentes. Assim, os experimentos são repetidos para que se possam estimar esses erros. Os 

experimentos identificados pela letra “C” na Tabela 2.1 representam, então, a repetição dos 

experimentos.  



 

 

34 

 

Os pontos da Tabela 2.1 formam um cubo em que eles se situam no meio das arestas e no 

centro, conforme mostra a Figura 2.13 

 

Figura 2.13 – Método de BB na forma gráfica para 3 fatores, discretizados em 3 níveis 

(FERREIRA et al., 2007, p.183). 

O número total de simulações realizadas é       (   )     (Ferreira et al., 2007, 

p.182), em que   é o número de fatores e    é o número de pontos centrais. Assim, o método de 

BB utiliza menos simulações do que o modelo fatorial completo. Outra característica do modelo é 

que ele não contém pontos em que todos os fatores são simultaneamente máximos ou mínimos, 

ou seja, ele não gera condições extremas (Ferreira et al., 2007, p.182). Dessa maneira, o modelo 

não é indicado para experimentos nos quais se deseja determinar condições extremas. 

Segundo Mason et al. (2003) a utilização de planejamento estatístico nas etapas de coleta 

de dados permite realizar conclusões diretas e precisas, o que geralmente não é possível quando a 

coleta é realizada de forma não planejada. 

Uma explicação completa sobre a metodologia pode ser encontrada em Box e Behnken 

(1960). 

 

 

 



 

 

35 

 

2.4.2 Hipercubo Latino 

O método do HL foi proposto por Mckay et al. (1979) como alternativa atrativa ao método 

aleatório simples (Monte Carlo) em experimentos computacionais. Segundo o autor, o método é 

utilizado quando se deseja que cada variável de entrada tenha todas as regiões de sua distribuição 

representadas. 

Na amostragem por Hipercubo Latino (HL), o domínio de cada variável é dividido em   

intervalos e valores são sorteados dentro de cada intervalo. A quantidade de valores sorteados 

dentro de cada faixa pode variar de acordo com sua probabilidade, conforme mostra a Figura 

2.14. 

 

Figura 2.14 – Exemplo de discretização de uma distribuição normal em 7 intervalos. (MASCHIO 

et al., 2009, p.3) 

Observa-se que a quantidade de valores sorteados na faixa central (em azul) é maior e vai 

diminuindo conforme a curva de probabilidade da faixa. Para uma distribuição uniforme, as 

faixas possuem probabilidades iguais (  ? ). Os componentes sorteados de cada variável são 

permutados de forma aleatória. A Figura 2.15 mostra um exemplo da amostragem para 

distribuição normal e uniforme. 



 

 

36 

 

 

(a) (b) 

Figura 2.15 - Figura ilustrativa da amostragem por HL, para distribuição normal (a) e uniforme 

(b).  

Segundo Maschio et al. (2009), “uma característica importante dessa técnica é que, 

independentemente do número de sorteios, o número de amostras representa de forma adequada a 

distribuição de probabilidades” (MASCHIO et al., 2009, p.3).  

Maiores detalhes podem ser encontrados no trabalho de Mckay et al. (1979), o qual realiza 

comparações da técnica do HL com o método aleatório simples e estratificado e apresenta as 

vantagens em estimar empiricamente distribuições. 

2.4.3 Sequência de Sobol  

A Sequência de Sobol (SS) faz parte do tipo de sequência de baixa discrepância ou quase-

aleatória (quasirandom) em que, segundo Frota (2003), as amostras são selecionadas de modo a 

preencherem igualmente todo o domínio do espaço de busca. O autor estudou a aplicação de 

sequências desse tipo em avaliação de opções americanas tradicionais e complexas (modelos de 

precificação), mostrando que a aplicação traz vantagens em relação à simulação de Monte Carlo. 

-4 -2 0 2 4

-4

-2

0

2

4

Variável 1

V
a
ri

á
v
e
l 

2

-4
-2

0
2

4
05

1
0

1
5

2
0

2
5

-4 -2 0 2 4
0

5

10

15

20

25

0 0.5 1

0

0.2

0.4

0.6

0.8

1

Variável 1

V
a
ri

á
v

e
l 

2

0 0.5 1
0

2

4

6

8

10

12

0
0

.5
1

02468

1
0

1
2



 

 

37 

 

O procedimento seguido para construir a SS envolve conceitos de números direcionais e 

polinômios primitivos e não será demonstrado nesse trabalho. Uma descrição sucinta pode ser 

encontrada no trabalho de Frota (2003) e uma descrição completa desse procedimento foi 

realizada por Bratley e Fox (1988). Um exemplo de amostragem pela técnica para 100 pontos é 

mostrado na Figura 2.16. 

 

Figura 2.16 – Exemplo de amostragem pela Sequência de Sobol. 

Uma observação importante dada por Bratley e Fox (1988) é que a SS deve utilizada para 

problemas de 2 a 6 dimensões. 

2.5 Comentário sobre as técnicas de amostragem 

Para os casos analíticos, a amostragem pelo HL, devido a suas características, deve 

proporcionar uma cobertura bem espaçada das amostras no espaço. O mesmo se pode dizer da 

SS, pois com até seis variáveis ela proporciona bom espaçamento. Assim, no caso de duas 

variáveis, para avaliação de uma região maior (toda a superfície de busca dos parâmetros), 

podem-se esperar resultados semelhantes para as duas técnicas em questão de qualidade da 

modelagem. Porém, se for realizada avaliação em regiões específicas (menores) deve-se destacar 

a diferença entre elas, pois cada uma tem um padrão de geração das amostras. 

-1 -0.5 0 0.5 1
-1

-0.5

0

0.5

1

Variável 1

V
a
ri

á
v
e
l 

2



 

 

38 

 

Para o caso com mais variáveis, quando comparada às técnicas do HL e BB, a diferença 

entre elas deve aumentar conforme se aumenta a quantidade de amostras e o tamanho do espaço 

de busca dos parâmetros, ou seja, os limites de variação de cada variável de modelagem. O BB 

amostra valores normalizados (mínimo, médio e máximo) enquanto que o HL, apesar de dividir a 

variável em intervalos, realiza o sorteio em uma faixa contínua de valores. Assim, para espaços 

maiores, o HL deve fornecer melhor cobertura de todo o espaço de busca. 

Deste modo, pode-se esperar que, para o caso prático de reservatório em que se tem maior 

quantidade de atributos incertos, melhores resultados sejam obtidos através da utilização da 

técnica do HL. 



 

 

39 

 

3 REVISÃO BIBLIOGRÁFICA 

3.1 Ajuste de histórico 

Para compreender melhor o processo de ajuste de histórico, bem como sua importância 

para estudos de reservatório, uma pesquisa bibliográfica foi realizada para conhecimento e 

análise de diferentes metodologias que vêm sendo aplicadas nessa área.  

Conforme visto no item de fundamentação teórica, o problema de ajuste de histórico é 

complexo e mal condicionado. Segundo Schiozer et al. (2009) dentre as etapas que envolvem 

esse processo, a que demanda maior esforço computacional e também em pesquisa e 

desenvolvimento, é a de otimização dos valores dos parâmetros do reservatório, a fim de ajustar o 

modelo de simulação com o histórico. Nesse contexto, muitos trabalhos têm sido propostos e o 

surgimento de novos estudos a fim de melhorar essa etapa é frequente. 

A seguir são analisados alguns trabalhos nos quais se realizam testes e comparações de 

diferentes técnicas nessa área.  

Leitão e Schiozer (1998) realizaram uma comparação entre algoritmos de primeira ordem 

(que utilizam informações de gradiente) e de busca direta (que não necessitam do cálculo da 

derivada). Os autores ainda utilizaram o pacote PVM (Parallel Virtual Machine), que paraleliza 

as simulações de modo a reduzir o tempo necessário para alcançar os resultados.  

Segundo os autores, nos casos em que a função objetivo é complexa, existe alta não 

linearidade e a superfície de resposta é bastante irregular, com diversos mínimos, sendo que 

nessas situações, os métodos de busca direta são mais eficientes do que os de primeira ordem, 

pois o segundo acaba convergindo para mínimos locais. Foi testado também um algoritmo 

híbrido, no qual se inicializa a otimização com o algoritmo de primeira ordem utilizando o pacote 

PVM e, posteriormente, utiliza-se o algoritmo de busca direta para refinar a solução. 



 

 

40 

 

Santos e Schiozer (2000) realizaram uma breve revisão bibliográfica sobre o assunto de 

ajuste de histórico e apresentaram uma metodologia utilizando os módulos de paralelização de 

simulações, análise de sensibilidades e otimização mostrando que a automatização de partes do 

processo possibilita a redução de tempo. 

Maschio e Schiozer (2004) aplicaram o método de busca linear diagonal, baseado no 

método de busca direta em um espaço discreto, para aumentar a eficiência em relação ao 

algoritmo de busca linear em conjunto com uma metodologia de ajuste de histórico assistido. A 

técnica resultou na redução do número de simulações para os casos estudados.  

Maschio e Schiozer (2005) realizaram ainda um estudo comparativo da aplicação de uma 

técnica de busca direta e um método baseado em cálculo de gradientes. O método dos gradientes 

reduz o esforço computacional, porém, o método baseado em busca global se mostrou mais 

eficiente para casos que possuem mais de um mínimo local. 

Maschio et al. (2006) testaram a aplicação do método Simplex ao problema de ajuste de 

histórico, avaliando a versão contínua e discreta do algoritmo e comparando com o algoritmo de 

Hooke &amp;amp; Jeeves, baseado na busca direta, mostrando que a técnica possui um bom potencial para 

ser aplicada em problemas de ajuste de histórico.  

Schulze-Riegert e Ghedan (2007) realizaram revisão de técnicas e metodologias para ajuste 

de histórico e análise de incertezas, ressaltando suas importâncias e aplicabilidades. Para ajuste 

de histórico foi realizada uma introdução e discussão sobre algoritmos evolucionários, otimização 

multiobjectivo e métodos de superfície de resposta (metamodelos). Segundo os autores, a 

aplicabilidade de metamodelos deve ser avaliada caso a caso, analisando os objetivos do estudo.  

Schiozer et al. (2009) realizaram uma breve introdução ao assunto de ajuste de histórico e 

utilizaram três exemplos de aplicação para mostrar os problemas inerentes ao processo com 

aumento da complexidade. Um enfoque maior no processo de ajuste assistido foi dado, 

ressaltando suas características e vantagens em relação ao método tradicional e automático de 

ajuste. 

Esses são apenas alguns dos exemplos encontrados na literatura. Uma boa ênfase tem sido 

dada à realização de estudos comparativos e ao desenvolvimento de novas metodologias para 

aplicação nessa área.  



 

 

41 

 

3.2 Aplicação de redes neurais artificiais e metamodelos  

A utilização de RNA para gerar metamodelos tem ganhado destaque, pois se trata de uma 

excelente ferramenta para ser utilizada em casos com alta não linearidade entre entrada e saída. 

Com relação à aplicação de RNA aos problemas da área de petróleo os seguintes trabalhos foram 

consultados: 

Doraisamy et al. (2000) aplicaram RNA para determinar a localização para alocação de 

novos poços em problemas de desenvolvimento de campo. Para tal propósito a RNA foi treinada 

utilizando as saídas geradas pelo simulador de escoamento. Seus resultados mostraram que a 

ferramenta pode trazer vantagens quando aplicada em conjunto com o simulador.  

Mohaghegh (2000) realizou uma breve introdução a respeito de RNA e citou algumas de 

suas aplicabilidades na indústria de petróleo, ressaltando que é recomendável a utilização da 

ferramenta em casos em que a modelagem matemática do problema se torna muito complexa. Em 

tais casos, as RNA podem ser construídas para observar o comportamento do sistema (que tipo de 

saída é produzido como resposta a certos valores de entrada) de modo a buscar “imitar” esse 

comportamento. 

Hirschen e Schafer (2006) aplicaram o método de regularização bayesiana para treinamento 

de RNA para determinação de parâmetros que definam a geometria de uma junção de canais, nos 

quais resultem na menor queda de pressão. O metamodelo gerado foi utilizado no lugar do 

simulador numérico no processo de otimização dos parâmetros. Seus estudos mostraram que 

redes treinadas com regularização bayesiana são melhores que redes convencionais (sem 

aplicação da regularização) para o caso estudado, porém, mais estudos na modelagem da rede e 

consequente melhoria na capacidade de aproximação se mostraram necessários. 

Lima et al. (2009) estudaram algumas formas de aplicação de metamodelos gerados por 

técnicas de planejamento estatístico em um reservatório sintético para o problema de ajuste de 

histórico. Seus estudos mostraram que utilizar o metamodelo para determinar a região de mínimo 

e depois realizar uma otimização local é mais eficiente do que realizar todo o processo de ajuste 

apenas com o metamodelo ou apenas com um algoritmo de otimização (usando somente o 

simulador). Os autores ainda observaram que o metamodelo não foi capaz de representar com 



 

 

42 

 

precisão a região de mínimo quando treinada para representar o reservatório inteiro para o caso 

estudado.  

3.3 Metamodelos gerados por redes neurais artificiais no processo de ajuste de histórico 

Para aplicação de RNA no processo de ajuste de histórico, encontram-se diversos estudos 

na literatura, sendo destacados alguns deles. 

Al-Thuwaini et al. (2006) estudaram a aplicação de SOM (Self Organizing Maps) para 

agrupar blocos do reservatório por regiões com propriedades semelhantes, possibilitando realizar 

ajustes de parâmetros de forma regional. 

Cullick et al. (2006) utilizaram RNA em conjunto com planejamento estatístico para gerar 

metamodelos representativos do simulador. O metamodelo gerado foi utilizado no processo de 

otimização para gerar valores iniciais para otimização direta com o simulador. Seus resultados 

mostraram que a utilização do metamodelo proporciona bons resultados com menos simulações. 

Silva et al. (2006) testaram a utilização de algumas RNA como RBN (Radial Basis 

Network) e GRNN (Generalized Regression Neural Network) para serem utilizadas para 

representar o simulador, ressaltando a importância de escolher uma arquitetura adequada ao caso 

a ser estudado a fim de obter boa generalização e número reduzido de simulações. Segundo o 

autor, um metamodelo pode ser considerado ótimo se o coeficiente de correlação linear entre 

resultados do simulador e do metamodelo estiverem entre 0.7 e 0.8.  

A ferramenta MATLAB
®
 da empresa The Mathworks Inc., utilizada nesse trabalho, calcula 

o coeficiente de correlação linear de acordo com a Equação 3.1. 

   
? (    ?)  (      ?)
 
   

? (    ?)
  

   

 Equação 3.1 

em que    representa o dado no passo  ,   representa o atraso e a média é dada pela Equação 3.2. 



 

 

43 

 

 ?  ?
  
 

 

   

 Equação 3.2 

A função corrcoef utilizada pelo MATLAB
®
 produz uma matriz de coeficientes de 

correlação linear, na qual cada coluna representa um dado diferente. Os valores podem variar de -

1 a 1, onde valores próximos de 1 indicam que há uma correlação linear positiva entre os dados; 

valores perto de -1 indicam que há uma correlação linear negativa entre os dados e valores 

próximos de zero indicam que não existe nenhuma correlação linear entre os dados. 

Zangl et al. (2006) estudaram a aplicação de metamodelos gerados por RNA em processos 

de otimização de produção e atentaram para alguns fatores.  

? O resultado gerado pela rede não será confiável caso seja utilizado como entrada 

valores que excedam os limites de variação para a qual a rede foi treinada. 

?  As configurações da rede são baseadas unicamente em observações numéricas, sem 

levar em consideração qualquer natureza ou conhecimento do problema, não 

existindo uma equação ou função que explique o valor gerado na saída. Assim, com 

os atuais recursos tecnológicos não é possível representar de forma analítica a 

resposta gerada pela rede, em relação à entrada. 

? Se o problema possui grau de liberdade elevado, muitas restrições e dependências 

presentes ou pouca correlação entre espaço de entrada e saída, a rede não será capaz 

de realizar uma representação satisfatória do comportamento desejado. 

Assim a aplicação da ferramenta, para cada caso, deve ser cuidadosamente analisada. 

Ramgulam et al. (2007) estudaram a aplicação de RNA para estimativa de atributos 

incertos do reservatório, realizando diversos testes para definição de arquiteturas de redes e 

adição de propriedades nos dados de treinamento da rede. Um exemplo de adição de propriedades 

utilizada pelo autor é o quociente entre a distância do poço produtor até o limite do reservatório e 

a permeabilidade em cada região (D/k) ou o quociente entre a área de cada região e a 

permeabilidade de cada região (A/k). A metodologia foi capaz de reduzir o erro entre os dados 

histórico e simulado e o número de simulações necessárias para atingir um bom ajuste.  



 

 

44 

 

Maschio et al. (2008) utilizaram metamodelos gerados a partir de RNA para utilização no 

processo de ajuste de histórico, mostrando que a ferramenta é capaz de reduzir bem o erro entre 

resultados do simulador e do histórico com um número menor de simulações. A qualidade do 

ajuste foi medida utilizando a expressão mostrada na Equação 3.3: 

  [  (
        

    
)]      Equação 3.3 

em que “Ajustado” representa o afastamento (com relação ao histórico) do modelo ajustado e 

“Base” representa o afastamento (com relação ao histórico) do modelo base (Caso Base). 

Os autores atentaram para o fato de que, para uma aplicação correta da técnica, a escolha 

dos pontos e método de treinamento é fundamental, sendo necessário aprimorar o processo de 

treinamento e geração dos metamodelos. Esse constituiu o ponto de partida e motivação para o 

presente trabalho.  

De acordo com a Equação 3.3, a qualidade do ajuste é medida em uma escala que vai de 

algum valor negativo até 100%. Valores entre 0% e 100% representam uma melhora do ajuste em 

relação ao Caso Base. O valor 100% representa um ajuste perfeito. Em contrapartida, valores 

negativos significam que houve uma piora em relação ao Caso Base. Vale lembrar que o 

afastamento é calculado utilizando a fórmula descrita pela Equação 2.1. Assim, por se tratar de 

uma soma quadrática o valor do coeficiente de ajuste (A) terá o mesmo valor, caso a curva esteja 

espelhada do lado oposto em relação ao histórico. 

A  Figura 3.1 mostra o comportamento do indicador (Q) da curva de produção de um 

determinado modelo com relação à curva de produção do Caso Base. 

 

Figura 3.1 – Exemplo do indicador de qualidade de ajuste com relação ao Caso Base. 

Q = 0% (base)

Q = 100% (ajuste perfeito)

0 &amp;lt;Q &amp;lt;100% (melhor que o base)

Base

Q &amp;lt;0% (pior que o base)

Qw

Tempo



 

 

45 

 

Sampaio et al. (2009) estudaram a aplicação de RNA do tipo direta (feedforward) para 

aplicação em um caso de ajuste de histórico, relatando as dificuldades existentes em definir e 

configurar uma rede adequadamente. 

Zubarev (2009) estudou a utilização de metamodelos como substitutos do simulador em 

algumas áreas, entre elas o ajuste de histórico. Em seu estudo o autor utilizou diferentes técnicas 

para criação dos metamodelos. Seus resultados mostraram que a qualidade do metamodelo é 

altamente dependente da qualidade dos dados de treinamento e de teste, sendo este seu ponto 

fraco. Se o conjunto de entrada possui informações a respeito do ótimo global, então este poderá 

ser encontrado, caso contrário, há uma grande chance de parar em ótimos locais. Tratando 

especificamente de RNA, diferentes topologias geram diferentes resultados. Além disso, elas 

“suavizam” o formato da superfície de resposta (fato que se torna mais evidente em casos em que 

a superfície possui muitas irregularidades), o que gera um erro inerente à aplicação da técnica. 

Assim, conhecer suas limitações e definir um critério de confiabilidade é importante. 

Como pôde ser observado existem inúmeras metodologias para ajuste de histórico, como 

métodos de gradiente, de busca global, algoritmos híbridos, paralelização de simulações, 

utilização de metamodelos e tantos outros não mencionados aqui. Isso reforça o fundamento de 

que o processo de ajuste pode ser extremamente complexo, possuindo particularidades a cada 

caso, de modo que uma ferramenta que serve para um determinado caso pode não servir para 

outro, e vice-e-versa. Assim, estudos e atualizações nessa área devem ser constantemente 

realizados. 

Vários trabalhos mostram que a aplicação de RNA no problema de ajuste de histórico pode 

contribuir para a redução do número de simulações. Porém, conforme ressaltado por Zubarev 

(2009) a qualidade das RNA depende das variáveis de entrada, utilizadas no processo de 

treinamento. Em problemas de ajuste de histórico a escolha das variáveis de entrada influencia 

diretamente nos resultados, em que a quantidade e qualidade dos dados são cruciais para obter 

bons ajustes. Como cada caso possui particularidades, é difícil definir a quantidade mínima 

necessária para proporcionar resultados satisfatórios. A melhor maneira de se determinar a 

quantidade e qualidade desejada dos dados é através da experiência dos profissionais da área e da 

avaliação dos objetivos propostos. Dessa maneira, a compreensão da influência que as variáveis 



 

 

46 

 

de entrada exercem sobre o desempenho do metamodelo gerado por RNA contribui para 

melhorar a qualidade dos resultados proporcionados pela ferramenta. 



 

 

47 

 

4 METODOLOGIA 

Com o intuito de deixar claros os objetivos do estudo e escolher os casos de aplicação mais 

adequados à proposta, a metodologia desse trabalho foi dividida em duas partes. A primeira parte 

consistiu na metodologia geral do trabalho, na qual foram definidos basicamente os objetivos de 

estudo, os casos de aplicação e o procedimento de ajuste a ser adotado. A segunda parte consistiu 

na metodologia específica, em que o procedimento de ajuste foi definido. 

4.1 Metodologia geral do trabalho 

As etapas seguidas pela metodologia geral do trabalho estão descritas no fluxograma da  

Figura 4.1.  

  

Figura 4.1 - Fluxograma descrevendo as etapas utilizadas para realização da metodologia geral do 

trabalho. 

A Etapa1 da metodologia geral consistiu em definir os objetivos a serem alcançados através 

do processo de ajuste. Conforme especificado no Subitem 1.2 (Objetivos), o objetivo foi avaliar a 

aplicação de metamodelos gerados através de redes neurais artificiais no processo de ajuste de 

histórico, e, posteriormente, avaliar a forma de utilização da ferramenta em conjunto com o 

simulador de escoamento. Dessa maneira, o foco não foi conseguir ao final um ajuste perfeito das 

1. Definição dos objetivos do trabalho.

2. Definição dos casos de estudo a serem utilizados no trabalho.

2A. Definição de casos teóricos (validação).

2B. Definição do caso prático (aplicação).

Metodologia geral do trabalho

3. Definição do procedimento de ajuste a ser utilizado, ferramenta 

de otimização e indicadores de qualidade do ajuste.



 

 

48 

 

curvas, mas avaliar a aplicação da ferramenta como substituta do simulador de escoamento ou 

complementar. 

A Etapa2 consistiu em definir os casos de estudo para aplicação da metodologia, sendo 

dividida em duas subetapas.  

Na Etapa 2A foram definidos casos analíticos, de apenas duas variáveis, para avaliar as 

características e limitações com relação à aplicação das RNA, e um caso simples de reservatório 

para validar os resultados obtidos. Como são casos de duas variáveis, foi possível realizar uma 

avaliação direta do comportamento da superfície de resposta gerada pela RNA. 

Na Etapa 2B, foi definido um caso complexo de reservatório com características reais, para 

simular uma aplicação prática. 

 A Etapa3 consistiu em definir o procedimento de ajuste, a ferramenta utilizada para 

otimização e os indicadores de qualidade a serem utilizados nos casos de estudo. 

Para esse trabalho um procedimento semelhante ao de Ertekin et al. (2001) e aos utilizados 

nos trabalhos de Cullick et al. (2006), Maschio et al. (2008) e Sampaio et al. (2009) foi elaborado 

e será descrito no Subitem 4.2 a seguir.  

Para realizar o processo de otimização dos parâmetros foi escolhido o Algoritmo Genético. 

Como indicador da qualidade dos metamodelos gerados, nos casos analíticos, utilizou-se 

principalmente a superfície de resposta para avaliar os resultados. Como indicadores secundários 

foram utilizados o coeficiente de correlação (Equação 3.1) e o erro médio. Para os casos de 

reservatório, foi empregado o coeficiente de correlação como indicador principal para avaliação e 

comparação do desempenho de cada metamodelo gerado, uma vez que não é possível realizar a 

análise visual da superfície de resposta. Os valores do coeficiente de correlação e erro médio são 

calculados entre a saída desejada e a gerada pela RNA. Para o caso prático ainda foi utilizado um 

indicador que mede quanto o modelo ajustado melhorou o afastamento em relação ao Caso Base, 

descrito pela Equação 3.3 e ilustrado na Figura 3.1, além da análise das curvas de produção, 

comparando os resultados do modelo de simulação ajustado com o histórico. 

 



 

 

49 

 

4.2 Metodologia específica - procedimento de ajuste 

O procedimento de ajuste adotado consistiu em utilizar metamodelos gerados através de 

RNA para realizar a parte de alteração dos atributos do reservatório (exploração do espaço de 

soluções). Os passos seguidos para realizar o procedimento de ajuste estão descritos no 

fluxograma mostrado na Figura 4.2. 

 

Figura 4.2 – Fluxograma que descreve os passos seguidos pelo procedimento de ajuste adotado 

nesse trabalho. 

O procedimento mostrado na Figura 4.2 pode ser dividido em duas partes principais; 

treinamento das RNA (geração dos conjuntos de treinamento; treinamento e avaliação dos 

metamodelos gerados – Passos 1 e 2) e a aplicação do metamodelo gerado no processo de ajuste 

de histórico (Passos 3). E adicionalmente, se necessário, Passo 4.  

 

 

Procedimento de ajuste

Início

1. Definição do conjunto de treinamento

2. Treinamento das RNA e análise de 

desempenho dos metamodelos gerados.

3. Otimização utilizando o metamodelo e 

validação do mínimo encontrado.

Fim

4. Retreinamento?Sim

Não



 

 

50 

 

4.2.1 Treinamento das redes neurais artificiais 

O Passo 1 consistiu na definição do conjunto de treinamento, formado pelas entradas e 

saídas desejadas da rede, que são as variáveis de modelagem e as respostas do dado problema, 

respectivamente. Para gerar as entradas foram utilizadas técnicas de amostragem distintas. Dessa 

maneira, conjuntos com diferentes características de espaçamento e quantidade de amostras 

foram obtidos. Ao serem geradas, as entradas foram utilizadas para determinar as saídas 

desejadas, que representam as respostas do problema.  

Os casos analíticos são funções em que a superfície de resposta é descrita por uma equação. 

Assim, as saídas desejadas para esses casos foram determinadas calculando o valor da função, 

dado pela resposta da equação para as duas variáveis de entrada. 

Nos casos de reservatório, as saídas desejadas foram determinadas com o auxílio do 

simulador de escoamento. A entrada gerada (atributos que modelam o reservatório, ou seja, um 

modelo de simulação) é simulada com o simulador de escoamento e as curvas de produção são 

comparadas com o histórico para calcular o afastamento do modelo com relação ao histórico, 

parâmetro que consistiu na saída desejada para esses casos. 

O Passo 2 consistiu no treinamento das RNA e análise de desempenho dos metamodelos 

gerados. Nesse trabalho, a RNA treinada é chamada de metamodelo. Para avaliar o desempenho 

dos metamodelos gerados foram utilizados os indicadores definidos na Etapa 4 da metodologia 

geral (Subitem 4.1).  

A respeito do treinamento das RNA, alguns algoritmos empregados no processo de 

treinamento, que não serão abordados nesse trabalho, possuem certo grau de aleatoriedade, de 

modo que, a cada treinamento, um metamodelo diferente é gerado. Dessa maneira, o processo de 

treinamento foi realizado diversas vezes com a finalidade de encontrar um metamodelo capaz de 

atender aos requisitos com a confiabilidade desejada.  

 

 

 



 

 

51 

 

4.2.2 Aplicação de metamodelos no processo de ajuste de histórico 

Cullick et al. (2006), Maschio et al. (2008) e Sampaio et al. (2009) utilizaram metamodelos 

gerados a partir de RNA para realizar a otimização dos atributos no lugar do simulador de 

escoamento. Apesar de utilizarem diferentes ferramentas para otimização e diferentes FO, a 

metodologia utilizada pelos autores foi capaz de encontrar resultados satisfatórios, e dessa 

maneira, serviu como base para a aplicação do algoritmo genético. 

O Passo 3 do procedimento de ajuste consistiu na otimização utilizando o metamodelo e 

validação do mínimo encontrado. Na otimização utilizou-se o metamodelo gerado para calcular o 

valor da Função Objetivo (FO) a ser minimizada pelo AG. Para validação, nos casos analíticos o 

mínimo encontrado foi comparado com o mínimo global do problema, determinado através da 

otimização utilizando a equação que define cada caso. Já para os casos de reservatório, como na 

prática a resposta não é conhecida, a validação é realizada através da comparação das curvas de 

produção do modelo simulado com o histórico de produção e pressão medido nos poços. O 

modelo simulado consiste no mínimo encontrado através da otimização, em que, conforme 

mencionado, o metamodelo gerado é utilizado para calcular a FO no processo de minimização. 

Uma maneira de melhorar a capacidade de representação e generalização da rede é realizar 

um novo treinamento em uma região específica do espaço de soluções, pois com uma região 

reduzida torna-se mais fácil a representação pelo metamodelo. Com o Passo 3, acredita-se que o 

mínimo encontrado esteja nas proximidades do mínimo global do problema. 

Dessa maneira, para casos em que o valor encontrado com a otimização não atenda aos 

critérios de precisão desejados, mas que estejam relativamente próximos (o quão próximo varia 

de caso a caso) define-se uma região de interesse ao redor do valor encontrado (mínimo) e 

realiza-se novo procedimento de treinamento (repetição dos Passos 1, 2 e 3). Assim, o Passo 4 

consistiu em avaliar e, caso constatada a necessidade, realizar novo treinamento em um 

subdomínio do espaço de busca. 

Para a definição de uma nova faixa de variação dos atributos adotou-se o seguinte 

procedimento:  



 

 

52 

 

? A partir dos resultados da otimização com o metamodelo tomou-se como base os 

indivíduos que geraram valores de FO inferiores a um determinado valor de corte 

(particular a cada caso);  

? Dentre os indivíduos que atendem à condição anterior consideraram-se os limites 

máximo e mínimo de variação dos atributos para nova amostragem, os quais 

definiram uma nova região de interesse.  

Para os casos analíticos, em caso de novo retreinamento, a definição da nova região para 

amostragem foi feita a partir da avaliação visual da superfície de resposta, por ser mais direta e 

precisa. 



 

 

53 

 

5 APLICAÇÃO 

Esse capítulo é dedicado à apresentação dos casos de estudo aos quais a metodologia 

proposta foi aplicada. Foram escolhidos quatro casos analíticos, um caso de reservatório simples 

(validação) e um caso de reservatório complexo com características reais.  

5.1 Casos analíticos 

Para os casos analíticos, primeiramente foi escolhido um caso simples para iniciar os 

estudos; posteriormente, um caso em que a superfície de resposta a ser modelada possui alguma 

irregularidade, com um mínimo global e um local; um caso com diversas irregularidades, com 

mais de um mínimo global e diversos mínimos locais (diversas regiões de interesse) e, 

finalmente, um caso em que a superfície de resposta é modelada por mais de uma função. Com 

isso buscou-se avaliar as características e limitações da ferramenta para casos com diferentes 

graus de dificuldade. 

5.1.1 Premissas e considerações 

Os casos analíticos consistiram em casos de duas variáveis, em que a superfície de reposta é 

descrita por uma equação. 

O mínimo global de cada problema foi determinado através do processo de otimização, 

utilizando a equação que descreve a função para calcular o valor da Função Objetivo. O mínimo 

encontrado nesse processo foi considerado como sendo o mínimo global da função.  

Para esses casos, a superfície de resposta foi utilizada como parâmetro principal na 

avaliação do desempenho do metamodelo gerado. 



 

 

54 

 

Como complementos foram utilizados o coeficiente de correlação, cuja expressão foi 

mostrada na Equação 3.1 (Capítulo 3), e o erro entre a saída desejada e gerada pelo metamodelo, 

mostrado abaixo na Equação 5.1. 

   
?[(

         
    

)     ]

 
 

Equação 5.1 

em que      representa os dados simulados com o metamodelo,      representa os dados 

calculados diretamente com a função analítica e   representa o número total de amostras 

5.1.2 Caso 1A 

O Caso 1A é o mais simples, representado por uma superfície com concavidade voltada 

para baixo e com um mínimo global, conforme mostra a Figura 5.1. Esse caso foi utilizado 

apenas para iniciar os estudos, com o intuito de mostrar que para casos extremamente simples a 

RNA modela a resposta desejada sem dificuldades. 

 

Figura 5.1 – Superfície de resposta para o Caso 1A. 

 



 

 

55 

 

A saída desejada para treinar a RNA consistiu no valor da função que modela a superfície, 

mostrada pela Equação 5.2: 

        Equação 5.2 

5.1.3 Caso 1B 

A superfície de resposta do Caso 1B é mostrada na Figura 5.2, a seguir: 

 

Figura 5.2 – Superfície de resposta para o Caso 1B. 

A saída desejada para treinar a RNA consistiu no valor da função que modela a superfície, 

mostrada pela Equação 5.3: 

    (    )    ( 
  (   ) )     (  ?       )   (  

    )   ... 

  ?   ( (   )
    ) 

Equação 5.3 

Como pode ser observado na Figura 5.2, a superfície de resposta para esse caso possui um 

mínimo global e um mínimo local. 

 



 

 

56 

 

5.1.4 Caso 1C 

Esse caso possui uma superfície de resposta irregular, com mais de um mínimo global 

(quatro no total) e diversos mínimos locais, conforme pode ser observado na Figura 5.3: 

 

Figura 5.3 – Superfície de resposta para o Caso 1C. 

A saída desejada para treinar a RNA consistiu no valor da função que modela a superfície, 

mostrada pela Equação 5.4: 

       (   )       (     )    Equação 5.4 

5.1.5 Caso 1D 

O Caso 1D é modelado por uma função pré-definida pelo Matlab chamada NonSmothFcn, 

formada por três diferentes superfícies e possui apenas um mínimo global, conforme pode ser 

visualizado na Figura 5.4. 



 

 

57 

 

 

Figura 5.4 – Superfície de resposta para o Caso 1D. 

A saída desejada para treinar a RNA consistiu no valor da função no espaço que é retornada 

automaticamente através da função NonSmothFcn do Matlab. 

5.2 Casos de reservatório 

Para os dois casos de reservatório (2A e 2B) utilizou-se o mesmo modelo, porém para o 

Caso 2A foram realizadas algumas modificações para simular um caso simples de validação dos 

resultados obtidos com o estudo dos casos analíticos.  

5.2.1 Premissas e considerações 

Trata-se de um reservatório sintético no qual o histórico é conhecido. Os atributos incertos 

do reservatório são fornecidos, de forma que se considera que sejam os que mais influenciam na 

produção de água do reservatório.  

Para os casos de reservatório foi utilizado como indicador principal para avaliação de 

desempenho o coeficiente de correlação linear entre saída do metamodelo e do simulador. Como 

não é possível realizar a visualização da superfície de resposta, graficamente foi utilizada a 



 

 

58 

 

relação entre os afastamentos gerados através da simulação com o simulador de escoamento 

(histórico) e aqueles gerados através da simulação com os metamodelos. 

5.2.2 Reservatório utilizado 

O modelo, construído sinteticamente através de técnicas geoestatísticas, é mostrado na 

Figura 5.5. 

 

Figura 5.5 - Modelo de reservatório (permeabilidade horizontal – md). 

O modelo mostrado na Figura 5.5 representa um reservatório de óleo leve, cujo mecanismo 

de produção natural é a expansão de líquido e gás em solução e o mecanismo de recuperação é a 

injeção de água. Ele foi discretizado em uma malha corner point com dimensão 90x110x5 

(49500 blocos), é composto por três fácies caracterizadas de acordo com três faixas de 

permeabilidades (baixa, intermediária e alta) e possui quatro falhas, representadas pelas linhas em 

preto na Figura 5.5. Um modelo de referência (escolhido dentre as possíveis combinações dos 

dezesseis atributos incertos do problema) foi simulado para gerar o histórico de dez anos. O 

reservatório é drenado por quinze poços verticais (oito produtores e sete injetores). Os dezesseis 

atributos, considerados de maior impacto sobre o comportamento do reservatório são mostrados 

no Subitem 5.2.4. 



 

 

59 

 

5.2.3 Caso 2A 

Os atributos incertos do reservatório para o Caso 2A foram definidos como sendo o 

multiplicador da porosidade da fácies 2, o multiplicador do logaritmo da permeabilidade 

horizontal da fácies 2, a transmissibilidade da falha 3 e o expoente do modelo de Corey para a 

permeabilidade relativa da água da fácies 2, totalizando 4 atributos incertos, que estão elencados 

na Tabela 5.1.  

Tabela 5.1 – Atributos incertos para o caso 2A. 

Atributos Descrição Tipo Min. Máx. 

1 Porosidade (Por2) – fácies 2 Multiplicador 0.85 1.15 

2 Permeabilidade horizontal (kx2) - fácies 2 Multiplicador do log. (kx) 0.75 1.1 

3 Transmissibilidade da falha (T3) Multiplicador 0 1 

4 Permeabilidade relativa (kr2) - fácies 2 
Expoente da fase água 

(modelo de Corey) 
1 5 

 

Para esse caso o problema consistiu em realizar o ajuste da vazão de água do campo 

(apenas uma saída). Assim, para gerar os metamodelos, os valores de saída desejada utilizados 

foram o afastamento da vazão de água do campo (entre modelo simulado e o histórico). 

5.2.4 Caso 2B 

Para o Caso 2B os atributos incertos foram definidos como sendo o multiplicador do 

logaritmo da permeabilidade horizontal, multiplicador da porosidade, razão entre 

permeabilidades vertical e horizontal e o expoente do modelo de Corey para permeabilidade 

relativa da água. Como o modelo é caracterizado por três fácies, conforme citado anteriormente 

no Subitem 5.2.2, os atributos incertos são considerados distintos para cada fácies. O modelo 

ainda possui quatro falhas, conforme pode ser observado na Figura 5.5. A transmissibilidade de 

cada falha também foi incluída na lista de atributos incertos, totalizando, assim, dezesseis 

variáveis incertas, mostradas na Tabela 5.2, que serão modificadas no processo. 

 

 



 

 

60 

 

Tabela 5.2 – Atributos incertos para Caso 2B. 

Atributos Descrição Tipo Min. Máx. 

1 ao 3 Porosidade (Por1-3) Multiplicador 0.85 1.15 

4 ao 6 Permeabilidade horizontal (kx1-3) Multiplicador do log. (kx) 0.75 1.1 

7 ao 9 Permeabilidade vertical (kz1-3) Porcentagem de kx 4 25 

10 ao 13 Transmissibilidade da falha (T1-4) Multiplicador 0 1 

14 ao 16 Permeabilidade relativa (kr1-3) 
Expoente da fase água 

(modelo de Corey) 
1 5 

 

O objetivo desse caso foi realizar o ajuste de vazão de água de cada poço (oito poços 

produtores), sendo assim, o problema composto por uma Função Objetivo calculada pela média 

de oito componentes a ser minimizada. Deste modo, cada valor de saída desejada, utilizada para 

gerar os metamodelos, corresponde ao afastamento de um poço (diferença entre vazão de água do 

modelo simulado e o histórico). 

5.3 Geração dos conjuntos de entrada para treinamento  

Para a amostragem dos conjuntos de entrada foram utilizadas as técnicas de Hipercubo 

Latino (HL), Sequencia de Sobol (SS) e Box Behnken (BB). Com isso obtiveram-se amostras 

dispostas de forma diferente no espaço dos parâmetros. Adicionalmente a esse fator foram 

gerados amostras de 25, 50 e 100 pontos para os Casos 1A a 1D. Para o Caso 2A as mesmas 

quantidades de pontos foram amostradas, porém utilizando apenas a técnica do HL. Para o Caso 

2B, 100, 250 e 396 pontos foram amostrados utilizando as técnicas do HL e BB (apenas um 

conjunto com 396 pontos, que é o número de combinações pré-fixado pela técnica de Box 

Behnken para 16 variáveis). Nos casos de reservatório, cada conjunto de dados de entrada 

amostrado representa um modelo de simulação. 

Uma observação a ser feita é que a técnica do BB, conforme mencionado no Subitem 2.5, 

para poucas variáveis a quantidade de pontos amostrados é muito baixa. Por isso ela foi aplicada 

apenas para o Caso 2B, que contém 16 variáveis de entrada (resultando em 396 amostras: 16 

atributos, 3 níveis = 16
3
 pontos). Dessa maneira, para os Casos 1A e 1D foi utilizada a SS, a fim 

de obter uma comparação entre dados com diferentes características de espaçamento. No Caso 

2A, como foi utilizado apenas para validação, aplicou-se somente o HL para gerar os dados. 



 

 

61 

 

Com relação aos dados de teste, nos Casos 1A a 1D, os pontos de treinamento gerados por 

uma técnica foram utilizados como pontos de teste para a outra e vice-e-versa, ou seja, foram 

utilizados os 100 pontos amostrados da SS para testar os metamodelos gerados com dados do HL 

e os 100 pontos amostrados pelo HL para testar os metamodelos gerados com dados da SS. Já 

para o Caso 2A foram gerados 25 pontos pelo HL e para o Caso 2B foram gerados 100 pontos 

pelo HL para realizarem as simulações de teste. 

As saídas desejadas, para os Casos 1A a 1D foram calculadas utilizando a equação que 

define cada caso. Já para os casos de reservatório, foram geradas através do simulador de 

escoamento utilizando o programa IMEX da CMG. Os dados de produção de água, resultantes da 

simulação, foram comparados com o histórico de produção disponível e o afastamento foi 

calculado, compondo dessa maneira as saídas desejadas para esses casos.  

Conforme citado anteriormente, para o Caso 2A o afastamento do campo foi utilizado. Já 

para o Caso 2B, foi usado o afastamento poço a poço. A fórmula utilizada para calcular o 

afastamento é a mesma mostrada na Equação 2.1, considerando o valor do peso igual a “1” para 

todos os dados, resultando na expressão mostrada na Equação 5.5. 

  ?(    
      

 )
 

 

   

 Equação 5.5 

em que   representa o número de dados observados de cada série (produção de água, por 

exemplo),     
  e     

 
 são os dados observados e simulados, respectivamente. 

Para o Caso 2B, foi realizada a análise de sensibilidade para gerar conjuntos adicionais de 

entrada a fim de melhorar a qualidade dos resultados e realizar comparações entre os diversos 

metamodelos gerados. Assim, para entrada foram utilizadas duas opções de configuração:  

? Opção 1: utilizar todos os atributos incertos; 

? Opção 2: utilizar os atributos determinados através da AS.  

Nesse procedimento foram realizadas simulações (com o simulador de escoamento) com 

valores extremos de cada atributo (máximo e mínimo) enquanto se mantém as outras no valor do 

Caso Base (valor médio). Assim, avaliou-se quanto o afastamento dos poços variou com um dado 



 

 

62 

 

atributo em relação ao afastamento do Caso Base, possibilitando, dessa maneira, identificar quais 

atributos influenciam mais a FO para o caso a ser estudado. Com isso, determinaram-se os 

seguintes atributos para treinar a RNA, mostrados na Tabela 5.3. 

Tabela 5.3 – Atributos que mais influenciam os poços. 

Atributo Atributo 
Poço 

Média 
1 2 3 4 5 6 7 8 

Porosidade (Por) 

1 x         

2 x x x  x x x x x 

3  x x   x   x 

Permeabilidade horizontal (kx) 

4  x   x x  x x 

5 x  x  x x  x x 

6 x x    x  x x 

Permeabilidade vertical (kz) 

7          

8  x   x   x x 

9   x   x    

Transmissibilidade da falha (T) 

10      x    

11 x x        

12      x    

13   x x x  x  x 

Permeabilidade relativa (kr) 

14 x       x  

15 x x x x x x x x x 

16  x x x x x   x 

 

Na Tabela 5.3, os atributos marcados com “x” representam aqueles considerados de maior 

impacto sobre cada poço e sobre a média dos oito poços, em relação ao comportamento da curva 

de produção de água. Para tanto foram considerados aqueles atributos nos quais a soma das 

variações causadas pela alteração de seus valores para os limites máximo e mínimo resultaram 

em valor maior ou igual a 20%. 

Para saída da RNA também foram definidas duas configurações diferentes:  

? Opção 1: treinar uma RNA para cada poço, ou seja, treinar oito RNA 

independentes, de uma saída;  

? Opção 2: treinar uma RNA para os oito poços, ou seja, ou RNA com oito saídas.  

Assim, os atributos marcados nas colunas “Poço 1” a “Poço 8” foram escolhidos para 

compor os dados de treinamento para treinar uma RNA para representar cada poço, e os atributos 



 

 

63 

 

selecionados na coluna “Média” foram utilizados na opção em que foi treinada uma RNA para 

representar os oito poços. 

Juntando as duas opções de configuração para entrada e para a saída, puderam-se definir 

quatro opções de configuração de RNA a serem estudadas nesse caso: 

? Opção 1 (PP_SAS – por poço, sem análise de sensibilidade):  

o Entrada: todos os dezesseis atributos incertos do reservatório; 

o Saída: treinamento de oito RNA de uma saída, cada uma representando um 

poço produtor. 

? Opção 2 (PROD_SAS – produtores, sem análise de sensibilidade): 

o Entrada: todos os dezesseis atributos incertos do reservatório; 

o Saída: treinamento de uma RNA com oito saídas, representando os oito 

poços produtores. 

? Opção 3 (PP_AS – por poço, com análise de sensibilidade):  

o Entrada: apenas os atributos que mais influenciam no comportamento de 

cada poço. Nesse caso quais atributos são utilizados como entrada para cada 

RNA varia. Por exemplo, para a RNA treinada para representar o poço 

PROD4, de acordo com o resultado da AS mostrada na Tabela 5.3, foram 

utilizados como entrada os atributos 13, 15 e 16.  

o Saída: treinamento de oito RNA de uma saída, cada uma representando um 

poço produtor. 

? Opção 4 (PROD_AS – produtores, com análise sensibilidade): 

o Entrada: apenas os atributos que mais influenciam no comportamento dos 

oito poços produtores, ou seja, mais influenciam na média do afastamento da 

vazão de água dos oito poços produtores. 

o Saída: treinamento de uma RNA com oito saídas, representando os oito 

poços produtores. 

Resumindo, as configurações de RNA aplicadas a cada caso foram: 

 

 



 

 

64 

 

Casos 1A a 1D: 

o Dados de treinamento: 

o 25, 50 e 100 pontos gerados pela técnica do HL 

o 25, 50 e 100 pontos gerados pela técnica da SS 

o Dados de teste: 

o RNA treinadas com pontos do HL: 100 pontos gerados pela técnica da SS  

o RNA treinadas com pontos da SS: 100 pontos gerados pela técnica do HL  

o Configurações de RNA:  

o Entrada: as duas variáveis de modelagem da função 

o Saída: uma rede para representar o valor da função no ponto 

Caso 2A: 

o Dados de treinamento: 

o 25, 50 e 100 pontos gerados pela técnica do HL 

o Dados de teste:  

o 25 pontos gerados pela técnica do HL 

o Configurações de RNA:  

o Entrada: quatro atributos incertos do reservatório (Tabela 5.2) 

o Saída: uma rede para representar o afastamento da produção de água do modelo 

simulado com relação ao histórico 

Caso 2B: 

o Dados de treinamento: 

o 100, 250 e 396 pontos gerados pela técnica do HL 

o 396 pontos gerados pela técnica do BB 

o Dados de teste:  

o 100 pontos gerados pela técnica do HL 

o Configurações de RNA:  

o As quatro opções descritas anteriormente, 



 

 

65 

 

5.4 Treinamento das redes neurais artificias 

Para treinar uma RNA é necessário inicialmente criá-la e configurá-la. Para isso foi 

utilizado o software MATLAB
®

 da Mathworks Inc., pois ele possui um Toolbox de RNA (Neural 

Network Toolbox) o qual disponibiliza diversas estruturas, algoritmos e funções pré-definidas, 

cabendo ao usuário configurar a rede da maneira que desejar. Os principais parâmetros 

configurados são mostrados a seguir. 

? Tipo de rede Feed-Forward completamente ligada. 

? Funções de transferência do tipo tangente hiperbólica na camada oculta e linear 

(Casos 1A a 1D e 2A) ou tangente hiperbólica (Casos 2A e 2B) na camada de saída. 

? Métodos de pré e pós-processamento dos dados: fixunknnows, removeconstantrows 

e mapminmax para os dados de entrada e removeconstantrows e mapminmax para os 

dados de saída. A função fixunknnows transforma linhas contendo valores definidos 

como NAN (desconhecidos) em linhas que processam a mesma informação 

numericamente; a função removeconstantrows remove linhas com valores 

constantes e a função mapminmax transforma valores para intervalos entre -1 e 1 

(normalização). 

? Algoritmo de treinamento Levenberg-Marquardt com Regularização Bayesiana -

trainbr- (maiores informações no Capítulo 2, de fundamentação teórica). 

? Método para prevenir contra memorização Early Stopping: separação do conjunto 

de treinamento em três partes: treinamento, validação e teste. O conjunto de 

treinamento é utilizado para atualizar os valores dos pesos; o conjunto de validação 

serve para que, de tempo em tempo, a rede seja testada para verificar se está 

havendo memorização dos dados e, caso positivo, parar o treinamento no momento 

em que a rede começar a perder a capacidade de generalização (erro de treinamento 

baixo, porém erro de validação alto); e o conjunto de teste serve parar testar a rede 

após o treinamento. Os dados são separados de forma aleatória, de maneira que o 

treinamento deve ser realizado diversas vezes para obter resultados satisfatórios. O 

valor default é 60%, 20% e 20% (treino, validação e teste) do total de dados de 

treinamento e foi o valor adotado nesse trabalho. 



 

 

66 

 

Ainda existe o algoritmo de inicialização dos pesos da rede. Esse algoritmo utiliza um 

padrão tal que os valores dos pesos são inicializados em uma faixa determinada com certo grau 

de aleatoriedade. Assim, a cada inicialização têm-se diferentes valores dos pesos, o que pode 

levar a RNA diferentes no final do treinamento. Portanto, é altamente recomendável realizar 

diversos treinamentos com a mesma configuração para determinar o melhor modelo para o 

problema.  

Com base nas sugestões de Silva e Oliveira (2004), para os Casos 1A a 1D e Caso 2A foi 

utilizada uma camada oculta e para o Caso 2B,  de maior complexidade, foram testadas uma, 

duas e três camadas para treinar as redes. Para o número de neurônios em cada camada utilizou-

se um valor tal que a quantidade de sinapses fosse em torno de dez vezes menor do que o número 

de amostras utilizadas para treinamento. Para o Caso 2B foram testados mais valores situados ao 

redor desse patamar para expandir o horizonte de resultados.  

Ainda em relação ao Caso 2B, devido à complexidade do problema, foi testada a geração 

de um metamodelo por poço e um metamodelo para os oito poços produtores, ou seja, foram 

treinadas oito redes de uma saída e uma única rede com oito saídas. Dentre essas duas 

possibilidades, foram utilizadas como entrada um conjunto de dados contendo as dezesseis 

variáveis incertas e um conjunto de dados provenientes da análise de sensibilidade, conforme 

descrito no Item 5.3. 

5.5 Otimização  

O processo de otimização foi realizado utilizando o algoritmo genético. O MATLAB
®

 

também disponibiliza um Toolbox (Global Optimization Toolbox) para essa técnica já com as 

configurações padrão. Foram utilizadas para todos os casos essas configurações com algumas 

modificações, julgadas necessárias a cada caso. A Tabela 5.4 mostra os valores dos parâmetros 

principais que foram utilizados pelo AG nos processos de otimização. O tamanho da população 

refere-se à quantidade de modelos que serão utilizados em cada iteração; o número máximo de 

gerações representa o máximo de iterações que o algoritmo irá executar; a fração de crossover 

indica quantos indivíduos, do total, sofrerão recombinação (crossover); e a taxa de mutação 

representa a probabilidade de o indivíduo sofrer mutação. 



 

 

67 

 

Tabela 5.4 – Principais parâmetros utilizados pelo AG. 

Parâmetro 
Valor 

Casos 1A a 1D Caso 2A Caso 2B 

Tamanho da população 50 50 50 

Máximo de gerações 100 500 500 

Fração de crossover 0.6 0.8 0.8 

Taxa de mutação 50% 50% 50% 





 

 

69 

 

6 RESULTADOS E DISCUSSÃO 

Os resultados mostrados nesse capítulo referem-se à aplicação do procedimento de ajuste 

definido no Subitem 4.2 de Metodologia. 

Conforme citado no Subitem 4.1, primeiramente foram estudados os casos analíticos 

(Casos 1A a 1D) e, posteriormente, o caso intermediário (Caso 2A) e complexo (Caso 2B). 

Assim, os itens subsequentes foram ordenados dessa maneira: casos analíticos, caso intermediário 

e caso complexo, seguindo os passos do procedimento de ajuste adotado. 

Conforme detalhado no capítulo de aplicação, foram utilizados diferentes conjuntos de 

pontos para treinamento, gerados através das técnicas do HL e SS. Nos itens subsequentes, no 

entanto, não serão mostrados todos os gráficos e resultados devido ao grande volume de dados 

obtidos. Serão mostrados apenas alguns resultados, considerados de maior relevância para as 

conclusões. 

6.1 Caso 1A 

6.1.1 Passo 1: Definição do conjunto de treinamento 

A Figura 6.1 mostra os conjuntos de treinamento de 25 pontos amostrados utilizando as 

técnicas do HL (a) e SS (b), respectivamente, representados pelos pontos em preto, sobrepostos 

na superfície de resposta, gerada pela função analítica. 



 

 

70 

 

 

(a) (b) 

Figura 6.1 – Amostragem no espaço do conjunto de treinamento de 25 pontos; HL (a) e SS (b) – 

Caso 1A. 

Pela Figura 6.1 observa-se que o HL proporcionou espaçamento melhor dos pontos do que 

a SS, que possui algumas regiões concentradas de pontos. Pode-se observar ainda que 25 pontos 

são capazes de proporcionar boa cobertura de todo o espaço. Para os demais conjuntos de pontos 

pôde-se observar melhor cobertura do espaço de soluções e a diminuição dos espaços vazios 

entre pontos, constantes na  Figura 6.1 (b). 

6.1.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho dos 

metamodelos gerados 

Por se tratar de um caso muito simples, pouca diferença com relação à qualidade do 

metamodelo pôde ser observada entre os dados gerados com HL25 e SS25.  

Para obter um comparativo entre quantidade de amostras, a Figura 6.2 mostra as saídas dos 

metamodelos, gerados através do treinamento das RNA com HL25 (a) e HL50 (b) pontos. 



 

 

71 

 

 

(a) (b) 

Figura 6.2 – Superfícies de resposta e conjunto de teste, para os metamodelos gerados com HL25 

(a) e HL50 (b) – Caso 1A. Pontos em azul: erro médio menor que 1% e pontos em vermelho: erro 

médio maior ou igual a 1%. 

Pode-se observar que o erro para o metamodelo gerado com HL50 pontos foi menor, 

mostrando que o aumento da quantidade de amostras para treinamento melhorou a capacidade de 

representação. 

O erro pode ser visualizado de forma diferente na Figura 6.3, que mostra os gráficos do erro 

em função da coordenada do eixo horizontal, para os metamodelos gerados com HL25 (a) e 

HL50 (b) pontos, em que são mostrados apenas os pontos nos quais o erro foi menor que 4% e 

0.012% para os metamodelos gerados com HL25 e HL50 pontos, respectivamente.  

 



 

 

72 

 

 

(a) (b) 

Figura 6.3 – Visualização dos erros ponto a ponto para os metamodelos gerados com HL25 (a) e 

HL50 (b) pontos – Caso 1A. 

Os valores dos coeficientes de correlação linear e erro médio entre saídas do metamodelo e 

saídas calculadas pela equação que modela a função, referentes ao conjunto de teste estão 

mostrados na Tabela 6.1. 

6.1.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo encontrado 

Os valores dos mínimos encontrados, assim como suas respectivas localizações no espaço 

estão mostrados na Tabela 6.1. Observa-se que a utilização de 25 amostras para treinamento foi 

suficiente para alcançar resultados satisfatórios, pois o metamodelo Caso1A_RNA_HL25 

encontrou uma coordenada para o mínimo muito próximo da localização real do mínimo global 

(0,0). Observa-se ainda que a adição de mais amostras para treinamento ajudou a melhorar a 

precisão.  

É importante salientar que, mesmo com muitos pontos, o erro ainda existe, pois o mínimo 

global não está incluído no conjunto de treinamento, o que induz a RNA a “suavizar” a superfície 

nessa área. 

-10 -5 0 5 10
0

1

2

3

4

x

E
rr

o
 (

%
)

-10 -5 0 5 10
0

0.002

0.004

0.006

0.008

0.01

0.012

x

E
rr

o
 (

%
)



 

 

73 

 

Comparando-se os resultados obtidos entre os metamodelos gerados com HL e SS, 

observa-se que os resultados foram bem próximos, não sendo possível concluir qual tipo de 

ferramenta de amostragem foi a melhor. 

Nesse caso não foi necessário realizar o processo de retreinamento, pois conforme 

mostrado através dos gráficos e tabela apresentados, a região de mínimo foi identificada com 

precisão com apenas 25 pontos. 

Tabela 6.1 – Coeficiente de correlação linear, erro médio e mínimo determinados através da 

otimização utilizando o metamodelo - Caso 1A. 

Tipo de 

dado 

Nome 

Metamodelo 

Erro 

(%) 

Coeficiente 

correlação 

Mínimo 

(FO) 
Variável x Variável y 

HL25 Caso1A_RNA_HL25 0.4195 0.9999 0.16320 0.012000 0.001400 

HL50 Caso1A_RNA _ HL50 0.0017

1 
1.0000 0.01700 -0.0000398 0.000034 

HL100 Caso1A_RNA _ HL100 0.0011 1.0000 0.000192 0.0000235 0.000257 

SS25 Caso1A_RNA _ SS25 0.6919 0.9999 0.07630 0.022700 0.014100 

SS50 Caso1A_RNA _ SS50 0.0065 1.0000 0.00100 -0.000227 -0.0000357 

SS100 Caso1A_RNA _ SS100 0.0021 1.0000 -0.00034 0.000095 0.0000518 

6.2 Caso 1B 

6.2.1 Passo 1: Definição do conjunto de treinamento 

A Figura 6.4 mostra os pontos amostrados para treinamento (em preto) no espaço de busca 

dos parâmetros para os conjuntos de HL25 (a) e SS25 (b) pontos.  



 

 

74 

 

 

(a) (b) 

Figura 6.4 – Amostras de 25 pontos, do HL (a) e da SS (b) para treinamento – Caso 1B. 

Observa-se que com 25 pontos poucas informações do comportamento da superfície foram 

obtidas. Por outro lado, dentre os 25 pontos do HL, um deles se situa na região de interesse, 

próxima do mínimo global, o que pode fazer com que essa região seja identificada pelo 

metamodelo gerado.  

A Figura 6.5 mostra os conjuntos de treinamento para HL50 e SS50 pontos. 

 

(a) (b) 

Figura 6.5 - Amostras de 50 pontos, do HL (a) e da SS (b) para treinamento – Caso 1B. 

Observa-se que com 50 pontos, informações mais detalhadas sobre a superfície de resposta 

foram amostradas. Porém, ainda existem espaços vazios, o que pode fazer com que nessas regiões 



 

 

75 

 

a precisão seja inferior às demais. No entanto, a presença de um número maior de amostras nas 

vizinhanças pode fazer com que uma representação satisfatória seja obtida (padrão de 

comportamento dessas regiões seja representado). 

Apesar de não apresentada, a amostragem com 100 pontos, para as duas técnicas, foi capaz 

de proporcionar uma boa cobertura do espaço de soluções. 

6.2.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho dos 

metamodelos gerados 

As superfícies de resposta dos metamodelos gerados com HL25 e SS25 pontos são 

mostradas na Figura 6.6 (a) e (b), respectivamente. Para mostrar os pontos sobre o espaço foi 

utilizado um ângulo de visão diferente para proporcionar uma avaliação mais eficiente da 

distribuição dos mesmos. Por outro lado, para mostrar a superfície de reposta do metamodelo foi 

utilizado outro ângulo de visão, com o intuito de proporcionar uma avaliação mais eficiente de 

todas as irregularidades presentes. Esse padrão foi aplicado para todos os casos analíticos 

apresentados.  

 

(a) (b) 

Figura 6.6 – Superfícies de resposta dos metamodelos gerados com 25 pontos do HL (a) e da SS 

(b) – Caso 1B. 



 

 

76 

 

Pela Figura 6.6, observa-se que apesar de apresentar maior dificuldade em relação ao Caso 

1A, o metamodelo gerado com HL25 pontos foi capaz de identificar a região de mínimo. É de se 

notar que nas regiões às quais pouca ou nenhuma informação (amostragem) foi obtida, o 

metamodelo não proporcionou boa representação. Esse aspecto pode ser analisado comparando-

se as imagens da Figura 6.6 com as da Figura 6.4, que mostram as regiões com e sem informação 

na amostragem. 

Observa-se ainda que, conforme previsto no Subitem 6.2.1, a presença de uma amostra 

dentro da região de interesse fez com que o metamodelo fosse capaz de fornecer uma boa 

modelagem dessa região. Da mesma forma a ausência de amostras dentro dessa área para o 

conjunto SS25 fez com que o metamodelo gerado com esse conjunto não a representasse bem. A 

comparação entre as duas superfícies da Figura 6.6 deixa claro que a representação 

proporcionada pelo metamodelo gerado com 25 pontos do HL foi superior a SS, conforme 

previsto no Subitem 6.2.1. 

A Tabela 6.2 mostra os valores dos coeficientes de correlação e do erro médio entre saída 

do metamodelo e da equação que modela a superfície, relativos ao conjunto de teste para todos os 

metamodelos.  

Observa-se que foram obtidos valores elevados para o erro médio. O motivo se deve ao fato 

de a parte plana da superfície de resposta desse caso situar-se muito próxima do zero 

(z=4.1030x10
-5

), de modo que, assim como no Caso 1A, qualquer valor um pouco diferente desse 

ponto acabou gerando erro elevado. Uma possível saída seria utilizar a diferença simples para 

medição do erro ao invés da Equação 5.1, ou adicionar uma constante à função para “elevar” a 

superfície de resposta de modo a evitar a realização de cálculos de valores próximos do zero.  

Ao se compararem os valores dos coeficientes de correlação dos metamodelos gerados com 

HL25 e SS25, os valores foram semelhantes, porém, como mostra a Figura 6.6, a superfície 

modelada com cada um foi diferente. Assim, através da análise dos resultados fica clara a 

importância de realizar a avaliação conjunta entre resultados numéricos e gráficos, pois a 

avaliação de apenas um deles isoladamente pode levar a conclusões equivocadas. 

Com o aumento do número de amostras para 50 e 100 pontos, para ambas as técnicas, a 

representação da superfície de resposta proporcionada pelos metamodelos melhorou 



 

 

77 

 

significativamente, conforme pode ser observado pelos coeficientes de correlação mostrados na 

Tabela 6.2, que superaram 0.97, e pelos resultados gráficos apresentados na Figura 6.7, que 

mostram as superfícies de resposta dos metamodelos gerados com HL25 (a), HL50 (b), HL100 

(c) pontos e a superfície da função analítica (d). 

 

(a) (b) 

 

(c) (d) 

Figura 6.7 - Superfícies de resposta dos metamodelos gerados com HL25 (a), HL50 (b), HL100 

(c) pontos e da função analítica (d) – Caso 1B. 

A partir da visualização das superfícies da Figura 6.7, fica clara a melhora na qualidade da 

superfície gerada pelos metamodelos com o aumento do número de amostras, podendo observar 

como a superfície vai se assemelhando à da função analítica com a adição de mais amostras para 

treinamento. 



 

 

78 

 

6.2.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo encontrado 

Os valores dos mínimos encontrados, assim como suas coordenadas no espaço para a 

otimização utilizando os metamodelos gerados estão mostradas na Tabela 6.2, que também 

mostra o mínimo e suas coordenadas para a função analítica (“Função peaks”). 

Apesar da semelhança numérica entre os coeficientes de correlação linear obtidos com os 

metamodelos gerados com HL25 e SS25 (0.6911 e 0.7110, respectivamente), o valor final da 

otimização para o metamodelo Caso1B_RNA_HL25 foi melhor (valor do mínimo), conforme 

comprovado visualmente pela Figura 6.6.  

Tabela 6.2 – Coeficiente de correlação linear, erro médio e mínimo determinados através da 

otimização utilizando o metamodelo - Caso 1B. 

Tipo de 

dado 

Nome 

Rede 

Erro 

médio (%) 

Coeficiente 

correlação 
Mínimo Variável x Variável y 

- Função peaks - - -6.5511 0.2258 -1.6258 

HL25 Caso1B_RNA_HL25 22590 0.6911 -5.6154 0.2258 -1.7159 

HL50 Caso1B_RNA_HL50 12849 0.9755 -6.4047 0.2878 -1.5755 

HL100 Caso1B_RNA_HL100 3032.2 0.9993 -6.5550 0.2106 -1.6257 

SS25 Caso1B_RNA_SS25 8200.8 0.7110 -1.8480 0.4061 -1.9087 

SS50 Caso1B_RNA_SS50 6563.5 0.9786 -5.3705 0.2572 -1.5941 

SS100 Caso1B_RNA_SS100 4346.3 0.9996 -6.5573 0.2325 -1.6353 

6.2.4 Passo 4: Retreinamento 

A partir dos resultados da otimização utilizando o metamodelo Caso1B_RNA_HL25 

definiu-se uma nova região de busca, de acordo com o mínimo encontrado na otimização. O 

critério adotado para definir a nova região de amostragem foi baseado em uma inspeção visual. 

Uma vez que os casos teóricos possibilitarem avaliar diretamente a superfície de resposta, a 

definição da nova região também foi realizada de forma direta, sem utilizar o critério de valor de 

corte, conforme consta na metodologia. Assim, a partir das coordenadas do mínimo encontrado 

pela otimização utilizando o metamodelo, foi considerada uma região ao redor com distância 

unitária, respeitando os limites máximos dos parâmetros. 



 

 

79 

 

A Tabela 6.3 mostra as coordenadas do mínimo encontrado com a otimização utilizando o 

metamodelo e o novo limite de variação dos parâmetros para amostragem. 

Tabela 6.3 – Definição dos novos limites para retreinamento – Caso 1B. 

Metamodelo 
Coordenada do 

mínimo x 

Coordenada do 

mínimo y 

Novos limites- 

variável x 

Novos limites-

variável y 

RNA_caso2_HL25 0.2258 -1.7159 [-0.7, 1.3] [-2.7, -0.7] 

  

Na Figura 6.8 (a) é mostrado o novo limite de variação dos parâmetros (área em negrito) e 

os respectivos pontos amostrados (em vermelho, sendo amostrados 25 pontos pelo HL), e a 

Figura 6.8 (b) mostra a superfície de resposta do metamodelo gerado com o novo treinamento 

(região em negrito da Figura 6.8 (a)), em que os pontos em vermelho representam regiões onde o 

erro em relação à superfície da função analítica ultrapassa 10% e os pontos em azul representam 

erros até 10%.  

 

(a) (b) 

Figura 6.8 – Conjunto de treinamento e novos limites (a) e superfície de resposta do metamodelo 

gerado (b), relativos ao retreinamento – Caso 1B. 

Os valores encontrados com a otimização utilizando o novo metamodelo são mostrados na  

Tabela 6.4, juntamente com os resultados do treinamento com 25 e 100 pontos e da função 

analítica (Peaks). O erro médio apresentado corresponde ao valor calculado na área retreinada. 

 



 

 

80 

 

Tabela 6.4 - Resultados obtidos com o retreinamento – Caso 1B. 

Metamodelo Erro Médio (%) Mínimo Variável x Variável y 

Peaks - -6.5511 0.2258 -1.6258 

HL25 149.6033 -5.6154 0.2258 -1.7159 

HL100 10.2412 -6.5550 0.2106 -1.6257 

HL25_RTR 10.7055 -6.5517 0.2265 -1.6265 

 

Conforme pode ser observado, o retreinamento melhorou o resultado, obtendo erro médio 

baixo para a região retreinada e foi capaz de encontrar um valor muito próximo do mínimo global 

da função.  

Com o processo de retreinamento foram utilizadas, no total, 50 amostras (25 pontos para o 

primeiro treinamento e mais 25 pontos para o retreinamento) e os resultados obtidos foram 

semelhantes aos obtidos com 100 pontos. Para esse caso, realizar um treinamento geral 

(representação de todo o espaço de soluções) para encontrar a região de mínimo e, 

posteriormente, realizar uma busca mais refinada (amostragem em uma região menor, específica) 

se mostrou eficiente. Porém, vale ressaltar que se fosse utilizado o metamodelo treinado com 

SS25, talvez o objetivo não fosse alcançado, uma vez que ele não foi capaz de representar bem a 

superfície de resposta na região de mínimo, conforme comentado no Subitem 6.2.3. Isso mostra a 

grande importância da qualidade dos dados de treinamento, os quais influenciam fortemente no 

sucesso do processo de retreinamento e representação da superfície de resposta. 

Mesmo para o caso do metamodelo gerado com SS25 pontos poderia ser adotado um 

procedimento de retreinamento diferente daquele proposto na metodologia (que consiste em 

realizar busca em um região específica). Um novo treinamento, após uma nova amostragem de 

todo o espaço de busca dos parâmetros poderia ser realizada. Assim, podem-se adicionar pontos 

de treinamento em etapas, de forma iterativa, possibilitando encontrar uma quantidade reduzida 

de amostras que são capazes de proporcionar boa representação do espaço de soluções.  

Esse procedimento, no entanto, considerando as técnicas de amostragem utilizadas nesse 

trabalho se restringe a ser aplicada somente com a técnica do HL, uma vez que a SS possui 

limitações quanto a gerar conjuntos com características diferentes e o BB gera sempre o mesmo 

conjunto de pontos.  



 

 

81 

 

Apesar de visualmente estar claro quando um mínimo está na região de interesse, para 

casos com mais de duas variáveis essa conclusão deve ser tomada realizando-se a validação do 

mínimo obtido através da otimização com o mínimo real. 

O mesmo princípio aplica-se à definição da nova região de retreinamento. Nesse caso foi 

possível obter maior confiança através da inspeção visual, porém, em casos com mais de duas 

variáveis deve-se utilizar a metodologia do valor de corte, descrita no Capítulo 4. 

6.3 Caso 1C 

6.3.1 Passo 1: Definição do conjunto de treinamento 

A Figura 6.9 mostra os conjuntos de treinamento para 25 pontos gerados através das 

técnicas do HL (a) e da SS (b), distribuídos na superfície de busca dos parâmetros. 

 

(a) (b) 

Figura 6.9 - Conjunto de treinamento para HL25 (a) e SS25 (b) - Caso 1C. 

Observa-se que, tanto para o HL quanto para a SS, existe uma amostra em cada uma das 

quatro regiões de mínimo global da função. Porém, quase nenhum ponto foi amostrado nas 

regiões de mínimos locais, situados próximos aos mínimos globais. Isso pode fazer com que o 

metamodelo não seja capaz de determinar as regiões de mínimos globais precisamente, pois não 



 

 

82 

 

se sabe que padrão de comportamento a superfície terá ao redor dessas regiões que não tem 

informação. 

A Figura 6.10 mostra os conjuntos de treinamento para 50 pontos amostrados utilizando as 

técnicas do HL (a) e da SS (b). 

 

(a) (b) 

Figura 6.10 – Conjunto de treinamento para HL50 (a) e SS50 (b) - Caso 1C. 

A Figura 6.10 mostra que com 50 pontos foi possível melhorar a amostragem em algumas 

regiões, porém ainda ficaram algumas “lacunas” entre os pontos amostrados, de forma que 

possivelmente uma representação precisa da superfície de resposta em todo o espaço também não 

seja possível para essa quantidade de amostras. Já com a amostragem realizada com 100 pontos, 

ambas as técnicas proporcionaram boa amostragem do espaço. 

 

 

 

 

 



 

 

83 

 

6.3.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho dos 

metamodelos gerados 

A Figura 6.11 mostra as superfícies de resposta dos metamodelos gerados com HL25 (a) e 

SS25 (b) pontos.  

 

(a) (b) 

Figura 6.11 - Superfícies de resposta dos metamodelos gerados com HL25 (a) e SS25 (b) pontos - 

Caso 1C. 

Observa-se que 25 pontos foram incapazes de extrair todas as informações necessárias para 

uma representação confiável da função. A partir da Figura 6.11 (a) pode-se visualizar que os 

quatro pontos amostrados na região de mínimo global contribuíram para que o metamodelo 

representasse bem essas regiões (regiões em cor azul acentuada). No entanto, o padrão de 

comportamento nas outras regiões ficou mal representado devido à falta de informações.  

A Tabela 6.5 mostra os valores dos coeficientes de correlação e do erro médio entre a saída 

gerada pelo metamodelo e a saída calculada pela equação que descreve a função, com relação ao 

conjunto de teste para todos os metamodelos gerados. Os resultados quantitativos apresentados na 

Tabela 6.5 mostram que os metamodelos gerados com 50 pontos também foram incapazes de 

proporcionar uma boa representação, pois os coeficientes de correlação foram baixos e os erros 

médios foram altos, apesar de melhorarem bastante os resultados em relação aos metamodelos 

gerados com 25 pontos. 



 

 

84 

 

A Figura 6.12 mostra as superfícies de resposta dos metamodelos gerados com HL50 (a) e 

SS50 (b) pontos. 

 

(a) (b) 

Figura 6.12 - Superfícies de resposta dos metamodelos gerados com HL50 (a) e SS50 (b) pontos - 

Caso 1C. 

Ao se comparar as superfícies geradas pode-se observar que, apesar de resultarem em 

coeficientes de correlação parecidos, o formato das superfícies resultantes das duas técnicas foi 

diferente, refletindo os valores de erro médio. Como o caso possui muitas irregularidades, a 

diferença da característica de espaçamento dos pontos ficou evidente (quando analisada 

visualmente). 

Os valores encontrados para os coeficientes de correlação e erros médios dos metamodelos 

gerados com 100 pontos mostram que uma representação confiável foi obtida, conforme pode ser 

visualizado pela Figura 6.13, que mostra as superfícies de resposta dos metamodelos gerados com 

HL100 (a) e SS100 (b) pontos. 



 

 

85 

 

 

(a) (b) 

Figura 6.13 - Superfícies de resposta dos metamodelos gerados com HL100 (a) e SS100 (b) 

pontos - Caso 1C. 

Pela Figura 6.13 fica claro que com 100 pontos a diferença entre a característica de 

espaçamento entre as duas técnicas desapareceu, e ambas proporcionaram resultados 

semelhantes. 

Para mostrar como a qualidade de representação melhorou com o aumento da quantidade 

de amostras a Figura 6.14 mostra as superfícies dos metamodelos gerados com HL 25 (a), 50 (b) 

e 100 (c) pontos e da função analítica (d). 

 

 

 



 

 

86 

 

 

(a) (b) 

 

(c) (d) 

Figura 6.14 - Superfícies de resposta dos metamodelos gerados com HL25 (a), HL50 (b), HL100 

(c) pontos e da função analítica (d) – Caso 1C. 

Assim, pode-se concluir que, para esse caso, foram necessários 100 pontos para uma boa 

representação do problema. O erro médio mostrado na Tabela 6.5 indica que os 25 e 50 pontos 

não forneceram toda a informação necessária para reproduzir as irregularidades presentes. O 

resultado da escassez de informação foi uma superfície “mais suave”, com menos irregularidades 

e, portanto, com menos precisão. 

Nesses casos de duas variáveis ficou explícito, através da inspeção visual do espaço de 

soluções, quando um conjunto de treinamento não é capaz de representar o comportamento 

desejado. Para casos com mais de duas variáveis, porém, devem-se utilizar indicadores de 



 

 

87 

 

qualidade para chegar a essas conclusões. O coeficiente de correlação linear pode mostrar se o 

metamodelo gerado foi capaz de representar a região descrita pelos dados de teste. Porém, uma 

conclusão precisa é extraída através da validação do mínimo encontrado com a resposta 

conhecida do problema. 

6.3.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo encontrado 

Os mínimos encontrados e suas respectivas coordenadas no espaço para o processo de 

otimização utilizando os metamodelos gerados são mostrados na Tabela 6.5.  

Tabela 6.5 - Coeficiente de correlação linear, erro médio e mínimo determinados através da 

otimização utilizando os metamodelos - Caso 1C. 

Tipo de 

dado 
Metamodelo 

Erro 

médio (%) 

Coeficiente 

correlação 
Mínimo Variável x Variável y 

HL25 Caso1C_RNA_HL25 177.1364 0.3235 -0.8669 -0.7414 -0.9896 

HL50 Caso1C_RNA_HL50 253.3417 0.4132 -1.9427 -0.9959 0.9973 

HL100 Caso1C_RNA_HL100 1.5516 0.9999 -0.7433 -0.8816 0.8863 

SS25 Caso1C_RNA_SS25 137.5484 0.2155 -1.4290 -0.9696 0.4463 

SS50 Caso1C_RNA_SS50 87.9112 0.4872 -2.7439 0.9844 0.9934 

SS100 Caso1C_RNA_SS100 0.9445 0.9999 -0.7504 0.8833 -0.8902 

 

Com 25 e 50 pontos, como a superfície é bastante irregular, a diferença quanto ao tipo de 

dado pôde ser observado. Já com o aumento do número de pontos a diferença entre as técnicas 

desapareceu, pois todas as irregularidades presentes no problema foram devidamente 

representadas. Em diversas situações práticas, no entanto, a utilização de uma quantidade 

suficientemente grande para alcançar tal situação é muitas vezes inviável.  

Quando não se conhece o comportamento da superfície de resposta e não é viável realizar 

amostragem grande, o melhor procedimento a ser adotado é ir adicionando amostras aos poucos 

até se atingir uma precisão desejada através da validação. Nesse sentido, o HL é a melhor 

escolha, pois a técnica da SS, além de amostrar sempre o mesmo padrão de espaçamento 

(limitado quanto à diversificação dos pontos quando se realizada diversas amostragens), passa a 

não ser viável para problemas de dimensões maiores. 



 

 

88 

 

Quanto ao valor do mínimo apresentado, nota-se que apenas um valor foi encontrado em 

cada otimização, enquanto que, conforme pode ser observado na Figura 6.15 (a), a função possui 

4 mínimos. O motivo é que o AG, apesar de varrer com eficiência o espaço de busca dos 

parâmetros, tende a convergir para apenas um valor final de mínimo. Para contornar esse 

problema, os resultados de todas as gerações foram armazenados em um arquivo para posterior 

análise e possível identificação de outros mínimos. Para essa análise foi adotado o seguinte 

procedimento: 

1. Estabeleceu-se um valor de corte de FO e consideraram-se apenas valores menores 

ou iguais a esse valor de corte; 

2. Estabeleceu-se um critério de vizinhança baseado na discrepância das variáveis. Se 

um mínimo que atende a condição anterior for vizinho a outro mínimo, apenas um 

deles é considerado mínimo de interesse. 

A Figura 6.15 mostra a localização dos mínimos globais da função sobre a superfície de 

resposta (a), representados por pontos azuis, e uma ilustração do critério de vizinhança adotado 

para identificação de mínimos de interesse (b). A Figura 6.15 (b) mostra três pontos (preto, 

vermelho e azul) sendo que, através do critério de vizinhança adotado, os pontos em preto e 

vermelho são considerados vizinhos (região em vermelho) e, portanto apenas um deles (o menor) 

é tomado como mínimo de interesse. 

 

(a) (b) 

Figura 6.15 - Mínimos globais, representados pelos pontos em azul (a); e critério de vizinhança 

adotado para identificação de mínimos de interesse (b) – Caso 1C. 



 

 

89 

 

A Tabela 6.6 mostra os resultados da avaliação dos mínimos de interesse para HL25, 

HL100 pontos e F(x), que representa os quatro mínimos globais da função.  

Tabela 6.6 - Mínimos de interesse - Caso 1C. 

Metamodelo Conjunto Mínimo Variável x Variável y 

F(x) 

1 -0.7558 0.8865  0.8813 

2 -0.7554 -0.8871 -0.8830 

3 -0.7513  0.8798 -0.8733 

4 -0.7515  0.8798  0.8735 

Caso1C_RNA_HL25 

1 -0.8669 -0.7414 -0.9896 

2 0.5555  0.8629 -0.4172 

3 -0.5361 -0.8713 -0.6043 

4 -0.9675 -0.9115 -0.6270 

5  0.7603  0.7757 -0.4175 

6 -0.9820 -0.5928 -0.4164 

Caso1C_RNA_HL100 

1 -0.7433 -0.8816  0.8863 

2 -0.7236  0.8822 -0.8709 

3 -0.7360  0.8822  0.8662 

4 -0.7428 -0.8816 -0.8709 

 

Pelos resultados da Tabela 6.6, a otimização utilizando o metamodelo Caso1C_RNA_HL25 

identificou, pelo critério adotado anteriormente, seis regiões de mínimo, sendo que apenas uma 

delas é realmente uma região de mínimo global (resultado em negrito). Em contrapartida, com o 

metamodelo Caso1C_RNA_HL100 foi possível identificar as quatro regiões de mínimo global da 

função. 

Foi comentado no Subitem 6.3.1 que, apesar do conjunto de HL25 pontos englobar 

amostras nas quatro regiões de mínimos globais, a falta de informação nas regiões vizinhas, com 

irregularidades, poderia gerar um padrão de comportamento que poderia vir a prejudicar a 

representação pelo metamodelo. Analisando novamente a Figura 6.9 (a) observa-se que perto do 

mínimo que se situa próximo às coordenadas (-1,-1) existem ainda duas amostras vizinhas nas 

regiões de mínimos locais. Isso fez com que fosse possível identificar esse mínimo, enquanto que 

os outros mínimos globais não foram identificados devido ao padrão de comportamento menos 

preciso da região próxima. 



 

 

90 

 

O procedimento adotado de analisar posteriormente os valores obtidos com a otimização, 

foi aplicado para verificar se o metamodelo foi capaz de modelar as outras regiões de mínimo. 

Nesse caso também foi utilizada a inspeção visual, porém em casos com mais de duas variáveis, a 

decisão de utilizar tal procedimento deve surgir a partir da validação dos mínimos encontrados na 

otimização com a resposta conhecida do problema.  

Ao invés de realizar a análise posterior dos resultados, uma opção seria estudar a utilização 

de um algoritmo de otimização que determine mais de uma região de mínimo. Isso não foi 

realizado nesse trabalho, pois o foco não foi a etapa de otimização dos parâmetros (utilizada 

apenas como parte complementar aos estudos). 

A partir da análise do resultado da otimização com o metamodelo HL25 pontos, foi 

constatado que uma região de mínimo foi identificada. Essa informação poderia ser incluída no 

procedimento de novo treinamento proposto no Subitem 6.3.2, de forma que na nova amostragem 

menos pontos fossem amostrados nessa região e mais pontos seriam amostrados nas outras 

regiões, de menor precisão. 

6.4 Caso 1D 

6.4.1 Passo 1: Definição do conjunto de treinamento 

A Figura 6.16 mostra os conjuntos de treinamento (pontos em preto), amostrados sobre o 

espaço de busca dos parâmetros, de HL25 (a) e SS25 (b) pontos. 

 



 

 

91 

 

  

(a) (b) 

Figura 6.16 – Conjunto de treinamento para HL25 (a) e SS25 (b) pontos – Caso 1D. 

Pode-se observar que, na região de mínimo, enquanto que para o conjunto HL25 existem 

apenas duas amostras na região, para o conjunto SS25 existem três amostras mais concentradas 

perto do mínimo global. Assim, pode-se esperar que na região de mínimo, o desempenho do 

metamodelo gerado com SS25 pontos seja melhor do que o do metamodelo gerado com HL25 

pontos. 

6.4.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho dos 

metamodelos gerados 

As superfícies de resposta dos metamodelos gerados com HL25 e SS25 pontos são 

mostradas na Figura 6.17. 



 

 

92 

 

 

(a) (b) 

Figura 6.17 - Superfícies de resposta dos metamodelos gerados com HL25 (a) e SS25 (b) pontos - 

Caso 1D 

Pode-se observar que a superfície da Figura 6.17 (b) está melhor do que a da Figura 6.17 

(a), porém ambas foram capazes de identificar a região de interesse, representada pela cor azul 

acentuada.  

Para mostrar como a qualidade de representação melhorou com o aumento da quantidade 

de amostras a Figura 6.18 mostra as superfícies de resposta dos metamodelos gerados com 25 (a), 

50 (b) e 100 (c) pontos do HL e da função analítica (d).   

 

 

 



 

 

93 

 

 

(a) (b) 

 

(c) (d) 

Figura 6.18 - Superfícies de resposta dos metamodelos gerados com HL25 (a), HL50 (b), HL100 

(c) pontos e da função analítica (d) – Caso 1D. 

A Figura 6.18 mostra que o aumento do número de pontos proporciona melhor 

representação da superfície de resposta. Uma observação interessante é que perto de regiões de 

mudança brusca no formato da superfície de resposta, os erros foram maiores. Isso comprova 

que, para situações de alta irregularidade da função, a rede tende a gerar erros maiores. 

Os valores dos coeficientes de correlação linear e erro médio entre saída gerada pelo 

metamodelo e pela equação que descreve a função para todos os metamodelos gerados são 

mostrados na Tabela 6.7. Os resultados mostram que desempenhos semelhantes foram obtidos 



 

 

94 

 

entre os metamodelos gerados com HL e SS, em questão de representação de todo o espaço de 

soluções. 

6.4.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo encontrado 

Os valores dos mínimos encontrados, assim como suas coordenadas no espaço para a 

otimização utilizando os metamodelos gerados, são mostrados na Tabela 6.7. É mostrado também 

o valor do mínimo e sua coordenada para a função analítica F(x).  

Tabela 6.7 - Coeficiente de correlação linear, erro médio e mínimo determinados através da 

otimização utilizando o metamodelo - Caso 1D. 

Tipo de 

dado 
Nome da rede 

Erro médio 

(%) 

Coeficiente 

correlação 
Mínimo Variável x Variável y 

- F(x) - - 13.000 -4.7124 8.1258e-06 

HL25 Caso1D_RNA_HL25 7.8769 0.8875 5.6007 -6.0000 0.4753 

HL50 Caso1D_RNA_HL50 5.6256 0.9031 13.1296 -3.7178 -2,3725 

HL100 Caso1D_RNA_HL100 2.2230 0.9808 12.5672 -3.6153 -0.2673 

SS25 Caso1D_RNA_SS25 6.2709 0.8781 12.5224 -4.4154 0.1136 

SS50 Caso1D_RNA_SS50 5.2949 0.9256 11.9259 -3.9644 0.1949 

SS100 Caso1D_RNA_SS100 2.8880 0.9633 12.7835 -3.5991 -0.3232 

 

Observa-se que, apesar de todos os metamodelos encontrarem a região de mínimo, a 

determinação mais precisa da localização não foi possível. O fato da superfície de resposta 

possuir mudanças repentinas em seu formato acabou criando dificuldades para a rede definir 

padrões que representem a função nessa região com precisão.  

Apesar de não ter encontrado a localização precisa da coordenada do mínimo, a região foi 

encontrada facilmente com poucos pontos, de maneira que um retreinamento posterior seria 

capaz de encontrar a localização do mínimo com precisão.  

A Tabela 6.7 mostra que o mínimo encontrado pela otimização utilizando o metamodelo 

Caso1D_RNA_SS25, assim como suas coordenadas, foi mais preciso comparativamente à 

otimização utilizando o metamodelo Caso1D_RNA_HL25, complementando a observação 

realizada no Subitem 6.4.1. Apesar dessa diferença na precisão com relação ao mínimo global, no 

aspecto geral, a qualidade da representação da superfície de resposta proporcionada pelos dois 



 

 

95 

 

metamodelos foi semelhante, uma vez que os valores dos coeficientes de correlação linear e do 

erro médio foram parecidos. 

Esse resultado mostra que, apesar de globalmente as duas técnicas de amostragem 

proporcionarem desempenhos semelhantes aos metamodelos, quando analisadas em regiões 

específicas, elas possuem suas particularidades, podendo uma destacar-se em relação à outra. 

A Tabela 6.7 mostra que, apesar de ter resultado em menor correlação linear, o metamodelo 

gerado com SS25 pontos foi melhor que todos os demais para determinar o mínimo. Para avaliar 

melhor esse resultado, na Figura 6.19 são expostos os conjuntos de treinamento de HL100 (a) e 

SS100 (b) pontos. 

 

(a) (b) 

Figura 6.19 – Conjunto de treinamento de HL100 (a) e SS100 (b) pontos – Caso 1D. 

Comparando os conjuntos SS25 (Figura 6.16 (b)) e HL100 observa-se que em relação ao 

mínimo, a amostragem proporcionada pelo conjunto SS25 foi melhor, porém para a modelagem 

de toda a superfície o conjunto HL100 foi melhor, refletindo os valores de correlação e do 

mínimo encontrado. Porém, com relação à amostragem do conjunto SS100, a Figura 6.19 (b) 

mostra que mesmo na região de mínimo sua amostragem foi melhor do que a de SS25 pontos. O 

motivo do resultado inferior com relação ao mínimo é que, provavelmente, o treinamento não 

tenha ocorrido bem para o metamodelo SS100 escolhido. Um novo treinamento deve resultar em 

um metamodelo com melhor qualidade.  



 

 

96 

 

Esse resultado mostra que o treinamento da RNA deve ser realizado diversas vezes para 

garantir a geração de um metamodelo de qualidade. Adicionalmente, um critério de escolha bem 

definido deve ser utilizado para obter um metamodelo que proporcione o melhor desempenho 

possível para o problema. 

6.5 Comentários dos casos analíticos  

Os casos analíticos estudados possibilitaram a identificação de particularidades e, 

principalmente, limitações das RNA que devem ser consideradas em sua aplicação. 

Caso 1A 

A primeira característica importante das RNA observada foi que, por mais simples que seja 

a superfície de resposta a qual se deseja modelar, existe um erro envolvido na representação 

proporcionada pelo metamodelo gerado (comentado no Subitem 6.1.3), a não ser que se tenha um 

número suficiente de amostras convenientemente espaçadas (tal que cubram de forma eficiente 

todo o espaço de busca dos parâmetros), o que dificilmente será possível. Portanto, pode-se 

esperar que em regiões que não possuem informações sobre o comportamento da superfície de 

resposta, a RNA provavelmente proporcione uma modelagem menos confiável. Isso faz com que 

a otimização utilizando o metamodelo não seja capaz de determinar a coordenada precisa do 

mínimo de interesse, porém, não significa que a região de mínimo não seja identificada. Para 

saber se o metamodelo foi capaz de modelar a superfície de resposta tal que a região de interesse 

seja identificada, deve-se realizar a validação do resultado da otimização com a resposta 

conhecida do problema.  

Por outro lado, caso a região a ser modelada seja comportada, a RNA é capaz de modelar o 

seu padrão de comportamento com poucas amostras sem maiores dificuldades. 

Caso 1B 

Pelo Caso 1B pôde-se comprovar que a presença de amostras na região de interesse 

contribuiu para que o metamodelo fosse capaz de modelar com maior precisão essa região, 

conforme comentado no Subitem 6.2.2. 



 

 

97 

 

A falta de informação em determinadas regiões faz com que a RNA atenue ou acentue a 

curvatura da superfície, dependendo do padrão de curva que a superfície possuir ao seu redor, 

podendo levar a solução a regiões de mínimo equivocadas (Subitem 6.2.2). 

Para esse caso a determinação de uma nova região de treinamento foi realizada através da 

inspeção visual (Subitem 6.2.4), porém conforme já comentado nos resultados, para casos de 

mais de duas variáveis o procedimento a ser adotado é o proposto na metodologia.  

Caso 1C 

Para casos com mais de um mínimo global é necessário utilizar uma ferramenta de 

otimização que seja capaz de fornecer mínimos situados em regiões diferentes como resposta. 

Outra opção é realizar o procedimento proposto no Caso 1C, que consiste em analisar os 

resultados da otimização posteriormente, para verificar se o metamodelo encontrou regiões 

potencialmente de mínimos (Subitem 6.3.3). 

No caso de duas variáveis foram utilizados mais pontos para treinar as RNA (utilização de 

100 pontos). Porém, em casos complexos, e, portanto, com mais variáveis, um procedimento 

adequado consistiria em iniciar o treinamento com poucos pontos, em seguida validar os 

resultados com a resposta conhecida do problema e, caso houvesse necessidade, mais pontos 

seriam adicionados (novamente para todo o espaço de busca dos parâmetros) e as RNA seriam 

treinadas novamente. Esse processo iterativo de treinamento e validação de RNA prosseguiria até 

que uma qualidade satisfatória de representação dos metamodelos fosse alcançada. 

Com isso possivelmente pode-se encontrar uma quantidade reduzida de pontos capaz de 

modelar o padrão desejado do problema. No Caso 1C, por exemplo, poderia se chegar a um 

metamodelo bom com 75 pontos ou até com 50 pontos através desse procedimento. 

Caso 1D 

Com o Caso 1D, que mostra uma superfície modelada por mais de uma função, pôde-se 

observar que nas regiões de mudança brusca de comportamento a RNA gera maior erro. 

Conforme comentado no Subitem 6.4.3, ao se analisarem os resultados em algumas regiões 

específicas, a diferença em relação à técnica utilizada para amostrar os dados pôde ser 



 

 

98 

 

evidenciada, ao realizar a comparação entre os metamodelos Caso1D_RNA_HL25 e 

Caso1D_RNA_SS25. 

Dessa maneira, mesmo um metamodelo com menos pontos pode proporcionar melhores 

resultados, quando regiões específicas são analisadas.  

Os resultados do Caso 1D ainda mostraram que a realização de vários treinamentos e a 

utilização de um critério bem definido para escolher o metamodelo treinado é importante para 

obter aquele que proporcione melhor modelagem para o problema. Pelos resultados apresentados 

no Subitem 6.4.3, pôde-se observar que apesar de o metamodelo SS100 resultar em melhor 

coeficiente de correlação linear comparativamente ao metamodelo SS25, as coordenadas do 

mínimo encontradas pelo metamodelo SS25 foram melhores. Isso mostra que a definição de um 

critério específico, que realize a comparação na região de interesse é importante. 

Comentários gerais 

Uma maneira de melhorar a qualidade da modelagem é através de um novo treinamento, 

em uma região menor. Porém, a realização desse tipo de procedimento nem sempre é vantajosa, 

de forma que só agregará valor caso a região identificada para realizar o novo treinamento seja 

realmente uma região de interesse (que contém o mínimo). No entanto, identificar se o mínimo 

encontrado é um mínimo local ou global não é fácil em situações em que exista muita 

irregularidade na superfície de resposta e pouca informação do problema. 

Através dos resultados dos casos analíticos, pôde-se identificar e propor mais um tipo de 

retreinamento. Esse procedimento deve proporcionar bons resultados para casos complexos.  

As técnicas de amostragem, em geral, proporcionaram metamodelos de qualidade 

semelhante quando analisadas globalmente, ou seja, o resultado para toda a superfície de 

resposta, conforme pôde ser observado pelos coeficientes de correlação linear e pelos erros para 

todos os casos. Porém, quando analisada em regiões específicas, a diferença entre o tipo de 

amostragem apareceu. Dessa maneira, um estudo para definição de critérios de comparação em 

regiões específicas deve agregar valor aos resultados. 

Nos casos analíticos, várias conclusões puderam ser tiradas a partir da análise visual da 

superfície de resposta (espaço de soluções). Porém, o procedimento de validação com a resposta 



 

 

99 

 

conhecida do problema permite realizar avaliações importantes, como determinar se o mínimo 

encontrado está na região de interesse, se o caso possui diversas regiões de interesse, se é 

necessário realizar novo treinamento, se esse retreinamento deve ser refinado ou global etc. de 

forma que qualquer decisão ou avaliação mais precisa dos resultados seja realizada através da 

validação. 

Assim, pode-se concluir que através da análise visual do espaço de soluções foram 

identificadas características e particularidades das RNA, de forma que novos procedimentos e 

necessidades de estudo puderam ser identificados e propostos. O conhecimento proporcionado 

pelos estudos dos casos analíticos contribuiu para formar uma base teórica para aplicação da 

ferramenta nos casos de maior complexidade. 

6.6 Caso 2A 

6.6.1 Passo 1: Definição do conjunto de treinamento 

A Figura 6.20 mostra a relação existente (amostragem no espaço) entre dois dos quatro 

atributos incertos (porosidade da fácies 2 e transmissibilidade da falha 3), do conjunto de 

treinamento HL25 (a) e HL50 (b) pontos. 

 

 



 

 

100 

 

 

      (a)   (b) 

Figura 6.20 – Pontos de treinamento, relativos aos atributos porosidade da fácies 2 e 

transmissibilidade da falha 3 para os conjuntos HL25 (a) e HL50 (b) pontos - Caso 2A. 

Observa-se que para o conjunto de HL50 existem mais pontos concentrados bem próximos. 

Esse fator pode resultar em melhor representação do espaço de soluções nessas áreas, quando 

comparado com o metamodelo gerado com o conjunto HL25, que possui apenas pontos 

individualmente dispersos no espaço e algumas regiões sem amostragem. Em contrapartida 

existem também espaços vazios para o conjunto de HL50, onde há falta de informações. O 

motivo disso vem do fato de que a técnica do hipercubo latino, apesar de amostrar valores bem 

distribuídos para cada atributo, realiza a combinação entre eles de forma aleatória, o que acaba 

gerando regiões com mais e com menos informações. 

Para avaliar os valores de afastamento com relação ao histórico gerado, a Tabela 6.8 mostra 

a frequência de ocorrência dos valores de saídas desejadas, geradas pela simulação dos conjuntos 

de treinamento amostrados (afastamento da produção de água do campo, do modelo simulado 

com relação ao histórico). 

 

 

 

 

0.85 0.9 0.95 1 1.05 1.1
0

0.2

0.4

0.6

0.8

1

Por2

T
3

0.85 0.9 0.95 1 1.05 1.1
0

0.2

0.4

0.6

0.8

1

Por2

T
3



 

 

101 

 

Tabela 6.8 – Frequência de ocorrência dos valores de saída para os conjuntos de 

treinamento, HL25, HL50 e HL100 pontos – Caso 2A. 

HL25 HL50 HL100 

Frequência Faixa (x10
8
) Frequência Faixa (x10

8
) Frequência Faixa (x10

8
) 

16 0.0125 - 1.35 33 0.00585 - 1.25 59 0.00224 - 1.19 

4 1.35 - 2.69 4 1.25 - 2.50 17 1.19 - 2.37 

3 2.69 - 4.03 3 2.50 - 3.75 3 2.37 - 3.55 

0 4.03 - 5.37 5 3.75 - 5.00 6 2.55 - 4.74 

1 5.37 - 6.71 1 5.99 - 6.25 4 4.74 - 5.92 

1 6.71 - 8.05 3 6.25 - 7.50 3 5.92 - 7.10 

    0 7.50 - 8.75 5 7.10 - 8.29 

    1 8.75 – 10 2 8.29 - 9.47 

        0 9.47 – 10.7 

  

 

    1 10.7 – 11.8 

Mínimo 0.0125   0.00585   0.00224 

Máximo 8.05   10   11.8 

 

As faixas mostradas na Tabela 6.8 indicam que uma determinada quantidade de amostras 

(coluna “Frequência”), possui valor de afastamento situado entre um limite mínimo e máximo, 

especificados (coluna “Faixa”). Por exemplo, para o conjunto HL25 pontos, dezesseis amostras 

geraram afastamentos que se situam em uma faixa entre 1.25x10
6
 e 1.35x10

8
. Assim, quanto 

menor for o valor de afastamento gerado pela amostra, significa que mais perto do mínimo de 

interesse ela se situa e, quanto mais amostras de valores menores existirem dentro do conjunto de 

treinamento, melhor a qualidade do conjunto de treinamento.  

A Figura 6.21 mostra os histogramas com a frequência de ocorrência dos valores de saída 

da Tabela 6.8, referente aos conjuntos de treinamento HL25 e HL50 pontos. 



 

 

102 

 

   

(a) (b) 

Figura 6.21 – Histograma dos valores de saída para os conjuntos de treinamento HL25 e HL50 

pontos – Caso 2A. 

A avaliação dos histogramas da Figura 6.21 mostra a superioridade do conjunto de HL50 

pontos comparativamente ao conjunto de HL25 pontos, com relação a fornecer informações mais 

próximas à região de interesse (de mínimo). Além de amostrar um valor mínimo mais próximo 

do mínimo de interesse, o conjunto HL50 pontos também concentra maior quantidade de pontos 

em regiões mais próximas do mínimo. 

6.6.2 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho dos 

metamodelos gerados 

A Figura 6.22 mostra os gráficos de dispersão (crossplot) entre os afastamentos da 

produção de água obtidos com o simulador e com o metamodelo, com relação às amostragens 

realizadas com HL25 (a), HL50 (b) e HL100 (c) pontos. 

0

2

4

6

8

10

12

14

16

0.0125 1.62 3.23 4.83 6.44 Mais

F
r
e
q

ü
ê
n

c
ia

Bloco

HL25 (x108)

0

5

10

15

20

25

30

35

0.00585 1.43 2.86 4.29 5.71 7.14 8.57 Mais

F
r
e
q

ü
ê
n

c
ia

Bloco

HL50 (x108)



 

 

103 

 

 

(a) (b) 

 

(c) 

Figura 6.22 – Gráfico de dispersão (crossplot) entre saída do simulador e saída do metamodelo, 

gerado com HL25 (a), HL50 (b) e HL100 (c) – Caso 2A; pontos em azul: pontos de treinamento e 

pontos em vermelho: pontos de teste. 

A partir dos gráficos da Figura 6.22 fica claro que com 100 pontos a rede obteve melhor 

correlação dos dados. Em contrapartida, a diferença entre os gráficos obtidos com os 

metamodelos gerados com 25 e 50 pontos não ficou evidente. 

A Tabela 6.9 mostra os valores obtidos para os coeficientes de correlação linear entre saída 

do simulador e do metamodelo, relativos aos conjuntos de treino e teste. 

2 4 6 8

x 10
8

2

4

6

8

x 10
8

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o
d
e
lo

 (
Y

)
Correlação linear - HL25

 

 

Y=T

Dados de treino - HL 25

Dados de teste - HL 25

2 4 6 8

x 10
8

2

4

6

8

x 10
8

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o
d
e
lo

 (
Y

)

Correlação linear - HL50

 

 

Y=T

Dados de treino - HL 50

Dados de teste - HL 25

2 4 6 8 10

x 10
8

2

4

6

8

10

x 10
8

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o
d
e
lo

 (
Y

)

Correlação linear - HL100

 

 

Y=T

Dados de treino - HL 100

Dados de teste - HL 25



 

 

104 

 

Tabela 6.9 – Correlação linear entre saída do simulador e do metamodelo (afastamento da 

produção de água, do modelo de simulação com relação ao histórico), relativos aos conjuntos de 

treino e teste – Caso 2A. 

Metamodelo Tipo Correlação linear 

Caso2A_HL25 
Treino 0.9880 

Teste 0.9743 

Caso2A_HL50 
Treino 0.9794 

Teste 0.9825 

Caso2A_HL100 
Treino 0.9948 

Teste 0.9972 

 

A avaliação apenas dos valores de coeficiente de correlação linear, mostrados na Tabela 

6.9, não possibilita definir qual metamodelo foi melhor, pois os valores são bem próximos. 

Apesar disso, os valores para teste sugerem que o aumento da quantidade de amostras contribuiu 

para melhorar a qualidade do metamodelo.  

6.6.3 Passo 3: Otimização utilizando o metamodelo e validação do mínimo encontrado 

Os resultados da otimização utilizando os metamodelos gerados são apresentados na Tabela 

6.10, que mostra os afastamentos do mínimo determinado pela otimização, com relação ao 

histórico, quando simulado com o metamodelo (coluna “Metamodelo”) e com o simulador 

(coluna “Simulador”).  

Tabela 6.10 – Afastamento obtido com o mínimo encontrado na otimização, quando 

simulado com o metamodelo e com o simulador – Caso 2A. 

Metamodelo Metamodelo (x10
6
) Simulador (x10

6
) 

Caso2A_HL25 7.3398 209.6290 

Caso2A_HL50 24.5380 4.8652 

Caso2A_HL100 11.5150 0.2701 

 

Observa-se que para o metamodelo Caso2A_HL25, a simulação do mínimo com o 

metamodelo gerou um valor baixo de afastamento, enquanto que a simulação com o simulador 

resultou em valor de afastamento elevado. Isso indica que a otimização utilizando esse 

metamodelo não identificou de fato a região de mínimo, ou seja, levou a solução para uma região 



 

 

105 

 

de afastamento elevado. Portanto, pode-se concluir que esse metamodelo não foi capaz de 

representar o simulador com precisão.  

Já em relação aos metamodelos Caso2A_HL50 e Caso2A_HL100, observa-se que os 

valores obtidos com o metamodelo e o simulador não foram tão discrepantes, provando que 

proporcionaram bons resultados. Vale ressaltar que essa diferença existente dificilmente será 

eliminada, pois o metamodelo fornece apenas uma estimativa da resposta, na qual deve ser 

confirmada posteriormente através da simulação. 

A Figura 6.23 mostra as curvas de produção de água do campo dos modelos encontrados 

com a otimização utilizando os metamodelos.  

 

Figura 6.23 – Curva de produção de água do campo do Caso base, histórico e metamodelos 

gerados com HL25, HL50 e HL100 pontos – Caso 2A. 

Com relação às curvas apresentadas na Figura 6.23, a do metamodelo Caso2A_HL25 ficou 

distante do histórico, chegando até a piorar o ajuste em comparação com o Caso base, enquanto 

que as curvas dos metamodelos Caso2A_HL50 e Caso2A_HL100 melhoraram o Caso base e 

ajustaram bem a curva de produção de água do campo em relação ao histórico. Foi traçada a 

curva e produção de água obtida através do metamodelo Caso2A_HL25, porém, na prática essa 

solução seria descartada, pois piorou o Caso base. Nesse trabalho o resultado foi considerado 

500 1000 1500 2000 2500 3000 3500
0

1000

2000

3000

4000

5000

6000

7000

Tempo (dias)

P
ro

d
u

ç
ã
o

 d
e
 á

g
u

a
 d

o
 c

a
m

p
o

 (
m

3
/d

ia
)

 

 

Histórico

Caso base

Caso2A-HL25

Caso2A-HL50

Caso2A-HL100



 

 

106 

 

para mostrar que, com menos pontos, a probabilidade de obter resultados equivocados é maior. 

Em outras palavras, a probabilidade de amostrar a região de mínimo é menor. 

O fato de a correlação linear para o metamodelo Caso2A_HL25 ter resultado em valores 

elevados indica que o espaço de soluções do problema possui irregularidades e que os 25 pontos 

não foram capazes de fornecer essa informação, de forma que, mesmo que nos pontos amostrados 

a correlação esteja boa, não significa que nas demais regiões a correlação também esteja. O 

mesmo se pode dizer a respeito dos dados de teste que indicaram boa correlação. Se os dados de 

teste englobassem alguma região com irregularidade ou a região de interesse, o resultado da 

correlação para o metamodelo HL25 provavelmente teria sido ruim. Assim, o ideal para os dados 

de teste é que eles indiquem a qualidade do metamodelo na região de interesse. A melhor maneira 

de obter uma avaliação precisa dos resultados, no entanto, é através da validação da curva de 

produção do modelo com o histórico. 

Um procedimento que poderia melhorar essa etapa de análise seria calcular o coeficiente de 

correlação linear em uma região mais refinada, em que os valores de afastamento fossem abaixo 

de um determinado valor de corte. Assim, ter-se-ia uma avaliação para uma região maior e uma 

avaliação em uma região menor, possivelmente próxima do mínimo de interesse.  

6.6.4 Passo 4: Retreinamento 

O processo de retreinamento realizado nesse trabalho, conforme consta no Capítulo 4 de 

metodologia, consistiu em realizar uma nova amostragem e treinamento das RNA em uma região 

menor, ao redor do mínimo encontrado através da otimização utilizando o metamodelo. O ideal 

seria realizar o retreinamento com o metamodelo que utilizou menos pontos, no caso o 

Caso2A_HL25. Porém, conforme pôde ser observado pelo gráfico da Figura 6.23, o mínimo 

encontrado com esse metamodelo gerou uma curva de produção distante do mínimo desejado 

para esse caso. Por esse motivo, a realização de um novo treinamento, utilizando como base o 

mínimo encontrado com esse metamodelo, não iria melhorar os resultados, pois o retreinamento 

ocorreria em uma região de mínimo errada.  



 

 

107 

 

Apesar disso, para comprovar essa hipótese foi realizado o retreinamento utilizando os 

resultados desse metamodelo. O gráfico de produção gerado, conforme se esperava, continuou 

distante do histórico, apesar de melhorar um pouco com relação ao treinamento. O retreinamento 

foi, então, realizado a partir do mínimo encontrado com a otimização utilizando o metamodelo 

gerado com HL50 pontos. 

Para a definição dos novos limites de treinamento (conforme Subitem 4.2.2 do capítulo de 

metodologia) foi adotado um valor de corte de 40% de FO (modelos que resultam em FO menor 

que 40% do valor máximo alcançado na otimização, ou seja, que proporcionaram mais de 60% de 

redução em relação ao valor máximo atingido com a otimização), e chegou-se aos limites 

mostrados na Tabela 6.11. 

Tabela 6.11 – Definição dos atributos para novo treinamento – Caso 2A. 

Limite Por2 Kx2 Falha3 Kr2 

Inferior 0.9727 0.7500 0.4512 2.6180 

Superior 1.1492 0.9402 1.0000 3.6223 

 

Para dados de teste foram utilizados 5 dos 25 pontos amostrados, sendo os outros 20 pontos 

utilizados para validação e treino (5 pontos para validação e 15 pontos para treino).  

A Tabela 6.12 a seguir mostra o coeficiente de correlação linear (treino e teste) entre saída 

do simulador e do metamodelo e o valor do mínimo encontrado com a otimização, referente ao 

retreinamento. 

Tabela 6.12 – Coeficientes de correlação linear do retreinamento; mínimo obtido com a 

otimização e simulação do mínimo com o simulador – Caso 2A. 

Metamodelo 

Treinamento Otimização (x10
6
) 

Correlação linear 
Metamodelo Simulação 

Treino Teste 

Caso2A_HL50_novo 0.9906 0.9536 -0.6984 0.2644 

 

Observa-se que o valor de afastamento obtido com a simulação do modelo resultante da 

otimização foi próximo ao adquirido com o metamodelo gerado com 100 pontos 

(Caso2A_HL100), mostrado na Tabela 6.10 (0.2701). 



 

 

108 

 

O valor negativo que aparece para o mínimo encontrado com a otimização foi devido à 

utilização da função linear como função de transferência para treinamento da RNA. Apesar disso, 

como os valores dos atributos do reservatório respeitam os limites impostos, a simulação do 

modelo resultante da otimização com o simulador gerou valores plausíveis, conforme mostra o 

resultado da simulação da Tabela 6.12. 

A Figura 6.24 mostra as curvas de produção de água do campo para o retreinamento. 

 

Figura 6.24 - Curva de produção de água do campo do Caso base, histórico e metamodelos 

gerados com HL50, HL100 pontos e HL50 após retreinamento – Caso 2A.  

Observa-se que a curva de produção de água obtida com o retreinamento assemelhou-se à 

curva resultante da otimização utilizando o metamodelo gerado com HL100 pontos. 

Nesse caso, a realização de um novo treinamento agregou valor aos resultados uma vez que 

com um total de 75 simulações (50 para primeiro treinamento e mais 25 para retreinamento) foi 

possível obter uma curva de produção igual à obtida com 100 simulações. Isso foi possível 

porque o conjunto de treinamento incluía informações suficientes a respeito da região de interesse 

(de mínimo).  

Com o intuito de entender melhor a influência dos dados de entrada na qualidade do 

metamodelo gerado, foi realizada uma análise comparativa entre os dados HL50, HL100 e HL25 

500 1000 1500 2000 2500 3000 3500
0

1000

2000

3000

4000

5000

6000

7000

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 d

o
 c

a
m

p
o
 (

m
3
/d

ia
)

 

 

Histórico

Caso base

Caso2A-HL50

Caso2A-HL100

Caso2A-HL50ret



 

 

109 

 

(este último utilizado no retreinamento). Para cada atributo, foi calculada a diferença absoluta e 

normalizada entre o valor do atributo do modelo amostrado e o valor real conhecido pelo modelo 

de referência. A soma dessas diferenças para os quatro atributos que compõem o modelo de 

simulação foi considerada como sendo a distância média da amostra em relação ao valor 

conhecido. A fórmula utilizada para calcular a diferença é mostrada pela Equação 6.1. 

     [
           

    
] 

Equação 6.1 

em que      representa o dado observado e        representa o dado amostrado. 

Com isso foi possível obter uma ideia de quão distante do modelo de referência o modelo 

amostrado estava, conforme consta na Tabela 6.13, que mostra para cada conjunto de entrada a 

quantidade de amostras que se situam nas diferentes faixas de distâncias médias (0% - 100% de 

distância) em relação ao modelo de referência. 

Tabela 6.13 - Relação da distância relativa dos atributos de treinamento com o histórico – 

Caso 2A 

Faixa de variação HL50 HL100 HL25 (retreino) 

0% - 10% 1 0 0 

11% - 50% 5 6 17 

51% - 100% 17 37 8 

&gt;101% 27 57 0 

 

Observa-se pela Tabela 6.13 que são poucos os dados amostrados perto da região de 

mínimo, ou seja, amostragem de modelos próximos ao histórico (faixa de 0% - 10%). Porém, a 

amostragem de 50 pontos conseguiu reunir a mesma quantidade de dados (informações), situados 

na faixa entre 0% a 50%, que os 100 pontos, justificando o bom desempenho do metamodelo 

gerado com esses dados e, consequentemente, o retreinamento.  

 

 

 

 



 

 

110 

 

6.7 Caso 2B 

6.7.1 Análise de sensibilidade 

A Figura 6.25 mostra os resultados da análise de sensibilidade dos atributos utilizados no 

modelo de reservatório do Caso 2B, com relação a um dos poços (PROD4) e a média aritmética 

dos oito poços. O eixo horizontal apresenta a variação percentual no valor do afastamento, em 

relação ao Caso Base (modelo de referência), e o eixo vertical apresenta os atributos, sendo que a 

cor em bege indica que o atributo foi alterado para o seu limite inferior e a cor em azul indica que 

ele foi alterado para o seu limite superior. Valores negativos indicam que o afastamento do 

modelo piorou em relação ao afastamento do Caso Base e valores positivos indicam o contrário 

(exemplo na Figura 3.1). 

    

                                       (a)                                      (b) 

Figura 6.25 – Análise de sensibilidade para o afastamento da produção de água do poço PROD4 

(a) e média aritmética (b) – Caso 2B. 

A Figura 6.25 (a) mostra que existem atributos que não influenciam na produção de água 

do poço PROD4, sendo que, nesse caso em particular, são poucos os atributos que influenciam.  

O poço PROD7 também teve poucos atributos que o influenciam, porém, para os demais poços a 

quantidade de atributos que influenciam é maior (ver Tabela 5.3).  

Observa-se que enquanto a variação de um atributo acarreta uma redução do afastamento 

(em relação ao Caso Base) para o poço PROD4, para a média ela acarreta em aumento. Como os 

0% 10% 20% 30% 40% 50%

por1
por2
por3
kx1
kx2
kx3
kz1
kz2
kz3
F1
F2
F3
F4

kr1
kr2
kr3

Sensibilidade

A
tr

ib
u

to
s

Limite inferior

Limite superior

-200% -160% -120% -80% -40% 0% 40%

por1
por2
por3
kx1
kx2
kx3
kz1
kz2
kz3
F1
F2
F3
F4

kr1
kr2
kr3

Sensibilidade

A
tr

ib
u

to
s

Limite inferior

Limite superior



 

 

111 

 

atributos são regionalizados, o impacto que cada um deles causa varia de poço a poço, podendo 

ser até desprezível, como pode ser observado pelos resultados para o PROD4.  

A Tabela 6.14 mostra os valores numéricos do gráfico apresentado na Figura 6.25. As 

colunas do limite inferior e limite superior mostram a variação porcentual do afastamento quando 

os valores dos atributos são alterados para os seus limites inferior e superior, respectivamente. 

Tabela 6.14 – Análise de sensibilidade do poço PROD4 e da média dos oito poços. 

 Variação no afastamento - PROD4 (%) Variação no afastamento - média (%) 

Atributo Limite inferior Limite superior Limite inferior Limite superior 

Por1 0 0 -2 1 

Por2 0 0 -45 10 

Por3 0 0 -13 -6 

Kx1 0 0 -23 16 

Kx2 4 0 33 -10 

Kx3 0 8 11 -19 

Kz1 0 0 0 0 

Kz2 0 0 -19 10 

Kz3 0 0 7 -7 

F1 0 0 1 0 

F2 0 0 -9 -1 

F3 0 0 6 -3 

F4 19 0 22 0 

Kr1 0 0 4 -5 

Kr2 42 0 -176 7 

Kr3 41 0 -23 -11 

 

Conforme mostra a Tabela 6.14, para o poço PROD4, ao modificar o valor da 

permeabilidade horizontal da fácies 3 para o limite superior, reduziu-se em 8% o afastamento em 

relação ao Caso Base; ao modificar os atributos permeabilidade horizontal da fácies 2, 

transmissibilidade da falha 4 e os expoentes do modelo de Corey para a permeabilidade relativa 

da água das fácies 2 e 3 para o limite inferior reduziu-se o afastamento em 4%, 19%, 42% e 41%, 

respectivamente. Os demais atributos não influenciaram no afastamento para esse poço, nem ao 

aumentar seus valores para o limite superior, nem ao reduzir seus valores para o limite inferior. 

Baseado nesses valores obtidos definiu-se que os atributos F4, kr2 e kr3 devem ser aqueles a 



 

 

112 

 

serem utilizados como entrada para treinar a RNA na representação do comportamento do poço 

PROD4, pois apresentaram maior influência nos resultados para esse poço.  

Considerando a média dos afastamentos dos poços, foram utilizados nove atributos: por2, 

por3, kx1, kx2, kx3, kz2, F4, kr2 e kr3. Foram escolhidos os atributos nos quais a soma da 

variação porcentual quando alterados os limites inferior e superior fosse maior que 20%. O 

mesmo procedimento foi adotado para definição dos atributos que mais influenciam os demais 

poços. 

Os atributos encontrados com a análise de sensibilidade poço a poço foram utilizados para 

treinar as RNA no caso de treinar um RNA para cada poço. No caso de treinar uma única RNA 

para representar todos os poços, os atributos determinados segundo a análise de sensibilidade 

para a média dos afastamentos dos poços foram utilizados. 

6.7.2 Passo 1: Definição do conjunto de treinamento 

A Figura 6.26 mostra os gráficos de dispersão dos pontos de treinamento entre os atributos 

Kz2 e Kr2, relativos aos conjuntos HL100 (a) e HL250 (b) pontos. 

  

                                     (a)                                     (b) 

Figura 6.26 – Gráfico de dispersão dos pontos de treinamento entre os atributos Kz2 e Kr2, 

relativo aos conjuntos HL100 (a) e HL250 (b) pontos – Caso 2B. 

Os gráficos da Figura 6.26 mostram que os pontos seguem uma distribuição 

aproximadamente uniforme no espaço, sendo que os HL250 pontos apresentam mais pontos 

próximos uns dos outros. Em contrapartida os HL100 pontos apresentam algumas “lacunas”, que 

1

1.5

2

2.5

3

3.5

4

4.5

5

4 9 14 19 24

K
r
2

Kz2

HL100

1

1.5

2

2.5

3

3.5

4

4.5

5

4 9 14 19 24

K
r
2

Kz2

HL250



 

 

113 

 

são as áreas sem informação do comportamento a respeito do espaço de soluções. Essa 

característica de espaçamento, conforme já mencionado (Subitem 6.1.1), se deve ao fato de que o 

HL realiza a combinação das diversas variáveis de forma aleatória, de modo que, mesmo que os 

pontos estejam bem espaçados entre uma variável e outra, eles podem não estar com relação a 

uma terceira. Observa-se ainda que os pontos extremos de cada variável foram amostrados, 

porém, as condições extremas não (amostras situadas em um dos quatro cantos dos gráficos da 

Figura 6.26). O mesmo padrão foi observado para os demais atributos. 

A Figura 6.27 mostra os gráficos de dispersão dos pontos de treinamento entre os atributos 

Kz2 e Kr2, referente aos conjuntos HL396 (a) e BB396 (b). 

  

                                    (a)                                     (b) 

Figura 6.27 - Gráficos de dispersão dos pontos de treinamento entre os atributos Kz2 e Kr2, 

referente aos conjuntos HL396 (a) e BB396 (b) – Caso 2B. 

A diferença entre as duas técnicas pode ser observada comparando-se os gráficos da Figura 

6.27. Apesar da Figura 6.27 (b) mostrar que as condições extremas entre essas duas variáveis 

foram amostradas, o mesmo não ocorre quando comparadas todas as dezesseis variáveis, ou seja, 

um modelo composto pelos valores extremos de todas as variáveis. Conforme mencionado no 

Subitem 2.4.1 de fundamentação teórica, o BB utiliza uma matriz pré-definida, composta por 

valores extremos e médios, em que as combinações entre as variáveis também são pré-definidas. 

 

 

1

1.5

2

2.5

3

3.5

4

4.5

5

4 9 14 19 24

K
r
2

Kz2

HL396

1

1.5

2

2.5

3

3.5

4

4.5

5

4 9 14 19 24

K
r
2

Kz2

BB396



 

 

114 

 

6.7.3 Passo 2: Treinamento das redes neurais artificiais e análise de desempenho dos 

metamodelos gerados 

Das opções de configuração de RNA definidas no Subitem 5.3 de aplicação, nesse capítulo 

serão mostrados apenas os resultados relativos aos metamodelos gerados com a opção 4 de 

configuração (PROD_AS – produtores, com análise de sensibilidade), que consistiu em treinar 

uma RNA com oito saídas (representando os oito poços produtores), em que, como entrada, foi 

utilizado o conjunto com os nove atributos que mais influenciam a média dos afastamentos dos 

oito poços produtores.  

De acordo com os resultados, através dessa opção de configuração, obteve-se o modelo de 

RNA que gerou o menor afastamento final, ao simular o modelo de simulação encontrado com a 

otimização utilizando o metamodelo. Esses resultados são mostrados resumidamente no 

Apêndice II.  

Com a utilização de oito RNA independentes, eventuais inter-relações existentes entre os 

poços não puderam ser captadas. Por outro lado, a utilização de uma única rede para representar 

os oito poços pode captar essas inter-relações, o que constitui uma possível causa para seus 

melhores resultados.  

Quanto aos atributos, utilizar apenas aqueles sugeridos pela análise de sensibilidade 

também pode contribuir para melhorar os resultados, pois são selecionados apenas os mais 

importantes para a Função Objetivo (maior influência). 

A Tabela 6.15 mostra os valores dos coeficientes de correlação linear entre saídas geradas 

através do simulador de escoamento (afastamento da produção de água do modelo com relação 

ao histórico) e do metamodelo (coeficientes poço a poço, geral e média, para as oito saídas), com 

relação aos metamodelos gerados com BB396, HL396, HL250 e HL100 pontos com a 

configuração de rede do tipo PROD_AS. As linhas “Tr” são relativas ao conjunto de treinamento 

e as linhas “Tt” são relativas ao conjunto de teste.  

 

 



 

 

115 

 

Tabela 6.15 – Coeficientes de correlação linear dos metamodelos gerados – PROD_AS – 

Caso 2B. 

Meta 

modelo 

Tipo 

dado 

PROD 
Geral Média 

1 2 3 4 5 6 7 8 

BB396 
Tr 0.80 0.95 0.89 0.75 0.88 0.87 0.98 0.72 0.93 0.86 

Tt 0.63 0.95 0.86 0.66 0.91 0.86 0.78 0.60 0.89 0.78 

HL396 
Tr 0.74 0.98 0.96 0.83 0.95 0.91 0.95 0.70 0.96 0.88 

Tt 0.62 0.96 0.95 0.78 0.92 0.92 0.86 0.70 0.94 0.84 

HL250 
Tr 0.83 0.97 0.95 0.82 0.93 0.90 0.95 0.83 0.95 0.90 

Tt 0.56 0.97 0.96 0.80 0.90 0.83 0.90 0.85 0.93 0.85 

HL100 
Tr 0.87 0.98 0.96 0.78 0.94 0.89 0.91 0.82 0.96 0.89 

Tt 0.67 0.95 0.94 0.73 0.91 0.84 0.83 0.75 0.92 0.83 

 

Conforme mostra a Tabela 6.15, alguns poços como o PROD1, PROD4 e PROD8 

resultaram em baixos valores de correlação linear comparativamente aos demais poços, 

independentemente da quantidade e tipo de dado amostrado. Isso pode ser devido a não 

linearidade existente entre entrada e saída, diferente para cada poço.  

Apesar das diferenças nos coeficientes poço a poço, os coeficientes de correlação linear 

geral (coeficiente analisando as oito saídas juntas) atingiram valores relativamente altos.  

Ao comparar a média dos valores de correlação linear pode-se observar que os 

metamodelos gerados com HL tiveram valores semelhantes (HL396-0.84, HL250-0.85 e HL100-

0.83) e foram superiores ao metamodelo gerado com BB (BB396-0.78). 

As Figura 6.28 e Figura 6.29 mostram os gráficos de dispersão (crossplot) entre saída do 

simulador de escoamento e do metamodelo, para os poços PROD2 (Figura 6.28) e PROD3 

(Figura 6.29). 

 



 

 

116 

 

 

                                   (a)                                  (b) 

 

(c) (d) 

Figura 6.28 - Gráficos de dispersão (crossplot) para o poço PROD2 – PROD_AS – Caso 2B.  

2 4 6 8 10

x 10
7

2

4

6

8

10
x 10

7

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o

d
e
lo

 (
Y

)
Caso2B - PROD2 - Metamodelo BB396

 

 

Y=T

Dados de treino - BB 396

Dados de teste - HL 100

2 4 6 8

x 10
7

2

4

6

8

x 10
7

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o

d
e
lo

 (
Y

)

Caso2B - PROD2 - Metamodelo HL396

 

 

Y=T

Dados de treino - HL 396

Dados de teste - HL 100

2 4 6 8

x 10
7

2

4

6

8

x 10
7

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o

d
e
lo

 (
Y

)

Caso2B - PROD2 - Metamodelo HL250

 

 

Y=T

Dados de treino - HL 250

Dados de teste - HL 100

2 4 6 8

x 10
7

1

2

3

4

5

6

7

8

x 10
7

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o

d
e
lo

 (
Y

)

Caso2B - PROD2 - Metamodelo HL100

 

 

Y=T

Dados de treino - HL 100

Dados de teste - HL 100



 

 

117 

 

 

                                    (a)                                 (b) 

 

(c)                                 (d) 

Figura 6.29 - Gráficos de dispersão (crossplot) para o poço PROD3 – PROD_AS – Caso 2B.  

Comparando os gráficos de HL396 e BB396 observa-se que o gráfico do metamodelo 

HL396 está um pouco melhor, pois os pontos se concentram mais ao redor da linha “y=x” em 

preto, o que demostra melhor correlação linear. Analisando apenas os gráficos do HL, pode-se 

observar uma melhoria do metamodelo gerado com 250 pontos em relação ao gerado com 100 

pontos, relativo à concentração dos pontos ao redor da linha “y=x”, porém entre os metamodelos 

gerados com 250 e 396 pontos não é possível observar grandes diferenças. 

Realizando a comparação entre os poços, a correlação linear para o poço PROD2 foi 

melhor do que para o poço PROD3, concentrando mais valores com afastamento menor (mais 

1 2 3 4

x 10
7

0.5

1

1.5

2

2.5

3

3.5

4

x 10
7

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o

d
e
lo

 (
Y

)
Caso2B - PROD3 - Metamodelo BB396

 

 

Y=T

Dados de treino - BB 396

Dados de teste - HL 100

1 2 3 4

x 10
7

0.5

1

1.5

2

2.5

3

3.5

4

x 10
7

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o

d
e
lo

 (
Y

)

Caso2B - PROD3 - Metamodelo HL396

 

 

Y=T

Dados de treino - HL 396

Dados de teste - HL 100

1 2 3 4

x 10
7

0.5

1

1.5

2

2.5

3

3.5

4

x 10
7

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o

d
e
lo

 (
Y

)

Caso2B - PROD3 - Metamodelo HL250

 

 

Y=T

Dados de treino - HL 250

Dados de teste - HL 100

1 2 3 4

x 10
7

0.5

1

1.5

2

2.5

3

3.5

4

x 10
7

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o

d
e
lo

 (
Y

)

Caso2B - PROD3 - Metamodelo HL100

 

 

Y=T

Dados de treino - HL 100

Dados de teste - HL 100



 

 

118 

 

perto da origem) enquanto que para o poço PROD3, além de poucos valores perto do mínimo, 

eles ficaram dispersos. Isso demonstra que o poço PROD3 oferece mais dificuldade em relação 

ao poço PROD2 para modelar, de modo que se pode inferir que existe maior não linearidade 

entre entrada e saída para o poço PROD3, comparativamente ao poço PROD2. Para os demais 

poços, também existem aqueles com dados mais concentrados perto da origem, quanto dados 

mais afastados ou mais dispersos. 

A Figura 6.30 mostra os coeficientes de correlação linear da Tabela 6.15 na forma de barras 

para visualizar melhor a diferença que existe entre os poços e os tipos de dados. O grupo de 

barras que aparecem na esquerda representam os resultados do treinamento e os que aparecem na 

direita representam os resultados do teste. 

0.5

0.55

0.6

0.65

0.7

0.75

0.8

0.85

0.9

0.95

1
BB396 HL396 HL250 HL100

 

Figura 6.30 – Coeficiente de correlação linear em gráfico de barras; grupo de barras da esquerda: 

resultados do treinamento; grupo de barras da direita: resultados do teste – Caso 2B. 

A diferença entre a correlação dos dados de treinamento e dos dados de teste que pode ser 

visualizada na Figura 6.30 é natural, uma vez que os dados de teste são dados para os quais o 



 

 

119 

 

metamodelo nunca foi utilizado. Pela Figura 6.30 fica claro que os valores de correlação linear 

para os poços PROD1, PROD4 e PROD8 foram piores, comparativamente aos demais poços.  

Os valores de correlação linear mostrados na coluna “Geral” (relativo aos oito poços) e na 

coluna “Média” mostram que o desempenho dos metamodelos gerados pelo HL foi melhor que o 

do metamodelo gerado pelo BB. Em relação aos metamodelos gerados pelo HL pode-se observar 

que o aumento do número de amostras contribuiu para melhorar o valor da correlação linear 

quando comparados os resultados para os conjuntos de 100 e 250 pontos. Porém, não houve 

melhora na qualidade dos resultados ao aumentar de 250 para 396 pontos.  

Uma possibilidade para a qualidade inferior do metamodelo HL396 com relação ao Hl250 

seria a memorização, ou seja, o metamodelo, apesar de boa correlação, estaria começando a 

memorizar os resultados e isso pode ter contribuído para que não houvesse um aumento 

expressivo na sua capacidade de generalização. 

6.7.4 Passo 3: Otimização utilizando o metamodelo e validação do mínimo encontrado 

A Tabela 6.16 mostra os afastamentos dos oito poços produtores e a sua média aritmética 

(coluna “Média”) em valores numéricos e porcentuais, que indicam a redução do afastamento em 

relação ao Caso Base (qualidade do metamodelo – Equação 3.3 e Figura 3.1). Para obter os 

valores dos afastamentos, os valores dos atributos (ponto de mínimo) encontrados com a 

otimização utilizando o metamodelo foram substituídos no simulador de escoamento.  O objetivo 

dessa tabela é apresentar um resumo dos resultados de forma quantitativa. Porém, a sua análise 

dever ser realizada em conjunto com os gráficos de produção apresentados mais adiante. 

 

 

 

 

 



 

 

120 

 

Tabela 6.16 – Valores de afastamento e indicador de qualidade (%), obtidos com a 

simulação do mínimo (x10
6
) – PROD_AS – Caso 2B. 

Modelo 
PROD (x10

6
) – Valores absolutos 

Média 
1 2 3 4 5 6 7 8 

Base 0.973 4.32 31.9 5.76 11.5 0.738 1.10 0.439 7.09 

BB396 1.44 1.34 0.493 0.0176 7.28 0.273 0.204 0.108 1.39 

HL396 3.49 0.179 2.16 9.17 1.44 0.0153 0.919 0.0083 2.17 

HL250 2.68 0.0413 1.28 0.0791 1.92 0.716 0.0738 0.0052 0.851 

HL100 0.924 0.525 2.40 7.75 0.278 0.217 0.257 0.708 1.63 

Valores em % 

BB396 -48 69 98 100 37 63 81 75 80 

HL396 -259 96 93 -59 87 98 16 98 69 

HL250 -175 99 96 99 83 3 93 99 88 

HL100 5 88 92 -35 98 71 77 -61 77 

 

Analisando a coluna “Média” para porcentagem da Tabela 6.16 pode-se observar que em 

geral a metodologia proposta foi capaz de melhorar o Caso Base, variando de uma redução de 

69% no valor do afastamento para o metamodelo gerado com HL396 pontos até uma redução de 

88% no valor do afastamento para o metamodelo gerado com HL250 pontos.  

A otimização utilizando o metamodelo gerado com HL396 acabou piorando o afastamento 

do poço PROD1 em relação ao Caso Base muito mais que em relação aos demais metamodelos (-

259%), o que explica a média menor em relação aos demais. Porém, o poço PROD1, conforme 

mostrado na Figura 6.31 (a) adiante, já estava razoavelmente ajustado e possui vazão de produção 

de água elevada, de modo que uma pequena variação da curva acaba gerando valor de erro muito 

alto. 

Os resultados para o metamodelo HL250 mostrados na Tabela 6.16 indicam que os ajustes 

para os poços PROD1 e PROD6 não foram bons. Porém, conforme citado no parágrafo anterior o 

poço PROD1 já se encontrava relativamente bem ajustado e a Figura 6.32 (b), apresentada 

adiante, mostra que o poço PROD6 também se encontrava bem ajustado. Para os demais poços a 

otimização utilizando o metamodelo HL250 melhorou o Caso Base consideravelmente (todos 

acima de 80%), indicando que a sua utilização proporcionou bons ajustes das curvas de produção 

dos poços. 



 

 

121 

 

A Figura 6.31 e a Figura 6.32 mostram as curvas de produção de água geradas pela 

simulação dos modelos encontrados através da otimização utilizando os metamodelos, assim 

como a curva do Caso Base e do histórico, para todos os poços.   

 

                                     (a)                                    (b) 

 

    (c) (d) 

Figura 6.31 – Simulação dos mínimos encontrados com a otimização utilizando os metamodelos 

para os poços PROD1 (a), PROD2 (b), PROD3 (c) e PROD4 (d) – PROD_AS – Caso 2B.  

A Figura 6.32 (a) do poço PROD1 mostra que a curva do Caso Base (vermelho) já estava 

bem ajustada, justificando o comentário realizado anteriormente sobre pequenos desvios das 

curvas gerarem grandes erros, conforme observado na Tabela 6.16. Para os poços PROD2, 

PROD3 e PROD4 é possível notar que houve melhora na curva de produção de água com relação 

ao Caso Base, sendo que para o PROD4 a curva do metamodelo HL250 se aproximou bastante do 

500 1000 1500 2000 2500 3000 3500
0

500

1000

1500

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Caso2B - Simulação - PROD1

 

 

Histórico

Caso base

BB396

HL396

HL250

HL100

500 1000 1500 2000 2500 3000 3500
0

200

400

600

800

Tempo (dias)
P

ro
d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Caso2B - Simulação - PROD2

 

 

Histórico

Caso base

BB396

HL396

HL250

HL100

500 1000 1500 2000 2500 3000 3500
0

500

1000

1500

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Caso2B - Simulação - PROD3

 

 

Histórico

Caso base

BB396

HL396

HL250

HL100

500 1000 1500 2000 2500 3000 3500
0

200

400

600

800

1000

1200

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Caso2B - Simulação - PROD4

 

 

Histórico

Caso base

BB396

HL396

HL250

HL100



 

 

122 

 

histórico e do metamodelo BB396 ajustou o histórico perfeitamente. Em contrapartida, os 

modelos otimizados através dos metamodelos HL100 e HL396 apresentaram uma vazão de água 

maior que o histórico.  

 

                                    (a)                                    (b) 

 

  (c) (d) 

Figura 6.32 - Simulação dos mínimos encontrados com a otimização utilizando os metamodelos 

para os poços PROD5 (a), PROD6 (b), PROD7 (c) e PROD8 (d) – PROD_AS – Caso 2B. 

Para os poços PROD5, PROD6, PROD7 e PROD8, os modelos encontrados melhoraram o 

Caso Base.  

Os resultados mostram que a qualidade dos resultados para os metamodelos gerados com 

HL foi superior em comparação a do BB. Em relação à quantidade de amostras, comparando os 

500 1000 1500 2000 2500 3000 3500
0

200

400

600

800

1000

1200

1400

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Caso2B - Simulação - PROD5

 

 

Histórico

Caso base

BB396

HL396

HL250

HL100

500 1000 1500 2000 2500 3000 3500
0

200

400

600

800

1000

Tempo (dias)
P

ro
d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Caso2B - Simulação - PROD6

 

 

Histórico

Caso base

BB396

HL396

HL250

HL100

500 1000 1500 2000 2500 3000 3500
0

100

200

300

400

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Caso2B - Simulação - PROD7

 

 

Histórico

Caso base

BB396

HL396

HL250

HL100

500 1000 1500 2000 2500 3000 3500
0

50

100

150

200

250

300

350

400

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Caso2B - Simulação - PROD8

 

 

Histórico

Caso base

BB396

HL396

HL250

HL100



 

 

123 

 

resultados do HL, houve uma melhora significativa dos resultados para os casos com 250 e 396 

pontos em relação ao caso com 100 pontos. No entanto, o resultado do metamodelo gerado com 

HL250 pontos foi melhor do que o HL396 pontos. Pode ser que o metamodelo HL396 escolhido 

estivesse começando a memorizar os resultados, o que constitui uma possível explicação para sua 

qualidade inferior. Uma maneira de contornar esse problema seria utilizar diversos metamodelos 

gerados para a fase de otimização e realizar a comparação entre eles através da validação com o 

simulador de escoamento. Os resultados também sugerem que a melhora na qualidade do 

metamodelo não é linear com o aumento da quantidade de amostras, tendendo, possivelmente, a 

um ponto de saturação, em que a adição de mais pontos não aumenta de forma expressiva a 

qualidade dos resultados.  

6.7.5 Passo 4: Retreinamento 

Para avaliar o efeito do retreinamento foi utilizado o metamodelo HL100_PROD_AS. 

Conforme critério de corte definido na seção 4.2.2, o valor de corte considerado para esse caso 

foi 70% da Função Objetivo do Caso Base, ou seja, o valor máximo e mínimo de variação dos 

atributos dos modelos que conseguiram reduzir mais que 30% a média dos afastamentos (oito 

poços) com relação à média do Caso Base. 

A Tabela 6.17 mostra os coeficientes de correlação linear entre saída do simulador e do 

metamodelo para o conjunto de treinamento, relativo ao novo processo de treinamento. 

Tabela 6.17 - Coeficientes de correlação linear – PROD_AS – Caso 2B – retreinamento. 

Nome 
PROD 

Geral Média 
1 2 3 4 5 6 7 8 

HL100 

RTR 
Tr 0.83 0.98 0.97 0.90 0.94 0.98 0.75 0.82 0.97 0.90 

 

A Tabela 6.17 mostra que o retreinamento resultou em boa correlação linear, atingindo uma 

média de 0.90. 



 

 

124 

 

A Tabela 6.18 mostra os valores numéricos e porcentuais (que indicam a redução com 

relação ao Caso Base, ou seja, qualidade do ajuste – Equação 3.3) dos afastamentos poço a poço 

e a média aritmética dos oito poços, calculados a partir da simulação do modelo obtido com a 

otimização utilizando o metamodelo HL100_PROD_AS e HL100_PROD_AS_RTR 

(retreinamento). Foram inseridos também os valores de afastamento do Caso Base para 

comparação. 

Tabela 6.18 – Valores de afastamento gerados com a simulação dos mínimos obtidos com a 

otimização – PROD_AS – Retreinamento – Caso 2B. 

Nome 
PROD (x10

6
) Total  

1 2  3  4  5  6  7  8  Média 

PROD (x10
6
) – Valores absolutos 

Base 0.973 4.32 31.9 5.76 11.5 0.738 1.10 0.439 7.09 

HL100  0.924 0.525 2.40 7.75 0.278 0.217 0.257  0.708 1.63 

HL100 RTR  0.761 0.111 0.849 1.20 1.87 1.62 0.00708 0.0575 0.809 

Valores em % 

HL100  5 88 92 -35 98 71 77 -61 77 

HL100 RTR  22 97 97 79 84 -120 99 87 89 

 

A Tabela 6.18 mostra que o retreinamento proporcionou melhor ajuste em comparação ao 

treinamento anterior (HL100), conseguindo um valor médio de 89% do indicador de ajuste, 

chegando a valores similares aos alcançados no treinamento com HL250 pontos (88%). Apesar 

disso, os ajustes para os poços PROD5 e PROD6 pioraram em relação ao treinamento. O poço 

PROD6, porém, estava bem ajustado, e qualquer pequena alteração resultaria em grandes 

mudanças em seu valor porcentual.  

Os gráficos da Figura 6.33 mostram as curvas de produção de água dos poços PROD1 (a), 

PROD2 (b), PROD3 (b) e PROD4 (b), referente ao retreinamento, comparadas com o histórico. 



 

 

125 

 

  

                                      (a)                                    (b) 

 

                                     (c)                                     (d) 

Figura 6.33 – Simulação dos mínimos encontrados com a otimização utilizando os metamodelos 

para os poços PROD1 (a), PROD2 (b), PROD3 (b) e PROD4 (b) – retreinamento – Caso 2B. 

Os gráficos para esses quatro poços mostram que houve melhora no ajuste dos poços. 

Os gráficos da Figura 6.34 mostram as curvas de produção de água dos poços PROD5 (a), 

PROD6 (b), PROD7 (b) e PROD8 (b), referente ao retreinamento. 

500 1000 1500 2000 2500 3000 3500
0

500

1000

1500

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Produção de água - PROD1

 

 

Histórico

Caso base

HL100-prod-AS

HL100-prod-AS-retreino

500 1000 1500 2000 2500 3000 3500
0

200

400

600

800

Tempo (dias)

P
ro

d
u

ç
ã
o

 d
e
 á

g
u

a
 (

m
3

/d
ia

)

Produção de água - PROD2

 

 

Histórico

Caso base

HL100-prod-AS

HL100-prod-AS-retreino

500 1000 1500 2000 2500 3000 3500
0

500

1000

1500

Tempo (dias)

P
ro

d
u

ç
ã
o

 d
e
 á

g
u

a
 (

m
3

/d
ia

)

Produção de água - PROD3

 

 

Histórico

Caso base

HL100-prod-AS

HL100-prod-AS-retreino

500 1000 1500 2000 2500 3000 3500
0

200

400

600

800

1000

1200

Tempo (dias)

P
ro

d
u

ç
ã
o

 d
e
 á

g
u

a
 (

m
3

/d
ia

)

Produção de água - PROD4

 

 

Histórico

Caso base

HL100-prod-AS

HL100-prod-AS-retreino



 

 

126 

 

 

                                      (a)                                     (b) 

 

                                     (c)                                    (d) 

Figura 6.34 – Simulação dos mínimos encontrados com a otimização utilizando os metamodelos 

para os poços PROD5 (a), PROD6 (b), PROD7 (b) e PROD8 (b) – retreinamento – Caso 2B. 

Pela Figura 6.34 (b) pode-se observar que a curva para o poço PROD6 não ficou tão 

desajustada quanto mostra o resultado da Tabela 6.18 (-120%). Já as curvas dos poços PROD7 e 

PROD8 melhoraram significativamente. 

Em relação aos poços PROD7 e PROD8 pode-se observar que, apesar de seus coeficientes 

de correlação linear resultarem em valores menores, as curvas de produção ficaram bem 

ajustadas. Uma explicação para esse fato é que, ao utilizar uma rede para representar os oitos 

poços produtores, é possível que o metamodelo tenha conseguido captar eventuais 

interdependências que podem existir entre os poços. Além disso, o fato de o processo de 

500 1000 1500 2000 2500 3000 3500
0

200

400

600

800

1000

1200

1400

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Produção de água - PROD5

 

 

Histórico

Caso base

HL100-prod-AS

HL100-prod-AS-retreino

500 1000 1500 2000 2500 3000 3500
0

200

400

600

800

1000

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Produção de água - PROD6

 

 

Histórico

Caso base

HL100-prod-AS

HL100-prod-AS-retreino

500 1000 1500 2000 2500 3000 3500
0

50

100

150

200

250

300

350

400

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Produção de água - PROD7

 

 

Histórico

Caso base

HL100-prod-AS

HL100-prod-AS-retreino

500 1000 1500 2000 2500 3000 3500
0

50

100

150

200

250

300

350

400

Tempo (dias)

P
ro

d
u
ç
ã
o
 d

e
 á

g
u
a
 (

m
3
/d

ia
)

Produção de água - PROD8

 

 

Histórico

Caso base

HL100-prod-AS

HL100-prod-AS-retreino



 

 

127 

 

otimização consistir em otimizar a média de produção dos oito poços, os poços com valores 

elevados de afastamento acabaram influenciando mais nos resultados, comparativamente aos 

poços com valores de afastamento menores, como nos poços PROD7 e PROD8. Dessa maneira, 

uma avaliação do processo de otimização também pode contribuir para melhorar os resultados, o 

que pode ser feito em trabalhos futuros, pois não era o foco desse trabalho. 

6.8 Comentários gerais dos casos de reservatório. 

O estudo dos casos de reservatório (Caso 2A e Caso 2B) possibilitou validar os resultados 

obtidos com os casos teóricos (Casos 1A a 1D) e estendê-los a casos complexos.  

Com o aumento da dificuldade de modelagem do problema, ou seja, à medida que o espaço 

de soluções a qual se deseja modelar se torna mais irregular e o número de atributos aumenta, a 

obtenção de um metamodelo capaz de modelar esse espaço se torna mais difícil. 

Os resultados obtidos indicam que, para o caso estudado nesse trabalho (Caso 2B), a 

utilização do metamodelo para substituir o simulador de escoamento em todo o processo de 

ajuste não é recomendável. Para casos com muitos atributos incertos, a melhor utilização é como 

ferramenta auxiliar, para ajudar em etapas que demandam maior esforço computacional, sendo a 

etapa de varredura do espaço de soluções uma das que deve agregar mais valor aos resultados. 

Dessa maneira, em situações em que o número de simulações de escoamento é um fator limitante, 

como no caso de ajuste de histórico, a utilização do metamodelo é indicada em etapas que não 

exigem muita precisão nos resultados. 

Quando a quantidade de amostras se torna um fator limitante para o problema, o espaço a 

ser modelado também se torna um fator limitante. Com o aumento do número de variáveis, se o 

espaço a ser modelado for muito grande, a amostragem eficiente do espaço de busca dos 

parâmetros se torna difícil, e às vezes até inviável, e, consequentemente, a geração de um 

metamodelo capaz de modelar o espaço de soluções precisamente também se torna difícil.  Uma 

sugestão para essas situações é realizar a adição gradativa de amostras à medida que se gera e 

valida o metamodelo com o simulador. Outra sugestão seria realizar um estudo preliminar para 



 

 

128 

 

simplificar o problema, como por exemplo, realizar uma otimização rápida, a fim de determinar 

uma região menor do espaço de soluções para treinar as redes. 

Conforme mostrado nos resultados, a avaliação do coeficiente de correlação linear e erro 

médio serviram apenas para uma análise preliminar, não sendo possível chegar a conclusões 

precisas se os metamodelos gerados são adequados para representar o problema em questão. 

Dessa maneira, um metamodelo que possivelmente tenha sido capaz de modelar com mais 

precisão a região de mínimo de interesse pode não ter sido escolhido. Assim, recomenda-se 

utilizar diversos metamodelos com coeficiente de correlação bom e posteriormente realizar a 

validação deles com a resposta do simulador para verificar qual metamodelo melhor representou 

o problema. Pelo fato do problema de ajuste de histórico possuir múltiplas soluções não se deve 

realizar a escolha dos metamodelos apenas através do coeficiente de correlação linear. 

Mesmo amostrando valores extremos dos atributos, as técnicas de amostragem dificilmente 

amostram condições extremas, de modo que se o mínimo se encontrar na região próxima de uma 

condição extrema o metamodelo não será capaz de detectá-lo. Para esses casos, uma solução seria 

realizar novo treinamento, porém amostrando novamente todo o espaço de busca dos parâmetros 

forçando a inclusão das condições extremas, para garantir a varredura, mesmo que superficial de 

todo o espaço de soluções. 

A respeito do Hipercubo Latino, foi adotada uma distribuição uniforme para todos os 

atributos. Porém, caso se tenha conhecimento da função de distribuição de probabilidade dos 

atributos, a técnica permite que essa informação seja incluída no processo de amostragem, o que 

pode contribuir para melhorar a qualidade dos dados de treinamento, pois o conjunto de 

treinamento estaria englobando atributos com valores mais prováveis. 

A escolha de uma região adequada para retreinamento (que contenha o mínimo de 

interesse) está diretamente relacionada com a qualidade do metamodelo gerado, de modo que, se 

o metamodelo não for capaz de identificar a região do mínimo de interesse, há grandes chances 

de que esse mínimo não seja encontrado com o retreinamento (refinamento). Nesse aspecto a 

característica de suavização da superfície de resposta se torna fator limitante para utilização de 

metamodelos gerados por RNA, pois, se informações suficientes não forem amostradas na região 

do mínimo de interesse, a RNA irá suavizar essa região e ela dificilmente será encontrada.  



 

 

129 

 

Isso mostra a grande importância que a técnica de amostragem tem sobre o desempenho do 

metamodelo gerado. Se a técnica de amostragem for capaz de coletar informações suficientes da 

região do mínimo de interesse, essa região será identificada e um refinamento posterior 

identificará o mínimo, porém, se na amostragem inicial essas informações não forem coletadas o 

metamodelo dificilmente irá identificar essa região. Um procedimento que poderia ser adotado, 

caso não se tenha informações da região de interesse, consiste em utilizar a rede após uma pré-

otimização com alguma técnica que demande menos simulações. 

Lima et al.(2009) realizaram um procedimento diferente, avaliando os resultados em duas 

regiões distintas: uma região macro, englobando todo o espaço de soluções, e uma região micro, 

mais específica, possivelmente englobando o mínimo. A realização de uma avaliação em uma 

região específica possibilita identificar um metamodelo que, mesmo que não proporcione uma 

representação satisfatória quando avaliado globalmente, possa ter sido capaz de modelar melhor a 

região de mínimo. Assim, a utilização desse tipo de procedimento pode ajudar na etapa de análise 

de desempenho das RNA treinadas e na escolha dos melhores metamodelos gerados.  

   





 

 

131 

 

7 CONCLUSÕES E SUGESTÕES PARA TRABALHOS 

FUTUROS 

Nesse trabalho foi avaliada a aplicação de metamodelos gerados por redes neurais artificiais 

(RNA) para serem utilizados no lugar do simulador de escoamento no processo de ajuste de 

histórico. Por ser tratar de uma estrutura simplificada, já era esperado que o metamodelo não 

fosse capaz de reproduzir o comportamento do simulador com 100% de precisão. Apesar disso, 

através do estudo do Caso 2B foi possível concluir que a ferramenta pode ser uma opção viável 

para ser aplicada ao processo de ajuste de histórico para casos práticos.  

Casos teóricos 

O objetivo dos casos teóricos foi avaliar as características do metamodelo através de uma 

análise visual do espaço de soluções (superfície de resposta), o que é impossível de se obter para 

casos práticos de reservatório, que tipicamente possuem bem mais que duas variáveis incertas. 

Essa análise permitiu identificar e avaliar as qualidades e limitações que o modelo de RNA 

escolhido possui. As principais características identificadas foram: 

? Amostragem: para casos simples a diferença na característica de espaçamento entre as 

amostras não exerceu grande influência. Para casos com irregularidades, porém, as 

diferenças apareceram. No entanto, quando se aumentaram o número de amostras, a 

diferença entre as técnicas se tornou irrelevante, além de melhorar a qualidade da 

resposta. 

? Retreinamento: mesmo se no conjunto de treinamento não houver informações 

suficientes para detectar o mínimo, mas apresentar boas informações sobre a região na 

qual ele se situa a RNA será capaz de identificar essa região e um refinamento 

posterior, poderá ter grandes possibilidades de identificar com boa precisão o mínimo 

de interesse. Esse aspecto foi comprovado através do estudo do Caso 1B. 



 

 

132 

 

? Suavização do espaço de soluções: a característica em que nas áreas do espaço de 

soluções para a qual não há dados de treinamento (não há informações) a RNA tende a 

suavizar a curvatura da superfície pôde ser observada em todos os casos, na ocasião de 

comparar as superfícies de resposta geradas.  

? Superfície irregular: quando o espaço de busca dos parâmetros é muito grande e 

irregular, o metamodelo necessita de uma quantidade maior de amostras que descrevam 

o padrão de comportamento da superfície nessas regiões para obter resultados 

confiáveis, conforme constatado pelo estudo do Caso 1C. 

? Indicadores: o indicador de erro utilizado nos casos teóricos não foi eficaz em situações 

em que o mínimo se localizava perto da origem, pois o erro tendia a ficar muito grande. 

Como esse indicador era apenas um complemento para os resultados não houve 

problemas, porém isso mostra que a escolha de um indicador adequado ao problema é 

importante para avaliar os resultados corretamente.  

Casos de reservatório 

Através do Caso 2B foi possível avaliar a aplicabilidade do metamodelo gerado através de 

RNA em situações práticas. O Caso 2A mostrou que em casos mais simples a RNA encontra 

bons resultados facilmente. Porém com o aumento da complexidade do problema (Caso 2B), fica 

mais difícil encontrar uma configuração de rede capaz de representar o problema. 

Algumas conclusões que foram realizadas através dos casos de reservatório foram: 

? Técnica de amostragem: a técnica do Hipercubo Latino (HL) proporcionou melhores 

resultados comparativamente ao Box Behnken (BB). Uma possível explicação vem do 

fato do HL realizar amostragem em um intervalo contínuo de valores, ao passo que o 

BB amostra apenas valores normalizados (mínimo, médio e máximo).  

? Quantidade de amostras: no Caso 2B, houve melhora nos resultados com o aumento 

de 100 para 250 pontos, porém, o mesmo não foi observado ao se aumentar de 250 

para 396 pontos. Duas possíveis explicações são: ou o metamodelo gerado com 396 

pontos memorizou os resultados ou a qualidade dos resultados não segue uma relação 

linear com a quantidade de amostras, ou seja, seria necessário aumentar ainda mais a 

quantidade de amostras para observar melhora nos resultados. 



 

 

133 

 

? Indicador de qualidade do metamodelo: foi utilizado o valor do coeficiente de 

correlação linear para escolher um dado metamodelo após o treinamento para ser 

submetido ao processo de otimização. A avaliação da sua capacidade de representar o 

simulador de escoamento, no entanto, deve ser realizada através da validação com o 

simulador, executando a simulação da resposta encontrada pelo metamodelo e 

comparando as curvas de produção e pressão simuladas com o histórico, pois, 

dependendo do conjunto de teste, um metamodelo com coeficiente de correlação 

linear bom pode não proporcionar bons resultados.  

? Configuração da RNA: nesse trabalho, mais especificamente no Caso 2B, foi testada a 

utilização de um metamodelo para representar cada poço produtor e um metamodelo 

para representar todos os poços produtores. Os resultados mostraram que a utilização 

de um metamodelo para representar todos os poços produtores é a melhor opção. O 

motivo, conforme explicado no Subitem 6.7, reside principalmente no fato de que a 

utilização de um metamodelo possibilita que possíveis interações que possam existir 

entre os poços sejam captadas. 

? Atributos de entrada: a utilização dos atributos escolhidos segundo a análise de 

sensibilidade proporcionou resultados mais precisos, comparativamente à utilização de 

todos os dezesseis atributos do reservatório previamente escolhidos. Conforme 

mostrado no Subitem 6.7.1, a análise de sensibilidade possibilitou a eliminação de 

atributos que não estavam exercendo grandes influências na produção de água. 

? Metamodelo como substituto do simulador: foi mostrado que é possível utilizar o 

metamodelo como substituto do simulador em partes do processo em que não se 

requer grande precisão dos resultados, sendo que o controle de qualidade da resposta 

(validação) pode dar mais confiabilidade aos resultados.  

? Retreinamento: os resultados do retreinamento com HL100 pontos mostraram que a 

utilização de menos pontos no treinamento e um refinamento posterior pode ser uma 

boa opção. Com um total de 200 pontos foi possível obter índice de qualidade de 

ajuste semelhante ao obtido com o treinamento utilizando 250 pontos. 

A partir dos resultados obtidos conclui-se que a ferramenta pode ser utilizada em conjunto 

com o simulador de escoamento no processo de ajuste de histórico, porém, não é recomendável a 



 

 

134 

 

sua utilização como substituta do simulador no processo inteiro, pois por se tratar de um modelo 

simplificado sempre há uma margem de erro envolvida. Assim, a ferramenta pode contribuir em 

etapas do processo que não demandem grande precisão dos resultados. Para avaliar a 

confiabilidade dos resultados gerados pelo metamodelo deve-se realizar a validação da resposta 

encontrada com o mesmo utilizando o simulador de escoamento. 

Sugestões para trabalhos futuros 

Segue abaixo algumas sugestões que surgiram durante o desenvolvimento do trabalho, que 

podem contribuir para o prosseguimento da pesquisa: 

? Ferramenta de otimização: nesse trabalho foi utilizado o Algoritmo Genético (AG) 

apenas como ferramenta complementar ao estudo, sem se preocupar em obter a 

melhor configuração ou a melhor forma de aplicação da ferramenta. Assim, a etapa de 

otimização dos atributos utilizando o AG pode ser melhorada através de um estudo 

mais detalhado da ferramenta. Existem ainda diversas ferramentas que podem ser 

utilizadas no processo de otimização, que podem ser testadas e, possivelmente, ajudar 

a melhorar os resultados. 

? Utilização de pesos: a utilização de uma Função Objetivo (FO) com peso para cada 

saída ou a utilização de algum critério que torne a influência maior dos poços com 

melhor desempenho pode contribuir para obtenção de melhores ajustes. 

? Pré-otimização: uma opção interessante seria a realização de uma pré-otimização 

antes de amostrar os dados. O procedimento consistiria em realizar uma otimização 

rápida, com poucas simulações, de forma que se reduza o espaço de busca dos 

atributos. Esse resultado poderia ser utilizado para formação do conjunto de entrada 

para treinamento das RNA. 

? Coeficiente de correlação: conforme discutido no Capítulo 6 de resultados, são 

necessários critérios mais consistentes para escolha dos melhores metamodelos 

gerados para serem utilizados na otimização. A utilização apenas do coeficiente de 

correlação linear entre saídas do simulador e do metamodelo não foi capaz de refletir 

com precisão os resultados obtidos a partir da validação com o simulador, ou seja, 

mesmo um metamodelo com coeficiente de correlação bom pode não proporcionar 



 

 

135 

 

bons resultados na região do mínimo. Uma opção seria utilizar o procedimento 

descrito por Lima et al. (2009) de avaliar os resultados em regiões específicas. 

? Outros tipos de RNA: existem ainda outros tipos de RNA que podem ser utilizadas 

para gerar os metamodelos, sendo uma delas as redes radiais. Mesmo sobre as redes 

do tipo direta (FeedForward) existem ainda diversas configurações, como por 

exemplo, ao invés de representar o afastamento do modelo com relação ao histórico, 

poderia gerar na saída, os valores de produção do poço (curva).  

? Retreinamento: outra metodologia para retreinamento poderia ser utilizada, que 

consistiria em gerar o metamodelo com poucos pontos, realizar a otimização 

utilizando o metamodelo, validar o resultado, e ir adicionando mais pontos aos poucos 

iterativamente, repetindo o processo (geração do metamodelo, otimização e 

validação). A escolha por adicionar mais pontos pode ser, ou em todo o espaço de 

busca dos parâmetros ou em regiões específicas, a variar de acordo com o resultado 

obtido na validação. Através dessa metodologia pode-se chegar a uma quantidade 

reduzida de amostras que proporcionem o desempenho desejado do metamodelo sobre 

o problema em estudo. 

? Escolha dos melhores metamodelos após o treinamento: nesse trabalho foi escolhido 

um entre diversos metamodelos que resultaram em coeficiente de correlação linear 

bom. Outra possibilidade, contudo, seria utilizar diversos metamodelos com 

coeficientes de correlação linear bom e validá-los com o simulador, após a otimização.





 

 

137 

 

REFERÊNCIAS BIBLIOGRÁFICAS 

Al-THUWAINI, J. S., SAUDI ARAMCO, ZANGL, G. e PHELPS, R., Innovative Approach to 

Assist History Matching Using Artificial Intelligence. SPE Intelligent Energy Conference and 

Exhibition, paper number SPE99882, Amsterdam, Netherlands, 11 – 13 April, 2006. 

AVANSI, G. D., Uso de Metamodelos na Seleção de Estratégias de Produção e Avaliação 

Econômica de Campos de Petróleo. Campinas, 2008. 156pp. Dissertação (Mestrado em 

Ciências e Engenharia de Petróleo) – Faculdade de Engenharia Mecânica e Instituto de 

Geociências, Universidade Estadual de Campinas – UNICAMP. 

AZIZ, K. e SETTARI, A., Petroleum Reservoir Simulation. Applied Science Publishers LTD, 

London, 1979. 

BISHOP, C. M., Neural Networks for Pattern Recognition. Oxford University Press Inc., New 

York, 1995. 

BOX, G. E. P. e BEHNKEN, D. W., Some New Three Level Design for the Study of 

Quantitative Variables. Technometrics, Vol. 2, No. 4, p.455-475, 1960. 

BRATLEY, P. e FOX, B. L., Algorithm 659 Implementing Sobol’s Quasirandom Sequence 

Generator. ACM Transactions on Mathematical Software, Vol. 14, No. 1, p. 88-100, 1988. 

CARVALHO, C. P. V., MASCHIO, C. E SCHIOZER, D., Aplicação da Técnica de Hipercubo 

Latino na Integração do Ajuste de Histórico com a Análise de Incertezas. 5º Congresso 

Brasileiro de Pesquisa e Desenvolvimento em Petróleo e Gás, Fortaleza, Ceará, Brasil, 15 a 22 de 

Outubro, 2009. 

CONSENTINO, L., Integrated Reservoir Studies. Editions Technip, Paris, 2001. 



 

 

138 

 

CULLICK, A. S., JOHNSON, D. e SHI, G., Improved and More-Rapid History Matching 

with a Nonlinear Proxy and Global Optimization. SPE Annual Technical Conference and 

Exhibition, paper number SPE101933, San Antonio, Texas, U. S. A., 24-27 September, 2006. 

DEMUTH, F., BEALE, M. e HAGAN, M., Neural Network Toolbox
TM

 6 – User’s Guide. The 

MathWorks Inc., 2010. 

DORAISAMY, H., ERTEKIN, T. e GRADER, A. S., Field Development Studies by Neuro-

Simulation: an Effective Coupling of Soft and Hard Computing Protocols. Science Direct, 

Computer &amp;amp; Geosciences 26, p.963-973, 2000. 

ELPHICK, R. Y., Facies. Reservoir Characterization Module, Schlumberger Oilfield Glossary, 

http://www.glossary.oilfield.slb.com/search.cfm, acesso em 01/06/2012, às 22h21min. 

ERTEKIN, T., ABOU-KASSEM, J. H. e KING, G. R., Basic Applied Reservoir Simulation. 

Society of Petroleum Engineering Inc., Texas, USA, 2001. 

FERREIRA, S. L. C., BRUNS, R. E., FERREIRA, H. S., MATOS, G. D., DAVID, J. M., 

BRANDÃO, G. C., da SILVA, E. G. D., PORTUGAL, L. A., dos REIS, P. S., SOUZA, A. S. e 

dos SANTOS W. N. L., Box-Behnken: An Alternative for the Optimization of Analytical 

Methods. Science Direct, Analytica Chimica Acta 597, p179-186, 2007. 

FORESEE, F. D. e HAGAN, M. T., Gauss-Newton Approximation to Bayesian Learning. 

Proceendings of the International Joint Conference on Neural Networks, 1997. 

FROTA, A. E. F., Aplicação de Opções Americanas Tradicionais e Complexas. Rio de 

Janeiro, 2003. Dissertação (mestrado em Engenharia de Produção: Finanças e Análise de 

Investimentos). Departamento de Engenharia Industrial, Pontifícia Universidade Católica.   

HAGAN, M. T., DEMUTH, H. B. e BEALE M., Neural Network Design.  PWS Publishing 

Company, a division of Thompson Learning, United States of America, 1996. 



 

 

139 

 

HAGAN, M. T. e MENHAJ, M. B., Training Feedforward Networks with the Marquardt 

Algorithm. IEEE Transactions on Neural Networks, Vol.5, No. 6, p.989-993, November 1994. 

HIRSCHEN, K. e SCHÄFER, M., Bayesian Regularization Neural Networks for Optimizing 

Fluid Flow Processes. Science Direct , Comput. Methods Appl. Mech. Engrg. 195, p.481-500, 

2006. 

LEITÃO, H. C. e SCHIOZER, D. J., Ajuste de Histórico Automatizado Através de 

Otimização Multivariada e Paralelização Direta.  Rio Oil &amp;amp; Gas Conference, paper número 

IBP25498, Rio de Janeiro, Rio de Janeiro, Brasil, 05 a 08 de Outubro, 1998. 

LIMA, A., RISSO, F. V. A. e SCHIOZER, D. J., Uso de Meta-Modelos Gerados por 

Planejamento Estatístico no Ajuste de Histórico de Produção de Campos de Petróleo. 5º 

Congresso Brasileiro de P&amp;amp;D em Petróleo e Gás, Fortaleza, Ceará, Brasil, 15 a 22 de Outubro, 

2009.  

MASCHIO, C., dos SANTOS, A. A. e SCHIOZER, D. J., Aplicação do Método Simplex no 

Processo de Ajuste de Histórico Assistido. Rio Oil &amp;amp; Gas Expo and Conference, paper número 

IBP1343_06, Rio de Janeiro, Rio de Janeiro, Brasil, 11 a 14 de Setembro, 2006. 

MASCHIO, C., NAKAJIMA, L. e SCHIOZER, D. J., Uso de Redes Neurais Artificiais no 

Processo de Ajuste de Histórico de Produção.  Rio Oil &amp;amp; Gas 2008 Expo and Conference, 

paper número IBP2444_08, Rio de Janeiro, Rio de Janeiro, Brasil, 15 a 18 de Setembro, 2008. 

MASCHIO, C. e SCHIOZER, D. J., Ajuste de Histórico Assistido Usando Métodos de 

Otimização de Busca Direta. Rio Oil &amp;amp; Gas Expo and Conference, paper número IBP06204, 

Rio de Janeiro, Rio de Janeiro, Brasil, 04 a 07 de Outubro, 2004. 

MASCHIO, C. e SCHIOZER, D. J., Comparação entre Metodologia de Otimização Global e 

Método de Gradientes para Ajuste de Histórico Assistido. 3º Congresso Brasileiro de P&amp;amp;D 

em Petróleo e Gás, Salvador, Bahia, Brasil, 02 a 05 de Outubro, 2005.  



 

 

140 

 

MASON, R. L., GUNST, R. F. e HESS, J. L., Statistical Design and Analysis of Experiments 

With Application to Engineering and Science. Second edition, John Wiley &amp;amp; Sons Inc., 

Hoboken, New Jersey, 2003. 

MCKAY, M. D., BECKMAN, R. J. e CONOVER, W. J., A Comparison of Three Methods for 

Selecting Values of Input Variables in the Analysis of Output from a Computer Code. 

Technometrics, Vol. 21, No. 2, 1979. 

MOHAGHEGH, S., Virtual-Intelligence Applications in Petroleum Engineering: Part I – 

Artificial Neural Networks.  Society of Petroleum Engineers, SPE58046, September, 2000.  

MONTGOMERY, D. C., Design and Analysis of Experiments. 4
th

 Ed. John Wiley &amp;amp; Sons Inc., 

U.S.A., 1996.   

NGUYEN, D. e WIDROW, B., Improving the Learning Speed of 2-Layer Neural Networks 

by Choosing Initial Values of the Adaptive Weights. Proceedings of the IJCNN, Vol. 3, p. 21-

26, Julho, 1990. 

PINHEIRO, J. M., Redes Neurais Artificiais. http://www.din.uem.br/~jmpinhei/IA-

CC/08Redes%20Neurais%20Artificiais.pdf, acesso em 27 de Abril de 2011 às 15h20.  

RAMGULAM, A., ERTEKIN, T. e FLEMINGS, P., Utilization of Artificial Neural Networks 

in the Optimization of History Matching. SPE Latin American and Caribbean Petroleum 

Engineering Conference, paper number SPE107568, Buenos Aires, Argentina, 15-18 April, 2007. 

RISSO, F. V. A., RISSO, V. F. e SCHIOZER, D. J., Estudo de Influência de Tratamento de 

Atributos em Análise de risco usando Planejamento Estatístico e Superfície de Resposta. 

XXVII CILAMCE, Belém, Pará, Brasil, 03-06 Setembro, 2006. 

http://www.din.uem.br/~jmpinhei/IA-CC/08Redes%20Neurais%20Artificiais.pdf
http://www.din.uem.br/~jmpinhei/IA-CC/08Redes%20Neurais%20Artificiais.pdf


 

 

141 

 

RISSO, F. V. A., RISSO, V. F. e SCHIOZER, D. J., A Influência do Tipo de Distribuição dos 

Atributos Críticos na Obtenção da Curva de Risco Utilizando Planejamento Estatístico . 

XXVII CILAMCE, Porto, Portugal, 13-15 junho, 2007. 

SAMPAIO, T. P., FERREIRA FILHO, V. J. M. e de SA NETO, A., An Application of Feed 

Forward Neural Network as Nonlinear Proxies for the Use During the History Matching 

Phase. SPE Latin American and Caribbean Petroleum Engineering Conference, paper number 

SPE122148, Cartagena, Colombia, 31 May-3 June April, 2009. 

SANTOS, J. P. M. e SCHIOZER, D. J., Determinação de Metodologia de Ajuste 

Automatizado de Histórico. Rio Oil &amp;amp; Gas Conference, paper número IBP19300, Rio de 

Janeiro, Rio de Janeiro, Brasil, 16 a 19 de Outubro, 2000. 

SCHIOZER, D. J., SOUSA, S. H. G. e MASCHIO, C., Ajuste de Histórico de Produção 

Assistido. Boletim Técnico da Produção de Petróleo, volume 3, nº 1, p. 63-82, Rio de Janeiro, 

Rio de Janeiro, Brasil, 2009. 

SCHULZE-RIEGERT, R. E GHEDAN, S., Modern Techniques for History Matching. 9
th

 

International Forum on Reservoir Simulation, Abud Dhabi, United Arab Emirates, 9-13 

December, 2007. 

SILVA, P. C., MASCHIO, C. e SCHIOZER, D. J., Use of Neuro-Simulation Techniques as 

Proxies to Reservoir Simulation: Application in Production History Matching. Science 

Direct, Journal of Petroleum Science and Engineering 57, p.273-280, 2006. 

SILVA, E. e OLIVEIRA, A. C., Dicas para a Configuração de Redes Neurais. Universidade 

Federal do Rio de Janeiro - NCE, 2004. 

THE MATHWORKS, MATLAB7 - Data Analysis. The MathWorks Inc., 2007. 



 

 

142 

 

VON ZUBEN, F. J., Algoritmos Genéticos (AG’s). 

ftp://ftp.dca.fee.unicamp.br/pub/docs/vonzuben/ia707_01/topico6_01.pdf, 

DCA/FFEC/UNICAMP, acesso em 28 de Maio de 2011, às 13h44. 

ZANGL, G., GRAF, T. e Al-Kinani, A., Proxy Modeling in Production Optimization. SPE 

Europec/EAGE Annual Conference and Exhibition, paper number SPE100131, Vienna, Austria, 

12-15 June, 2006. 

ZUBAREV, D. I., Pros and Cons of Applying Proxy-Models as a Substitute for Full 

Reservoir Simulations. SPE Annual Technical Conference and Exhibition, paper number 

SPE124815, New Orleans, Louisiana, USA, 4-7 October, 2009. 



 

 

143 

 

APÊNDICE 

I. Capacidade de extrapolação da rede neural artificial – Caso 2A 

Para avaliar a capacidade de extrapolação foi utilizado o metamodelo Caso2A_HL50_novo 

(resultante do retreinamento do metamodelo gerado com HL50 pontos) e, como entrada, o 

conjunto de 25 pontos utilizados no novo treinamento e o conjunto de teste utilizado para 

treinamento das RNA para todo o espaço de busca dos atributos. O resultado é indicado na Figura 

I.1, que mostra o gráfico de dispersão entre valores de afastamentos obtidos com a saída do 

simulador e valores de afastamentos gerados pelo metamodelo, sendo os pontos em azul relativos 

aos dados que respeitam a faixa de variação dos atributos (conjunto utilizado no retreinamento) e 

os pontos em vermelho relativos aos dados que ultrapassam os limites de variação dos atributos 

(utilizados para treinar as RNA em todo o espaço de busca dos atributos). Na Figura I.1 (a) é 

mostrado o gráfico para todos os pontos e na Figura I.1 (b) é mostrado o gráfico numa área mais 

próxima do mínimo. 

 

(a) (b) 

Figura I.1– Exemplo sobre capacidade de extrapolação da RNA. Em (a) são mostrados todos os 

pontos; em (b) é mostrada uma área menor, mais próxima do mínimo. 

Como pode ser observado, quando inseridos atributos de entrada fora dos limites de 

variação do treinamento o metamodelo não extrapola os resultados, saturando em um valor 

2 4 6 8

x 10
8

2

4

6

8

x 10
8

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o
d
e
lo

 (
Y

)

Caso 2A - metamdodelo HL50 - novo

 

 

Y=T

Dados de treino - HL 25

Dados de teste - HL 25

1 2 3 4 5

x 10
7

1

2

3

4

5

x 10
7

Saída do simulador (T)

S
a
íd

a
 d

o
 m

e
ta

m
o

d
e
lo

 (
Y

)

 

 
Caso 2A - metamodelo HL50 - novo

Y=T

Dados de treino - HL 25

Dados de teste - HL 25



 

 

144 

 

próximo ao máximo e mínimo contidos no conjunto de treinamento. Dessa maneira, pode-se 

deduzir que esse tipo de RNA não possui a capacidade de extrapolar os resultados em regiões 

para as quais ela não foi treinada.  

Ao definir um novo conjunto de treinamento, reduziu-se a região de busca dos atributos e, 

consequentemente, o intervalo de variação da saída do metamodelo. Com isso, o metamodelo 

gerado com o novo treinamento se limita a representar apenas a nova região específica para o 

qual foi gerado, não sendo capaz de extrapolar os resultados para variáveis de entrada e saída fora 

dos limites de variação.  

Dessa maneira caso se deseje utilizar o metamodelo para realizar uma tarefa diferente da 

qual ele foi gerado é necessário realizar novamente o treinamento para o propósito específico. 

II. Melhor configuração de rede neural artificial obtida – Caso 2B 

Após gerar os metamodelos e realizar a otimização com cada um deles, o modelo de 

simulação resultante de cada otimização foi simulado utilizando o simulador de escoamento, de 

forma a obter uma validação final da qualidade do metamodelo gerado. Através dessa validação 

pôde-se identificar qual foi o melhor metamodelo obtido através dos diversos treinamentos de 

RNA realizados. 

A Tabela II.1 mostra a média dos afastamentos dos oito poços produtores, obtidos através 

da simulação do modelo resultante da otimização utilizando os metamodelos com BB396, 

HL396, HL250 e HL100 pontos com as configurações PROD (um único metamodelo 

representando todos os poços, ou seja, com oito saídas), PP (um metamodelo para representar um 

poço, ou seja, oito metamodelos), SAS (utilização de todos os dezesseis atributos incertos como 

entrada) e AS (utilização apenas dos atributos que impactam mais na produção de água, definidos 

de acordo com a análise de sensibilidade). A linha “Metamodelo” mostra o afastamento obtido 

com a simulação utilizando o metamodelo, e a linha “Simulador” mostra o afastamento obtido 

com a simulação utilizando o simulador de escoamento. 

 

 



 

 

145 

 

Tabela II.1–Média dos afastamentos para os modelos de simulação encontrados através da 

otimização utilizando o metamodelo – Caso 2B. 

Média dos afastamentos dos oito poços (x10
6
) 

Nome  
Tipo de metamodelo 

PP_AS PP_SAS PROD_AS PROD_SAS 

BB396 
Metamodelo 1.140 0.735 2.094 1.744 

Simulador 3.306 2.480 1.395 1.345 

HL396 
Metamodelo 1.006 1.097 2.059 1.811 

Simulador 2.580 1.991 2.172 3.248 

HL250 
Metamodelo 1.406 1.112 2.448 2.092 

Simulador 1.314 3.063 0.851 2.742 

HL100 
Metamodelo 1.865 0.966 2.397 1.888 

Simulador 1.647 2.616 1.632 1.278 

 

De acordo com a Tabela II.1, o metamodelo que proporcionou a menor média dos 

afastamentos após simular o modelo no simulador de escoamento foi o metamodelo HL250 com 

configuração PROD_AS (destacada em negrito). Isso significa que ele foi o que conseguiu 

conduzir a otimização para mais perto do mínimo. 

O procedimento de análise de sensibilidade possibilitou eliminar atributos com pouca 

influência sobre a Função Objetivo (FO), de forma a reduzir o número de atributos de entrada que 

contribuem apenas para aumentar o nível de dificuldade do processo de treinamento. Além disso, 

a utilização de um metamodelo para representar as oito saídas fez com que possíveis inter-

relações existentes entre os poços fossem captadas, pois com essa configuração qualquer 

alteração realizada nos parâmetros da rede interfere em todas as saídas. Em contrapartida, com a 

utilização de um metamodelo para representar cada poço não é possível captar eventuais inter-

relações. 


</field>
	</doc>
</add>