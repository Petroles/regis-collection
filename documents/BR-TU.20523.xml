<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.20523</field>
		<field name="filename">4095_Oliveira_MarceloLopesde_M.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">
UNICAMP 

UNIVERSIDADE ESTADUAL DE CAMPINAS 

INSTITUTO DE GEOCIÊNCIAS 

PÓS-GRADUAÇÃO EM GEOCIÊNCIAS- ÁREA DE 

GEOENGENHARIA DE RESERVATÓRIOS 

MARCELO LOPES DE OLIVEIRA 

ANÁLISE DAS INCERTEZAS ENVOLVIDAS NA MODELAGEM 

DE RESERVATÓRIOS NO CONTEXTO GEOESTATÍSTICO 

Dissertação apresentada ao Instituto de Geociências como 

parte dos requisitos para obtenção do título de Mestre em 

"Geociências - Área de Geoengenharia de Reservatórios" 

Orientador: Professor Dr. Armando Zaupa Remacre 

CAMPINAS- SÃO PAULO 

DEZEMBRO - 1997 



UNICAMP 

UNIVERSIDADE ESTADUAL DE CAMPINAS 

INSTITUTO DE GEOCIÊNCIAS/ÁREA DE GEOLOGIA DE 

PETRÓLEO 

PÓS-GRADUAÇÃO EM GEOCIÊNCIAS - ÁREA DE 

GEOENGENHARIA DE RESERVATÓRIOS 

MARCELO LOPES DE OLIVEIRA 

ANÁLISE DAS INCERTEZAS ENVOLVIDAS NA MODELAGEM 

DE RESERVATÓRIOS NO CONTEXTO GEOESTATÍSTICO 

Orientador: 

Dissertação apresentada ao Instituto de Geociências como requisito 

parcial para obtenção do título de Mestre em Geociências - Área de 

Geoengenharia de Reservatórios. 

Dr. Armando Zaupa Remacre - UNICAMPIIG/ AGP 

CAMPINAS- SÃO PAULO 

DEZEMBRO- 1997 

ll 



FICHACATALOGRÁFICAELABORADA 
PELA BIBLIOTECA I.G. UNI C AMP 

Oliveira, Marcelo Lopes de 
OL4a Análise das incertezas envolvidas na modelagem de 

reservatórios no contexto geoestatístico I Marcelo Lopes de 
Oliveira.- Carnpinas,SP.: [s.n.], 1997. 

Orientador: Armando Zaupa Remacre 
Dissertação (mestrado) Universidade Estadual de Campinas, 

Instituto de Geociências 

/ 
I. Geoestatística. 2. Incerteza. 3. Reservatórios· 4. Petróleó. 

I. Remacre, Armando Zaupa II. Universidade Estadual de 
Campinas, Instituto de Geociências. III. Título 



UNIVERSIDADE ESTADUAL DE CAMPINAS/ 

INSTITUTO DE GEOCIÊNCIAS/ÁREA DE GEOLOGIA DE 

PETRÓLEO 

UNICAMP 

PÓS-GRADUAÇÃO EM GEOCIÊNCIAS - ÁREA DE 

GEOENGENHARIA DE RESERVATÓRIOS 

AUTOR: Marcelo Lopes de Oliveira 

TÍTULO DA DISSERTAÇÃO: ANÁLISE DAS INCERTEZAS ENVOLVIDAS NA 

MODELAGEM DE RESERVATÓRIOS NO CONTEXTO GEOESTA TÍSTICO. 

ORIENTADOR: Dr. Armando Zaupa Remacre 

PRESIDENTE: Dr. Armando Zaupa Remacre 

EXAMINADORES: 

Prof. Dr. Armando Zaupa Remacre - Presidente 

Prof. Dr. Ademir José Petenate 

Prof. Dr. João Felipe C. L. Costa 

Campinas, de janeiro de 1998 

ll1 



À TERESA. 

IV 



Agradecimentos 

À Petróleo Brasileiro S.A. - PETROBRÀS - pela oportunidade e apoio financeiro 

oferecidos. 

Ao Dr. Armando Zaupa Remacre pela sugestão do tema da dissertação e pelas 

valiosas orientações. 

Aos membros das bancas examinadoras de qualificação e defesa pelas valiosas 

sugestões. 

Aos professores e funcionários do IG e do DEP- UNICAMP que participaram da 

formação teórica e prática durante o mestrado. 

Às bibliotecárias Alice e Dora pela presteza e colaboração. 

Aos colegas de mestrado que souberam manter a união, colaboração e amizade. 

À Nery pelo apoio e confiança em meu trabalho e potencial. 

Aos meus irmãos Geraldo e Cristóvão, pelas oportunidades que me concederam. 

À minha esposa Teresa pela compreensão, carinho e incentivo 

À Deus pela concessão de chegar ao final de mais uma jornada. 

v 



UNICAMP 

UNIVERSIDADE ESTADUAL DE CAMPINAS/ 

INSTITUTO DE GEOCIÊNCIAS/ÁREA DE GEOLOGIA DE 

PETRÓLEO 

PÓS-GRADUAÇÃO EM GEOCIÊNCIAS -ÁREA DE 

GEOENGENHARIA DE RESERVATÓRIOS 

ANÁLISE DAS INCERTEZAS ENVOLVIDAS NA MODELAGEM DE RESERVATÓRIOS 

NO CONTEXTO GEOESTATÍSTICO 

RESUMO 

DISSERTAÇÃO DE MESTRADO 

Marcelo Lopes de Oliveira 

A análise dos diversos algoritmos de krigagem e simulação estocástica possibilitou o 
entendimento do potencial e das limitações das ferramentas geoestatísticas na modelagem de 
reservatórios. Esses algoritmos diferem em suas hipóteses básicas, faixa de aplicação, complexidade 
e eficiência computacional. Portanto, cada técnica tem seu uso a depender da fase de 
desenvolvimento do reservatório, dos objetivos do estudo, dos atributos que estão sendo modelados 
e, consequentemente, da quantidade e da qualidade dos dados disponíveis sobre o reservatório: 
dados sísmicos, geológicos e de produção. 

Assim, diante da diversidade de situações encontradas na modelagem estocástica de 
reservatórios, é imprescindível o entendimento das caracteristicas das diferentes alternativas de 
simulação estocástica disponíveis, para que se possa escolher a metodologia mais adequada ao 
contexto que está sendo analisado. Nesta dissertação foram analisados os principais algoritmos de 
simulação estocástica e krigagem com o objetivo de facilitar a análise do tema incerteza. É 
importante ressaltar que as estimativas, simulações estocásticas e as conseqüentes avaliações de 
incerteza são dependentes do modelo adotado e de seus parâmetros. 

Em relação às krigagens, foram construídos intervalos de incerteza a partir de krigagens 
paramétricas, enfatizando as hipóteses adotadas. Verificou-se também a influência do aumento do 
número de dados condicionantes e da representatividade dos mesmos na melhor definição dos 
semivariogramas e na obtenção de estimativas mais representativas. 

Quanto a simulação estocástica, foram obtidas representações de incerteza como mapas de 
quantis, de probabilidade, de dispersão, etc. Foi implementado o algoritmo de simulação campo de 
probabilidade, sendo proposta uma alternativa específica para distribuição multivariada gaussiana. 

Enfim, a análise critica de tópicos e problemas específicos sobre avaliação de incertezas 
evidenciam que muitos conceitos devem ser melhor entendidos, para possibilitar melhor utilização 
das ferramentas geoestatísticas e, consequentemente, melhor conhecimento de suas limitações. 
Dentre os diversos tópicos abordados, destacam-se: equiprobabilidade das realizações, flutuações 
etgódicas, número de realizações necessárias para cobrir adequadamente o espaço de incertezas, etc. 
Para alguns destes problemas, a geoestatística não tem uma solução específica. 

VI 



UNICAMP 

UNIVERSIDADE ESTADUAL DE CAMPINAS/ 

INSTITUTO DE GEOCIÊNCIAS/ÁREA DE GEOLOGIA DE 

PETRÓLEO 

PÓS-GRADUAÇÃO EM GEOCIÊNCIAS -ÁREA DE 

GEOENGENHARIA DE RESERVATÓRIOS 

GEOSTATISTICAL APPROACH OF UNCERTAINTIES ANALYSIS 

RELATED TO RESERVOIR MODELING 

ABSTRACT 

MAS TER DISSERTA TION 

Marcelo Lopes de Oliveira 

The analysis of severa! algorithms of k:riging and stochastic simulation allowed the 
understanding of potential and shortcomings of geostatistics tools for reservoir modeling. Those 
algorithms differ in range of application, underlying assumptions, complexity of usage and computer 
efficiency. However, each technique has its application, depending on the reservoir development 
levei, the purpose of the study, the modeled parameter, and consequently on the reservoir quality 
data: seismic, geologic and production data. 

Thus, depending on the diversity of the problems faced stochastic reservoir modeling, it is 
of utmost importance the understanding of the characteristics related to the different algorithms of 
stochastic simulation available, and the choosing of methodology better applied to the studied case. 
In this dissertation, the most used algorithms of stochastic simulation and k:riging were analyzed 
within purpose of facilitating the analysis related to uncertainty. It is important to be aware that the 
estimations, stochastic simulations and uncertainty evaluations are dependents on the adopted model 
and its parameters. 

Concerning the k:riging, confidence intervals from parametric k:riging were built with 
emphasis on the adopted hypotheses. The influence of the increasing of number of the conditioning 
data and its representativity were also verified to achieve an adequate semivariogram and consistent 
estimation. 

Uncertainty representations such as maps of spread, quantile maps, probability maps were 
obtained. The algorithm of simulation p-field was implemented and a specific altemative for 
multigaussian distributions was proposed. 

At last, a criticai analysis of specifics topics and problems related to uncertainty evaluation 
show that many concepts need to be better understood to enable better application of the 
geostatistics tools and, consequently, better knowledge of their shortcomings, such as realizations 
equiprobability , ergodic fluctuations, number of realizations necessary for to adequately cover the 
uncertainty space. For some problems, geostatistics does not have a specific solution. 

VIl 



Sumário 
Agradecimentos----------------------------v 

~mm ~ 

Abstract ,;i 

Índic ~ii 

ListadeFigura~------------------------------x 

Lista de Tabel xi 

Lista de Símbolo xii 

ListadeAb~atu~~--------------------------xv 

1. Introdução-------------------------1 

1.1 Motivação--------------------------------------------------------4 

1.2 Objetivos da Dissertação------------------------------------------------------5 

1.3 Organização da Dissertação-------------------------------------------------------6 

2. Terminologia 7 

2.1 Incerteza e Erro -----------------------------------------------------------7 

2.2 Precisão e Acurácia----------------------------------------------------7 

2. 3 Ergodicidade e Integral range --------------------------------------------------9 

2.4 Heterogêneo e Homogêneo ----------------------------------------------- 11 

2.5 Sinergismo----------------------------------------------------------- 12 

3. Krigagem 13 

3.1 Conceitos Iniciais----------------------------------------------------------------- 13 

3.2 Krigagem da Média ----------------------------------------------------- 14 

3.3 Krigagem Simples----------------------------------------------------------------- 15 

3.4 Krigagem Ordinária------------------------------------------------------------ 16 

3.5 Krigagem Universal--------------------------------------------------------------------------- 17 

3. 6 Krigagem Fatorial -------------------------------------------------------------------------- 19 

3. 7 Krigagem Com Deriva Externa------------------------------------------------------------ 20 

3.8 Cok:rigagem---------------------------------------------------------------------- 21 

3.8.1 Cokrigagem Col/ocated--------------------------------- 22 

3.9 Krigagem lndicatriz--------------------------------------------------- 24 

3.10 Cok:rigagem Indicatriz-------------------------------------------- 26 

3.1 0.1 Cokrigagem Jndicatriz Reduzida------------------------------ 27 

3.11 Krigagem dos Componentes Principais Indicatrizes---------------------------------------- 28 

3.12 Krigagem com Dados Qualitativos-------------------------------------------- 30 

3.12.1 Tipos de Dados 30 

3.12.2 Abordagens Alternativas------------------------------------------- 32 

3.12.3 Krigagem Sojl: Modelo de Markov-Bayes 32 

3.13 A Questão dos Ponderadores Negativos------------------------------------------- 3 5 

4. Incertezas na Estimativa 39 

VIU 



4.1 Escolha do Tipo de Krigagem -----------------------------------------------------------40 

4.2 Medidas de Incerteza------------------------------------------------------------------------- 41 

4.3 Intervalos de Incerteza com Krigagens Paramétricas ----------------------------------------43 

4.3.1 Abordagem alternativa ---------- 45 

4.4 Verificação Experimental ------------------------------------------------------------ 46 

4.4.1 Dados Básicos-- -------- -------46 

4.4.2 Construção do Caso Base-------------------------------------------- 47 

4.4.3 Parâmetros das Krigagens -------- 47 

4. 4.4 Resultados das Krigagens --------------------------------------------49 

4.4.5 Intervalos de Incerteza ---------51 

4.4. 6 Análise Visual------------------------------------------------ 52 

4. 4. 7 Variogramas Cruzados------- 53 

4.4.8 Comparação através de cortes------------------------------------------ 54 

4. 4. 9 Intervalos de Incerteza -Abordagem de Roth e Armstrong --- ---55 

4. 5 Comentários ----------------------------------------------------------------------------- 57 

5. Simulação Estocástica 59 

5. 1 Bandas Rotativas------------------------------------------------------------------------ 61 

5.2 Simulação Gaussiana Seqüencial--------------------------------------------------------------- 63 

5.2.1 Cossimulação SeqUencial Gaussiana------------------------------------- 65 

5.3 Simulação Indicatriz Seqüencial------------------------------------------------66 

5.4 Simulação Gaussiana Truncada ------------------------------------------------------------ 68 

5.4. 1 Simulação Plurigaussiana Truncada------------------------ 70 

5.5 Simulação Campo de Probabilidade -------------------------------------------------------------71 

5.6 Simulated Annealing--------------------------------------------------------------------- 7 4 

5. 7 Simulações Baseadas em Objetos---------------------------------------------------------- 77 

6. Incertezas na Simulação Estocástica 80 

6.1 Comparação de Algoritmos------------------------------------------------------------------ 81 

6.2 Imagens equiprováveis--------------------------------------------------------------------- 82 

6.3 Escolha de um Algoritmo------------------------------------------------------------------- 83 

6.4 Representações de Incertezas ------------------------------------------------------------- 86 

6.5 Flutuações Ergódicas--------------------------------------------------------------- 89 

6.6 Simulação Condicional, Não Condicional e Krigagem -------------------------------------- 90 

6. 7 Ergodicidade ------------------------------------------------------------------------------------- 92 

6.8 Número de Realizações Necessárias ------------------------------------------------------------- 94 

6.9 Simulação Campo de Probabilidade------------------------------------------------------------ 96 

6.10 Animação de Incerteza---------------------------------------------------------------------- 97 

6.11 Proposta Alternativa Para a Simulação P-field. ------------------------------------------------- 98 

6.12 Incertezas nos Parãmetros e no Modelo--------------------------------------------------------1 O 1 

7. Conclnsões:---------------------------104 

Referências Bibliográficas--------------------------------------------------------------1 08 

Bibliografia:---------------------------ll4 

IX 



Lista de Figuras 

Figura 1-1: Incertezas na caracterização e simulação de reservatórios. ------------------------------------1 

Figura 2-1: Precisão e acurácia. ----------------------------------------------------------------------------8 

Figura 3-l:Informações codificadas como cdfs. Os valores 'a' e 'b' são os limites extremos dos dados.-------- 33 

Figura 4-1: Mapa base com a posição dos poços. ------------------------------------------------------------ 46 

Figura 4-2: Histograma dos dados origínais. --------------------------------------------------- 46 

Figura 4-3 : Caso base ------------------------------------------------------------------------------------------------- 4 7 

Figura 4-4: Conjuntos amostrais retirados do caso base ---------------------------------------------------48 

Figura 4-5: Resultados das krigagens. -------------------------------------------------------------------------------50 

Figura 4-6: Mapas dos percentis 15.87 e 84.13 %. ------------------------------------------------ 51 

Figura 4-7: Variogramas cruzados entre estimativas e caso real.------------------------------------------------- 54 

Figura 4-8: Distribuições de volumes porosos em relação ao corte de 1.3 m. ------------------------------55 

Figura 4-9: Intervalo de incerteza ao longo de uma linha com coordenada Y fixa. passando por dois poços 

(figura 7-20 de Harbaugb et al., 1995, p.l6 7) ----------------------------------------------------- 58 

Figura 5-1 :Krigagem x simulação condicional. --------------------------------------------------------------------- 60 

Figura 5-2: Simulação campo de probabilidade. ------------------------------------------------------72 

Figura 6-1: Realizações estocásticas utilizando SGS. ---------------------------------------------------------------- 86 

Figura 6-2: Média e desvio padrão das 100 simulações SGS. ---------------------------------------------------87 

Figura 6-3: Coeficiente de variação das 100 Simulações SGS. ------------------------------------------------------87 

Figura 6-4: Mapas de probabilidade.---------------------------------------------------------------------------- 88 

Figura 6-5: Mapas de quantis. --------------------------------------------------------------------------------------------89 

Figura 6-6: Semivariogramas das simulações e da krigagem.---------------------------------------------------- 89 

Figura 6-7: Comparação entre os mapas krigado c o da média das 100 simulações. ----------------------------90 

Figura 6-8: Esquema ilustrativo para cálculo do H CIP.------------------------------------------------------- 91 

Figura 6-9: Resultados do cálculo dos VOIPs simulados c krigados ------------------------------------------------92 

Figura 6-IO:Ergodicidade versus a) Alcance; b) Modelo de Semivariograma: c) Tamanho do Donúnio------- 93 

Figura 6-11: Geração de imagens minimamente diferentes --------------------------------------------------------- 97 

Figura 6-12: Volumes porosos totais obtidos com a simulação campo de probabilidade.---------------------- 98 

Figura 6-13: Realizações P:field minimamente diferentes ----------------------------------------------------------- 99 

Figura 6-14: Proposta Alternativa para a P-fi e ld --------------------------------------------------------------100 

Figura 6-15: Volume poroso total e média/variância do campo uniforme cm cada simulação.-----------------101 

X 



Lista de Tabelas 

Tabela 1-1: Trabalhos apresentados nos Congressos Internacionais de Geoestatística por país. ------------------5 

Tabela 4-1: Tipos de k:rigagem, hipóteses e características.------------------------------------------------------- 42 

Tabela 4-2: Varíogramas e Vizinhanças Adotadas nas Krígagens --------------------------------------------49 

Tabela 4-3: Resultados das Krígagens --------------------------------------------------------------------------------- 49 

Tabela 4-4: Intervalos de Incerteza e Erros------------------------------------------------------------------------- 52 

Tabela 4-5: Fato r de correlação--------------------------------------------------------------------------------------- 53 

Tabela 4-6: Volumes porosos para diferentes cortes-------------------------------------------------------- 54 

Tabela 4-7: Intervalos de Incerteza-------------------------------------------------------------------------------- 56 

Tabela 4-8:Intervalos de Incerteza (Estimativa Local: H&lt;j&gt; por bloco em m) -------------------------------------56 

Tabela 6-1: Resultados obtidos por Srívastava ( 1997)--------------------------------------------------------------- 83 

Tabela 6-2: Algoritmos de Simulação: Parâmetros de entrada, Hipóteses. Características. ----------------84/85 

Tabela 6-3 :Estatística das Realizações---------------------------------------------------------------------------------- 88 

Tabela 6-4: Simulação condicional, não condicional e krigagem------------------------------------------------ 91 

Tabela 6-5: Expressões do integral range em função do alcance.---------------------------------------------------- 93 

Tabela 6-6: Estatística das Realizações-------------------------------------------------------------------------- 96 

Tabela 6-7: Estatisticas das Simulações com Abordagem P -fi eld Alternativa -------------------------------------100 

XI 



A 

a, 

B 

C(x;-x;) 

C(h) 

C(Z(x 1 ),Z(x 2 )) 

CEF(x,x+h) 
'J 

C,(h;z,) 

C,(h;z,,z,.) 

C,(h) 

Cp(h) 

C.(h) 

Cv(h) 

Cap(h) 

D(x) 

Dk(x) 

E[Z(x)] 

E[l(x;z, )] 

E[I(x;z,)j(n)] 

F(zk) 

F(x;zk) 

F(x; z, l(n)) 

Fz 

F-1(x;pl(n)) 

f,(x) 

G() 
H&lt;jl 

Lista de Símbolos 

Integral range. 

Coeficientes do componente t do modelo de deriva. 

Matriz ortogonal ( autovetores) oriunda da decomposição espectral da matriz 

covariâncias (Análise do componente principal). 

Elementos da matriz ortogonal B. 

Covariância estacionária entre duas V As nas posições X; ex J. 

Covariância estacionária entre duas V As separadas por h. 

CovariânciaentreduasVAs Z(x,) e Z(x,). 

Covariância cruzada entre fácies F; e Fi separadas por h. 

Covariância estacionária para o corte z, . 

Covariância estacionária cruzada entre os cortes z, e z, .. 

Covariância de um dos fatores ou estruturas da covariância imbricada. 

Covariância do campo de probabilidades. 

Covariância do campo uniforme. 

Covariância estacionária da FA residual Y(x) ou covariância da gaussiana Y(x). 

Covariância entre uma variável primária e uma secundária. 

Vetor dos componentes principais indicatrizes. 

Cada um dos componentes principais indicatrizes. 

Esperança matemática de Z(x). 

Esperança da indicatriz do corte z, na posição x. 

Esperança condicional da indicatriz do corte z, na posição x em relação aos 

dados indicatrizes da vizinhança. 

Função de distribuição acumulada estacionária relativa ao corte zk. 

Função de distribuição acumulada não estacionária relativa ao corte zk . 

Função de distribuição acumulada não estacionária na posição x até 

o corte Zk condicionada a n dados na vizinhança de x. 

Função de distribuição acumulada univariada, obtida a partir de dados amostrais, 

representativa da área em estudo. 

Inversa da ccdf para o valor de probabilidade p na posição x. 

Funções que compõem a deriva. 

Função de distribuição acumulada gaussiana padrão. 

Produto espessura x porosidade (m). 

XI! 



m 

m(x) 

llle 

N(O,l) 

N(h) 

o. 
P(x) 

Indicatriz da Fácies F; em uma dada posição x. 

Indicatriz correspondente a um corte z. na posição x. 

Esperança matemática estacionária de uma V A. 

Esperança matemática não estacionária, deriva. 

Esperança matemática da ccdf gaussiana, no caso o valor da estimativa. 

Esperança matemática do campo gaussiano, no caso igual a O. 

Número de amostras de um tipo de variável na cokrigagem. 

Distnbuição gaussiana padrão com média zero e variância unitária. 

Número total de pares de amostras separadas pela distância h. 

Componentes da função objetivo. 

Campo de Probabilidade. 

P[Z(x) s z.] Probabilidade de Z(x) ser menor ou igual ao corte z •. 
P[Z(x) s z. l(n)] Probabilidade condicional de Z(x) ser menor ou igual ao corte z. considerando as 

informações da vizinhança. 

P[Z(x) s ziv(x)] Probabilidade de Z(x) ser menor ou igual a z dado que a variável secundária 

V tem o valor v no mesmo ponto x. 

R 

s(x) 

U(Z(x)) 

V(x) 

V ar(.) 

w. 
y; 

Y(x) 

z• 
~, 

z(x;) 

zjk 

z •• (x) 

z.,n, (x) 

Alcance, amplitude prática, praticai range. 

Função da deriva externa. 

Transformação uniforme de Z(x). 

Variável secundária. 

Variância. 

Posição genérica em que é realizada a estimativa. 

Ponderadores da função objetivo. 

Parâmetros de corte (cuto.ffs) gaussianos. 

Componente estocástico com média zero e covariância conhecida; 

V A correspondente às ccdfs prévias na krigagem de Markov-Bayes; 

Função gaussiana nas simulações gaussianas. 

Estimativa de uma Variável na cokrigagem. 

Valor amostral na posição x;. 

Variável aleatória correspondente a um atributo k em uma posição j. 

Valor obtido através da krigagem dos dados condicionantes (bandas rotativas). 

Valor obtido através da krigagem dos valores simulados (bandas rotativas) não 

condicionalmente na mesma posição dos dados originais condicionantes. 

Fator que compõe uma variável aleatória para a KF. 

Valor simulado condicional. 

Valor simulado não condicional. 

Xlll 



z,.(x) 

A 

* 

À.; 

cr' k 

cr 

2y(.) 

y 1(h;z.) 

y ,(h;zk ,z,.) 

Yaa, (h) 

p(h) 

l.l 

õkk o 

Resultado de cada uma das i simulações unidimensionais da TB. 

Matriz diagonal correspondente aos autovalores da decomposição espectral da 

matriz de covariâncias. 

Para todo e qualquer valor. 

Referente à estimativa. 

Erro médio da estimativa. 

Erro médio absoluto da estimativa. 

Ponderadores da krigagem relativos a uma variável transformada auxiliar. 

Ponderadores da krigagem. 

Variância. 

Variância de krigagem. 

Desvio padrão. 

Desvio padrão da ccdf gaussiana, no caso a raiz quadrada da cr~ . 

Desvio padrão do campo gaussiano, no caso igual a 1. 

Variograma. 

Semivariograma indicatriz estacionário para o corte zk . 

Semivariograma indicatriz cruzado estacionário entre os cortes z. e z •.. 

Semivariograma cruzado entre duas variáveis na cokrigagem. 

Correlograma. 

Multiplicador de Lagrange. 

Delta de Kronecker. 

XIV 



ACP 

cb 

ccdf 

cdf 

coKI 

coKir 

COK 

COKS 

FA 

FAik 

FO 

GSLIB 

VOIP 

HCIP 

IC 

IPCK 

ISATIS 

KDE 

KF 

KI 

Kim 

KM 

KO 

KS 

KT 

KU 

LU 

Mm3 

pdf 

P-field 

Lista de Abreviaturas 

Análise do Componente Principal 

Relativo ao caso base 

Função de distribuição acumulada condicional. 

Função de distribuição acumulada. 

Cokrigagem Indicatriz 

Cokrigagem Indicatriz Reduzida 

Cokrigagem Ordinária 

Cokrigagem Simples 

Função aleatória. 

Função aleatória intrínseca de ordem k. 

Função objetivo. 

Geostatistical Software Library 

Volume de óleo in place. 

Volume de hidrocarboneto in place. 

Intervalo de Incerteza 

Krigagem dos Componentes Principais Indicatrizes 

Software Geoestatístico da Geovariances. 

Krigagem com Deriva Externa 

Krigagem Fatorial 

Krigagem Indicatriz 

Krigagem Indicatriz Mediana 

Krigagem da Média 

Krigagem Ordinária 

Krigagem Simples 

Krigagem com modelo de trend, deriva. 

Krigagem Universal 

Decomposição LU (lower/upper) de Cholesky 

Volume em milhares de metros cúbicos. 

Função de densidade de probabilidade 

Campo de Probabilidade 

XV 



RA 

SA 

SCRF 

SGS 

SIS 

TB 

VA 

VPT 

Abordagem de Roth e Armstrong (1995) para intervalos de incerteza locais. 

Simulated Annealing 

Publicações de Stanford Center for Reservoir Forecasting 

Simulação Gaussiana Seqüencial 

Simulação Indicatriz Seqüencial 

Simulação Tuming Bands ou Bandas Rotativas 

Variável aleatória. 

Volume poroso total do reservatório. 

XVI 



1. Introdução 

Muitos e diversificados processos geológicos tais como sedimentação, erosão, 

migração, diagênese produzem complexas distribuições espaciais das propriedades do 

reservatório. O desafio atual em caracterização de reservatórios é combinar o maior número de 

componentes relevantes das incertezas sobre as características do reservatório (volume de 

hidrocarboneto in-place, falhas, continuidade das argilas e areias, tamanho de aqüífero, 

permeabilidades relativas, etc) com intuito de obter uma distribuição de probabilidade da 

performance de produção. 

Mesmo com os grandes avanços em todas as áreas que envolvem a estimativa de 

performance de reservatórios petrolíferos, muitas incertezas ainda persistem. 

Muitos fatores contribuem para a incerteza na estimativa de performance e do 

volume de hidrocarboneto in-place (HCIP). Das quatro incertezas na figura 1.1, as que mais se 

destacam são as referentes às etapas de caracterização do reservatório e mudança de escala 

(upscaling). 

Qualidade dos 
Dados 

Análise e 
Seleçiodos 

Dados 

Caracterização de Reservatórios 

Modelo 
Geológico 
Conceituai 

Previsão de 
Produção 

Ptoobabllistlca 

Estimativa 
f----------.1 Probabllistlca 

doHCIP 

Figura 1-1: Incertezas na caracterização e simulação de reservatórios. 

A primeira etapa consiste no levantamento dos dados oriundos da geologia, 

engenharia e geofisica. Constantes avanços têm possibilitado a obtenção de dados com melhor 

qualidade e com menor incerteza, por exemplo: melhorias nas técnicas de perfilagem, na 

execução e interpretação de testes, utilização de sísmica 3D, etc. Ressalta-se que mesmo nesta 

fase, têm-se muitas incertezas, principalmente porque medidas são obtidas de forma indireta e 

l 



as condições de coleta e análise das amostras não representam convenientemente as condições 

de subsuperficie. 

Em seguida, começa a etapa de caracterização de reservatórios propriamente dita. 

São realizadas análises estatísticas dos dados, correlações rocha-perfil, definição de 

eletrofácies e das unidades de fluxo. O segundo passo na caracterização de reservatórios é a 

construção de um modelo geológico conceitua! quando são definidos os ambientes 

deposicionais e diagenéticos e o arcabouço estrutural e estratigráfico da acumulação. 

Todas as informações servirão de base para a modelagem do reservatório no que diz 

respeito à distribuição· de fácies e de suas características permoporosas. Procura-se extrapolar 

caracteristicas petrofisicas para todas as regiões do reservatório a partir das informações nos 

poços, dos levantamentos sísmicos, dados de afloramentos, etc. A geoestatística possibilita a 

integração de dados de diversos tipos, escalas, suportes e graus de confiabilidade. As 

abordagens geoestatísticas são a krigagem e a simulação estocástica. 

A krigagem envolve a obtenção dos atributos em cada célula (bloco) do reservatório 

para a alimentação dos simuladores de fluxo ou obtenção de mapas para cálculo de volumes. É 

obtida uma única realização segundo o critério de minimização da variância do erro. Os mapas 

krigados capturam as grandes variações, mas sempre suavizam e não descrevem 

realisticamente a variabilidade do fenômeno. Este comportamento pode ser crucial quando as 

imagens krigadas são submetidas às simulações de fluxo. 

Haldorsen e Damsleth ( 1993) reportaram que os projetes iniciais para campos 

descobertos, avaliados e explotados no Mar do Norte do Reino Unido apresentaram alto 

percentual de erros nas estimativas de custos, produção de óleo e água, etc. De uma forma 

geral apresentaram grandes diferenças, principalmente pelo fato de que o breakthrough de 

água ter ocorrido muito mais cedo do que o previsto nos projetes. Os principais motivos 

expostos por Haldorsen e Damsleth ( 1993) para estes resultados foram: 

• Qualidade dos dados sísmicos - disponibilidade apenas de sísmica 2D resultando 

em reduzido número de falhas e mapas estruturais incorretos; 

• Modelos de simulação de fluxo com propriedades do reservatório muito 

homogêneas, com pouco detalhamento de heterogeneidades; 

• Exagerada comunicação vertical e lateral nos modelos de simulação. 

A necessidade de modelar realisticamente heterogeneidades do reservatório tem 

levado a adoção da abordagem estocástica. A abordagem estocástica envolve a determinação 

de inúmeros modelos prováveis para o reservatório sob estudo, em termos de distribuição de 

2 



fácies e de suas propriedades petrofisicas. Há duas classes de modelos estocásticos: os 

discretos e os contínuos. Os discretos foram desenvolvidos para descrever características 

geológicas de natureza discreta: posição e dimensões dos corpos de areia (por exemplo canal, 

crevasses em um ambiente deposicional fluvial); distribuição e tamanhos dos corpos de argila 

suspensos no meio das areias; distribuição, orientação e comprimento de fraturas e falhas; 

modelagem de fácies, etc. Em todos esses casos, um ponto no espaço pertence a apenas um 

limitado número de classes, e o modelo estocástico controla como as classes interagem em 

cada ponto. 

Já os modelos contínuos foram desenvolvidos para descrever um fenômeno que varia 

continuamente, por exemplo as propriedades da rocha tais como: porosidade, permeabilidade, 

velocidades sísmicas, etc. 

Para o técnico que faz uso da simulação estocástica, as diferenças entre os diversos 

algoritmos disponíveis e os efeitos nos resultados da modelagem necessitam ser melhor 

entendidos para que possa utilizar o algoritmo adequado à situação que ele estiver analisando. 

Cada algoritmo de simulação estocástica tem seu campo de aplicação, não havendo o melhor 

para qualquer situação. 

As avaliações de incertezas derivadas de análises geoestatísticas devem sempre ser 

acompanhadas das condições (hipóteses) sob as quais os resultados foram obtidos. Deve-se 

sempre ter em mente que a incerteza não está apenas na variabilidade entre realizações a 

modelos fixos e parâmetros fixos, mas também na validade do próprio modelo ou em seus 

parâmetros. Um modelo por definição é uma simplificação ou uma aproximação do 

fenômeno real, e consequentemente não pode representar na totalidade todos os seus 

aspectos particulares. 

A dissertação estará limitada ao estudo das incertezas envolvidas na modelagem do 

reservatório com as ferramentas geoestatísticas. 

É salutar que outras incertezas sejam introduzidas no processo de avaliação da 

performance do reservatório, destacando-se principalmente a etapa de mudança de escala 

(upscaling) que basicamente é a transferência da malha geoestatística refinada para uma malha 

mais grosseira para simulação de fluxo. Nesta etapa, grandes incertezas são introduzidas, 

sendo que muitas vezes, detalhes das heterogeneidades modeladas na fase anterior, são 

parcialmente perdidos. Outras incertezas são introduzidas quando da seleção das imagens a 

serem submetidas a simulação de fluxo. Têm-se também as incertezas devido às simplificações 

envolvidas nos simuladores numéricos. Grandes progressos já foram alcançados e vários 

3 



modelos de simuladores foram desenvolvidos: black-oil, composicional, modelos térmicos, etc. 

Uma das limitações em termos de simulação de fluxo é a impossibilidade de utilizar modelos 

com "bilhões de blocos", o que descartaria a necessidade da mudança de escala. 

MUitos trabalhos têm sido realizados no sentido de identificar e reduzir as incertezas 

nas várias etapas da caracterização e simulação de fluxo para previsão de comportamento. 

Contudo, poucos trabalhos têm sido realizados no sentido de explicitar as incertezas 

intrínsecas da modelagem geoestatística. 

1.1 Motivação 

Nos últimos congressos de geoestatística, foram apresentados trabalhos voltados para 

analisar a capacidade da geoestatística enquanto ferramenta de avaliação do espaço de 

incerteza de um determinado atributo. Em especial, Srivastava (1997) fez uma análise critica 

da geoestatística, expondo os principais problemas que devem ser analisados pela comunidade 

de geoestatísticos. Dentre estes problemas destacam-se: geoestatística e as universidades, 

softwares geoestatísticos, notação geoestatística, geoestatística e quantificação de incertezas. 

Em seu trabalho Srivastava (1997) reporta que ainda são poucas as universidades que 

têm a disciplina geoestatística a nivel de graduação e que deve se dar prioridade na formação 

de novos professores. O levantamento dos trabalhos publicados nos últimos congressos sobre 

geoestatística e geologia quantitativa (tabela 1-1) representa um forte indício de que, a nivel de 

Brasil, esta questão também deve ser relevante. Neste levantamento foi considerado apenas a 

instituição ou universidade do primeiro autor, na época da publicação. Apesar do levantamento 

incluir trabalhos de universidades, consultores e da indústria, verifica-se claramente a 

preponderãncia dos principais centros de referência em geoestatística: França e Estados 

Unidos. Até mesmo o destaque de outros países como Portugal, Canadá e Noruega pode ser 

observado. A nivel de indústria de petróleo, alguns trabalhos de técnicos e geoestatísticos 

brasileiros têm sido publicados no SCRF, na Mathematical Geology e nos congressos 

específicos da área. 

Uma outra questão levantada por Srivastava ( 1997) diz respeito aos softwares que, 

segundo ele, apresentam bugs e algoritmos muito rígidos, dificeis de serem otimizados para 

uma situação específica. O autor também reporta que a notação geoestatística utilizada nas 

publicações é bastante diversificada, o que dificulta o intercâmbio de idéias e disseminação de 

novos algoritmos. 

4 



Tabela 1-1: Trabalhos apresentados nos Congressos Internacionais de Geoestatística por pais. 

País Congresso 83 Congresso 88 Congresso 92 Congresso 96 Total 
França 20 32 18 16 86 
USA 27 14 19 20 80 
Portugal 1 6 6 14 27 
Canadá 9 2 8 6 25 
Noruega - 1 4 16 21 
Inglaterra 3 4 5 3 15 
:Africa do Sul 2 3 4 4 13 
Austrália 1 2 2 6 11 
Espanha - 1 5 4 10 
Holanda - 3 4 3 10 
Brasil - 2 1 4 7 
Outros (15) 2 9 9 15 35 
Total 65 79 85 111 340 

A questão central levantada por Srivastava (1997) diz respeito ao espaço de 

incertezas coberto pelos algoritmos de simulação estocástica. Alguns outros trabalhos de 

Srivastava (1994) e de outros autores como por exemplo Journel (1994 e 1997) enfocam 

tópicos relativos a incertezas na modelagem estocástica, que muitas vezes são mal 

compreendidos. A motivação foi basicamente fazer uma análise critica e uma reflexão sobre 

conceitos e temas relativos a incertezas, quando da utilização da ferramenta geoestatística na 

modelagem de reservatórios. Será dado um enfoque às aplicações da área de petróleo, porém 

muitas das questões abordadas são extensíveis a outros campos de aplicação. 

As questões levantadas por Srivastava ( 1997) devem ser motivo de reflexão por parte 

da comunidade de geoestatísticos. 

1.2 Objetivos da Dissertação 

Assim, o objetivo primordial desta dissertação é fazer uma reflexão e análise critica, 

esclarecendo conceitos relativos ás incertezas na modelagem geoestatística. Serão utilizados 

exemplos práticos e alguns disponíveis na literatura. Um objetivo secundário é revisar os 

principais métodos de estimativa (krigagem) e de simulação estocástica com ênfase na 

avaliação de incertezas. Para as principais metodologias serão feitos breves resumos para que a 

discussão sobre incerteza se torne facilitada. 

Algumas das questões abordadas não têm uma solução, como por exemplo o número 

de simulações estocásticas necessárias para cobrir adequadamente o espaço de incertezas. 

Este, dentre outros conceitos, serão abordados de forma a elucidá-los. 

5 



1.3 Organização da Dissertação 

Trata-se de uma dissertação baseada em uma extensa revisão bibliográfica, acrescida 

de reflexão e análise crítica, expondo as questões relevantes em termos de incertezas 

envolvidas na utilização da geoestatística como ferramenta auxiliar na caracterização de 

reservatórios. 

O capítulo 2 apresenta um conjunto de termos e conceitos envolvidos na modelagem 

estocástica de reservatórios que dada a importância dos mesmos no escopo do trabalho optou-

se por constituir um Cl\pítulo em separado no início da dissertação. 

No capítulo 3, são apresentados os principais tipos de krigagem. Serão abordadas as 

metodologias que possibilitam a utilização de dados qualitativos e a evolução das propostas 

que enfocam a questão da ocorrência dos ponderadores negativos. 

No capítulo 4, são apresentadas as principais incertezas envolvidas na krigagem. São 

analisados a influência do número de dados condicionantes e do viés na amostragem na 

obtenção da estimativa. Foram comparadas duas abordagens para geração de intervalos de 

incerteza a partir das krigagens paramétricas: a tradicional (distribuição multivaríada gaussiana 

dos erros de estimativa) e a metodologia proposta por Roth e Armstrong (1995). 

O capítulo 5 compreende uma revisão bibliográfica sobre os principais métodos de 

simulação estocástica. 

No capítulo 6, são apresentadas maneiras de visualização de incerteza referentes a 

simulação de variáveis aditivas (porosidade, volume poroso, etc). Foi implementado o 

algoritmo de simulação campo de probabilidade. Serão também abordados temas relacionados 

à incerteza, tais como: flutuações ergódicas e integral range, equiprobabilidade das 

realizações, incertezas nos parâmetros e no modelo, etc. 

No capítulo 7 estão as principais conclusões. 

6 



2. Terminologia 

A utilização da geoestatística como ferramenta de modelagem de reservatórios tem 

colocado uma porção de conceitos nem sempre bem entendidos pelos usuários finais. Os 

termos descritos a seguir fazem parte de um trabalho maior realizado em paralelo à preparação 

da dissertação. Este trabalho denominado Glossário Geoestatístico Básico (Oliveira; Remacre, 

1997) está em fase final de elaboração. 

2.1 Incerteza e Erro 

Em sentido lato, erro é a diferença entre um valor medido ou calculado e o valor 

correto. Contudo erro em problemas de modelagem estocástica não pode ter esta abordagem. 

Na realidade, quando são usados modelos para obter estimativas não se conhece o valor real, 

mas apenas valores potenciais para o atributo. Sem uma possibilidade de determinação do erro 

nestas circunstâncias, pode-se introduzir o termo que é definitivamente melhor - incerteza. 

Incerteza é o conceito ou condição de estar em dúvida sobre um valor. Note que na 

definição de incerteza não há julgamento da exatidão e precisão de um dado valor. Erro, como 

usado em modelagem matemática, poderia ser definido como um desvio de um resultado de 

algum valor considerado o valor real para aquele lugar, tempo e sob aquelas condições. 

O conhecimento incompleto do fenômeno e a falha na inclusão de todos os fatores 

pertinentes que influenciam a variável de interesse resultam necessariamente em incertezas. As 

ferramentas geoestatísticas são usadas com o objetivo de delimitar estas incertezas. 

2.2 Precisão e Acurácia 

Na literatura técnica, às vezes, os termos precisão e acurácia são usados com o 

mesmo significado. Porém, alguns geoestatísticos evidenciam a diferença entre os dois termos. 

Técnicas geoestatísticas são usadas para construir modelos probabilísticos de incerteza sobre 

valores verdadeiros não conhecidos. A qualidade desses modelos probabilísticos pode dar as 

medidas relativas aos conceitos de precisão e acurácia. 

7 



A idéia básica da geoestatística é modelar a incerteza a respeito de um valor 

desconhecido de z sobre uma variável aleatória (V A) Z caracterizada por uma específica 

distribuição de probabilidade. O valor desconhecido pode ser um parâmetro global tal como o 

fator de recuperação, o tempo de breakthrough, ou um atributo local tal como a porosidade e 

a permeabilidade em uma determinada região ou posição do reservatório. 

Uma distribuição é dita acurada se dado algum intervalo de probabilidade, ela contém 

a resposta verdadeira. Por exemplo Deutsch e Joumel (1992) utilizaram intervalo de 

probabilidade de 95%, enquanto Gotway eRutheford (1994), 80"/o. 

A precisão é avaliada diretamente da dispersão da distribuição, o que facilita a 

comparação de algoritmos. Será tanto mais precisa, quanto mais estreita for a distribuição. 

Contudo é impossível avaliar a acurácia, uma vez que não se conhece a priori, o valor 

verdadeiro do atributo ou da performance do reservatório que se está simulando. Uma 

condição mínima para acurácia é que a técnica utilizada leve em consideração todos as 

informações consideradas relevantes. Na Figura 2-1 estão exemplos de distribuições de 

resposta com diferentes situações de precisão e acurácía. O ideal é obter uma distribuição 

precisa e acurada. 

Legenda 

Valor Verdadeiro 

D Distribuição Precisa e Acurada 
~~ ~--} Distribuição Pr-ecisa e Na. o Acurada 

,-6-- Distribuição Não Precisa e Acurada 

ET- ~ Distrlbuiç&lt;!!to Não Precisa e Não 

Figura 2-1: Precisão e acurácia, 

"-r 

I I r 1 
\ 

No contexto de avaliação do modelo probabilístico, Deutsch ( 1997) propôs definições 

específicas de acurácia e precisão utilizando uma abordagem tipo validação cruzada, uma vez 

que a avaliação da acurácia requer o conhecimento do valor real. 

8 



2.3 Ergodicidade e Integral Range 

Ergodicidade está relacionada com a questão de determinar as estatísticas de um 

processo estocástico Z(x) a partir de uma única realização. Um processo estocástico é dito 

ergódico se com probabilidade 1 todas as suas estatísticas podem ser determinadas a partir de 

uma única realização (Papoulis, 1965, p.327). Ressalta-se que o conceito de ergodicidade foi 

definido inicialmente para processos estocásticos temporais, sendo estendido posteriormente 

para processos estocásticos espaciais. 

Geralmente não se está interessado em todas as estatísticas do processo, mas em 

apenas algumas particulares. Assim, pode-se definir ergodicidade com respeito a estas 

estatísticas. Por exemplo, considere uma função aleatória (FA) Z = (Z(x),x E R 0 ) com média 

m, variância a 2 e função de correlação p(h) . Dispondo de uma realização desta F A no 

domínio V, um estimador natural para a média m é: 

Este estimador Z(V) tem variância 

a' 
Var[Z(V)]= IV!' fvfvp(x-y)dxdy 

onde p(h) = C(h) I a 2 . 

A precisão deste estimador será tão maior quanto maior for o domínio; será máxima 

quando o volume V for infinito. Contudo, os domínios analisados em geoestatística são finitos. 

Por esta razão é utilizado o conceito de ergodicidade. 

Uma F A aleatória é dita de média ergódica se: 

lim Var{Z(V)} =O 
V-+:IJ 

Então, a ergodicidade faz com que Z(V) seja assintoticamente um bom estimador de 

m. Mas a ergodicidade não indica quão grande deverá ser o valor de V para que a variância de 

Z(V) se tome neglicenciável. Para isto é utilizado o conceito de integral range1 . 

O integral range (Lantuéjoul, 1991, p.390) é definido pela fórmula: 

A= lim lVI Var{Z(V)} 
v-+:JJ a 2 

1 Alternativas para 'integral range' são as expressões 'alcance integral' ou 'dontinio de ccrrelação'. 
Optou-se por não utilizá-las na dissertação. 

9 



Esta quantidade é não negativa, mas pode ser zero ou infinita. Ela tem a dimensão de 

um volume-O. Pode ser dada a seguinte interpretação física para o integral range: suponha 

O &amp;lt;A &amp;lt;+oo . Se lVI é muito maior do que A, então: 
crzA 

Var{Z(V)} "'lVf 

E pode se determinar um inteiro tal que 

lVI 
N ,., A e portanto 

O lado direito da fórmula acima representa a variância da média de n observações 

independentes. O dominio V pode ser dividido em n subdomínios independentes e disjuntos de 

tamanho A. Interpreta-se assim o integral range como a escala do fenômeno. Lantuéjoul 

(1991) apresentou uma metodologia prática para determinação do domínio V para se obter 

uma variância de Z(V) dentro de limítes predeterminados. 

O integral range também pode ser escrito com a fórmula (Matheron, 1989, p. 84): 

Quando a função de correlação p(h) tem uma baixa taxa de decrescimento, o 

integral range é infinito. Porém, para um modelo de semívariograma que atinge um patamar, 

pode-se dizer que o integral range objetivamente existe. Só que, muitas vezes, o domínio em 

que será realizada a simulação é pouco maior que o integral range e não se observará 

ergodicidade. 

A noção de ergodicidade pode ser estendida para qualquer outro parâmetro do 

modelo, por exemplo, a função covariância ou o semívariograma. 

Em simulação estocástica, utiliza-se a expressão 'flutuações ergódicas' para se referir 

ás variações nas estatísticas das várias realizações em relação a estatística do modelo de F A 

escolhido. Por exemplo, os variogramas e as ccdfs (funções de distribuição acumulada 

condicionais) das realizações apresentam diferenças em relação ao variograma e á cdf (função 

de distribuição acumulada) que foram utilizados para gerá-las. As flutuações ergódicas 

aumentam o espaço de incertezas. Realizações que honrem exatamente os modelos de cdf e 

variograma podem ser consideradas como um subconjunto de todas as realizações. 

10 



Algumas flutuações ergódicas são aceitáveis desde que o modelo estatístico esteja 

afetado por flutuações de amostragem. Em muitas aplicações, os modelos estatísticos são 

inferidos de amostras esparsas e não podem ser considerados como perfeitamente conhecidos. 

Portanto, desvios em relação ao modelo estatístico podem ser desejáveis, pois eles se 

relacionam com o aspecto da incerteza inerente. 

A partir das formulações apresentadas por Matheron (1989) e Lantuéjoul (1991) 

pode-se verificar que o tamanho de um domínio V suficiente para verificar a ergodicidade 

depende do alcance2 do modelo do semívariograma. Quanto mais contínuo for o 

semívariograma na origem e maior o alcance do semivariograma, maior será o domínio V 

necessário para se verificar a ergodicidade. 

Ergodicidade é uma propriedade do modelo probabilístico e não característica dos 

dados ou fenômenos sob estudo. É a propriedade da ergodicidade que permite inferir 

distribuição e momentos do modelo a partir de uma única realização. 

2. 4 Heterogêneo e Homogêneo 

Heterogeneidade é equivalente a variabilidade espacial. Significa que o valor de um 

atributo muda com a sua posição no reservatório. Portanto, quando se considera, para efeito 

de simulação de fluxo, reservatório homogêneo em relação a algum atributo, está se 

considerando que este atributo é uniforme no reservatório, isto é, ele não varia com a posição. 

Um reservatório apresenta vários níveis de heterogeneidades geológicas, cada um 

deles influenciando diferentemente o fluxo de fluidos e consequentemente a produção de 

hidrocarbonetos. 

De uma forma geral, os sistemas de classificação de heterogeneidades se baseiam na 

escala de observação, na origem genética e na influência no fluxo de fluidos. Por exemplo, 

Haldorsen e Lake ( 1984) analisando as propriedades internas dos reservatórios, que envolvem 

fatores como continuidade dos folhelhos, valores de porosidade e escala de observação, 

definiram quatro escalas de heterogeneidades: 

• escala microscópica (escala de poros e gargantas - 11m); 

• escala macroscópica (escala de plugs- cm); 

• escala megascópica (escala de blocos para simulação de fluxo - 200 a 400 m); 

2 Alcance ou amplitude prática é a distância h, na qual o semivariograma atinge o patamar. ou 95% 
do mesmo para os modelos que o atingem assintoticamente. O alcance representa o comprimento de correlação. 

11 



• escala gigascópica (escala da formação ou reservatório- maior que 1000 m). 

Um outro conceito, algumas vezes mal relacionado com homogeneidade, é a 

estacionariedade. Madureira et a!. (1994, p.SS) reportam que "estacionariedade é um outro 

nome para a noção intuitiva de homogeneidade espacial ... ". A noção correta de 

estacionariedade é a de um processo estocástico que apresenta flutuações regulares em torno 

de um valor médio, o que necessariamente não implica em um reservatório homogêneo. 

2.5 Sinergismo 

Há uma forte tendência na indústria de petróleo para agrupar todos os técnicos em 

uma equipe. Deve-se ter em mente que não existe o trabalho individual de um profissional, mas 

sim o trabalho de uma equipe. Cada profissional pode ser um especialista em sua área de 

atuação, porém não se pode prescindir que este profissional tenha um conhecimento 

generalizado de todas as etapas envolvidas na caracterização de reservatórios. Assim, o 

profissional saberá das limitações e das incertezas introduzidas nas etapas anteriores e os 

possíveis impactos em seu trabalho e consequentemente quais novas incertezas são 

introduzidas na etapa por ele trabalhada. Damsleth e Tjolsen ( 1993) sugerem que as 

universidades incluam um pouco mais de disciplinas ligadas à matemática, estatística e 

computação nos currículos de geologia. A recomendação multidisciplinar desses autores pode 

ser estendida para cada profissional que compõe a equipe de gerenciamento. 

Estes profissionais, sejam engenheiros, geólogos ou geofisicos, devem ter 

conhecimento multidisciplinar, sem contudo perderem a identidade profissional. Trata-se do 

sinergismo em gerenciamento de reservatórios. No escopo desta dissertação, várias vezes será 

utilizado o termo usuário para se referir ao profissional da equipe de gerenciamento que está 

mais envolvido com a modelagem de reservatórios via geoestatística. É evidente que todos, 

indistintamente, devem ter embasamento geoestatístico, tão mais especializado quanto maior 

for o envolvimento na utilização da ferramenta geoestatística para a modelagem de 

reservatórios e mais importantes forem os estudos desenvolvidos. A utilização dos algoritmos 

de simulação estocástica requer por parte do usuário, bom conhecimento do processo fisico do 

fenômeno sob estudo, e consequentemente do modelo escolhido. Não se trata de aplicar as 

ferramentas geoestatísticas a qualquer reservatório que se estiver analisando. É preciso 

identificar qual o tipo de heterogeneidade que mais influencia o fluxo de fluidos no meio 

poroso. Também é preciso saber quais técnicas geoestatísticas são aplicáveis, se os dados 

disponíveis são suficientes para a modelagem escolhida e, principalmente, se o objetivo do 

estudo requer um estudo mais ou menos detalhado. 

12 



3. Krigagem 

Geoestatística é um ramo da estatística que se originou na indústria mineira no início 

da década de 50 para auxiliar na estimativa de reservas minerais. Nesta área, ressaltam-se os 

trabalhos estatísticos de Krige sobre jazidas auriferas e os trabalhos de Wijs sobre jazidas 

uraníferas, ambos na África do Sul. 

Nos últimos anos da década de 50, as técnicas adotadas pela escola sul-africana 

chamaram a atenção de engenheiros franceses do Comissariado de Energia Atômica, e em 

especial de Georges Matheron, que a partir delas, desenvolveu conceitos inovadores 

colocando-as dentro de um arcabouço teórico chamado Teoria das Variáveis Regionalizadas 

Originalmente desenvolvido para solucionar problemas de estimativas de reservas 

minerais, a geoestatística tem se expandido para outras áreas das ciências naturais. 

Krigagem, procedimento geoestatístico introduzido por Matheron, foi definido por ele 

como uma estimativa de um atributo (no caso teor de minério), em um volume de suporte, 

através da ponderação de todas as amostras disponiveis, onde os pesos são obtidos com a 

restrição de que a somatória dos mesmos seja igual a 1 e a variãncia de estimativa seja mínima. 

A krigagem é originalmente um estimador linear. Nos recentes desenvolvimentos em 

geoestatística, métodos de estimativas espaciais não lineares têm tomado parte da 'família de 

krigagens'. 

3.1 Conceitos Iniciais 

Dispõe-se de n dados z(x;) em posições x;. Admite-se que em cada uma das i 

posições, tem-se urna variável aleatória (V A) Z(x;) e que dada uma posição adicional Xo, tem-

se que Z(Xo) também é uma V A em Xo. 

Assume-se também que estas V As são um subconjunto de um função aleatória (F A) 

Z(x) com estacionariedade de segunda ordem sobre um domínio D: 

E[Z(x +h)]= E[Z(x)] = m 

C[Z(x + h),Z(x)] =C( h) 

l3 



Deseja-se estimar Z(Xo) em uma posição pontual conhecida Xo, baseando-se nos 

dados disponíveis z( x;). 

Os diferentes tipos de krigagem podem dar uma falsa impressão de complexidade. 

Porém, todas as krigagens são técnícas de regressão que diferem apenas nos tipos particulares 

de funções obtidas a partir dos dados, que estão sendo recombinadas para a obtenção da 

estimativa. Assim, as principais técnícas de krigagem serão apresentadas com o objetivo de 

esclarecer tanto a obtenção da estimativa, quanto dos intervalos de incerteza, e 

consequentemente, das funções de distribuição acumulada condicional ( ccdfs) que são 

utilizadas em alguns álgoritmos de simulação estocástica. As técnícas básicas de krigagem são 

a krigagem simples e a krigagem ordinária, sendo que as demais constituem variações das 

mesmas em relação a utilização de mais de um tipo de atributo desde que correlacionados, a 

modelagem com deriva, ou mesmo transformações realizadas nos dados originais, por exemplo 

a indicatriz. De uma forma geral cada metodologia constitui uma alteração das abordagens 

básicas iníciais ora no sentido de incorporar mais informações oriundas de outras fontes de 

dados, ora no sentido de diminuir o tamanho dos sistemas de krigagens priorizando as 

informações adicionais que são mais conseqüentes para a obtenção da estimativa e da ccdf em 

qualquer posição do domínio. Ressalta-se que para a construção de ccdfs locais a partir de 

krigagens, adota-se o modelo gaussiano. A exceção é com relação às abordagens indicatrizes 

que não necessitam da adoção de nenhum modelo a priori. As principais técnícas de krigagem, 

priorizando as que são mais utilizadas na simulação estocástica, serão apresentadas em uma 

seqüência que considera o aumento de informações. 

3.2 Krigagem da Média 

O valor médio de um conjunto de amostras pode ser calculado através da média 

aritmética se as amostras estiverem regularmente distribuídas, ou através da krigagem da média 

que considera a configuração espacial das amostras e a correlação espacial entre as mesmas. 

Assim a estimativa da média ( m ·) pode ser realizada através da combinação linear: 

n 

m· = ~)-;Z(x;) (3.2.1) 
i;;;:] 

Com o critério de minímização da variância do erro de estimativa da média 

n n 

Var(m-m·) = LLÀ.).;C(x, -x;) 
i==l j"'l 

14 



e com a condição de não viés ( somatória dos pesos igual a 1 ), é obtido o sistema de equações: 

n 

~) ... ;C(x,- x;) -1-1 =O '&lt;ti= 1,2, ... ,n 
j=l 

(3.2.2) 

Resolvendo este sistema de equações, obtêm-se os ponderadores e o multiplicador de 

Lagrange que corresponde à própria variância de estimativa da média. Com os ponderadores, 

estima-se a média. 

3.3 Krigagem Simples 

Assume-se que a média m é conhecida, isto é, E[Z(x)] é a mesma em qualquer ponto 

x do domínio. Então, o estimador de krigagem simples (KS) é definido como: 

n 

z• (xo) = m + L).&lt;xo )(Z(x;)- m) (3.3.1) 
i= I 

n n n 

Z'(x 0 ) = m[1- l).;(x0 )]+ 2).;(x 0 )Z(x;) = mÂ.m + ~&gt;,(x0 )Z(x;) (3.3.2) 
i=l i=l 

Na equação 3.3 .2, Â.m corresponde ao peso que a média global m recebe na 

estimativa da variável na posição XtJ. O estimador da krigagem simples não inclui restrições 

quanto aos pesos. O estimador da KS é sempre não enviesado, pois o erro da estimativa, 

diferença entre o valor estimado e o valor verdadeiro, é sempre nulo na média. 

A variância da estimativa pode ser expressa por: 

n n n 

cr 2 (x 0 )= LL),(x 0 )Â.;(x 0 )C(x, -x;)+C(x 0 -x 0 )-2LÃ.,(x 0 )C(x, -x0 ) (3.3.3) 
~lj=l ~I 

Com o critério de mínimízação da variância de estimativa, é obtido o sistema de 

equações da krigagem simples : 

n 

L Ã.,(x 0 )C(x, -x) = C(x, -x 0 ) '&lt;ti = 1,2, ... , n 
j=l 

(3.3.4) 

Da resolução deste sistema são obtidos os pesos ótimos da krigagem À.;, e 

consequentemente a estimativa da variável no ponto XtJ a partir da equação 3.3.1. 

Com as expressões 3.3.3 e 3.3.4, pode-se obter a variância da krigagem simples: 

n 

cr~,(x0 ) =C( O)- L Ã.;(x 0 )C(x,- x 0 ) (3.3.5) 
i"" I 

15 



Como pode ser observado, os valores de Z(x) não entram na formulação, portanto a 

variância de krigagem é um indicador da qualidade do arranjo geométrico dos dados. Ela 

depende apenas da configuração dos dados e do modelo de covariância adotado. 

3.4 Krigagem Ordinária 

A krigagem ordinária (KO) é um dos mais importantes tipos de krigagem. Deseja-se 

determinar um valor em uma determinada posição Xo usando os n dados vizinhos Z(xi) através 

de uma combinação linear com ponderadores À.;: 

n 

z' (x 0 ) = ~).;(x 0 )Z(x;) (3.4.1) 
i::::: I 

Da mesma forma que na KS, deseja-se minimizar a variância do erro, só que na KO é 

necessário acrescentar a condição não viés, isto é, a somatória dos pesos igual a 1. O sistema é 

então resolvido introduzindo o multiplicador de Lagrange Jl. O procedimento fornece um 

sistema com (n+l) equações e (n+1) incógnitas que correspondem aos n valores dos 

ponderadores mais o parãmetro de Lagrange. O sistema de krigagem pode ser escrito em 

função da covariância (3.4.2) ou do semivariograma, pois foi incluída a condição de não viés. 

n 

L À;(x 0 )C(x,- x;) -!l(X 0 ) = C(x,- x 0 ) 'v'i = 1,2, ... ,n 
.PI 

n 

LÀ;(x 0 )=1 
j""t 

(3.4.2) 

O sistema de equações terá uma única solução se, e somente se, a função covariância 

modelada a partir dos dados for positiva definida. A variância de krigagem é escrita como: 

n 

a~. (x 0 ) =C( O)+ !l(X0 )- :L;t..;(x0 )C(x, - x0 ) (3.4.3) 
i""' I 

Da mesma forma que na KS, a variância da KO não fornece medida absoluta de 

confiabilidade. Trata-se de uma medida relativa da qualidade da interpolação para as diferentes 

regiões, ou a qualidade da configuração geométrica dos pontos. Implicitamente dentro da KO 

está o cálculo da média dos dados através da KM. Remacre (1995) demonstrou a relação 

entre os ponderadores obtidos através da KM, KS e KO e o relativo à média na estimativa 

através da KS: 

Usando vizinhança móvel, para cada posição Xo, a KO estima a média m(Xo) a partir 

dos dados da vizinhança. Assim sendo, a KO com vizinhança móvel já é um algoritmo não 

16 



estacionário que pode manusear não homogeneidade dos dados, sendo este o fator de sucesso 

e durabilidade da KO quando aplicada com vizinhança móvel. 

3.5 Krigagem Universal 

A krigagem universal (KU) difere da krigagem ordinária no modelo do componente 

da deriva, trend. Na KO o componente da deriva é limitado a uma simples constante (m). Na 

KU, também conhecida como krigagem com modelo de trend (KT), o mesmo é modelado por 

uma expressão analítica que toma diferentes valores no espaço. 

Define-se a função aleatória Z(x) composta por um componente determinístico m(x), 

a deriva, e uma função residual aleatória Y ( x). 

Z(x) = m(x) + Y(x) 

O componente Y(x) é modelado como uma função aleatória estacionária de segunda 

ordem com média zero e covariância Cy(h). Assim sendo, tem-se que: 

E[Z(x)] = m(x) 

O componente de deriva, chamado também de média local, definido como m(x) é 

geralmente modelado como um polinômio de baixa ordem das coordenadas do vetar x. 

T 

m(x) = 2&gt;.f.(x) 
t=O 

Na equação acima, a, são coeficientes desconhecidos do modelo de deriva e são não 

nulos; f.( x) são funções conhecidas das coordenadas e f
0 

( x) = I . As funções f.( x) que 

definem a deriva devem ser prioritariamente especificadas conforme a fisica do problema. 

Para a krigagem é usada a combinação linear: 

n 

z• (x 0 ) =L Ã;(x 0 )Z(x;) (3.5.1) 
i: I 

A partir da condição de não viés, pode ser obtida a relação entre os ponderadores da 

krigagem e as funções f, ( x) da deriva. Esta relação faz parte do sistema de equações da KU. 

Desenvolvendo a expressão para a variância de estimativa e minimizando-a, é obtido 

o sistema da krigagem universal (KU). 

n T 

L À;(x 0 )Cy(x, - x;)- L f! 1 (x 0 )f, (x;) = Cy (x, x 0 ) vi= 1,2, ... , n 
J::ol t=O 

n (3.5.2) 

LÃ;(x 0 )f,(x;) = f,(x 0 ) Vt = 0,1, ... , T 
jol 

17 



onde 1-t, são os (T + 1) multiplicadores de Lagrange associados às (T + 1) restrições dos pesos. A 

variância de estimativa é escrita como : 

n T 

cr;.(x 0 ) = Cy(O)- ~),;(x0 )Cy(X; -x 0 )- L!J 1 (x 0 )f,(x 0 ) (3.5.3) 
t=O 

A inferência sobre o modelo de covariância residual Cy (h) a partir dos dados Z(x) é 

uma etapa crítica para os algoritmos de KU. Alguns softwares geoestatísticos, como o 

ISATIS, possuem um procedimento de reconhecimento de deriva onde o usuário pode 

escolher diversos tipos de funções. 

Às vezes, se observam problemas com a utilização da KU. Por exemplo, a remoção 

da deriva m(x) dos dados Z(x) para obtenção dos resíduos Y(x) pode introduzir correlações 

espúrias e obtenção da covariância dos resíduos não representativa para o fenômeno. 

Matheron (1973, apud Cressie, 1993) propôs uma abordagem para krigagem com 

existência de deriva através do formalismo da função aleatória intrínseca de ordem k (F Alk). 

Com esta abordagem é inferido um modelo de covariância generalizada que permite calcular a 

variância de qualquer combinação de dados Z(x) que filtram a deriva m(x). As covariâncias 

generalizadas de ordem k são definidas como variâncias das diferenças de ordem (k+ I) do 

modelo inicial da FA Z(x). O variograma tradicional corresponde à variância das diferenças de 

primeira ordem e portanto està relacionado com a covariância generalizada de ordem zero. 

Assim a utilização do semivariograma filtra qualquer componente polinomial de ordem zero 

das coordenadas adicionado ao modelo de FA Z(x) , tal como m(x)=constante. Da mesma 

forma, a covariância generalizada de ordem k filtra os componentes do polinômio de ordem k 

adicionados ao modelo de FA Z(x). Assim, a covariância generalizada pode ser usada nas 

equações de krigagem como se fosse uma covariância ordinária. 

Deutsch e Journel (1996, p.l4) reportam que "a despeito da importância teórica do 

formalismo das funções aleatórias intrínsecas de ordem k (F Alk)", decidiram não incluir 

covariâncias generalizadas e os modelos de FAlk na GSLID. Journel (1986a) refere-se a FAlk 

como um "formalismo esotérico" e reporta que a krigagem com F Alk resulta exatamente no 

mesmo sistema de equações da KU. Não obstante a controvérsia, a krigagem com FAlk 

proposta por Matheron é uma alternativa à KU com um embasamento teórico e matemàtico 

muito mais elaborado. Ressalta-se que KU foi proposta por Huijbregts e Matheron (1971, 

apud David, 1988). 

18 



3.6 Krigagem Fatorial 

A krigagem fatorial (KF), metodologia geoestatística desenvolvida por Matheron, 

permite a decomposição de uma variável regionalizada em diferentes componentes que podem 

ser mapeados separadamente para análise, possibilitando a eliminação de ruídos, sendo 

portanto utilizada como filtro. Trabalhos recentes têm retomado a utilização da KF como uma 

técnica geoestatistica de filtragem, principalmente nas aplicações que utilizam dados sísmicos 

e, por isso, optou-se por descrevê-la sucintamente apesar de não ser uma técnica de krigagem 

propriamente dita. 

Em vez de separar o modelo de FA Z(x) em uma deriva determinística m(x) mais o 

componente estocástico Y(x), a KF considera um modelo com dois ou mais componentes 

estocásticos independentes (também chamados fatores em relação a análise fatorial). 

Z(x) = Z0 (x) +Z,(x)+ ... +ZL(x) 
A covariància de Z(x) é então a soma de (L+!) covariàncias: 

L 

Cz(h) = 2;C,(h) 
t""O 

Por exemplo, as (L+ I) FAs Z,(x) podem ser modeladas a partir das (L+ I) estruturas 

da covariância imbricada C,(h) usadas para modelar a covariància dos dados amostrais. Assim 

sendo, cada estrutura do semivariograma imbricado modelado, corresponde uma variável 

aleatória 'fictícia'. 

A krigagem da soma parcial de qualquer número de componentes Z1(x) pode ser 

obtida por filtrar a contribuição da covariância dos componentes não selecionados. Por 

exemplo iniciando do sistema da KO, filtrando o primeiro componente, tem-se o seguinte 

estimador: 

(3.6.1) 

Onde os pesos À são obtidos pelo sistema de krigagem fatorial: 

n L 

LÀj(x.)Cz(X; -xJ+J.!o(Xo) = 2;C,(xo -xJ vi= l, ... ,n 
,Fl 1=10 

n (3.6.2) 

LÀ;(x 0 ) = 1 
j""l 

As equações podem ser rearranjadas para realizar a krigagem isolada de cada 

componente (fator), o que corresponderia à filtragem de todos os demais. 

19 



3. 7 Krigagem Com Deriva Externa 

Quando duas variáveis medidas de fonna diferente refletem o mesmo fenômeno e 

sendo a variável primária exata, porém conhecida em poucas posições, enquanto a variável 

secundária não pode ser medida com muita exatidão, mas pode estar disponível em um grande 

dominío espacial, pode-se usar a variável secundária para compor a deriva. 

A krigagem com deriva externa (KDE) é uma extensão da krigagem universal. O 

método de deriva externa consiste em integrar no sistema de krigagem, informações de uma ou 

mais funções de deri_va externa medidas exaustivamente no dominío. As funções de deriva 

devem ser conhecidas em todas as posições do grid, inclusive nas posições onde se dispõe da 

informação da variável primária. 

Admitindo a existência de apenas uma variável secundária e assumindo o modelo de 

deriva do tipo E(Z(x)) = a 0 +a1s(x), o sistema da KDE pode ser escrito como: 

n 

1).j(x0 )Cv (x, - x;) + Jlo (x 0) + J..t 1 (x0)s(xJ = Cy (x,- x0) Vi= 1,2, ... ,n 
_FI 

n 

~).j(x0 ) = 1 
FI 

n 

~). j(x 0 )s(xj) = s(x 0 ) 
j=l 

A variância de estimativa para a situação do sistema 3.7.1 é escrita como: 

n 

cria,E (x0) = Cy(O)- L ;\;(x0)Cy(x, - x0)- J..lo (x0) -J..t 1(x0)s(x 0) 
i=l 

(3.7.1) 

(3. 7.2) 

O sistema de equações 3.7.1 terá solução única se, e somente se, a função covariância 

modelada para os resíduos for positiva definida. 

A forma da deriva é definida implicitamente em cada posição através das variáveis 

secundárias que devem refletir a forma da variável primária. As relações entre as variáveis 

secundárias e a primária devem ter sentido tisico preferencialmente. Deutsch e Journel ( 1996, 

p. 70) reportam que as variáveis externas devem variar suavemente no espaço para não ocorrer 

problemas na inversão das matrizes quando da resolução do sistema de equações que pode 

ficar instável. 

Quando comparado com a cokrigagem, a KDE não requer inferência das covariâncias 

das variáveis secundárias e nem das cruzadas. O sistema de equações tem (n+2) equações no 

caso de uma variável secundária com modelo de deriva linear. A KDE tem como desvantagens 

20 



o fato de não capturar toda a correlação cruzada entre as variáveis corno a cokrigagern e 

também requerer o uso da covariància dos resíduos corno a KU. 

3.8 Cokrigagem 

A cokrigagern é urna extensão natural da krigagern quando variogramas e dados 

rnultivariados estão disponíveis. 

O estimador da cokrigagern ordinária (COK), também conhecida apenas corno 

cokrigagern, é urna combinação linear de pesos Â.~ com dados de diferentes variáveis 

localizados em pontos amostrais na vizinhança de um ponto Xo. Cada variável é definida corno 

um conjunto de amostras de tamanho 11a e o estimador é definido corno: 

N na 

z:, (x 0 ) = LL)~(x0 )Zu (x;) (3.8.1) 
a.=l i=l 

Onde o índice at se refere a urna variável particular do conjunto de n variáveis, para a 

qual será feita a estimativa. 

Deseja-se estimar urna variável do conjunto de n variáveis, baseando-se que a 

estimativa do erro deve ser nula na média. Esta condição é satisfeita por escolher pesos cuja 

sornatória é um para a variável de interesse e zero para as auxiliares (as demais). 

""l.."(x) =ii - I •• {1 Se a= a t't ' 0 =,- O Sea'i'a
1 

O sistema da cokrigagem ordinária é o seguinte: 

N •o 

L :L;I..j(x.)y a~(x,- x) + J.la (x.) = y aa, (x;- x.) V a= l, ... ,N; vi= l, ... ,nu 
~=1 Ft 

•• 
:L;I..j(x 0 )=ôuu, Va=l, ... ,N 
j-"'1 

(3.8.2) 

Como pode ser observado do sistema acima, a COK requer a inferência de todos os 

semivariogramas diretos e cruzados o que pode tomar a modelagem tediosa. Isto é a principal 

razão para o pouco uso da COK. A variância da cokrigagem pode ser expressa como: 

(3.8.3) 

Com dados amostrados na mesma posição, a COK de um conjunto de variáveis tem a 

importante vantagem de preservar a coerência dos estimadores em relação a krigagem 

ordinária em separado de cada variável. Isto pode ser observado quando estima-se por 

exemplo a soma de várias variáveis: 

21 



N 

N scoK(x) = LZ~oK(x) 
S(x) =L za (x)---+ ~:;' 

ao! SKO(x) * LZ~o (x) 
ct=l 

A somatória da krigagem ordinária de cada variável isoladamente é geralmente 

diferente do resultado da krigagem ordinária direta das variáveis adicionadas. As duas 

estimativas não são coerentes. Não existe critério para se definir qual é a melhor. 

A cokrigagem ordinária não tem sentido quando nenhum dado da variável de interesse 

está disponível em uma deterrnínada vizinhança. Uma alternativa para esta situação é a 

cokrigagem simples (COKS). Sendo conhecidas as médias das variáveis, a COKS perrníte a 

estimativa de uma variável sem ter uma informação sobre a mesma na vizinhança. Semelhante 

à KS, a COKS não tem restrições quanto aos pesos. 

3.8.1 Cokrigagem Collocated 
Xu et ai. (1992) denominaram cokrigagem collocated' a uma estratégia de definíção 

de vizinhança, em que a vizinhança da variável auxiliar é reduzida drasticamente para um 

ponto: a posição onde será estimada a variável principal. Portanto esta técníca é urna 

simplificação da cokrigagem e basicamente consiste em reter a informação dos dados da 

variável secundária somente onde a variável primária será estimada. Isto reduz o esforço de 

cálculo no sistema de cokrigagem. Considerando apenas uma variável secundária, o estimador 

da cokrigagem collocated pode ser escrito como: 

n, 

z; (xo)- m, =L Ã.\11 (xo)[Z, (xJ- mJ + À.(Z) (Xo )[Z, (xo)- m,] 
Í=l 

Onde m, = E{Z,(x)} e m 2 = E{Z,(x)} são duas médias estacionárias. 

O sistema de equações da cokrigagem collocated é : 

., 
L Ã.j 1 (xo )Cll (xj - x;) + À.(l) (xo)C21 (X o - x;) = cll (xo x;) vi = l, ... ,n, 
jol 

., 
L Ã.j 1 (xo)Cl2 (x j -X o)+ À.(Z) (xo)C,, (O)= cl2 (O) 
}"'1 

(3.8.4) 

(3.8.5) 

3 Eventualmente. pode ser encontrada. na literatura geoestatística. tradução para cokrigagem 
col/ocated como cokrigagem colocada. Esta tradução não representa a idéia da cokrigagem collocated que é a 
de posicionar a variável secundária na posição da estimativa junto. ou melhor. ao lado das demais informações 
sobre a variável primária na vizinhança. Alternativas seriam co-localizadas ou co-alocadas. De qualquer 
forma. optou-se por não traduzir o termo col/ocated. 

22 



onde Cu (h), C22 (h), C 12 (h)= C2, (h) são as autocovariâncias e as covariâncias cruzadas das 

variáveis primária e secundária, respectivamente. O sistema de equações não utiliza a 

covariância direta da variável secundária, mas necessita da inferência e modelagem da 

covariância cruzada Cu (h). O sistema da cokrigagem col/ocated tem (n+ 1) equações. 

Uma aproximação para C
12 

(h) é utilizar o modelo markoviano de corregionalização. 

Considerando a hipótese markoviana 

E[Z 2 (x)IZ, (x),Z, (x +h)]= E[Z 2 (x)IZ, (x)] 'IZ 1 (x +h) 

e considerando que. Z,(x) eZ 2(x) são FAs gaussianas N(0,1), Xu et al. (1992) 

demonstraram que a covariância cruzada pode ser adequadamente expressa como: 

Cu (O) ( ) ( ) 
C,2(h) = Cu(O) Cu h 'lh ou p 12 (h) = Pu(O)p, h 'lh (3.8.6) 

onde p,(h) = C,(h)/C,(O) corresponde ao correlograma da variável principal e 

p 12 (h)= C12 (h) I Jc, (O)C 2 (O) , ao correlograma cruzado entre as duas variáveis. 
O modelo de Markov é particularmente adequado no sentido de que fornece o 

modelo de covariância cruzada como uma versão modificada da covariância direta. 

Com o modelo markoviano, o estimador da cokrigagem collocated e o sistema de 

equações podem ser escritos como: 

z;(x 0 )-m1 = f.t.\'J[Z,(x;)-m,]+t.&amp;lt;2J[Z 2(x 0 )-m 2] 
crt 1=1 0'1 cr2 

n, 
L À~1 &gt;(x0 )p 1 (xi - x;) + t.&lt;2J (x 0 )Pu (O)p 1 (x 0 - x;) = p1 (x 0 - x;) 'li = 1, ... , n1 
j=t 

n, 

L t,.jl (xo )Pu (O)p, (xi- Xo) + t,.&lt;2J(xo) =Pu (O) 
j=I 

onde cr; = Var{Z,(x)} e cr~ = Var{Z 2 (x)} são duas variâncias estacionárias. 

(3.8.7) 

(3.8.8) 

O algoritmo da cok.rigagem collocated é fácil de implementar. O modelo markoviano 

3.8.6 pode ser checado a partir dos dados. 

Semelhante ao sistema da KDE, o sistema da cokrigagem collocated requer que a 

variável secundária seja conhecida em todos os nós onde a estimativa da variável primária será 

realizada. Porém, a informação extra não é incorporada como uma condição de deriva 

adicional, mas como pontos de dados adicionais que interagem com outras informações na 

função covariância. 

23 



3.9 Krigagem Indicatriz 

A krigagem indicatriz foi proposta por Joumel (1984) como uma alternativa não 

paramétrica para as abordagens paramétricas. A expressão 'não paramétrica' não significa que 

o modelo de função aleatória (FA) não tem parâmetros, mas que o mesmo tem mais 

parâmetros livres do que por exemplo o modelo gaussiano, em que as ccdfs são 

completamente definidas por dois parâmetros: a média e a variância. 

A abordagem indicatriz se baseia na codificação da função aleatória Z(x) em uma 

série de indicatrizes (variável aleatória binária) definidas em diferentes parâmetros de corte 

(cutoffs4)zk: 

{
I se Z(x) ~ zk 

I(x- z = 
' •) O se Z(x) &gt; z

1 

Esta codificação define uma vetor indicatriz estacionário: 

I(x;z) = [I(x;z,) .. .I(x;zKW onde K é o número de cortes. 

(3.9.1) 

A krigagem indicatriz (KI) fornece uma estimativa da função de distribuição 

acumulada condicional ( ccdt) para um dado corte : 

(3.9.2) 

Onde (n) representa o condicionamento das informações disponíveis nas vizinhanças 

da posição Xo, na qual será realizada a estimativa. O processo da KI é repetido para uma série 

de K valores de cortes que subdividem o intervalo de variabilidade de um atributo contínuo, 

ou para cada uma das classes de uma variável categórica. 

A ccdf construída através da união das K estimativas do tipo 3.9.2 representam um 

modelo probabilístico para a incerteza sobre um valor não amostrado Z(Xo). 

Para variáveis categóricas, não é necessária a prévia transformação indicatriz. Se 

Z(x) é uma variável contínua, então a correta seleção dos cortes z, é uma etapa crucial: 

quanto mais cortes, maior o número de covariâncias a serem inferidas; quanto menos cortes, 

mais detalhes da distribuição serão perdidos. 

Com os dados referentes às variáveis indicatrizes, pode-se usar tanto a KS como a 

KO para realizar a estimativa da ccdf em cada posição, relativa a cada corte. O sistema de 

4 
Com intuito de simplificação da terminologia será utilizado, às vezes, o termo corte( s) para se 

referir aos parámetros de corte ou cutoffs utilizados nas abordagens indicatrizes. 

24 



equações e o estimador da krigagem indicatriz simples são similares a da KS, só que agora 

assume-se ser conhecida a esperança estacionária das F As indicatrizes I( x; z.) : 

E[I(x;z.)] = P[Z(x)::; zd = F(zk) 

A formulação mais usual envolve a utilização da KO com vizinhança móvel, o que 

implica em uma estimativa local das prévias cdfs F(z.). O estimador pode ser escrito como: 

n 

[I(x 0 ;z.)]' = L).;(x 0 ;z.)I(x,;z.) (3.9.3) 
i=l 

onde 1.., (x 0 ;z.) são os pesos correspondentes a cada dado indicatriz relativo ao corte z, 

utilizado para a estimativa em uma posição Xo. Estes pesos são obtidos pelo sistema de 

equações da KO rescrito como: 

n 

LÀ.;(x 0 ;z.)C,(x; -x,;z.)+!!z, =C1 (x 0 -x,;z.), Vi= l, ... ,n 
jol 

n 

LÀ.;(x 0 ;z,) = 1 
pl 

(3.9.4) 

O modelo de krigagem indicatriz ordinária, ou simplesmente krigagem indicatriz, 

resulta em um sistema com (n+l) equações para cada corte. A KI requer o conhecimento de 

K autocovariâncias correspondentes aos K cortes. 

Uma outra possibilidade para a realização da KI é a krigagem indicatriz mediana 

(Klm) que é adequada a situações em que os variogramas ou as covariâncias indicatrizes são 

proporcionais entre si, isto é, os correlogramas indicatrizes são todos similares. O 

correspondente modelo de FA Z(x) é o denominado modelo mosaico: 

Pz(h) = P1(h;z,) = p 1(h;z,,z •. ), vz.,z,. (3.9.5) 
onde Pz(h) e p1 (h;z,,z,.)são os correlogramas diretos e os correlogramas indicatrizes 

cruzados da F A contínua Z(x). 

A krigagem indícatriz mediana (Klm) é um procedimento simples e rápido, pois 

requer apenas a inferência do semivariograma indicatriz mediano. Assim sendo, um simples 

sistema de KI deve ser resolvido, com os pesos resultantes sendo usados para todos os cortes. 

Qualquer que seja a KI utilizada (simples, ordinária ou mediana), verifica-se a 

propriedade que a ccdf estimada para a posição de um dado hanf é uma cdf de variância zero 

identificada com a classe a que pertence o dado hard. 

5 Neste contexto, dado hard se refere a uma informação conhecida com outro grau de precisão e 
acurácia. como por exemplo o valor de uma variável indicatriz (litologia ou classe de porosidade. 
permeabilidade, etc) obtido nos poços. Na classificação da página 31, representa o dado hard tipo l. 

25 



A partir da obtenção das ccdfs, intervalos de confiança e estimativas podem ser 

derivados. Na krigagem indicatriz, a determinação da ccdf precede a estimativa. Podem ser 

obtidas estimativas segundo o critério que se escolher. Por exemplo, o cálculo da estimativa 

'tipo E' que minimiza a variância de estimativa condicional é aproximado por uma soma 

discreta de (K + 1) contnbuições das classes, sendo portanto influenciado pelo número de cortes 

usados na discretização do intervalo: 

K 

z~ (x.) =L z~ (x.)[F' (x. ,zk+ll(n))- F' (x.,zk l(n))] 
k=O 

com z~(x0 ) E[zk,zk+~] sendo caracteristica da k-ésima classe, geralmente estimada pela 

média de todos os dados z;(x 0 ) E[zk,zk, 1 ] na vizinhança do ponto Xo ou utilizando 

procedimentos de interpolação como os propostos na GSLIB, seção V.1.6. 

A variância da KI pode ser definida como: 

A relação acima é uma caracteristica das variáveis indicatrizes. Observe que variância 

atinge o máximo de 0.25 quando F' (zk) = 0.5. 

Devido à ocorrência dos pesos negativos, as relações de ordem de uma ccdf, isto é 

F;; (x; zk.l(n))?: F;; (x; zk l(n)), \tzk, &gt; zk e F;; (x;zkl(n)) E [0,1], podem não ser obedecidas. 

Todas as metodologias que utilizam a abordagem indicatriz estão sujeitas à ocorrência dos 

problemas de relação de ordem. Deutsch e Joumel (1996) reportam como a GSLIB faz as 

correções necessárias para estes problemas. Segundo esses autores, as correções são 

geralmente bastante reduzidas. De qualquer forma, os problemas com as relações de ordem 

constituem uma desvantagem severa da abordagem indicatriz e reavivou a pesquisa em relação 

à questão dos ponderadores negativos da krigagem a ser analisada alguns tópicos a frente. 

Uma outra dificuldade com as abordagens indicatrizes é a dificuldade de inferir modelos de 

covariâncias para os cortes limites. 

3.1 O Cokrigagem Indicatriz 

A krigagem indicatriz pode ser vista como uma aproximação da coKI, onde foram 

ignoradas as covariâncias cruzadas. Uma alternativa à KI é considerar todas as K indicatrizes 

para a estimativa do valor da ccdf relativa a cada corte Zk. A implementação desta alternativa é 

denominada cokrigagem indicatriz e o estimador é definido como: 

26 



• K n 

[r(x 0 ;z,J] = F,:KI(x 0 ;z,J(n)) = L~).,(x,;z,,)I(xn;z,) 
k=l i""l 

(3.10.1) 

Os pesos t., (x,;z,,) são obtidos no sentido de minimizar a variância de estimativa, o 

que corresponde a resolver o sistema de equações da cokrigagem ordinária: 

K n 

L LÀ,. (x;;z,, )C 1 (X 1 - x;;z, ,z,.) + 11, (x 0 ) = C1 (x 0 - x 1;z,, ,z,. }Vk = l, ... ,K; vi= l, ... ,n 
k'=l j=-1 

n 

L f...(x;;z,) = Õu, k = 1,2, ... ,K 
j=l 

onde os parâmetros 11, são os multiplicadores de Lagrange e õ u corresponde ao delta de 
o 

Kronecker: 

{
1 Se k = k0 
O Sek *- k 0 

Assim sendo, para cada corte, o estimador da coKl requer a solução de um sistema de 

equações com K( n+ 1) equações. 

A coKl faz uso de todas as distribuições bivariadas como discretizadas pelos K cortes 

e então requer a modelagem de K2 covariâncias indicatrizes (auto e cruzada) ou de K(K+1)/2 

semivariogramas (cruzados e diretos). Agrupamentos, isto é, amostragens preferenciais em 

altos ou baixos valores e reduzido número de dados podem tomar difícil a inferência das 

autocovariâncias e covariâncias cruzadas indicatrizes. Por todos esses motivos, a coKl é 

raramente utilizada. 

Uma opção proposta por alguns autores consiste em usar um modelo de 

corregionalização que envolve a modelagem de todos os semivariogramas como combinações 

lineares de um conjunto de variogramas considerados básicos. 

3.10.1 Cokrigagem Indicatriz Reduzida 
O algoritmo da krigagem indicatriz mediana pode ser considerado como a máxima 

aproximação do algoritmo da coKl, onde a matriz original de K2 covariâncias é reduzida a um 

único modelo de covariância. Entre estes dois extremos existem muitas outras aproximações 

possíveis que ignoram elementos específicos da matriz de covariâncias. 

Goovaerts ( 1994) apresentou um algoritmo que ele denominou cokrigagem indicatriz 

dos cutoffs adjacentes, ou seja uma cokrigagem indicatriz reduzida. Baseando-se na hipótese 

de que a maior parte de informação está nas variáveis indicatrizes definidas para os cutoffs 

27 



mais próximos ao que está sendo considerado, Goovaerts (1994) neglicencia todos os termos 

da matriz de covariâncias com exceção das K covariâncias diretasC,(h;z,,z,) e as 2(K-l) 

covariâncias cruzadas C1 (h; z,, z,+,) e C1 (h; z,, z,_1 ). Obtém-se uma matriz de covariância 

tridiagonal onde somente os termos da diagonal e os imediatamente adjacentes a diagonal são 

não nulos. Então, para a estimativa em relação a um determinado cutoff zk , são utilizados 
' 

os dados do próprio cutoff e dos cutoffs adjacentes zk e z, . Para os cutoffs extremos z 0 e (}--1 0+1 

zK , apenas uma variável auxiliar é utilizada. 

A estimativa através da cokrigagem indicatriz dos cutoffs adjacentes ( coKir) e o 

sistema de equações resultantes para a obtenção dos pesos que minimizem a variância de 

estimativa são: 

ko+t n 

[I(x 0 ;z,,)]' = (,Kfr(x 0 ;zk, l(n)) = L LÀ.k(x,;zk,)l(x,;z,) 
k=ko-1 i=t 

ko+t n 

L L!..,. (x;;zk, )C 1 (x, - xi;zk ,zk.) + 11, (x 0 ) = C 1 (x 0 - x, ;zk ,zk,) 
k'.,k 0_ 1 .FI 

• 
LÀ.,(x;;z,,) =Ou, para k =(ko.1 ,k 0 , k 0+1 ) 
jo;;;l 

(3.10.2) 

(3.10.3) 

Em comparação com a completa coKI, o número de equações do sistema a ser 

resolvido para a coKir é inferior (3n+3) ao da coKI, mas mesmo assim um modelo de 

corregionalização ainda deve ser utilizado. 

Teoricamente a cokrigagem indicatriz deveria ser melhor do que os outros algoritmos 

indicatrizes, pois ela utiliza toda a informação disponível. 

3.11 Krigagem dos Componentes Principais Indicatrizes 

A inferência direta das K2 covariâncias para a coKI é bastante problemática para a 

condição de muitos cortes. Uma outra alternativa é utilizar transformadas lineares das variáveis 

indicatrizes que são menos correlacionadas, tais como as componentes principais indicatrizes. 

A análise do componente principal (ACP) é uma técníca algébrica envolvendo a 

transformação linear de um vetor em outro e não requer nenhuma hipótese estatística prévia 

sobre os dados. A interpretação estatística da ACP mostra que a covariância cruzada entre as 

variáveis transformadas é nula. 

28 



Adicionalmente, a pnme1ra variável transformada ou o primeiro componente 

principal tem a máxima variância, o segundo componente principal, a segunda maior variância 

e assim por diante. 

Estas propriedades fazem da ACP um caminho usual para reduzir a dimensão dos 

dados, selecionando um reduzido número de componentes principais, que mais contribuem 

para a variância. Portanto a opção por ACP implica na hipótese de que a variância é o principal 

aspecto da variabilidade e reter as variáveis com as maiores contribuições para a variância 

pode fornecer uma concisa, mas ainda satisfatória explicação da fonte da variabilidade. 

Dado um vetor indicatriz I(x;z) = [I(x;z
1
)I(x;z

2
) .• .I(x;zK)]T de uma variável 

continua Z(x) tais como a porosidade e a permeabilidade e dada um matriz de covariância 

indicatriz específica para uma dada distância, é feita a ACP desta matriz para obter o vetor dos 

componentes principais indicatrizes: 

D(x) = [D 1 (x)D 2 (x) ... DK (x)] 

D(x) = BTI(x;z) (3.11.1) 

A matriz BT é a transposta da matriz B obtida da decomposição espectral da matriz 

de covariâncias indicatrizes para uma distância específica h0 : 

[C 1(h 0 ,z,,zk. )] = BABT 

onde A é uma matriz diagonal (autovalores) e B é a matriz ortogonal (autovetores). Cada 

elemento do vetor D(x) pode ser escrito como: 

k 

Dk (x) = 2)k .. ,I(x;zk') (3.11.2) 
k'=l 

em que b,.,, e I(x; z,.) são os elementos da matriz B e do vetor I(x;z), respectivamente. 

Assim sendo, as novas variáveis D, são combinações lineares das indicatrizes originais com a 

propriedade adicional de que as covariâncias cruzadas são nulas para distância igual a da 

matriz de covariância indicatriz original. 

Um conjunto de n vetores D, ( x~) é obtido e um estimador tipo cokrigagem dos 

componentes principais indicatrizes é implementado: 

K n 

D~, (x 0 ) = LL t..,,.; (x 0 )D. (x;) (3.11.3) 
k-=1 i""l 

Assumindo que a condição de ortogonalidade se mantém verdadeira para todo h 

(distância), o estimador pode ser reduzido a versão simples da krigagem ordinária: 

29 



n 

D~ (x0) = L,)..k, (x 0)D,, (xJ '&lt;i k 0 = 1,2, ... ,K (3.11.4) 
i=l 

onde os pesos Â.k são obtidos com a resolução do sistema de equações: 
'• 

n 

L Â.k, (x 0 )C,(x i - x,; k 0 ) + llk, (x.) = C1 (x 0 - x,; k 0 ) '&lt;ti = 1,2, ... , n 
j=l J 

n (3.11.5) 

LÂ.k, (x.) =I 
j=l J 

onde C, (x, - xi;k 0 ) = C(Dk, (xJ,Dk, (x;)). 

A transformação inversa da equação 3.11.1 fornece um modelo para a ccdf de Z(x): 

FIPCK(x;zi{N}) = BD'(x) 
onde o vetor FIPCK(x;zi{N})é definido como: 

FIPCK (x;zi {n}) = [FIPCK (x;z,l {n} ) ... FIPCK (x;zKI {n})] 

e o vetor D'(x)é: 

D'(x) = [D;(x) ... D~ (x)] 

Deutsch e Journel (1996) retiraram da segunda versão da GSLIB a discussão sobre a 

krigagem dos componentes principais indicatrizes (IPCK) porque, segundo eles, o algoritmo 

não se firmou na prática. Não obstante, vários trabalhos publicados na literatura e algumas 

dissertações de mestrado se basearam na IPCK. A grande motivação da IPCK não é a redução 

do número de indicatrizes, mas sobretudo indiretamente considerar as covariâncias cruzadas 

entre indicatrizes requerendo apenas a inferência de (K-1) autocovariâncias das componentes 

principais indicatrizes. A grande questão da abordagem IPCK é a hipótese de que a 

ortogonalidade se mantém para qualquer distância h. Ressalta-se que em alguns trabalhos que 

utilizaram a IPCK, os autores certificaram que para as situações analisadas nos mesmos, as 

covariâncias cruzadas entre as componentes principais indicatrizes são neglicenciáveis quando 

comparadas com as autocovariâncias. 

3.12 Krigagem com Dados Qualitativos 

3.12.1 Tipos de Dados 
Em muitas aplicações na indústria do petróleo, os dados hard tais como informações 

oriundas de poços. Contudo, eles podem ser suplementados por informações sojt, ás vezes 

disponíveis em razoável quantidade. 

30 



De uma maneira geral, quando estimando um atributo sobre um determinado campo, 

as informações disponíveis podem ser classificadas em três categorias: 

• Tipo 1- Dados hard que são valores conhecidos do atributo em deterrnínadas 

posições. Z(x;) = z1 para i= 1,2, ... ,n 

• Tipo 2- Dados hard tipo desigualdade ou inequações, isto é, o valor de um 

atributo em determinadas posições é maior ou menor que um valor limite ou está 

dentro de um intervalo. Z(x1) E(a1, bJ i= n + 1, ... , n + n' = N 

• Tipo 3- Informações qualitativas sojt, ou de natureza global tais como a 

interpretação geológica sobre continuidade espacial, ou de natureza local como 

interpretação de dobramentos, falhas, limites da acumulação. Ou informações de 

que um deterrnínado valor Z(x;) está provavelmente em um deterrnínado 

intervalo, semelhante ao dado hard tipo 2. 

O desafio consiste em obter a estimativa que honre todas as informações disponíveis, 

soft ou hard, de natureza global ou local. 

Em todas as aplicações, os valores interpolados z'(x)devem obedecer alguns limites, 

geralmente desigualdades do tipo z• (X) ~ Ü, por exemplo para porosidade, permeabilidade, 

espessura porosa. Alguns atributos também têm limite superior, como é o caso da porosidade. 

Um dado hard Z(x;) = z1 pode ser interpretado como intervalo com largura zero, ou 

melhor, o limite inferior igual ao superior. Em verdade, sempre haverá uma largura miníma se 

for incluído o erro na obtenção da medida. Um dado limitado inferiormente Z(x;) &gt; a 1 é na 

prática um intervalo com limites Z(x;) E(a 1,b). Similarmente, um dado limitado 

superiormente Z(x;) &amp;lt;b1 é na prática um intervalo com limites Z(x;) E(a, b;). 

Pode-se considerar que sempre existe um intervalo limitado para todas informações 

em qualquer aplicação. Desta forma, a úníca diferença entre um dado tipo 1 (hard) ou tipo 2 

(hard com desigualdade) é a largura do intervalo. 

Z(xJ E[a(xJ,b(xJ] 

As técnícas usuais de krigagem (KO, KU) não perrnítem levar em consideração dados 

tipo 2 e 3. Os resultados obtidos a partir das mesmas podem não obedecer aos limites. 

31 



3.12.2 Abordagens Alternativas 
Várias abordagens que não se baseiam simplesmente na positividade dos pesos foram 

propostas no sentido de garantir a restrição de não negatividade de um atributo, bem como 

incorporar informações soft. 

Baseando-se nos algoritmos da programação quadrática e através do método das 

splines, Dubrule e Kostov (1986) propuseram uma solução para o problema mais geral de 

estimar uma superfície {z• (x), x E A} honrando todos os dados tipo l e tipo 2, isto é, dados 

exatos e do tipo inequações. Eles demostraram o paralelo entre splines e a krigagem. 

Barnes e You (1992) propuseram uma metodologia bastante simplificada para 

realizar a estimativa com dados tipo 2. Partindo das equações da KO, eles adotaram mais dois 

tipos de equações condicionantes: uma para os limites superiores e outra para os limites 

inferiores. Assim sendo, no sistema da KO, apareceram mais dois tipos de multiplicadores de 

Lagrange associados com os limites inferiores e superiores. Caso o valor estimado fique dentro 

do intervalo permitido, nada é alterado, isto é, a estimativa e a variância de krigagem são iguais 

a da KO sem a informação do intervalo. Porém, se o valor estimado através da KO está fora 

do intervalo permitido, a estimativa fica igual ao limite que estiver mais próximo. Isto é 

garantido através da introdução dos multiplicadores específicos para os limites. Para esta 

última condição, foram obtidas expressões para determinar as alterações na variância de 

krigagem que consiste em acrescentar um termo de correção positivo. 

Estas e algumas outras abordagens apresentam várias limitações comuns: 

1- A função estrutural usada, C(Z(x),Z(x +h)) é inferida somente dos dados exatos. 

Portanto, não extraem informações estruturais fornecidas pelos dados tipo inequações ou soft; 

2- Não permitem o uso de informação prévia sobre o valor mais provável de um valor 

dentro do intervalo limitante [a,,b;]; 

3- Não fornecem intervalos de confiança para os resultados das estimativas. 

3.12.3 Krigagem Soft: Modelo de Markov-Bayes 
Journel (1986b) propôs uma metodologia que permite colocar os dados tipo 3 (sojt) 

em um intervalo limitado hard do tipo Z(x,) E[a(x,), b(x,)] com uma distribuição provável 

do valor do atributo. O formalismo da indicatriz fornece uma solução direta para codificar 

dados tipo inequações. 

A função indicatriz I(x,;z) relacionada a um dado hard Z(x,) = z, pode ser vista 

como uma cdf prévia do parâmetro z, com variância zero (figura 3-l.a). Do mesmo modo, 
32 



em uma posição x, com um dado tipo 2, isto é, intervalo com limites Z(xJ E(a,,b;), a função 

indicatriz é conhecida apenas fora dos limites do intervalo onde ela ou é O ou I (3-l.b). 

(Xi;Z) i=1,2, ... ,n l(x;;z) 
l=n+1, •.• ,N 

l(x;;z) 1------- 1------- 1----; 
? 

~ 
I ~z I I ~ ~ z 

I I 
~. ~ z Zi a a. a a; 

a b c 

Figura 3-l:Informações codificadas como cdfs. Os valores 'a' e 'b' são os limites extremos dos dados. 

Se além do intervalo com limites Z(x;) E(a,,b;), algumas informações prévias 

permitem quantificar a probabilidade do valor Z(xJ dentro do intervalo, a correspondente 

função indicatriz pode ser completada com dados subjetivos de probabilidade acumulada 

(3-2.c). A única diferença entre dados indicatrizes oriundos de dados exatos ou do tipo 

inequações e a informação subjetiva é que os primeiros podem ser apenas O e 1, enquanto o 

último pode assumir valores entre O e 1. 

Os modelos de variogramas indicatrizes 

2y 1(h;z,z') = E[[I(x;z)- I(x + h;z)][I(x;z')- I(x + h;z')]] 

requeridos para resolver os vários sistemas de krigagens indicatrizes podem ser inferidos 

usando, não apenas os dados indicatrizes resultantes dos dados tipo I, mas também os dados 

indicatrizes oriundos de dados tipos 2 e 3. 

Em muitas aplicações, importantes informações residem nos dados tipo inequações 

(tipo 2) ou qualitativos (tipo 3). Dados tipo inequações são informações objetivas e a não 

utilização dos mesmos pode levar a resultados não acurados ou a estimativas inaceitáveis. 

O formalismo da krigagem sojt permite construir um estimador que honra todas as 

informações prévias, por exemplo dados tipo 2 ou 3. Na krigagem soft introduzida por Journel 

(1986b) e Kostov e Journel ( 1986) poder-se-ia usar tanto a coKl como a Kl. 

Baseando-se na metodologia da krigagem soft de Journel (1986b), Journel e Zhu 

(1990) apresentaram uma alternativa para a cokrigagem denominada pelos autores inicialmente 

como modelo de Markov-Bayes. 

A partir de dados oriundos de calibração entre a variável primária Z( x) e uma 

secundária V(x), esses autores fizeram uma codificação bayesiana da informação sojt. 

Em uma determinada posição onde o atributo Z não é amostrado, mas o valor da 

variável secundária V é disponível, a cdf condicional é extraída da calibração: 

33 



(3.12.1) 

Esta cdf representa a informação prévia disponível sobre o valor não amostrado de 

Z(x 0 ). Em um arcabouço bayesiano, todos os dados (hard ou soft) devem ser colocados na 

forma de cdfs prévias locais, como mostrado anteriormente (figura 3-1 ). Joumel e Zhu (1990) 

denominaram esta cdflocal prévia como uma variável y(x 1;z): 

y(x 1;z) = P[Z(x;)::; z I (Rx;)] (3.12.2) 

onde (ex,) representa a informação local em x1 , isto é, um dado hard ou soft. 

A partir da calibração da informação de uma variável secundária, pode ser obtida uma 

cdf prévia do tipo y(x,;z) = P[Z(x1)::; z I v(x 1)] E[0,1]. Igualmente, qualquer informação 

resultado de uma interpretação ou de experiência sobre a área em estudo pode ser codificada 

como uma cdf prévia. 

A cdfprévia local y(x,;z) toma a forma de um vetor de valores de probabilidade, um 

vetor para cada posição com K membros correspondentes aos K cortes que foram usados para 

discretizar a variabilidade deZ formando a VA indicatriz I(x,;z) referente aos dados hard. 

Para fornecer um modelo de incerteza em uma posição Xo qualquer, as cdfs locais prévias 

y(x 0 ;z) deverão ser atualizadas utilizando todas as informações da vizinhança. 

Esta informação a priori será atualizada, por algumas outras informações Z e/ou V na 

vizinhança, para compor uma cdfposterior e foi nomeada com uma variável y(x 0 ;z): 

y(x 0 ;z) = P[Z(x 0 }::; z I (n)] E[O,l] (3.12.3) 

Qualquer cdf local prévia y(x,;z) pode ser interpretada como realizações de uma 

variável aleatória Y(x;z), com suas específicas covariâncias diretas e cruzadas com a variável 

I(x;z). O algoritmo da cokrigagem simples pode ser utilizado para atualizar o valor de y a 

partir dos valores de seus vizinhos: 

n1 n2 

P'[Z(x 0 ) I (n)]- F(z) = ~)., (x 0 ;zXI(x 0 ;z)- F(z)) +Li; ;(x p)(y(x i; z)- E[Y(z}]) (3.12.4) 
i=l j=l 

onde F(z) é a cdf estacionária global prévia, E[Y(z)] é a esperança estacionária das variáveis 

soft, I(x;z) são as cdfs prévias geradas pelos dados hard em n, locações, e y(x;z) são as cdfs 

prévias geradas pelas informações soft em outras n
2 

posições. 

Contudo esta abordagem implicaria na modelagem de todas as covariàncias diretas e 

cruzadas das V As I(x;z) e Y(x;z), o que é impraticável. 

34 



Felizmente sob a hipótese de uma aproximação Markoviana (daí o nome Markov-

Bayes) que estabelece que a informação hard I(x;z) sempre prevalece sobre uma informação 

soft collocated Y(x; z), consideráveis simplificações podem ser feitas e um modelo de 

corregionaíização obtido. 

As seguintes relações podem ser obtidas: 

• E[Y(x;z)] = E[P[Z(x)::; z I v]]= F(z) = E[I(x;z)] 

• Var[Y(x;z)] = B(z)Var[I(x;z)] 

• CIY(h;z) = B(z)C 1(h;z) 

• Cy(h;z) = B2 (z)C1 (h;z) 

l 
B(z) = m&lt;1l (z)- m&lt;0l(z) 

Onde m&lt;0l(z) = E[Y(x;z) I I(x;z) =O 
m&lt;l)(z) = E[Y(x;z) I I(x;z) =I] 

B(z) E[-1,1] 

m&lt;0l(z) E[O.l] 

m&lt;1l(z) E[O,l] 

A covariância dos dados soft e a covariância cruzada entre dados hard e soft são 

deduzidas diretamente do modelo de covariância indicatriz facilitando o sistema de cokrigagem 

para o estimador da equação 3.12.4. Assim sendo, com a utilização do modelo de Markov-

Bayes somente a inferência da covariância indicatriz é requerida, equivalente ao que é 

requerido pela krigagem simples. 

3.13 A Questão dos Ponderadores Negativos 

A obtenção de valores negativos para a estimativa de um atributo que é 

necessariamente positivo, como por exemplo porosidade e permeabilidade, suscitou vários 

estudos quase sempre endereçados no sentido de garantir a positividade da estimativa através 

da não negatividade dos ponderadores. 

Sendo todos os dados positivos, um valor estimado somente pode ser negativo se um 

ou maís ponderadores da krigagem são negativos. Assim, os primeiros estudos foram no 

sentido de garantir que todos os ponderadores fossem positivos, e se basearam nas soluções 

de problemas de otimização com restrições. Por exemplo a resolução de problemas do tipo 

minimização de uma forma quadrática (variância de estimativa) sujeita a restrições (somatória 

dos ponderadores igual a um e todos os ponderadores positivos) que pode ser obtida através 

da programação quadrática. Com esta abordagem destacam-se os trabalhos de Barnes e 

Johnson (1984) e Limic e Mikelic (1984). 

35 



Barnes e Johnson (1984) apresentaram a metodologia que denominaram krigagem 

positiva com as seguintes considerações: 

Tentar justificar a existência de pesos negativos através do fato 
de que a krigagem é o melhor estimador linear não enviesado é 
um argumento vago, um dogma. A única justificativa da 
filosofia geoestatística é o fato de que ela é excelente para 
modelar a realidade. Quando a teoria diverge da realidade, é a 
teoria que deve ser modificada. 

A abordagem proposta por estes autores suscitou debates e controvérsias. Journel 

( 1986b) foi um dos opositores das metodologias que garantiam a não negatividade dos 

ponderadores. Segundo Journel (1986b), o fato de que os pesos da krigagem possam ser 

negativos é extremamente positivo, porque garante a possibilidade de uma estimativa não 

convexa, saindo, fora dos limites dos dados. 

Para Journel (1986b), o cerne do problema não está nos pesos negativos, mas no fato 

de que o sistema de krigagem não é informado sobre a limitação que Z( x) 2 O, para todo x no 

domínio. Enfim, a solução não consiste em forçar que todos os pesos sejam positivos, mas sim 

forçar que todas os valores estimados st&lt;iam positivos ou, mais genericamente, que 

Z'(x) E(a,b). As abordagens que não se baseiam na positividade dos ponderadores foram 

descritas no tópico anterior, referente a krigagens com dados qualitativos. 

Mesmo com a polêmica sobre a não negatividade dos ponderadores, abordagens 

continuaram a ser propostas neste sentido. 

Szidarovsky et ai. ( 1987) apresentaram uma metodologia que realiza a krigagem em 

todos os subconjuntos de amostras possíveis do conjunto total disponivel e, a partir desses 

resultados, são selecionadas as soluções que resultam em positividade de todos os 

ponderadores. Destas soluções, é escolhida a que apresenta a menor variância de estimativa, 

que certamente é maior que a mínima variância de krigagem. Como reportado por Sridarovsky 

et ai. (1987), a grande desvantagem da metodologia é a necessidade da resolução de (2n -1) 

sistemas de krigagem para cada estimativa a ser realizada. Os autores desta proposta não 

apresentaram nenhuma aplicação prática da metodologia. 

Com o aparecimento e desenvolvimento da proposta da krigagem das indicatrizes, 

novas pesquisas sobre a geração dos pesos negativos têm sido conduzidas. Isto se deve ao fato 

de que os pesos negativos prejudicam eventual interpretação dos mesmos como percentuais e 

no caso da krigagens indicatrizes provoca a ocorrência dos problemas de relação de ordem. 

36 



Observa-se recentemente uma retomada da consideração da não negatividade dos 

ponderadores. No último congresso de geoestatística, (Bourgault, 1997) relata que: 

Infelizmente, um problema com a krigagem é a ocorrência dos 
pesos negativos. Krigagem é um estimador não convexo porque 
pode gerar pesos negativos e produzir valores fora dos limites 
dos dados. Pior, com a krigagem é possível gerar estimativas 
negativas mesmo que todos os dados sejam estritamente 
positivos. 

A história dos ponderadores se faz assim cíclica, pois novas propostas estão sendo 

feitas, baseando-se nas idéias colocadas no início da década de 80. 

Por exemplo, Froideveaux (1993) propôs uma metodologia a que denominou 

krigagem restrita, na qual os ponderadores são forçados a serem estritamente positivos a fim 

de possibilitar a obtenção da função de distribuição acumulada condicional ( ccdf) local. A 

metodologia consiste em zerar todos os pesos negativos e renormalizar os pesos restantes de 

forma que a somatória dos mesmos seja igual a 1. Como os pesos são todos positivos, os 

mesmos podem ser encarados como percentuais e podem ser utilizados na construção das 

ccdfs locais: 

a 

F(x 0 ,Za) = L)j 
j=l 

onde F(za,x 0 ) é a probabilidade de que na posição x0 , o valor real seja menor ou 

igual a za , e Ã.j correspondem aos ponderadores relativos a dados amostrais com valores 

inferiores ou iguais a za . Esses ponderadores são obtidos através da krigagem ordinária com a 

correção de pesos proposta por Froideveaux. 

Remacre (1997) propôs uma metodologia que basicamente faz um recálculo dos 

pesos obtidos com a metodologia de Froideveaux de forma a privilegiar as amostras que estão 

mais próximas do ponto a ser estimado. 

Bourgault (1997) apresentou uma metodologia que gera ponderadores convexos, 

mantendo a condição da somatória igual a 1, como alternativa para krigagem. Os pesos 

convexos levam em consideração a redundância dos dados originais e o efeito dos 

agrupamentos estatísticos, isto é, dados com distâncias inferiores à amplitude prática que 

caracteriza a continuidade espacial do conjunto de dados. A abordagem de Bourgault 

apresenta um parâmetro que deve ser ajustado iterativamente, e portanto demanda maior 

tempo de CPU, para se obter a média desejada para o conjunto de dados. Como não se sabe, a 

37 



priori, o valor da média, o ajuste deste parâmetro pode resultar em estimativas errôneas e 

enviesadas. 

Joumel e Rao (1996) propuseram uma metodologia em que os pesos da krigagem são 

corrigidos de forma a serem todos positivos. Em vez de zerar todos os pesos negativos, uma 

correção tipo translação foi proposta por Joumel e Rao ( 1996), na qual o módulo do maior 

peso negativo é adicionado a todos os pesos da krigagem e em seguida é feito um 

reescalonamento de forma a manter a somatória dos pesos igual a 1. Esta correção segundo 

Joumel e Rao (1996) representa a diferença entre a média aritmética dos dados locais e a 

média estacionária usada na KS ou implicitamente calculada na KO. 

A diferença entre as metodologias de Froideveaux (1993) e a de Joumel e Rao 

(1996) é que a primeira resulta em ponderadores que valorizam proporcionalmente mais as 

informações que estão mais próximas do ponto a ser estimado em relação à segunda 

abordagem. 

Uma outra metodologia foi proposta por Deutsch (1996) que basicamente anula todos 

os pesos negativos e alguns pesos positivos pequenos relacionados aos negativos, e em seguida 

renormaliza os demais pesos no sentido de manter a condição de não viés. 

É importante ressaltar que em todas as abordagens que asseguram a não negatividade 

dos pesos e a estimativa convexa, a propriedade perdida é a mínima variància de krigagem. 

Uma característica muito importante para essas metodologias é que as mesmas devem ter 

praticidade, isto é, não devem ser computacionalmente intensivas. Ressalta-se que as recentes 

propostas que consideram a positividade dos ponderadores objetivam mais a determinação da 

ccdf no âmbito das indicatrizes, do que propor alternativa à krigagem tradicional. Estimativas 

que honrem informações sobre os limites de ocorrência do atributo podem ser obtidas de 

forma a não exigir a positividade dos ponderadores, como foi reportado no tópico anterior. 

38 



4. Incertezas na Estimativa 

Implícito em qualquer estudo geoestatístico está a escolha de um modelo. No início 

da exploração e desenvolvimento de um reservatório, poucos poços são disponíveis. Assim, na 

modelagem geoestatística, seja utilizando simulação estocástica ou krigagem, são necessárias 

informações adicionais (por exemplo oriundas da sísmica) para a construção do modelo. Por 

exemplo, extrair a forma da deriva do atributo de interesse correlacionado com um atributo 

sísmico qualquer. Nestas situações, a participação de uma variável secundária auxiliar é 

decisiva na construção do modelo. À medida que novos poços são perfurados, os mesmos 

podem ser utilizados na construção de um novo modelo, se necessário interagindo com a 

variável secundária. 

A crescente utilização dos algoritmos de simulação estocástica pode levar os mais 

afoitos a considerarem a krigagem como ferramenta geoestatistica ultrapassada. É importante 

frisar que a krigagem tem seu campo de aplicação a depender dos objetivos do estudo, e 

ademais, em grande parte dos algoritmos de simulação estocástica, ela é implicitamente 

realizada. Assim, todas as incertezas que se têm na estimativa de um atributo em uma 

determinada posição, ocorrerão também nas krigagens implicitamente realizadas nas 

simulações estocásticas e, portanto, também as influenciará. Por exemplo, nos algoritmos de 

simulação com abordagem seqüencial, as ccdfs são obtidas via krigagens. 

Nos textos sobre incerteza na estimativa geoestatística, o primeiro parâmetro que 

geralmente aparece é a variância de krigagem e, consequentemente, os intervalos de confiança 

derivados da mesma. Contudo, a incerteza na estimativa é muito mais do que isso. Têm-se 

incertezas no primeiro e segundo momentos oriundos das amostras disponíveis. V árias 

definíções apresentam caráter subjetivo, como por exemplo a escolha do modelo de 

semivariograma e seus parâmetros (efeito pepita, amplitude prática, patamar) que dependem 

do entendimento do fenômeno tisico e da relação com os parâmetros da modelagem. 

Em todo o desenvolvimento geoestatístico está implícita as propriedades de 

estacionariedade e ergodicidade do modelo probabilístico. Às vezes, a função covariància ou o 

semivariograma não podem ser completamente determinados, principalmente quando se tem 

39 



apenas poucos dados disponíveis. Tem-se o problema de definição de deriva e das anísotropias 

quando elas ocorrem. 

Starks e Fang (1982) analisaram o efeito da deriva no semivariograma experimental. 

Segundo estes autores, é possível que ocorra uma má interpretação da deriva no 

semivariograma experimental e, portanto, se consiga ajustar um outro modelo sem deriva. 

Englund (1990), em um trabalho intitulado "A Variance of Geostaticians", fez uma 

interessante pesquisa analisando o caráter subjetivo da escolha de uma determinada abordagem 

de estimativa e da definíção dos parâmetros da mesma, como por exemplo a interpretação da 

estrutura de correlação espacial. Conjuntos de dados idênticos foram enviados para 12 

pesquisadores, que independentemente analisaram os dados e produziram interpolações, não 

sendo especificado, entretanto, o uso da krigagem. 

A maioria dos pesquisadores (dez) consultados por Englund usaram a krigagem. 

Foram usadas krigagem ordinária, disjuntiva e indicatriz. Quanto à modelagem dos 

variogramas também foram observadas grandes diferenças: modelos de variogramas esféricos, 

exponenciais e gaussianos, com e sem efeito pepita, com e sem anísotropias. Foram 

observadas diferenças nos parâmetros de vizinhança utilizados pelos diversos pesquisadores. 

Em face das diferenças de como a estimativa foi realizada, os resultados variaram 

consideravelmente. 

4.1 Escolha do Tipo de Krigagem 

Desde a apresentação inícial da krigagem por Matheron, muitos algoritmos foram 

desenvolvidos no sentido de obter uma estimativa ótima face a uma diversidade de conjuntos 

de dados e também de obter medidas de incertezas em relação à estimativa. 

O avanço da geoestatística para outros campos além da mineração, como por 

exemplo para a área de petróleo, propiciou o desenvolvimento de alternativas para trabalhar 

com dados hard escassos, incorporando também as informações qualitativas, a experiência do 

profissional da área, etc. Os novos tipos de krigagem também incorporam a necessidade de se 

extrair também medidas de incerteza. 

De posse de um conjunto de dados, qual algoritmo de krigagem utilizar? 

Dependendo do tipo de dado (contínuo ou discreto), da quantidade, da existência de mais de 

uma variável correlacionada, do objetivo da estimativa, da existência ou não de deriva, a 

resposta a essa questão pode mudar signíficativamente. 

40 



É essencial que o usuário de qualquer tipo de krigagem saiba qurus são as 

características do modelo de F A, sobre quais hipóteses ela se fundrunenta e como elas 

influencirun o resultado, ou mesmo, o que elas representrun. 

Na tabela 4.1 está um resumo comparativo dos diversos tipos de krigagem com suas 

principais hipóteses, características e a forma de obter trunbém medidas de incerteza. 

4.2 Medidas de Incerteza 

Qualquer que seja o método de estimativa escolhido, sempre se terá um erro 

associado. Não se pode calcular este erro exatrunente. Incerteza é, de certa forma, alguma 

indicação da magnitude desse erro. 

A incerteza associada a um valor não runostrado, em uma determinada posição x, 

pode ser calculada através da ccdf (função de distribuição acumulada condicional) obtida 

diretamente, por exemplo, das krigagens indicatrizes. Para as demais krigagens, a obtenção de 

uma medida de incerteza requer a adoção de um modelo de distribuição dos erros de 

estimativa. 

A probabilidade do valor verdadeiro de um atributo Z ser menor do que um 

determinado valor limite z, condicionado aos n dados disponíveis, é igual a: 

P[Z(x) ~ zl(n)] = F(x;zl(n)) 

onde F(x;zl(n)) é a ccdf, e o símbolo l(n) indica o condicionrunento para os n dados 

disponíveis. Com essa ccdf, várias medidas de incerteza podem ser derivadas: 

• Intervalos de Probabilidade 

P[Z(x) E]a, b Jl(n)] = F(x; bl(n))- F(x;al(n)). 

O mesmo pode ser feito para a probabilidade do valor verdadeiro exceder a um 

determinado valor limite: P[Z(x) &gt; bl(n)] = 1- F(x;bl(n)) 

• Mapas de Quantis 

O p-quantil de uma ccdf de Z(x) é o valor limite a. tal que: 

F(x;a.l(n)) = p E[O,l],então a.(x) = p-'(x;pl(n)). 

O p-quantil de uma ccdf representa um valor para o qual se tem a probabilidade p do 

verdadeiro valor ser menor ou igual a ele, e portanto a probabilidade ( 1-p) do valor real 

excedê-lo. 

41 



.;:,. 
N 

Tabela 4-1: T" -- ---- . . - -- --· -~-&amp;amp;.!""&amp;amp;"'··~,_ ···t":~ .............. ........................................... dek · h" • 
Kril!;al!;em Hipóteses Variável 
Simples Média global conhecida. Primária contínua. 

Estacionariedade de 2' Ordem. 
Ordínária Hipótese íntrinseca. Primária contínua. 

Quase-estacionariedade 
Universal Quase-estacionariedade do Primária contínua. 

componente do resíduo. 
Deriva Externa Variáveis primária e secundária Primária e 

correlacionadas. Quase-estacionarie- secundária 
dade do componente do resíduo. contínuas. 

Krigagem Quase-estacionariedade. Desprezível Discreta ou contínua 
Indica triz as correlações cruzadas entre discretizada. 

indicatrizes. 
Cokrigagem Variável secundária correlacionada Primária e 

com a primária. Quase- secundária 
estacionariedade. contínuas. 

Cokrigagem Variável secundária correlacionada Primária e 
Co/located com a primária. Quase- secundária 

estacionariedade. contínuas. 

Cokrigagem Quase-estacionariedade. Discreta ou contínua 
Indicatriz discretizada. 

Cokrigagem Quase-estacionariedade. Discreta ou contínua 
lndicatriz Reduzida A maior parte da informação está discretizada. 

nos cutoffs adjacentes. 
IPCK Quase-estacionariedade. Variância é Discreta ou contínua 

o principal aspecto da variabilidade. discretizada. 
Soft: Markov- Markoviana - Os dados hard Discreta ou contínua 
Bayes prevalecem sobre os dados soft. discretizada. 

Quase-estacionariedade. 

Características 
Construção de ccdf requer adoção do modelo gaussiano (Variância é fato r 
geométrico). Simplicidade. Só usa covariância. 
Construção de ccdf requer adoção do modelo gaussiano. Simplicidade. 
Pode usar variograma ou covariância. Não exige conhecimento da média. 
Construção de ccdf requer adoção do modelo gaussiano. Não exige esta-
cionariedade de 2' Ordem. O variograma do resíduo pode íntroduzir viés. 
Construção de ccdf requer adoção do modelo gaussiano. Não requer 
covariância da variável secundária e nem covariância cruzada. Variável 
secundária conhecida em todo o domínio. Utiliza o variograma do resíduo. 
Fornece ccdf. Só utiliza as autocovariâncias. Problemas de relação de 
ordem. Problemas para processos tipo difusão. 

Construção de ccdf requer adoção do modelo gaussiano. Dados 
isotópicos - preserva coerência dos estimadores. Requer autocovariância 
da variável secundária e a cruzada. 
Construção de ccdf requer adoção do modelo gaussiano. Não usa 
covariância direta da variável secundária. Ignora informação dos dados 
secundários próximos ao nó onde está sendo realizada a estimativa. 
Variável secundária conhecida em todo o domínio. 
Fornece ccdf. Faz uso de toda a informação disponível. Problemas de 
relação de ordem. Necessita das covariâncias cruzadas entre as 
indicatrizes. 
Fornece ccdf. Exige apenas as autocovariâncias e as cruzadas com os 
cutoffi mais próximos. Problemas de relação de ordem. 

Fornece ccdf. Simplicidade. Problemas de relação de ordem. 
Transformada lineares das variáveis indicatrizes gerando novas variáveis. 
Fornece ccdf. Incorporação de dados soft e informações qualitativas. 
Utilização de parâmetros de calibração. Exige covariância apenas das 
indicatrizes dos dados hard. Problemas de relação ordem. 



O mesmo pode ser feito para a probabilidade do valor real exceder a um determinado 

valor limite: 

P[Z(x)~aPI(n)]=p e P[Z(x)&gt;aPI(n)]=l-p 

Pode-se construir mapas de p-quantis, por exemplo, mapas em que os valores 

estimados em cada posição têm uma determinada probabilidade de serem excedidos. 

A qualidade de um modelo de ccdt; ou seja, da cdf posterior depende da 

adequabilidade do modelo de dependência espacial utilizado e do percentual da informação 

disponível que foi utilizado na obtenção da mesma. 

O modo mais tradicional de construir um modelo de incerteza F(x;zl(n))é assumir 

uma forma ou expressão analítica completamente especificada por um número limitado de 

parâmetros. Por exemplo, se F(x; zl(n)) é assumida ser gaussiana, ela é determinada por dois 

parâmetros: sua média e sua variância. O problema de determinar os modelos de ccdfs se reduz 

a determinar os poucos parâmetros correspondentes. 

As abordagens não paramétricas não assumem um modelo de expressão analítica para 

as posteriores cdfs. A obtenção das ccdfs precedem a obtenção de uma estimativa ótima, como 

reportado nas krigagens indicatrizes. 

4.3 Intervalos de Incerteza com Krigagens Paramétricas 

A ccdf gaussiana F(x;zl(n)) é completamente determinada por um sistema de 

krigagem que requer apenas a inferência do modelo de covariância ou semivariograma. 

A variância de krigagem depende apenas da configuração dos dados e do modelo de 

covariância adotado, não dependendo do valor do atributo na posição. Consequentemente, a 

dispersão da ccdf em volta da média, a estimativa de krigagem, é também independente da 

mesma. Esta propriedade de independência da variância em relação aos valores dos dados é 

chamada homocedasticia. Esta propriedade é freqüentemente inadequada. 

A justificativa do modelo de distribuição gaussiana dos erros provém dos teoremas 

gerais da teoria das probabilidades, em especial do Teorema Central do Limite. Neste teorema 

tem-se que a soma de um grande número de variáveis independentes, com mesma distribuição 

(não necessariamente gaussiana) tende para uma distribuição gaussiana. Contudo, quando 

lidando com erros de interpolação, onde as fontes de erros não são necessariamente aditivas e 

independentes, não há razão para se acreditar que a distribuição dos erros seja gaussiana. Mas, 

43 



sem dúvida, o grande apelo desta abordagem é a extrema facilidade para se obter os intervalos 

de incerteza. 

Contudo, alguns cuidados devem ser tomados antes de adotar esta abordagem. Para 

serem obtidos os intervalos de incerteza, além da hipótese de distribuição gaussiana dos erros, 

se faz necessária a hipótese de que a variância de krigagem seja uma estimativa precisa da 

variância dos erros reais. Ao fazer essas hipóteses, pode-se combinar a estimativa z' com a 
variância de estimativa cr; para produzir intervalos de confiança e limites de confiabilidade. 

Por exemplo: 

1- P[Z' (x) -1.96cr • &amp;lt;Z(x) &amp;lt;z• (x) + 1.96cr.J = 0.95 

2- P[Z(x) &gt; Z'(x) + 0.675cr•] = 0.25 

Com estes intervalos de confiança poderiam ser construídos os mapas de quantis ou 

intervalos de probabilidade. 

Segundo Isaaks e Srivastava (1989), distribuições globais de erros, mesmo para 

distribuições assimétricas de dados, tendem a ser simétricas. Isto não significa contudo, que 

elas são necessariamente bem modeladas por uma distribuição gaussiana. Ao adotarmos a 

hipótese de distribuição normal, é importante considerar a segunda hipótese, isto é, capacidade 

de estimar a variância dos erros reais. Contudo, a cr; só será uma boa estimativa se o modelo 

de variograma estiver bem ajustado aos dados experimentais. Por exemplo, um pequeno erro 

no patamar do variograma não afeta os pesos da krigagem, mas afeta a variância da krigagem. 

Assim, a adoção da cr; para a estimativa dos intervalos de confiança requer, em parte, que o 

patamar do variograma seja uma estimativa precisa da variância global do atributo estimado. 

Embora as distribuições globais do erro possam ser simétricas, as distribuições locais 

dos erros não são. Nas áreas de baixos valores do atributo, há uma grande probabilidade de 

superestimação e, nas áreas de altos valores, uma correspondente tendência de subestimação. 

Particularmente, nas áreas com valores extremos que geralmente têm grande importância, as 

distribuições locais dos erros são freqüentemente assimétricas. A nível local, a hipótese de 

normalidade é ainda mais questionável e isto geralmente inviabiliza a determinação de 

intervalos de confiança locais, principalmente nas regiões onde se encontram os valores 

extremos do atributo a ser estimado. 

44 



4.3.1 Abordagem alternativa 
Na indústria do petróleo, as variáveis raramente apresentam distribuição normal. É 

razoável admitir que, para distribuições assimétrica dos dados, os intervalos de confiança 

também sejam assimétricos. 

Intervalos de confiança para a média de uma distribuição condicional de Zo I Z~, Zz, ... , 

Z.. devem ter a propriedade de assimetria reversa. Por exemplo, isto significa que valores da 

cauda superior de uma distribuição com assimetria positiva devem ter intervalos de confiança 

com assimetria negativa e os da cauda inferior, assimetria positiva. 

A nível de informação local, a variância de krigagem fornece uma indicação da 

precisão do valor estimado, blocos tendo variâncias de estimativa similares sendo muito bem 

ou pessimamente estimados. Contudo, a variância de estimativa não leva em conta a 

distribuição assimétrica dos dados. Por esta razão, quando lidando com dados assimétricos, 

intervalos de confiança (ICs) permitem uma maior apreciação da viabilidade da estimativa do 

que a real incerteza local. Apesar desta aparente necessidade para a obtenção de ICs realistas a 

nível de estimação local, muitas aplicações práticas ainda confiam nos ICs baseados em 

hipóteses, ás vezes questionáveis, sobre a normalidade dos erros de estimativa. 

Roth e Armstrong (1995) propuseram um método para construir ICs de atributos com 

distribuição não gaussiana. Eles utilizaram a transformação gaussiana dos dados originais. 

Intervalos de confiança são obtidos para estas variáveis normalizadas, e transformados de volta 

para dar os correspondentes intervalos de confiança dos valores estimados. Os autores da 

proposta frisaram algumas hipóteses para a aplicação da metodologia. Inícialmente o atributo, 

cujos ICs serão obtidos, deverá apresentar estacionariedade de segunda ordem. Se necessário, 

os conjuntos de dados devem ser submetidos a uma 'declusterização' (remoção dos 

agrupamentos) a fim de que o histograma possa ser considerado como representativo da 

distribuição. Eles ressaltaram a necessidade dos dados transformados apresentarem a 

propriedade de distribuição multivariada gaussiana para obtenção do I C. 

A metodologia proposta por Roth e Armstrong ( 1995) resulta em intervalos de 

incerteza com assimetria reversa e que não respeita apenas o erro associado com o processo de 

estimativa (a variância de krigagem), mas também a distribuição dos valores dos blocos. 

45 



4.4 Verificação Experimental 

4.4.1 Dados Básicos 
Foi utilizado um conjunto de dados de um campo real fornecido pela Al\10CO para 

os centros de geoestatística para fins de pesquisa. Os dados são de um reservatório 

carbonático, de idade permiana, produtor de óleo no oeste do estado do Texas, EUA. 

Este reservatório representa uma seqüência de plataforma carbonática progradante 

com arrasamento para o topo, formada em ambiente de moderada a baixa energia. 

Estes dados da AMOCO fazem parte do estudo de caso de petróleo do ISATIS. 

Foram usados também nos trabalhos de Chu et al. (1991 e 1994) e Deutsch e Journel (1992). 

No trabalho de Chu et ai. (1991), os dados relativos a Hojl (produto espessura x 

porosidade) estão dispostos em uma mapa com coordenadas espaciais transformadas para 

assegurar o sigilo, mas preservando as estruturas de variabilidade. Deste mapa foram obtidos 

os valores das coordenadas e os respectivos H&lt;jl dos 7 4 poços distribuídos em urna área de 

aproximadamente 15.4 km2 Nas figuras 4.1 e 4.2 estão respectivamente o mapa base com 

posição dos poços e o histograma dos dados relativos ao produto espessura vezes porosidade. 

++ + ++ + 3(1(1(1. + + + ++ ' O • 2C 
1!;(1(1, + + + + + ++ ++ 

+++ + + + +++ ++ o. :1.5 M!J(l, 
++ + + + + + + + + + 

10:0(1, 

+++ + 
o -1~ 

+ ++ + + 
1\)(1{\, 

++ + ++ + + + (I 'os 
~(1·), + + + + + + 

(1.(1. 
O. OQ 

i(t(l(o. l:(li.&lt;(l. Jo('{&gt;(l. ~(&lt;(I(&lt;~ 

Dados Originais- 7 4 poços H$(m) 

Figura 4-1: Mapa Base com a Posição dos Poços. Figura 4-2: Histograma dos dados originais. 

Verifica-se que a distribuição dos dados (poços) é aproximadamente regular, não 

apresentando agrupamentos, evidenciando apenas algumas regiões com reduzida amostragem 

como no extremo sudeste. Quanto ao histograma, pode-se observar que trata de uma 

distribuição com assimetria positiva. A distribuição apresenta média 1.294 m com desvio 

padrão 0.296 m. 

46 



4.4.2 Construção do Caso Base 
Com este conjunto de dados, realizou-se krigagem ordinária em um grid com 61 

blocos na direção X e 45 blocos na direção Y. Cada bloco tem dimensão de 75x75 metros. 

Este resultado foi considerado como caso base para análise da influência do número de dados 

iniciais e do variograma na estimativa. O caso base (figura 4.3) tem as seguintes características: 

Valor mínimo H$ por bloco: 0.9087 m; Valor máximo H$ por bloco: 1.8335 m; 

Valor médio de H$: 1.2949 m; Desvio Padrão de H$: 0.1760 

Volume Poroso Total (VPT) do reservatório: 20 Milhões de m3 ; 

Variograma: uma estrutura gaussiana com alcance 1776.7m e patamar 0.0442m2 . 

3000_ 
2 

2§01L 1. 87 
1_75 

2001L 
1_ 62 
1. 5 
1. 37 

1500. i_ 25 
1.12 

1000. 1 
O. 87 

500. 
tL 1§ 

Figura 4-3 : Caso base. 

Do caso base, foram retirados quatro conjuntos contendo 20, 48, 63 e 88 dados 

regularmente espaçados. Foram obtidos também quatro conjuntos de dados irregularmente 

espaçados, privilegiando ou altos ou baixos valores. Na figura 4.4 estão as distribuições das 

amostras constituintes dos conjuntos analisados. 

4.4.3 Parâmetros das Krigagens 
Na tabela 4-2 estão os modelos de variogramas e a vizinhança utilizados para as 

krigagens em cada conjunto de dados. Os termos 'melhor' e 'pior' referem-se aos conjuntos de 

dados com amostragem seletiva em melhores e piores situações. Observa-se (tabela 4-2) que à 

medida que aumenta o número de amostras, mais o modelo de variograma se aproxima do 

variograma do caso base. As vizinhanças, variando o raio e o número mínimo de amostras 

necessárias para a estimativa, e o percentual de efeito pepita no modelo de semivariograma 

(máximo de 8% do patamar) foram escolhidos de forma a obter uma validação cruzada mais 

robusta e permitir a estimativa de todos os blocos do domínio. 

47 



' ' ' ' ' ' ' -·- 1- + -- -+ + • + + + + + + • + + 
2580. 1- -- + + • + + + + + -
2088. - + + + + + 2088. t-+ + • + + + + + -
1580. 1580. t-+ -1- + + + + + + + + + + + 
1110G. :IIIQG. t-+ + + + • + + + 
soo. 1- -- t-+ . + • + • + + • + + + + + ..L _j_ ..L .L 

•li. J.UUO. 2008. 3000. 4000. •li. :IIIQG. -- -o. -·-20 A'lllostras 48 Alllostras 
' ' ' ' . ' ++ -·- 1- + + + + + + + - -- 1-+ + + • + + +++++ 2588. + + • + + +++ + 2500. r-+ + + • + + ++++ + 

-·- 1- + + + + + ++ + + - + + + 2088. • + + ++++ + + + + + + + + +++ + + ~ + + • + + + + + 1588. 1580. '""+ + ... ... .. + + + + + + + + + + + + + + + 
11100. :IIIQG. r-+ + + + + + + + + + + 

+ + + + + + + + + + + + • + + + ... + + + soo. r- + --+ • + + +,+ + + + + • • + + + + + + + f _L f f ... _ 11100. 2008. 3000. 4800. 811_ 11100. 2000. -- -·-S3 Amostras 88 Alllostras 
' . ' 

++ 
' -·- + ... + + ; -- + + • 2588. - +- -- + ++ + + + '-+ + -·- + 2088. • ++ + 1588. 

+ 1580. + + + + 
11100. r- + - + + 

+ :IIIQG. 1-
soo. 1- ... + + - -- '+ " + ... _ -'- .di :IIIQG. 2008. 3000. ...... ... _ 11108. -- -- -·-20 Jbl'lost.ras P .ier 20 Alrlostras Me:Dor 

+ + '+ -t+ +' + ' 
• f ' -- 1-+ 3008. f+ + • +++++++_ ++ + • 1-+ ++ + + + f* ... ++++ + + -- ++ 2500. + + + + + + • ++++ + + -- + ++ -- 1-+ + ++ + + + + + + + + l!iOO. + + ++ l!iOO. "" + + . ... + ++ + + + + ,.+ + + + + 11100. + + 11108. + + + + + + + + + + + + + + + + + + + -- r- ++ + -- 'i-+ + ++ + + + + ...±. + + + ... _ __[ + ,++ f :IIIQG. 2000. -- 4800. ... _ 1000. 2008. 3880. 4800. 1'3 7dftostras Pior 63 Amostras Mel.hor 

Figura 4-4: Conjuntos amostrais retirados do caso base. 

48 



Tabela 4-2: Variogramas e Vizinhanças Adotadas nas Krigagens 

Variograma Isotrópico Aiustado Vizinhança 
Conjunto de Dados Estrutura 1 Efeito Pepita Circular 

Modelo Alcance (m) Patamar Patamar Raio (m) 
Original (Controle) Gaussiano 1776.7 0.0442 - -
20 Amostras Esférico 2647.5 0.0391 0.0032 2000 
20 Amostras melhor Gaussiaoo 1848.4 0.0581 0.0030 1500 
20 Amostras pior Gaussiaoo 1942.0 0.0600 - 1600 
48 Amostras Esférico 2182.5 0.0419 - 1800 
63 Amostras Gaussiano 1793.1 0.0441 0.0031 1000 
63 Amostras melhor Gaussiaoo 1740.5 0.0433 0.0020 900 
63 Amostras pior Gaussiano 2181.9 0.0354 0.0016 1050 
88 Amostras Gaussiaoo 1839.6 0.0446 0.0008 900 

4.4.4 Resultados das Krigagens 
Os resultados das krigagens em termos de volume poroso do reservatório estão na 

tabela 4-3. O cálculo do volume poroso total é obtido a partir da sontatória do produto de H&lt;l&gt; 

em cada bloco pelas dimensões dos blocos (75m x 75m). Para dados regularmente espaçados, 

as estimativas de volume poroso total do reservatório apresentaram diferenças inferiores a 1%. 

Tabela 4-3: Resultados das Kri2a ens 
Conjunto Volume Poroso do (H&lt;!&gt;) médio 

reservatório (Mm3) por bloco (m) 
Caso Base - controle 19994 1.2949 
Krigagem - 20 Amostras pior 18825 1.2192 
Krigagem - 20 Amostras melhor 20851 1.3504 
Krigagem - 20 Amostras 19878 1.2874 
Krigagem - 48 Amostras 19993 1.2948 
Krigagem • 63 Amostras pior 19717 1.2769 
Krigagem - 63 Amostras melhor 20161 1.3057 
Krigagem - 63 Amostras 20019 1.2965 
Krigagem - 88 Amostras 19990 1.2947 

Para dados irregularmente espaçados privilegiando áreas de interesse, que é a situação 

mais comum em termos de engenharia de reservatórios, os resultados das estimativas podem 

ficar bastante enviesados. Por exemplo para o conjunto de dados com 20 amostras, a diferença 

entre a estimativa e o valor real apresentou uma diferença da ordem de 5%. Na indústria do 

petróleo, a depender da dimensão do reservatório e do atributo que está sendo estimado, 

diferenças de 1% ou 5% podem ter um impacto econômico bastante elevado. Os resultados 

(ntapas krigados) estão na figura 4-5. Ressalta-se que o caso base analisado não apresentava 

anisotropias ou deriva. A ocorrência das mesmas, dificultaria a modelagem a partir de poucos 

dados e poderia levar a resultados mais discrepantes em termos de volume poroso total do 

reservatório. 

49 



H+ (4&amp;amp; Amoot:ras) 

H+ (88 Amoot:ras) 

H+ (63 Amoot:ras Melhor) 

H.P (20 Amootras Pior_) H.P (20 Amootras Melhm) 

Figura 4-5: Resultados das krigagens. 

50 



4.4.5 Intervalos de Incerteza 
Admitindo a distribuição gaussiana para os erros, intervalos de incerteza foram 

obtidos considerando a estimativa mais ou menos um (intervalo 1) e dois desvios padrões 

(intervalo 2). 

Na figura 4.6 estão os mapas considerando a estimativa mais e menos um desvio 

padrão para o caso de 20 dados amostrais regularmente espaçados. Correspondem aos mapas 

dos quantis 15.87% e 84.13%, considerando as hipóteses propostas de Isaaks e Srivastava 

(1989), anteriormente mencionadas. 

Estimativa . 1 Demo Padrão 

Ht(m) 

&gt;=2 
1.875 
1.:15 
1.GZ!i 
1.5 
1.375 
1.25 
1.:125 
1 
o. 875 
&lt;0.75 

Figura 4-6: Mapas dos percentis 15.87 e 84.13 %. 

Fsfun.ai:iw +I Desvio P~ 

Na tabela 4-4, além dos resultados relativos a intervalos de confiança, estão os 

1 2745 1 2745 
relativos aos erros: &amp;amp;m = --"Lz~b -z; e &amp;amp;ma= -

2 4 
'2:1z;- z~bl 

2745 i=l 7 5 i=l 

onde &amp;amp;m é o erro médio, &amp;amp;ma é o erro absoluto médio, z; e z~b são respectivamente o valor 
estimado de Hq, e o valor do caso base em um bloco i do grid. Na tabela 4-4, as colunas 

relativas aos intervalos de incerteza 1 e 2 correspondem em quantos blocos, os valores reais 

(caso base) ficaram dentro dos respectivos intervalos construídos a partir da estimativa e de 

sua variância. 

Da tabela 4-4, confirma-se que o estimador é não enviesado, pois o erro de estimativa 

é nulo na média (em= 0). Para amostras regularmente espaçadas, verifica-se que à medida 

que aumenta o número das mesmas, ocorre uma diminuição acentuada do erro absoluto médio 

das estimativas em relação ao caso base. Para amostras irregularmente espaçadas, os erros 

absolutos médios se apresentaram sempre maiores em relação à situação com mesmo número 

de dados e amostragem regular. 

51 



Tabela 4-4: Intervalos de Incerteza e Erros 

Estimativa com Intervalo de Intervalo de Erro Erro absoluto 
Incerteza l Incerteza2 médio médio 

20 Amostras 2339 2658 0.0075 0.067 
20 Amostras pior 1982 2617 0.0757 0.087 
20 Amostras melhor 2220 2625 0.0554 0.070 
48 Amostras 2530 2670 0.0001 0.030 
63 Amostras 2509 2636 -0.0016 0.026 
63 Amostras pior 2210 2570 0.0180 0.034 
63 Amostras melhor 2439 2656 -0.0108 0.027 
88 amostras 753 1118 0.00024 0.020 

Como se dispõe dos dados considerados reais, era de se esperar que 187 4 e 2608 

valores estimados de Htjl por bloco (o grídtem 2745 blocos) ficassem dentro dos intervalos de 

incerteza I e 2, respectivamente, considerando a condição de distribuição gaussiana dos erros. 

Isto foi verificado com folga para as situações de 20, 48 e 63 amostras regular e irregularmente 

espaçadas, não ocorrendo para o caso de 88 amostras. Porém, para a condição de 88 

amostras, as estimativas ficaram mais próximas do valor real, isto é, foram observados os 

menores erros. Pode-se concluir que a variância de estimativa ficou reduzida o suficiente, de 

forma que os intervalos de incerteza ficaram bastante estreitos, a ponto de não incluírem o 

valor real. Para esta situação, poder-se-ia supor que a melhoria na precisão (variância de 

estimativa) se deu às custas da acurácia (conter o valor real). Nos casos de quantidades 

inferiores de amostras, ocorreu exatamente o contrário. Em verdade, é o modelo de 

distribuição gaussiana para os erros que não é adequado para todos os casos. 

Através de testes de hipóteses, verificou-se que todas as distribuições globais dos 

erros apresentaram grandes discrepâncias em relação a uma distribuição gaussiana, podendo 

rejeitar a hipótese de distribuição normal ao nível de 5% para todas as condições. 

4.4.6 Análise Visual 
A análise visual e qualitativa dos mapas gerados levam indubitavelmente a observar 

uma melhoria acentuada na semelhança com o caso base à medida que se aumenta o número 

de dados. Ressalta-se que apesar da diferença entre a estimativa do volume poroso total do 

reservatório para o caso de 20 e 88 amostras ser bem pequena, as diferenças bloco a bloco 

(figura 4.5) são marcantes. 

A comparação quantitativa entre as estimativas e o caso base podem ser feitas usando 

o coeficiente de correlação. Da Tabela 4-5, verifica-se que, com o aumento do número de 

52 



dados regularmente espaçados, ocorre um aumento do fator de correlação. Porém, o impacto 

de aumentar o número de dados é cada vez menor. O aumento foi mais pronunciado (13.8%) 

quando se aumenta de 20 para 48 dados. 

Tabela 4-5: Fator de correlação 

Estimativa com Fator de correlacão 
20 dados - pior 0.8336 
20 dados - melhor 0.8339 
20 dados 0.8405 
48 dados 0.9566 
63 dados - pior 0.9537 
63 dados 0.9635 
63 dados - melhor 0.9721 
88 dados 0.9779 

4.4.7 Variogramas Cruzados 
Como se dispõe de um caso base, considerado como referência, pode-se quantificar a 

melhoria da qualidade de uma estimativa com o aumento do número de dados amostrais, a 

partir do variograma cruzado entre os valores da imagem de referência e os valores de uma 

imagem krigada. Considere Z correspondente ao caso base e Y correspondente a uma imagem 

krigada. O semivariograma cruzado entre Z e Y é: 

J N(h) 
Y zv (h)= 

2
N(h) tt {[Z(x, +h)- Z(x;)][Y(x, +h)- Y(x;)]} 

Quanto mais próximo do caso base a imagem estiver, mais próximo o semivariograma 

cruzado vai estar do semivariograma do caso base. Na expressão do semivariograma cruzado, 

com Y=Z, obtém-se a expressão do semivariograma para Z. Para esta análise foram 

considerados apenas os conjuntos de dados regularmente espaçados. 

Na figura 4-7 estão os semivariogramas cruzados e o semivariograma do caso base. 

Verifica-se melhoria acentuada à medida que aumenta o número de amostras. Concordante 

com as análises anteriores, o maior percentual de melhoria se dà no aumento de 20 para 48 

amostras. O interessante desta visualização é que para valores de h (distância) maiores que 

I 000 metros, o aumento do número de poços continua a reduzir consideravelmente a diferença 

em relação ao semivariograma do caso base. Esta forma de comparação de estimativas com 

um caso de referência é mais informativa do que o coeficiente de correlação. Ressalta-se que 

poderiam ter sido utilizadas outras funções geoestatísticas como, por exemplo, a covariância e 

o correlograma cruzados. Os resultados seriam similares. 

53 



o.o45 I 

' 0.040 J 
0.035l 

0.030 ~ 

' 0.025 i 

0.020 jl 
0.015 

0.010 

~ 
0.005 --l 

..j 

0.000 

500 
I 

L"ll"llda 

---&amp;amp;-- c .. so ease 
--E:3-- KrlgaQ&lt;'&gt;m com :20 AmoS'tr"s 
---6--- K&lt;lgag&lt;&gt;m com 48 Amostras 
-+- Krlg,.çem com 63-AmoSO::ras 
---'2--- Krlgegem com 88 Amos:!:ms 

1000 1500 2000 
h (m) 

Figura 4-7: Variogramas cruzados entre estimativas e caso real. 

4.4.8 Comparação através de cortes 

250 

Uma outra maneira de comparar as diversas estimativas realizadas em relação ao caso 

de referência é a utilização de cortes. Isto corresponde a considerar um determinado parâmetro 

de corte para o atributo de interesse, no caso Hljl, e calcular o volume poroso do reservatório 

só considerando os blocos nos quais a estimativa é maior que o corte. Foram utilizados três 

cortes correspondentes a Hljl por bloco igual a l.l, 1.3 e 1.5 m. Realizou-se então o cálculo do 

volume poroso considerando apenas os blocos onde a estimativa do atributo Hljl era superior 

ao dado corte. Observa-se na tabela 4-6 que os erros podem ser elevados para as condições de 

poucas amostras, principalmente se irregularmente distribuídas. 

Tabela 4-6: Volumes porosos para diferentes cortes 

Estimativa com Corte H&lt;l&gt; 1.1 m Corte H&lt;l&gt; 1.3m Corte H&lt;l&gt; 1.5m 
Volume(Mm/ Erro(%) Volume (Mm") Erro(%) Volume(Mm/ Erro{%) 

Caso Base 18291 - 9032 - 3464 -
20 Dados melhor 20330 11.1 12991 43.8 3918 13.1 
20 Dados 19421 6.2 8401 -7.0 2566 -25.9 
20 Dados pior 16697 -8.7 4855 -46.2 1276 -63.2 
48 Dados 19009 3.9 9298 2.9 2964 -14.5 
63 Dados melhor 19239 5.2 9304 3.0 3400 -1.9 
63 Dados 18984 3.8 8826 -2.3 3215 -7.2 
63 Dados pior 18517 1.2 7569 -16.2 2873 -17.1 
88 Dados 18451 0.9 8886 -1.6 3556 2.7 

Para o corte de 1.3m foram refeitos os cálculos individuais dos volumes porosos 

estimados divididos em quatro classes: abaixo e acima do parâmetro de corte, os falsos 

positivos e os falsos negativos. Os falsos positivos são blocos que no caso de referência estão 

54 



abaixo do parâmetro de corte e na estimativa estão acima. Os falsos negativos correspondem a 

situação inversa. Na figura 4-8 estão os gráficos para as condições de 20 e 88 dados 

regularmente espaçados. Verifica-se que ao considerar apenas as estimativas onde realmente o 

valor real está acima do parâmetro de corte, as diferenças entre as duas situações aumentam 

significativamente. Como era de se esperar, a condição com menor número de amostras 

apresenta maior percentual de falsos positivos e falsos negativos. Como em todas as 

abordagens comparativas utilizadas, evidencia-se melhoria da qualidade da estimativa á medida 

que se aumenta o número de dados. Com a abordagem de cálculo dos volumes através de 

cortes esta melhoria ficou mais evidenciada. 

Ê 

i 

'"'' 

§ "' :õ 
R 

Estimativa com 20 dados regularmente espaçados 

J~.~-'--~ 
j 

1.10 

'" 

• 
9.nMilll!lesdeM3 

1.10 1.30 1.5(1 1.70 
V&amp;amp;l« Real (Caso Base)pa- bloco{em m) '" 

"' l , Estimativa com 88 dados regularmente espaçados 
1.70 _; 

Ê J 
i I 
§ uo -1 
jS I 0.50 Milhl!e$ de M3 

R 

J1.~ -'--~C"" 
j 

1.10 

0.59 Milhôes de M3 

10.51 Milh!le9de M3 

1.10 1.30 uo uo 
valor Reei (Caso Base)por bloco (em m) 

Figura 4-8: Distribuições de volumes porosos em relação ao corte de H&lt;l&gt; 1.3 m. 

.... 

4.4.9 Intervalos de Incerteza Locais- Abordagem de Roth e Armstrong 
Baseando-se na metodologia apresentada por Roth e Armstrong (1995), foram 

refeitas as krigagens para os conjuntos de dados uniformemente distribuídos. 

Para tal, os dados originais foram submetidos a transformação gaussiana sendo 

obtidos novos semivariogramas. Foram mantidos os alcances de todos os semivariogramas, 

bem como a vizinhança adotada para cada um dos conjuntos de dados regularmente 

espaçados. Nas tabelas 4-7 e 4-8 estão os principais resultados obtidos com esta nova 

abordagem. Adotou-se a sigla RA para fazer referência à abordagem proposta por Roth e 

Armstrong. 

Verifica-se a partir da tabela 4-7, uma tendência de aprmamar da distribuição 

gaussiana dos erros com a abordagem RA, o que corresponde a 1874 e 2608 valores de Hei&gt; 

reais dentro dos intervalos de incerteza 1 e 2 respectivamente. 

55 



Com relação aos intervalos de incerteza para a estimativa local, confirma-se que a 

grande maioria dos ICs obtidos com a abordagem RA apresentam assimetria reversa. Assim, 

estimativas próximas ao limite superior da distribuição apresentaram intervalos de incerteza 

predominantemente à esquerda da mesma. O contràrio foi observado para estimativas 

próximas ao limite inferior. Ressalta-se que as distribuições originais dos 4 conjuntos de dados 

são assimétricas positivas. 

Tabela 4-7: Intervalos de Incerteza 

Estimativa com Valores reais no Intervalo Valores reais no Intervalo 
de Incerteza 1 de Incerteza 2 

20 Amostras 2339 2658 
20 Amostras RA 2332 2508 
48 Amostras 2530 2670 
48 Amostras RA 2463 2621 
63 Amostras 2509 2636 
63 Amostras RA 2388 2590 
88 amostras 753 1118 
88 amostras RA 2228 2525 

Estimativas que na abordagem tradicional apresentam a mesma variância de krigagem 

(intervalos de incerteza iguais e simétricos), apresentam largura dos intervalos de incerteza, 

com a abordagem RA, tanto maior quanto maior for a estimativa (tabela 4-8). A largura de um 

intervalo de incerteza corresponde à diferença entre os seus dois limites. Para a abordagem 

tradicional, a largura do IC 2 é o dobro da largura do IC I. 

Tabela 4-8:Intervalos de Incerteza (Estimativa Local: H.P por bloco em m) 

Conjunto de Coordenadas Estimativa Largura do IC 1 Largura do IC 2 
Dados XfY do bloco de H&lt;l&gt; (m) Tradicional RA Tradicional RA 
20 Amostras 1050/1800 1.16 0.236 0.224 0.472 0.355 

3450/1800 1.47 0.236 0.332 0.472 0.490 
88 Amostras 105011800 1.06 0.0045 0.032 0.0090 0.064 

345011800 1.77 0.0045 0.036 0.0090 0.082 

Verificou-se que os intervalos de incerteza obtidos com a abordagem proposta por 

Roth e Armstrong tendem a ser mais conservativos, isto é, mais largos do que os obtidos com 

a abordagem tradicional, quanto maior for o valor da estimativa. Adicionalmente verificou-se 

também que se a variância de krigagem é pequena em relação à estimativa em qualquer 

posição, como no caso com 88 amostras, a abordagem RA tende a apresentar intervalos de 

incerteza locais mais conservativos que a abordagem tradicional, qualquer que seja o valor da 

estimativa local (Tabela 4-8). Isto leva a intervalos de incerteza globais muito mais 

conservativos com a abordagem RA do que a tradicional. Ressalta-se que a proposta de Roth e 

Armstrong visa apenas a obtenção de intervalos de incerteza locais representativos. 

56 



4. 5 Comentários 

Uma questão fundamental, bem colocada por Isaaks e Srivastava (1989), é se somos 

capazes de estimar a variância dos dados reais. Para esta condição, o patamar do 

semivariograma deve ser uma boa estimativa da variância global do atributo a ser estimado. 

Nas situações analisadas, o patamar dos semivariogramas ficaram sistematicamente acima da 

variância dos valores estimados por krigagem para cada conjunto de dados em cada situação e 

da variância dos valores do caso base. Em uma situação real não se dispõe do caso 

considerado referência. Mas, de qualquer forma, o patamar do semivariograma diferente da 

variância dos valores estimados em um determinado dominio é um forte e inquestionável 

indício que provavelmente não se pode estimar a variância dos erros reais. 

A abordagem proposta por Roth e Armstrong (1995) gera intervalos de incertezas 

com assimetria reversa e, portanto, representa um grande avanço no sentido de obter 

intervalos de incerteza de krigagens paramétricas. Porém requer, como na abordagem 

tradicional, que as hipóteses de distribuição multivariada gaussiana e a capacidade de avaliar a 

variância dos erros reais sejam verdadeiras. O principal problema verificado com a abordagem 

é a tendência de obtenção de intervalos de incerteza locais mais conservativos que a 

abordagem tradicional, qualquer que seja o valor da estimativa, para as situações em que a 

variância de krigagem é pequena comparada à estimativa. Isto leva a intervalos de incerteza 

globais muito mais conservativos. 

V àrias referências existem na literatura abordando intervalos de incerteza com 

krigagens paramétricas sob a ótica apenas da distribuição multivariada gaussiana. Poucos 

reportam e avaliam a capacidade de estimar a variância dos erros reais. Armstrong (1994, 

p.306) reporta que a idéia de obter intervalos de incerteza a partir da estimativa e da variância 

de krigagem reaparece regularmente, mesmo em respeitáveis periódicos. 

Por exemplo em Harbaug et ai. (1995, p.165-166), os autores mostram mapas de 

espessura estimada (krigagem) mais ou menos 1.63 desvios padrão. Os dados constituem a 

espessura de um reservatório carbonático de uma área do Oriente Médío. A única hipótese 

ressaltada pelos autores é que a distribuição dos erros de estimativa é gaussiana. Os autores 

avançam considerando distribuição gaussiana dos erros locais (Harbaugh et ai., 1995, p. 167). 

Eles construíram uma 'seção' de uma determinada coordenada e afirmam que 'a probabilidade 

é apenas de 10% da espessura cair fora do envelope da estimativa mais ou menos 1.63 desvios 

padrão para qualquer posição' (figura 4-9). Curiosamente na figura mostrada pelos autores, os 

57 



intervalos que deveriam ser simétricos em relação à estimativa (uma vez que admitiu-se a 

distribuição gaussiana local), são apenas aproximadamente simétricos. Observar na figura 4. 9, 

que o trecho entre as coordenadas 20 e 29 (coluna X), próximas aos 2 poços, os limites 

superiores e inferiores não são simétricos em relação à estimativa Provavelmente trata-se de 

um descuido quando da impressão original da citada obra. 

50 ••~••••••••••n•..,.•••••••••••••··-r--••-~•-•••••-.... -._...._ 
' • I ' o ~ ' 

.. ... 
=40 
I 
c. 
~ 35 

• • ' • .. p • 
o I 1 • • ' 

imite Su.periorl ; : 
-~t-•••~•~••••••••~• I 

' : 
' ' 
' 

~+---r-~~~---r--,_--+-~ 
o 5 10 15 20 ~ 35 

Coluna X (Km) 

Figura 4-9: Intervalo de incerteza ao longo de uma linha com coordenada Y f"lxa, 
passando por dois poços. (Figura 7.20 de Harbaugh et al1995, p.167) 

Concluindo, a construção de intervalos de incerteza globais e locais a partir de 

krigagens paramétricas é uma área em que a pesquisa pode avançar. O grande apelo da 

metodologia da distribuição gaussiana dos erros é a extrema facilidade com que se pode obter 

os intervalos de incerteza a partir da estimativa e da variância de krigagens paramétricas. 

Ressalta-se que a abordagem proposta por Roth e Armstrong (1995) segue a mesma linha da 

construção de ccdf a partir de krigagens nas etapas de simulação estocástica gaussiana. 

Apesar de não terem sido utilizadas abordagens não paramétricas (krigagem 

indicatriz) na construção de intervalos de incerteza para variáveis contínuas, algumas 

considerações podem ser feitas. A grande vantagem sempre reportada pelos autores e usuários 

da krigagem indicatriz é que ela não requer a adoção de nenhum modelo de distribuição a 

priori. Esta questionável supremacia da abordagem não paramétrica depende de um elevado 

número de cortes (cutoffs) e da utilização da cokrigagem indicatriz, que são condições difíceis 

de serem obedecidas. Por exetnplo, um reduzido número de cortes implica em uma redução da 

quantidade e consequentemente da representatividade dos diferentes intervalos de incerteza 

que podem ser obtidos. Ressaltam ainda os problemas de relação de ordem que ocorrem com 

as abordagens indicatrizes. De qualquer forma, esta metodologia exige um maior esforço 

computacional e um maior trabalho de inferência de semivariogramas do que a abordagem 

paramétrica, daí o porquê de muitas vezes se utilizar esta última, mesmo sob hipóteses 

algumas vezes questionáveis. 

58 



5. Simulação Estocástica 

Atualmente, existe uma grande variedade de algoritmos de simulação estocástica 

disponíveis que diferem em suas hipóteses básicas, campo de aplicação, dados requeridos, 

implementação prática, complexidade e eficiência computacional. 

A escolha de uma método de simulação estocástica deve se basear na disponíbilidade 

de tempo, dinheiro, recursos humanos e computacionais de hardware e software, bem como a 

complexidade requerida pelo estudo. Parafraseando Srivastava (1994b): nem todos os estudos 

de modelagem necessitam de uma técníca 'Cadillac', algumas vezes um 'Volkswagen' ou um 

bom par de patins pode ser suficiente. Esse bom par de patins pode ser a krigagem que, a 

depender do objetivo do estudo, pode ser aplicada. Infelizmente também pode ocorrer o 

inverso. A importância do estudo requerer uma modelagem geoestatística elaborada e se 

utilizar uma simplificada, ou mesmo não utilizar a geoestatística. 

Neste ponto se faz necessário explicitar os principais aspectos que diferem a krigagem 

da simulação estocástica. O objetivo da krigagem é fornecer uma úníca estimativa local, sem 

contudo respeitar a estatística espacial de todas as estimativas consideradas conjuntamente. 

Assim, o semivariograma de uma mapa krigado é diferente do usado na krigagem. Na 

simulação estocástica, a reprodução de características globais (textura) e estatísticas 

(histograma e covariância) são priorizadas em relação à acurácia local na obtenção de vários 

conjuntos alternativos de representações. 

A krigagem apresenta a característica de suavização. Só que esta suavização será 

menos acentuada quanto mais contínuo for o fenômeno que está sendo modelado. A título de 

demonstração foram construídos, via simulação estocástica, dois casos base, um com modelo 

de semivariograma gaussiano e outro com modelo de semivariograma exponencial. Destes 

casos, foram retiradas aleatoriamente I 00 amostras. Com estas amostras e os modelos de 

variogramas obtidos da variografia de cada caso base, foram realizadas uma simulação 

estocástica com bandas rotativas e a krigagem para cada um dos casos. Na figura 5-l estão os 

resultados das simulações e da krigagem. Verifica-se que quanto menos errático, isto é, mais 

contínuo for a realidade do fenômeno que está sendo modelado, menores serão diferenças 

entre as diversas realizações da simulação estocástica e a krigagem. Os efeitos de suavização 

59 



da krigagem são mais severos quanto mais errático, isto é, menos contínuo for o fenômeno 

analisado. 

Simulação 

Figura 5-1 :Krigagem x Simulação condicional. 

60 



Na geoengenharia de reservatórios, quando os resultados obtidos com as ferramentas 

geoestatísticas são submetidas a funções de transferência, possivelmente não lineares, como 

por exemplo um simulador de fluxo, deve-se optar pela utilização da simulação estocástica. 

A questão central na caracterização de reservatórios é a modelagem realística das 

heterogeneidades no reservatório. Portanto, todas as etapas envolvidas no processo de 

simulação estocástica devem ser cuidadosamente verificadas. A escolha do algoritmo de 

simulação estocástica e até mesmo a escolha do software a ser utilizado podem influenciar os 

resultados. Existem diferenças importantes na implementação do algoritmo de um mesmo tipo 

de simulação nos softwares geoestatísticos comerciais: parâmetros que podem ser gerenciados 

pelos usuários, na forma de apresentação dos resultados e mesmo na metodologia de 

implementação do algoritmo. Segundo Srivastava (1994b), escolher uma abordagem específica 

pode se tornar uma tarefa desconcertante para os novos usuários da simulação estocástica. É 

necessário saber qual método é mais adequado ao particular contexto. Infelizmente, não existe 

a melhor técnica, qualquer que seja a situação. 

Os artigos que propõem as novas metodologias de simulação estocástica geralmente 

se concentram nas vantagens das mesmas, deixando que as desvantagens sejam publicadas por 

outros autores que, ou propõem um algoritmo alternativo ou uma melhoria no algoritmo 

anterior. Assim, cada técnica tem seus próprios defensores, os seus próprios autores. 

V árias revisões de métodos de simulação estocástica estão disponíveis na literatura, 

destacando-se Dubrule (1989), Alabert e Modot (1992), Dowd (1992), Damsleth e Holden. 

(1994), Galli e Beucher (1997), dentre outros. Ressalta-se que a maioria desses trabalhos são 

direcionados a um leitor especialista em geoestatística. Para o usuário com menor 

conhecimento geoestatístico, é geralmente dificil entender as diferenças entre os métodos e 

suas principais características. Com intuito de fornecer uma visão global das técnicas de 

simulação estocástica mais utilizadas, as mesmas são abordadas a seguir de forrna a evidenciar 

suas linhas mestras de aplicação e principais características. 

5.1 Bandas Rotativas 

O algoritmo das bandas rotativas foi o primeiro algoritmo de simulação 3D realmente 

implementado em grande escala. Neste método são feitas as seguintes hipóteses: o campo a ser 

simulado é estacionário de segunda ordem e isotrópico com covariância C(h) conhecida; os 

valores deste campo são N(O, 1 ), se necessário, após a transformação gaussiana; o campo 

apresenta distribuição multivariada gaussiana. 

61 



A originalidade do método desenvolvido por Matheron (1973, apud Journel e 

Huijbregts, 1978) está na redução das simulações n-dimensionais em várias e independentes 

simulações unidimensionais ao longo de linhas que são giradas no espaço Rn. Um valor 

simulado em uma posição x é obtido a partir das contribuições das n simulações 

unidimensionais z,1 (x). 

1 00 
z,., (x) = .[Ii"?; z,;(x) 
A realização resultante z.,, ( x) é uma realização de urna F A, por exemplo no caso 3D 

Z,(x) = Z,(u, v, w), que é estacionária de segunda ordem, com esperança zero e covariância 
E[Z, (x)Z, (x +h)]= C(h) 

que tende à covariância isotrópica quando o número de linhas tende a infinito. Uma 

covariância C(h) anisotrópica pode ser modelada como somatória de modelos isotrópicos 

imbricados em espaços de dimensões n&amp;lt;3. Basta então simular independentemente cada um 

dos componentes do modelo e em seguida somar as realizações em cada ponto. 

Na prática, o número n de linhas não pode ser infinito. O reduzido número de linhas 

pode provocar o efeito de artefatos (lineamentos) nos campos simulados, gerando anisotropias 

inexistentes. Além disso, o algoritmo das bandas rotativas somente é capaz de lidar com 

determinados tipos de função covariância. 

O condicionamento para a simulação, via bandas rotativas, trata-se de uma etapa em 

separado. Para produzir um grid com os valores condicionantes e que reproduzam a 

variabilidade espacial da F A, valores são produzidos através de krigagens, usando os valores 

simulados não condicionais na posição dos dados originais. Este novos valores krigados são 

subtraidos dos valores da simulação não condicional para se obter um grid com valores de 

erros correlacionados. Estes erros correlacionados são adicionados aos valores de uma 

krigagem realizada considerando os dados originais, de forma a produzir uma simulação 

condicional. Então: 

Onde z,., é a simulação condicional, Zkd é a krigagem obtida a partir dos dados 

originais reais, z.,, é a simulação não condicional e Zkmc é a krigagem dos valores simulados 

não condicionalmente nas mesmas posições dos dados originais condicionantes. 

62 



5.2 Simulação Gaussiana Seqüencial 

Os algoritmos seqüenciais propostos por Joumel e Alabert (1989) são uma aplicação 

do Teorema de Bayes. Os n eventos independentes A,,i = l, ... ,n podem ser simulados 

seqüencialmente usando a expressão: 

P[A 1 ,A 2 , ... ,A.]= P[A. jApA2 , ... ,A._1 ]P[A._1 jA1 ,A 2 , ..• ,A._2 ]. •. P[A 2 jAJP[A 1 ]. 

A técnica requer a inferência de sucessivas (n-1) distribuições de probabilidades 

condicionais. Isto pode ser obtido de duas formas. A primeira é por adoção do modelo 

gaussiano, o que corresponde à simulação gaussiana seqüencial, e a segunda é por inferência 

direta da distribuição através do uso das indicatrizes correspondendo à simulação indicatriz 

seqüencial. 

No algoritmo de simulação gaussiana seqüencial, cada variável é simulada 

seqüencialmente de acordo com a sua ccdf gaussiana completamente caracterizada através de 

um sistema de krigagem. Em cada etapa, os dados condicionantes são todos os dados originais 

mais todos os valores previamente simulados que se encontram dentro da vizinhança da 

posição a ser simulada. 

O algoritmo da Simulação Gaussiana Seqüencial consiste das seguintes etapas: 

I. Determinar a cdf univariada F z representativa da área inteira sob estudo e não 

apenas dos dados amostrais disponíveis. A remoção dos agrupamentos 

(declustering) é necessária se os dados estão preferencialmente localizados; 

2. Fazer a transformação gaussiana da cdfunivariada de Fz; 

3. Calcular um modelo de semivariograrna dos dados condicionantes transformados; 

4. Definir um caminho aleatório, não necessariamente regular, que visita uma vez 

todos os nós do grid; 

5. Em cada nó x, reter um determinado número de dados condicionantes vizinhos 

incluindo os dados originais transformados e os previamente simulados; 

6. Usar um tipo de krigagem com o variograma dos dados transformados para obter a 

estimativa e a variância de krigagem. Construir a ccdf gaussiana da FA Y(x) em 

cada posição x; 

7. Sortear aleatoriamente um valor de y( x) desta ccdf; 

8. Adicionar o valor simulado ao conjunto de dados; 

9. Voltar ao passo 5 até todos os nós serem simulados; 

63 



lO. Transformar os valores simulados gaussianos para a ordem de grandeza da variável 

original. 

A transformação gaussiana dos dados originais define um nova variável Y que é, por 

construção, univariada normalmente distribuída. Contudo, todos métodos gaussianos requerem 

que esta nova variável também seja multivariada normalmente distribuída. 

O algoritmo de simulação gaussiana seqüencial cnmo foi descrito, requer a solução de 

sistemas de krigagem cada vez maiores para o cálculo das probabilidades à medida que o 

algoritmo progride, pois aumenta o número de dados cnndicionantes. Para cnntornar este 

problema se adota vizinhança móvel, em vez de vizinhança única para os cálculos das ccdfs. 

A vizinhança deveria ser tão grande quanto o alcance para possibilitar a reprodução 

dos variogramas. Às vezes, o uso de vizinhança muito grandes toma-se impraticável. Quando é 

importante a reprodução de amplitudes práticas muito grandes em relação ao espaçamento do 

grid, deve-se utilizar a alternativa da abordagem multigrid (Tran, 1993). 

A decomposição da função de densidade de probabilidade (pdt) multivariada em 

produto de pdfs univariadas é independente do ordenamento das n variáveis aleatórias. 

Contudo, cnmo a adoção da vizinhança móvel se faz necessária para reduzir o tempo de 

cálculo das ccdfs, uma seqüência que visite nós adjacentes deve ser evitada. Por exemplo, tem-

se a estratégia de busca em espiral que é um algoritmo eficiente quando os dados estão ou são 

reposicionados em um grid regular. A idéia é simular os nós em uma seqüência que sempre 

privilegie o nó mais distante do anteriormente simulado e que ainda não tenha sido simulado. 

Geralmente, o número de nós a ser simulado excede em muito o número de dados 

cnndicionantes e, cnnsequentemente, os dados originais terão sua influência reduzida à medida 

que o algoritmo progride. Os softwares comerciais, como por exemplo o ISATIS, fornece a 

opção do usuário limitar o número máximo de nós previamente simulados, mesmo que estejam 

na área da vizinhança, a serem usados nos sistemas de krigagem da simulação. 

As maiores vantagens da simulação seqüencial gaussiana são: fácil condicionamento, 

anisotropias manuseadas automaticamente, aplicável para qualquer função covariãncia. 

A aparente desvantagem do método é a utilização da distribuição gaussiana 

intermediária. Vários trabalhos reportam que as simulações gaussianas resultam em pequena 

cnntinuidade dos valores extremos. Se este comportamento for crucial para a confiabilidade da 

simulação, alguns autores, como por exemplo Journel e Deutsch (1993), não recomendam a 

utilização das técnicas gaussianas. 

64 



Na utilização das diferentes implementações da simulação seqüencial gaussiana, 

vários parâmetros devem ser especificados pelo usuário, tais como, krigagem simples versus 

krigagem ordinária, máximo número de nós simulados mantidos para a krigagem, parâmetros 

de vizinhança, estratégia de busca e, em particular, limites superior e inferior da escolha de 

extrapolação a serem usados na transformação gaussiana. A escolha dos diferentes 

parâmetros podem afetar a eficiência do algoritmo, a natureza das realizações, e o resultado 

da distribuição de incertezas. Por exemplo, a rigor, a reprodução dos histogramas e dos 

semivariogramas do modelo só podem ser alcançadas através da utilização da KS no sistema 

de krigagem da simulação seqüencial gaussiana. Os softwares comerciais, às vezes, só 

flexibilizam a escolha de alguns desses parâmetros. 

5.2.1 Cossimulação Seqüencial Gaussiana 

Na geoengenharia de reservatórios, as variáveis apresentam muitas vezes correlações 

e devem ser simuladas em conjunto. Verly (1993) e Gómez-Hemández e Joumel (1993) 

propuseram uma extensão á SGS, denominada cossimulação gaussiana seqüencial, como 

forma de simular diversas variáveis contínuas. Ela reproduz as distribuições e os variogramas 

diretos e cruzados das variáveis. O único problema adicional é a inferência e modelagem da 

matriz de covariâncias cruzadas. A metodologia assume que as variáveis são estacionárias de 

segunda ordem com covariâncias cruzadas também estacionárias e apresentam distribuição 

multivariada gaussiana, se necessário após a transformação gaussiana. 

O algoritmo de simulação pode ser facilmente generalizado para manusear múltiplas 

variáveis, representando vários atributos sobre um grande número de posições. Considere a 

distribuição conjunta de um total de n variáveis aleatórias. As n variáveis aleatórias incluem K 

diferentes atributos em n' nós de um grid, com n = Kn'. A notação genérica Z;, com 

i E [I, ... , n] é usada para indicar variável aleatória qualquer que seja sua posição ou tipo de 

atributo. A específica notação Z;k com j E[l, ... ,n']e k E[l, ... ,K]representa uma variável 

aleatória em uma posição j e um correspondente atributo K. 

Considere o condicionamento das n variáveis aleatórias por um conjunto no de dados 

de qualquer tipo. A correspondente pdf n-variada condicional pode ser decomposta usando o 

axioma da probabilidade condicional em um produto de n pdfs condicionais univariadas: 

f((z" ... ,z.)l(n 0 ))) = f((z.)!(n-l)u(n 0 )) f((z._ 1)l(n-2)u(n 0 )) ... 

. .. f((z 2 )l(z,) u (n 0 )) f(z 1 !(n0 )) 

65 



onde, por exemplo, f(z 2 iz, u (n 0 )) representa a pdf condicional de z2 dado a realização z, e 

um dado conjunto de no valores de dados originais. 

Esta decomposição permite obter realizações de n variáveis aleatórias Z, 

condicionadas a no dados originais. O algoritmo é independente da ordem usada para visitar as 

n variáveis aleatórias. O único pré-requisito para sua implementação é o cálculo da ccdf em 

cada passo, fornecidos os dados originais e os dados previamente simulados. As expressões 

requeridas para as ccdfs condicionais podem ser obtidas por cokrigagem no caso de simulação 

conjunta de V As com distribuições multivariadas gaussianas. 

As principais desvantagens da metodologia de cossimulação gaussiana seqüencial são: 

requer inferência das covariâncias diretas e cruzadas e, às vezes, instabilidade dos sistemas de 

cokrigagem. 

Almeida e Joumel (1994) apresentaram uma metodologia que permite a cossimulação 

direta de várias F As interdependentes, sem a inferência e modelagem da matriz completa de 

covariância cruzada, a partir de uma alteração da cossimulação seqüencial gaussiana. A 

abordagem se baseia em duas idéias chaves: a aproximação da cokrigagem collocated para 

reduzir o tamanho do sistema de cokrigagem; modelo de corregionalização tipo Markov para 

modelagem das covariâncias cruzadas. Com a cokrigagem collocated, as ccdfs são obtidas 

seguindo o princípio da simulação seqüencial. O algoritmo considera a correlação espacial 

entre diferentes variáveis retendo para simulação de qualquer variável primária, o valor 

collocated de todas as demais variáveis previamente simuladas. Deve-se definir uma hierarquia 

de simulação das variáveis primárias indo da mais importante para a menos importante. 

5.3 Simulação Indicatriz Seqüencial 

O algoritmo da simulação indicatriz seqüencial, como o próprio nome sugere, segue 

também a abordagem seqüencial, só que nenhuma hipótese é feita sobre a forma da 

distribuição condicional. Estimativas da distribuição condicional em cada nó são obtidas por 

krigagem indicatriz, utilizando semivariogramas indicatrizes. 

Como visto na KI, a geração da ccdf precede a estimativa. 

F(x 0 ;z,) = [I(x 0 ; z, )]' = E[I(x 0 ; z, )i(n)]' = p•[z(x 0 ),.;; z, i(n)] 

Na prática, em cada nó x, K sistemas de krigagens indicatrizes devem ser resolvidos 

para gerar um versão discretizada da ccdf P[Z(x) s zk l(n)], k 0 = 1, ... , K. Semelhante ao 
' 

algoritmo da SGS, na SIS também se faz necessário a utilização de algoritmos eficientes 

66 



baseados na vizinhança móvel para evitar problemas associados com o aumento do número de 

dados condicionantes. 

Em cada nó, a ccdf obtida via KI pode apresentar os problemas de relação de ordem: 

ccdfs maiores do que um e menores do que zero, ou não monotônicas. São feitas correções 

nestes problemas, porém nenhuma pesquisa foi ainda realizada no sentido de verificar quais 

efeitos estas correções podem ter nas realizações. 

Modelos de F As indicatrizes são adequados para simulação de variáveis categóricas 

(ou contínuas discretizadas) controladas por estatísticas de dois pontos (covariância). A 

questão fundamental é saber se a estatística de dois pontos é suficiente para caracterizar a 

geometria da distribuição das classes ou categorias. Se a resposta for não, deve-se optar por 

algoritmos que levem em consideração estatísticas de maior ordem como simulated annealing, 

por exemplo. 

As principais vantagens da SIS são: fácil condicionamento; não assurrur, a pnon, 

nenhum modelo de F A; flexibilidade de pennitir diferentes modelos de continuidade espacial 

para cada parâmetro de corte; pennite considerar informações sojt. 

As maiores desvantagens são: ocorrência eventual de viés nas freqüências geradas 

com a simulação; impossibilidade de reproduzir os modelos de variograma de uma variável 

original contínua; geometrias bem definidas não podem ser reproduzidas; parametrização e 

inferências são pesadas, principalmente quando muitas indicatrizes estão sendo modeladas; 

toma-se computacionalmente lenta quando a correlação cruzada entre as indicatrizes é 

introduzida. 

Na simulação indicatriz seqüencial, o uso da KI implica em desconsiderar a 

covariância cruzada entre as indicatrizes. Porém, as indicatrizes não são independentes. Por 

exemplo se Z(x) 2: z •. , então Z(x):::: zk para todo k &amp;lt;k'. Esta dependência entre 

I(x,zk.) e I(x,zk) se mantém entre pontos vizinhos 'x' e 'x+h', pois Z(x + h)tem pouca 

probabilidade de ser maior que zk. se Z( x) &amp;lt;zk . O adequado seria utilizar a cokrigagem 

indicatriz, mas isso exige a inferência e modelagem das covariâncias cruzadas entre as 

indicatrizes. 

Outras abordagens seqüenciais indicatrizes se encontram reportadas na literatura onde 

se varia o tipo de krigagem indicatriz a ser usada na detenninação das ccdfs. Assim, muitos 

outros algoritmos de simulação de indicatrizes que usam o princípio seqüencial, não o 

incluem em seu nome, por exemplo a Simulação de Markov-Bayes (Zhu e Joumel, 1993) e a 

67 



Simulação dos componentes principais indicatrizes (Suro-Pérez e Journel, 1990) que utilizam a 

krigagem sojt com modelo de Markov-Bayes e a lPCK respectivamente. 

5. 4 Simulação Gaussiana Truncada 

Journel e Isaaks (1984, apud Deutsch e Journel, 1996) apresentaram urna 

metodologia de simulação indicatriz baseada no truncamento do modelo gaussiano por um 

único cutojj gerando assim a distribuição de duas fácies complementares. 

No software Heresim© (heterogeneous reservoir simulation) desenvolvido pelo 

Instituto Francês do Pétróleo e pelo Centro de Geoestatística de Fontaineableau, a idéia prévia 

de um único truncamento foi ampliada para múltiplos truncamentos do mesmo campo 

gaussiano, com curvas de cutojjs que variam no espaço (Matheron et al., 1987). 

A idéia básica da metodologia proposta por Matheron et al. (1987) é descrever n 

fácies usando uma função indicatriz para cada fácies. A indicatriz para a fácies F, , definida 

por meio de uma FA gaussiana Y(x), é: 

{
1 se Y(x) E]y,_,,y;] 

I (x) = 
Fi O senão 

Portanto um ponto x pertence a fácies F, se Y(x) E]y,_,y;]. Os y, são denominados 

cutoffs gaussianos. A probabilidade para a FA gaussiana Y(x) ser menor que y, e maior que 

y,_, é P(y,_, ~ Y(x) &amp;lt;y;) = G(y;) G(y,_,), onde G é a distribuição acumulada gaussiana. Se 

Y(x) está entre estes dois valores, por definição o ponto x pertence à fácies F,. A 

probabilidade P(y,_, ~ Y(x) &amp;lt;y;) representa a proporção global de fácies F, no campo. 

Observa-se que no caso contínuo, somente fácies F,_, e F,+, podem ser contíguas à fácies F, . 

Assim, a idéia de gerar classes, interpretadas como fácies geológicas é muito simples, 

sendo realizada por truncamento de uma curva contínua ou superficie. 

Os niveis variáveis dos cutoffs permitem um controle direto na proporção de cada 

fácies gerada. O problema está em como controlar as estatísticas espaciais de ordem mais 

elevada das fácies geradas, por exemplo a probabilidade de transição de fácies k para fácies k' 

em função da separação h. 

A simulação é obtida por uma variável truncada gaussiana como descrita nas 

seguintes etapas: 

( 1) Calcular a proporção de pi em cada categoria Fi dos dados e então determinar os 

cutojjs gaussianos y i . 

68 



y1=G-1(p1) 

Y2 = G-
1
(P1 +P2) 

YN-1 = G-
1
(P1 +p,+ ... +pN-1) 

(2) Obter as covariâncias cruzadas e diretas das indicatrizes (fácies). 

(3) Determinar a covariância Cy (h) da variável gaussiana usando a relação: 

1 
Yi Yj u2 +v 2-2uvCy(h) 

C (x x +h) =-r=====:= I I e-&amp;lt;2&lt;1-(Cy(hll'l l dudv 
F;FJ , 21t 11- (C (h)) 2 . . 

"\j Y Y,-1 YJ-l 

(5.4.2) 

onde CFF(x,x+h) é a covariância cruzada entre as fácies F; 
'J 

corresponde à probabilidade de ocorrer fácies F; na posição x e F; na posição 

(x+h). 

( 4) Nas posições dos dados, gerar valores de uma variável gaussiana com a 

covariância Cy (h) de forma que y i s: y( x~) &amp;lt;y í+1, onde j é o índice 

correspondente à fácies FJ. 

(5) Simular uma variável gaussiana com covariância Cy (h) e condicionar os valores 

simulados, em uma maneira usual, com os dados transformados na etapa 4. 

(6) Transformar cada valor gaussianamente simulado y "(x) para a sua categoria 

indicatriz condicionalmente simulada por: 

1 (x) = {1 se y 1•1&amp;lt;y :,(x) s:y, 
F, O senao 

A determinação de Cy(h) é o principal aspecto computacional deste algoritmo. São 

calculadas todas as covariâncias diretas e cruzadas das diferentes fácies s. A covariância 

teórica da F A gaussiana é aceita se, e somente se, o ajuste resultante for satisfatório para as 

covariâncias diretas e cruzadas experimentais das fácies s. A equação 5.4.2 mostra que todas 

as covariâncias indicatrizes estão embutidas na covariância da gaussiana, o que leva a perda do 

controle espacial das fácies s. 

Apesar desta falta de controle na estatística espacial de cada fácies específica, a idéia 

do truncamento apresenta as seguintes caracteristicas positivas: velocidade, pois a simulação 

de n fácies no espaço é reduzida para a simulação de uma única gaussiana; sequenciamento de 

fácies s, importante principalmente em reservatórios flúvio-deltaicos; informações prévias 

sobre probabilidade da fácies F, prevalecer em um determinada posição x, também chamadas 

curvas de proporções p, = P[x E fácies F;], podem ser transformadas em cutoffs locais 

69 



y;(x), permitindo a utilização de dados soft e também a intervenção do geólogo com sua 

experiência na área; fácil condicionamento. 

Uma característica interessante da definição de indicatrizes por truncamento é sua 

flexibilidade em lidar com não estacionariedades. Beucher et ai. (1993) demonstraram a 

utilização do algoritmo de simulação truncado gaussiano com proporções não estacionárias 

tanto na vertical quanto na horizontal. Eles demonstraram como realizar a análise estrutural, 

que é possível porque a gaussiana é ainda estacionária, mesmo se as distribuições de fácies 

apresentarem fortes não estacionariedades. 

5.4.1 Simulação Plurigaussiana Truncada 

Extensões para o truncado gaussiano foram desenvolvidas no sentido de transpor as 

limitações relativas a pouca flexibilidade nas transições entre fácies, e a impossibilidade de 

simular fácies com diferentes anisotropias. 

A metodologia consiste em definir fácies por truncamento de duas ou mais funções 

aleatórias gaussianas que podem ser correlacionadas ou não. Esta extensão preserva o rigor e a 

capacidade de usar informações externas através de proporções. As propriedades e os 

exemplos fornecidos por Galli et al.(1994) demonstram o potencial deste método e sua 

habilidade em produzir realísticas imagens geológicas. 

O modelo de F A plurigaussiana truncada é definida baseando-se: 

• no número de funções gaussianas N(O, 1 ); 

• nas matrizes de covariâncias diretas e cruzadas, que completamente definem o 

modelo de funções gaussianas; 

• na maneira de transformar um conjunto de funções gaussianas em uma única 

função discreta de fácies s. É caracterizada pela partição do plano definida pela 

funções aleatórias gaussianas. Uma fácies é atribuída a cada conjunto desta 

partição, cuja forma pode ser tão complexa quanto se queira; 

Na determinação dos cutoffs, a partir dos dados de proporção de cada fácies, tem-se 

que estudar cuidadosamente com os geólogos as relações espaciais entre as mesmas, isto é, a 

probabilidade de contato direto, o ordenamento, etc. Isto assegurará uma adequada partição 

do espaço definido pelas funções gaussianas. 

As funções gaussianas podem ser correlacionadas ou não. A escolha do coeficiente de 

correlação entre as F As gaussianas afeta os cálculos dos cutoffs gaussianos e dos variogramas. 

70 



Um alto coeficiente introduzirá um ordenamento entre as fácies, enquanto contatos serão mais 

severos e desordenados quando o coeficiente de correlação é pequeno. 

Devem ser calculados os variogramas diretos e cruzados de cada indicatriz de fácies s, 

conhecendo os coeficientes de correlação, os cutoffs, e os modelos de variogramas da F As 

gaussianas. O ajuste consiste em comparar estes variograrnas com os variograma experimentais 

diretos e cruzados das fácies. Semelhante ao truncado gaussiano, a idéia é iterativamente 

modificar os parâmetros, obtendo um ajuste satisfatório aos variogramas experimentais. 

Porém, com o método plurigaussiano, tem-se mais liberdade no ajuste, pois se dispõe de mais 

parâmetros. Por exemplo, a anisotropia pode diferir entre as duas F As gaussianas, e até mesmo 

pode-se alterar o coeficiente de correlação entre as F As reconstruindo o modelo desde o 

inicio. 

5.5 Simulação Campo de Probabilidade 

Simulação campo de probabilidade (p:field) foi introduzida por Srivastava (1992) e 

Froideveaux (1993). Recentemente tem se observado uma retomada da utilização desta 

abordagem em conjunto com a krigagem fatorial para a simulação de atributos, usando 

informações obtidas de levantamentos sísmicos. A estimativa das ccdfs locais é separada da 

amostragem destas distribuições. Assim, a abordagem p:field oferece um método de simulação 

estocástica que é fácil de entender. É um algoritmo simples que pode pós processar os 

resultados dos procedimentos de estimativa ou de outras simulações estocásticas para produzir 

realizações prováveis. 

Resumidamente, a implementação da simulação p:field envolve as seguintes etapas: 

1. Definir um grid cobrindo a área de interesse; 

2. Obter para cada nó do grid, a ccdflocal F(x,z) do atributo a ser simulado. As ccdfs 

podem ser resultado de um processo de simulação estocástica ou de krigagem, ou 

definidas empiricamente; 

3. Calcular o modelo de variograma da transformada uniforme do atributo a ser 

simulado. Assumir que a covariância de U(Z(x)) e do campo de probabilidades 

P(x) são similares: c. (h)"' c. (h); 
4. Assumir que o campo de probabilidade P(x) segue uma distribuição uniforme; 

S. Gerar, em cada nó do grid, uma simulação estocástica não condicional de P(x) 

honrando a distribuição uniforme prévia e a função covariância C • (h) ; 

71 



6. Em cada nó do grid, obter uma realização zs (x) da ccdf local usando o valor do 

campo de probabilidade p(x): Z
5
(x) = F-1[x,p(x)]. (Figura 5-2); 

7. Repetir os passos 5 e 6 para cada imagem a ser gerada. 

Uma etapa crucial na simulação do campo de probabilidade (p-field) é estabelecer as 

distribuições de probabilidades condicionais em cada posição em que um valor simulado é 

requerido. As distribuições de probabilidades condicionais locais são simplesmente as possíveis 

realizações com suas respectivas probabilidades. 

Dados Originais 
· 1 -Geração das ccdfs 

ão do Cantpo de Probabilidad.es 
ão Não Condicional 

Transformação· · 

Campo Gaussiano [-5,5] 
Uniforme 

I 
I 
I 

~~~ 
: zl z 

Campo Unifonne (0,1) 

Figura 5-2: Simulação camt&gt;o de probabilidade. 

Simulação Estocástica 
P-field 

Embora a simulação campo de probabilidade não controle como as ccdfs são 

construídas, a relevância dos resultados depende da relevância das mesmas. Um outro ponto 

crítico é a correta inferência das características univariadas e bivariadas da distribuição de P(x), 

isto é, a forma da distribuição de probabilidade e suas características de continuidade espacial. 

Assim, a direção de máxima continuidade, alcance, razão de anisotropia e efeito pepita 

relativo, são similares para a transformada uniforme do atributo Z(x) e para seu campo de 

probabilidade P(x). A prática comum é gerar um campo de probabilidade que tem uma 

distribuição global uniforme entre O e 1 e com suas autocorrelações se ajustando à 

transformada uniforme das variáveis a serem simuladas. 

As ccdfs locais colapsam em uma distribuição de largura zero para as posições das 

amostras; qualquer percentil retido da distribuição honrará necessariamente o valor original da 

amostra. 

72 



Posto que a F A da qual os valores de probabilidade devem ser retirados é certamente 

uniforme em cada posição, a distribuição dos valores de probabilidade dentro de um campo 

finito pode não ser uniforme. Froidevaux (1993) mostrou que a distribuição observada dos 

valores do campo de probabilidade depende do tamanho do campo que está sendo simulado 

em relação ao alcance. Para campos muito maiores que o integral range, a distribuição p(x) 

dentro do campo será muito mais próxima da distribuição uniforme. À medida que o integral 

range toma-se semelhante ao tamanho do campo, a distribuição dos valores de probabilidade 

se tomam menos uniformes. 

A criação de um campo de probabilidade pode ser realizada de várias maneiras. O 

método mais comum é gerar uma simulação gaussiana não condicional com uma função de 

correlação igual a dos dados originais condicionantes. Só que não se completa a simulação 

fazendo a transformação de volta para o campo da variável simulada, mas realiza-se uma 

transformação dos valores simulados normalmente distribuídos N(O, 1) para valores uniformes, 

por exemplo, usando aproximações polinomiais para a função de distribuição gaussiana 

acumulada disponíveis na literatura. 

Segundo Srivastava (1992), umas das possibilidades para futuras investigações é a 

possibilidade de gerar diretamente realizações de um campo multivariado uniforme em vez de 

utilizar um campo intermediário gaussiano. 

Uma das principais vantagens da abordagem p-field para a simulação é sua velocidade 

computacional. O gargalo do tempo computacional está no cálculo das ccdfs locais. Pode-se 

escolher um algoritmo tão rápido quanto se queira para gerá-las. 

Uma vez calculadas e armazenadas as ccdfs, diferentes realizações podem ser criadas 

tão rapidamente quanto se cria um campo de probabilidade. Uma outra vantagem da 

abordagem é que ela separa o problema de estimar ccdfs locais do problema de criar uma 

simulação condicional. 

A técnica pode ser aplicada para qualquer conjunto de ccdfs locais, não importando 

como foram obtidas, podendo ser inclusive de métodos não geoestatísticos. Srivastava (1992) 

fornece um exemplo em que as distribuições são obtidas a partir da interpretação sísmica, 

produzindo vários mapas do topo de um reservatório. Esta flexibilidade é uma das principais 

vantagens práticas da abordagem p-field. Consequentemente, a simulação p-field permite uma 

fácil integração de dados hard muito esparsos com exaustivas informações soft. 

Devido a forma como o campo de probabilidade interage com a ccdf local, verifica-se 

que os dados condicionantes formam extremos locais. A razão para este artefato é devido ao 

73 



fato de que um dado condicionante será muito próximo da mediana da ccdf de seus vizinhos 

imediatos. O método da simulação p-field também se aplica a variáveis categóricas. Na 

verdade, ele trabalha melhor com variáveis categóricas, pois o artefato descrito não faz sentido 

nesta situação. 

Embora falte à simulação p-field uma base teórica claramente articulada, vários 

estudos de caso documentam seu sucesso prático. Entretanto, é fundamental um 

aprofundamento teórico do método para verificar sobre quais condições ele não trabalha 

adequadamente. De qualquer forma, o usuário deve checar se a realização honra a distribuição 

e o padrão de continuidade espacial. 

5. 6 Simulated Annealing 

Na abordagem annealing para simulação estocástica, a criação de realizações é 

formulada como um problema de otimização a ser resolvido com relaxação estocástica ou 

técnica annealing. A técnica tem o potencial de combinar a reprodução da estatística de dois 

pontos com estatísticas multipontos implícitas, por exemplo, em formas geométricas. A técnica 

de otimização mais freqüentemente usada para obter tais realizações é baseada no processo 

fisico de annealing (recozimento). 

A idéia básica do simulated annealing (SA) é perturbar continuamente uma imagem 

inicial até que ela se ajuste a algumas características preestabelecidas, escritas como 

componentes de uma função objetivo (FO). 

A função objetivo (ou energia) é uma medida da diferença entre as características 

espaciais desejadas e as da realização candidata. A característica básica dos métodos de 

relaxação estocástica é iterativamente perturbar (relaxar) a realízação candidata e então aceitar 

ou rejeitar a perturbação segundo alguma regra de decisão. A regra de decisão é baseada em 

quanto a perturbação traz a imagem candidata para mais próximo das propriedades desejadas. 

O real interesse do simulated annealing está na sua habilidade de melhor incorporar 

complexas estruturas geológicas e dados de engenharia. 

As simulações estocásticas convencionais estão limitadas a estatística de dois pontos. 

Simulated annealing não tem esta limitação: a função objetivo pode ser definida com 

componentes relativos a propriedades geológicas, estatísticas ou de engenharia. 

Em geral a função objetivo (FO) é uma soma ponderada de C componentes: 

74 



onde w, e O, são os pesos e os componentes da função objetivo, respectivamente. Um 

componente pode ser, por exemplo, a medida da diferença entre um variograma modelado a 

partir dos dados experimentais e um outro obtido a partir da realização. Um segundo 

componente pode ser urna medida de reprodução de urna particular estatística rnultiponto. Um 

terceiro componente poderia medir a fidelidade em relação a urna propriedade equivalente 

derivada de testes em poços, envolvendo muitos valores simulados simultaneamente. 

Os pesos são estabelecidos de forma que, em média, cada componente contribua 

igualmente para a mudança na função objetivo ou da forma que o usuário desejar. Por 

exemplo, pode-se usar pesos diferentes, quando se deseja que urna realização obedeça mais a 

um dos componentes. 

A taxa de decrescimento de cada componente não é considerada pelos pesos. Um 

componente pode rapidamente ir para zero, enquanto outro ainda está muito longe. 

Consequentemente, os pesos precisam ser reavaliados periodicamente durante a simulação. 

Muitas variações do mesmo algoritmo básico são possíveis, considerando funções 

objetivo, caminhos para criar a imagem inicial, mecanismos de perturbação e regras de decisão 

diferentes. 

As técnicas annealing baseiam em muitas, freqüentemente milhões de perturbações 

para atingir urna realização aceitável. Isto implica que cada componente da função objetivo 

(FO) deva ser razoavelmente simples e que a FO não tenha muitos componentes, nem 

componentes conflitantes. 

Vários são os mecanismos de perturbação no simulated annealing. Por exemplo, 

pode-se optar por trocar os valores de dois nós escolhidos aleatoriamente, modificar o valor de 

um nó de acordo com urna função de distribuição de probabilidade local, etc. 

A perturbação é aceita ou rejeitada, baseando-se em urna regra de decisão. Uma 

possibilidade é rejeitar todas as perturbações que levem a um aumento na função objetivo. Isto 

corresponde a abordagem steepest descent. 

Considerando o algoritmo de Metropolis, se a FO após a perturbação é maior que a 

FO anterior, ela será aceita ·ou rejeitada de acordo com a probabilidade 

P(M'O)=exp((FO.,. -FO,pó.)/T), onde T é análogo à temperatura do processo real do 

annealing e tem a mesma unidade da fimção objetivo. Computacionalmente este passo consiste 

em gerar um número aleatório z no intervalo [0, 1]. Se z &amp;lt;exp((FO ,., - FO ,pó.) I T), então a 

perturbação é aceita; do contrário é rejeitada. 

75 



Com temperatura alta constante, o erro total permanece grande, pms muitas 

perturbações serão aceitas. Por outro lado, temperatura baixa constante leva a solução ser 

'congelada' em um mínimo local. Disto resulta que se faz necessário uma adequada 

programação de 'resfriamento'. O sucesso do método depende de um lento 'resfriamento' das 

realizações controlado pela temperatura que deve decrescer com o tempo. Ressalta-se, porém, 

que se a temperatura for reduzida muito lentamente, a convergência para uma imagem ótima 

pode ser bastante lenta. Tem assim que ser definida a programação (schedule) do annealing 

que corresponde quando e quanto reduzir a temperatura. Deutsch e Joumel (1992) usaram 

uma programação de annealing empírica, cuja idéia básica é começar com uma temperatura 

elevada e reduzi-la, multiplicando por um fator de redução À. (0&lt;Ã.&lt;1), quando muitas 

perturbações tiverem sido aceitas, ou muitas tiverem sido tentadas. O algoritmo é interrompido 

quando mais esforços para reduzir a função objetivo ficarem desencorajadores ou já se atingíu 

um valor aceitável para a função objetivo. 

Simulated annealing apresenta artefatos conhecidos como efeitos de borda que 

ocorrem principalmente quando se utiliza uma programação rápida de 'resfriamento' ou 

quando a distribuição univariada é assimétrica. Os valores extremos tendem a se concentrar 

nas bordas, porque assim participam de menos pares quando da atualização dos componentes 

da função objetivo. 

Uma simples maneira de fazer com uma realização com a SA honre as informações 

locais hard é nunca perturbá-las. Esta solução, entretanto, introduz descontinuidades próximas 

aos dados condicionantes. Isto ocorre porque os dados condicionantes passam a não contribuir 

igualmente para a função objetivo global desde que eles não têm chance de serem perturbados. 

Uma correção proposta por Deutsch e Cockerham (1994) corresponde basicamente em dar 

maior peso aos pares que tem pelo menos um dado condicionante. 

A principal vantagem da SA é que ela pode incorporar na função objetivo qualquer 

tipo de informação que estiver disponível sobre o reservatório. 

Uma das principais desvantagens é o fato de ser uma metodologia ainda relativamente 

nova para a área de petróleo. Há pouca literatura que forneça detalhes de como preparar uma 

função objetivo adequada e principalmente fazer a programação (schedule) do annealing. Uma 

outra desvantagem é que o algoritmo toma-se cada vez mais lento, à medida que aumenta a 

complexidade da função objetivo. 

76 



A grande desvantagem teórica da SA é a falta de um arcabouço matemático 

consistente. O algoritmo básico é um procedimento de otimização e isto leva a muitos 

questionamentos sobre o espaço de incerteza que está sendo explorado. 

5. 7 Simulações Baseadas em Objetos 

As técnicas baseadas em objetos modelam a distribuição de objetos geológicos com 

geometria bem definida, tais como canais fluviais ou turbidíticos, frente deltaica, barras de 

desembocadura, lóbulos arenosos ou falhas. Os objetos são geralmente descritos com formas 

muito simples, tais como blocos retangulares ou elipsóides. A variabilidade geológica é 

modelada através da distribuição das formas, tamanhos e orientações dos objetos, cujas 

posições são aleatórias dentro do reservatório. 

A idéia básica é que o modelo de reservatório deve ser criado a partir de objetos que 

têm algum significado genético. É selecionada para cada litofácie, a forma básica que 

adequadamente descreve sua geometria. Por exemplo, as areias de um canal em um sistema 

turbidítico parecem meias elipses, ou as de leques deltaicos parecem cunhas triangulares. 

Atributos da forma (comprimento, largura, altura, orientação) são caracterizados por 

distribuições que podem ser independentes ou correlacionadas. Estes atributos podem ser 

dependentes da posição para levar em consideração tendências geológicas conhecidas. A 

posição da distribuição é, em muitos casos, puramente aleatória: posições dos centróides são 

independentes umas das outras, e a densidade do objeto (média de objetos por unidade de 

volume) é constante. Nestes casos, as posições dos centróides são ditas seguir um processo 

pontual de Poisson estacionário e o modelo estocástico resultante é o modelo booleano. 

Haldorsen e MacDonald (1987) publicaram um dos primeiros trabalhos com este tipo 

de abordagem de simulação estocástica, no qual eles modelaram a distribuição de corpos de 

areia em um reservatório de ambiente fluvial. Esses autores consideraram os canrus como 

barras retangulares dispersas em uma matriz argilosa. 

O modelo booleano também pode ser não estacionário para considerar as variações da 

densidade de objetos no reservatório. Modelagem de objetos é melhorada levando em conta a 

interação entre as posições dos objetos: fatores de repulsão ou atração são introduzidos no 

modelo probabilístico da posição dos centróides. Tais modelos permitem gerar vários canais 

dentro de um cinturão de canais, ou associações espaciais de diferentes tipos de objetos 

geológicos, por exemplo, associações canais-crevasses. Assim, alguns algoritmos sofisticados 

permitem escolher as regras que descrevem como as várias formas são posicionadas 

77 



relativamente umas às outras; estas regras podem exigir que determinada forma não possa 

ocorrer dentro de urna distância mínima de outras formas, ou que certas formas devam sempre 

estar justapostas. 

Numerosas melhorias tem sido propostas desde Haldorsen e MacDonald (1987) 

focalizando principalmente os seguintes aspectos: a interação dos objetos, a sinuosidade dos 

objetos em terceira dimensão, condicionamento aos dados dos poços. 

Escolhidos os parâmetros da distribuição e as regras de posicionamento, o seguinte 

algoritmo simplificado captura as etapas essenciais no procedimento de modelagem estocástica 

baseada em objetos: 

1. Preencher o modelo de reservatório com alguma litofácie de fundo (por exemplo, 

folhelho; 

2. Aleatoriamente escolher uma posição no modelo de reservatório; 

3. Aleatoriamente escolher uma das formas de litofácies e selecionar das distribuições 

desta forma, um tamanho apropriado e orientação; 

4. Checar se há conflito entre a forma escolhida e algum dado condicionante ou com 

outras formas que foram previamente simuladas. Se não houver conflito, aceitar a 

forma. Caso contrário, rejeitá-la e voltar ao passo 3; 

5. Checar se todas as proporções globais das várias formas foram alcançadas; se não 

voltar ao passo 2. 

Os dados de poços devem ser honrados primeiro. Quando a região entre poços é 

simulada, deve-se tomar cuidado para evitar conflitos com a seqüência conhecida de litologias 

nos poços. As muitas implementações desta abordagem diferem bastante em como assegurar 

que as regras de posicionamento relativo são honradas. Alguns algoritmos simplesmente 

rejeitam o objeto quando ele não se ajusta ás regras, outros tentam ser mais eficientes e 

checam se pequenas alterações no reposicionamento ou no tamanho do mesmo, permítem que 

as regras de posicionamento sejam obedecidas. 

Os métodos baseados em objetos são fáceis de entender, estão mais próximos do 

'sentimento' geológico, isto é, apresentam um maior apelo visual do que as técnicas baseadas 

empixel. 

As técnicas baseadas em objetos apresentam algumas desvantagens. A limítação mais 

critica é relativa ao condicionamento aos dados de poços que é muitas vezes manuseado 

inadequadamente. Isto resulta em sérios problemas de implementação, particularmente quando 

o espaçamento dos poços é menor do que a dimensão dos objetos e vários poços podem 

78 



interceptar o mesmo objeto. As formas dos objetos são, às vezes, irrealisticamente simples. 

Inferência dos parâmetros requeridos é impossível a partir de dados de poços geralmente 

esparsos. Usuàrios devem então confiar no altamente incerto e, às vezes, enviesado conjunto 

de dados de afloramento, supostamente de formação similar. Regras de erosão entre objetos 

necessitam ser especificadas podendo implicar em problemas na implementação. Por último, 

modelos com interações requerem algoritmos iterativos que podem convergir muito 

lentamente quando o domínio for grande com elevado número de poços. 

No último Congresso de Geoestatística (Wollongong'96), alguns trabalhos de grupos 

de pesquisadores noruegueses, como por exemplo Jolmsen et al. (1997), reportaram a 

utilização da sísmica na simulação estocástica baseada em objetos. Porém, nenhuma referência 

foi encontrada na literatura a respeito da utilização de dados dinâmicos, isto é, dados de 

produção, testes de formação, etc. Por exemplo, se dois intervalos em um mesmo poço ou em 

poços diferentes, reconhecidamente não pertencentes a um mesmo canal, estão hidraulicamente 

conectados, informação obtida dos dados de testes ou de produção, o modelo booleano 

deveria de alguma forma obedecer a essa restrição e construir um caminho continuo para 

permitir a ocorrência de fluxo entre os dois intervalos, seja através da geração de objetos de 

mesmo tipo (canais justapostos), ou através de geração de objetos de tipos diferentes 

(associação canais-crevasses), mas ambos camínhos devem ser permeáveis. Mais importante 

que a geração de unidades genéticas ou corpos geológicos é que os modelos resultantes desta 

abordagem, quando submetidos á simulação de fluxo sejam representativos e coerentes. Um 

modelo que não inclui a comunicação hidráulica entre os referidos intervalos, quando se tem 

esta informação a priori, é um modelo incorreto para o reservatório. 

79 



6. Incertezas na Simulação Estocástica 

Grande parte do crescimento da popularidade das simulações estocásticas 

condicionais na indústria do petróleo é devido ao fato de que elas acrescentam um apelo de 

realismo visual ao modelo. Por vezes, esse realismo visual obscurece o entendimento dos 

engenheiros e geólogos sobre as incertezas envolvidas. 

A simulação estocástica fornece maneiras de incorporar vários tipos de incertezas na 

previsão de performance de um reservatório. Imagens estocásticas, obtidas via algum 

algoritmo de simulação geoestatística, servem como parâmetros de entrada para o simulador 

de fluxo, obtendo-se assim a previsão de comportamento do reservatório para cada uma das 

realizações. Como as realizações caracterizam a incerteza espacial do parâmetro de interesse, a 

distribuição dos resultados (previsão de performance) refletem esta incerteza. V árias são as 

respostas que podem ser analisadas em cada uma das realizações: tempo de breakthrough, 

produção acumulada de água e hidrocarbonetos, fator de recuperação, etc. 

Decisões gerenciais importantes tais como a localização de poços horizontais, 

estratégia de desenvolvimento de um campo de petróleo podem ser baseadas na distribuição de 

incerteza da performance do reservatório. 

Ressalta-se que para um mesmo algoritmo, diferentes softwares poderão levar a 

diferenças consideráveis nas imagens geradas. Para o usuário da simulação estocástica, as 

diferenças entre os diversos algoritmos e suas diferentes implementações, e os efeitos na 

incerteza da previsão de performance do reservatório necessitam ser melhor entendidos para 

que possa utilizar o algoritmo e implementação adequados à situação que estiver analisando. 

Muito pouco tem sido feito para comparar os algoritmos que estão disponíveis nos 

softwares comerciais. Cada metodologia tem seus próprios defensores que, a priori, são os 

seus criadores, e como seus idealizadores, reforçam apenas as suas vantagens. 

Neste capítulo, diversos temas referentes a incertezas na simulação estocástica serão 

abordados. A questão principal é fomentar o debate sobre incertezas na modelagem. 

Geoestatísticos e usuários da geoestatística deveriam ser extremamente criteriosos 

quando assumirem que podem quantificar incertezas, especialmente se poucos dados são 

80 



disponíveis. É imprescindível que todas as hipóteses feitas para a escolha do modelo sejam 

identificadas, uma vez que as mesmas podem estar erradas, e isto ser observável quando mais 

dados se tornarem disponíveis. Ressalta-se que a principal incerteza pode não estar na 

variabilidade entre as realizações de um modelo fixo, com parâmetros fixos, mas na validade 

do próprio modelo ou dos parâmetros deste. 

6.1 Comparação de Algoritmos 

Algumas poucas publicações comparam alguns algoritmos de simulação estocástica, 

sem contudo entrar nas diferenças de implementação a nível de software. Por exemplo, a SGS 

implementada no !SATIS e na GSLm apresentam diferentes parâmetros que podem ser 

manuseados pelo usuário. Mesmo baseando-se nos mesmos parâmetros e metodologia, 

diferenças nos softwares poderão levar a resultados diferentes. 

Journel e Deutsch (1993) compararam a SISe a SGS chegando à conclusão de que, 

em deterrnínadas situações não completamente definídas e delirnítadas, o algoritmo de 

simulação seqüencial gaussiana apresenta distribuição de incerteza não acurada, isto é, que 

não contém o valor real. Esses autores estenderam estes resultados a todos os métodos 

gaussianos. Journel e Deutsch (1993) concluíram ainda que a modelagem seqüencial indicatriz 

é imprecisa no sentido de gerar distribuições de respostas com alto grau de variabilidade, mas 

esta imprecisão perrníte acurácia no sentido de que as distribuições incluem o valor verdadeiro. 

Para Journel e Deutsch (1993) a máxima entropia do modelo de FA não implica 

necessariamente em máxima entropia da distribuição de resposta. 

Esta afirmação de Deutsch e Journel ( 1993) em relação às simulações gaussianas 

pode ser encontrada em vários outros trabalhos destes e de outros autores. Curiosamente, no 

último congresso de Geoestatística, Journel (1997) apresentou um trabalho enfocando o 

princípio da parcimônía, isto é, para um dado objetivo, deve-se utilizar o modelo com o menor 

número de parâmetros e mais fáceis de serem inferidos. Esta colocação aparentemente está 

contradizendo a posição do referido autor em relação às simulações gaussianas e em defesa da 

abordagem indicatriz. O modelo gaussiano é bastante parcimoníoso e requer apenas dois 

parâmetros fáceis de serem inferidos. Contudo, Journel ( 1997) reporta que o critério de 

modelo parcimoníoso não deve ser seguido às custas de inconsistência dos dados, fazendo uma 

referência clara aos modelos gaussianos. Como formador de opiníão, as colocações de Journel 

e outros a respeito da simulação gaussiana podem confundir o usuário de simulação 

estocástica. 

81 



Um outro interessante trabalho comparativo de alguns algoritmos de simulação foi 

realizado por Gotway e Rutheford (1994) que utilizaram diferentes conjuntos de dados de 

forma a cobrir uma diversidade de situações. Entre os vários resultados e conclusões obtidos 

por estes autores devem ser destacados: algoritmos de Bandas Rotativas e Decomposição LU 

apresentam menos agrupamentos de valores similares (clusters) do que o algoritmo de 

simulação gaussiana seqUencial; algoritmos de simulação estocástica que usam os mesmos 

parâmetros (por exemplo mesmos semivariogramas) podem resultar em distribuições de 

incerteza bastante diferentes. Gotway e Rutheford (1994) chegaram a resultados de 

distribuição de incerteza mais acurados para os métodos gaussianos se comparados com a 

simulação indicatriz, diferentemente do obtido por Journel e Deutsch (1993). 

Os trabalhos que reportam as deficiências da SGS e das simulações gausstanas 

geralmente se baseiam em distribuições que apresentam fortes correlações de valores extremos 

(por exemplo baixas e altas permeabilidades). De concreto, esta é a única limitação a utilização 

do modelo gaussiano. Estudos devem ser conduzidos no sentido de melhor delimitar as 

fronteiras de utilização do modelo gaussiano. 

6.2 Imagens equiprováveis 

Uma importante questão é a equiprobabilidade das imagens. Sabe-se que o número 

de imagens possíveis é, via de regra, exorbitante. Em trabalho recente, Srivastava ( 1997) 

aplicou diversas técnicas de simulação em um grid 5x4 com uma variável binária e uma 

determinada função de correlação. Para a situação em questão, só eram possíveis 276 imagens 

diferentes. Srivastava ( 1997) então realizou 10000 simulações com diferentes algoritmos e 

verificou que em algumas técnicas de simulação estocástica, as 276 imagens não eram 

equiprováveis. 

Admitindo-se que elas fossem equiprováveis, então em um conjunto de 10000 

realizações, cada uma tem a probabilidade de 99% de ocorrer pelo menos 18 vezes e não mais 

que 54 vezes. Os resultados listados na tabela 6-1 indicam que para algumas abordagens de 

simulação estocástica não se verifica a equiprobabilidade das realizações, como por exemplo a 

seqUencial indicatriz. 

Se faz necessário desenvolver teoria e procedimentos práticos que verifiquem a 

equiprobabilidade das realizações. Em situações reais, corre-se o risco do algoritmo de 

simulação estocástica privilegiar um determinado conjunto de imagens que, por exemplo, pode 

82 



ser constituído de imagens bastantes similares e, portanto, não cobrirem o espaço de incerteza, 

resultando em distribuições de incertezas não representativas. 

Tabela 6-1: Resultados obtidos por Srivastava (1997) 

Tipo de Simulação Realização menos comum Realização mais comum 
Número Freqüência Número Freqüência 

Annealin1( Clássico 79 19 217 54 
Annealing 2 * 107 11 11 175 
Annealin1( 3 * 214 7 218 108 
Seqüencial Indicatriz 51 7 262 85 
Seqüencial Gaussiana 40 20 184 58 
Obs: • refere-se a diferentes 101plementações da s1mulated annealmg. 

6.3 Escolha de um Algoritmo 

Nenhum algoritmo de simulação é o melhor, qualquer que seja o conjunto de dados 

disponíveis e as situações que queremos simular. Como forma de fornecer uma diretriz básica 

para a escolha de um algoritmo de simulação, na tabela 6.2 estão os principais métodos de 

simulação com as principais caracteristicas, hipóteses, parâmetros de entrada. Nesta tabela 

estão outras metodologias não apresentadas no capítulo anterior como a decomposição LU, 

campos aleatórios markovianos, simulação gaussianas fractais e algoritmo genético, que foram 

analisadas no decorrer do trabalho mas, devido ao caráter da dissertação, procurou-se centrar 

nas metodologias mais usadas. O conhecimento das técnicas disponíveis, um claro 

entendimento de suas limitações, e o impacto potencial na descrição do reservatório são 

indiscutivelmente imprescindíveis para o sucesso do trabalho de modelagem. 

Em qualquer estudo, os resultados só são representativos quando as metodologias 

são aplicadas corretamente. Muitas vezes uma metodologia menos adequada e flexível, porém 

cuidadosamente utilizada, com reconhecimento e entendimento das limitações, pode dar 

melhores resultados do que uma metodologia mais adequada e abrangente, porém mal 

utilizada. Ressalta-se que todos os algoritmos de simulação tentam reproduzir um modelo de 

reservatório que é intrinsecamente o resultado de processos complexos que muitas vezes não 

são considerados pelos mesmos. Para os algoritmos baseados em pixel isto é bastante óbvio. 

Galli et a!. (1997) ressalta que isto também é válido para as metodologias baseadas em objetos: 

"Por exemplo, canais não são simples objetos, eles são o resultado da evolução temporal de 

uma canal primário sujeito a condições variáveis (aporte de sedimentos, erosões, avulsões, 

etc)". O essencial é o entendimento de que qualquer que seja a abordagem escolhida para a 

modelagem do reservatório, importantes hipóteses e simplificações serão adotadas. 

83 



00 ... 

Tabela 6-2: Algoritmos de Simulação: Parâmetros de entrada, Hipóteses, Características. 

Método/ Atributo Entrada Hipóteses Características 
Gaussiano Variogramas Multivariada gaussiana; Velocidade; 
Bandas Rotativas estacionariedade de 2' primeiro método de simulação, portanto muito difundido; 
(Contínuo) ordem. artefatos de lineamento; dificuldade de manusear anisotropias; restrição a determinados modelos de 

covariâncias· condicionamento em separado; simplicidade do modelo gaussiano. 
Gaussiano Variogramas Multivariada gaussiana; Velocidade; facilidade de implementação; 
Decomposição LU estacionariedade de 2' limitado a pequenos gri ds; imprecisões numéricas se a matriz de covariância for esparsa; 
(Contínuo) ordem. simplicidade do modelo gaussiano. 
Gaussiana Seqüencial Variogramas Multivariada gaussiana; Velocidade; 
(SGS) estacionariedade de 2' simplicidade do modelo gaussiano. 
(Contínuo) ordem 
Gaussiano Vario gramas Multivariada gaussiana; Simulação de atributos interdependentes; 
Co-SGS diretos e estacionariedade de 2' simplicidade do modelo gaussiano; instabilidade dos sistemas de cokrigagem; inferência de um 
(Contínuo) cruzados ordem elevado número de varioll,famas 
Gaussiano Co-SGS Variogramas Multivariada gaussiana; Simulação de atributos interdependentes; estabilidade do sistema de cokrigagem; 
Collocated estacionariedade de 2' simplicidade do modelo gaussiano; necessidade de definir hierarquia entre as variáveis; dados das 
(Contínuo) ordem variáveis secundárias conhecidos em todo o domínio. 
Gaussiano Variograma de Multivariada gaussiana; Dependência espacial em todas as escalas; dificuldade de incorporar dados soft; condicionamento é 
Fractal potência; autosintilaridade. uma etapa em separado; limitado ao variograma de potência 
(Contínuo) dimensão fractal. 
Gaussiano T roncado Variogramas, cur- Estacionariedadc de 2' Sequenciamento de fácies; velocidade; utilização de dados soft; permite intervenção do geólogo; 
Gaussiano vas de proporções ordem da gaussianas. modelo teórico bem fundamentado; habilidade de lidar com não estacionariedades; 
(Contínuo ou verticais c hori- impossibilidade de gerar fácies com diferentes anisotropias e complexas transições entre as mesmas; 
discreto) zontais complexidade na determinação do variograma da gaussiana (método iterativo). 
Plurigaussiano Variogramas, pro- Estacionariedade de 2' Simulação de fácies com diferentes anisotropias e complexas transições; 

Truncado( Contínuo porções verticais e ordem das gaussianas. complexidade na detenninação do variograma da gaussiana (método iteratívo). 
ou discreto) horizontais 
Seqüencial Indicatriz Variogramas das Estacionaridade de 2' Não assumir um modelo prévio de distribuição; permitir diferentes modelos de continuidade para os 
(SISe derivações) indicatrizes; a ordem. diferentes cutojfs; permitir utilizar informações soft; problemas de relação de ordem; 
(Contínuo ou depender da abor- impossibilidade de reproduzir variogramas de variáveis contínuas; parametrização e inferência 
discreto) dagem variograma bastante pesadas; lentidão se acrescentar o semivariograma cruzado; 

cruzado entre as 
indicatrizes. -----



ao 
V&gt; 

Continuação da Tabela 6-2: Algoritmos de Simulação: Parâmetros de entrada, Hipóteses, Vantagens, Desvantagens. 

Método/Atributo Entrada Hipóteses Características 
Simulated Annea/ing Variogramas; Dependentes da função Capacidade de modelar complexas estruturas geológicas; pode incluir estatística multiponto; pode 
(Contínuo ou estatísticas objetivo utilizada. ser usada como um pós-processador; pode incorporar informações soft e informações em diferentes 
discreto) multi ponto; suportes (testes e sísmica); ocorrência de artefatos (efeitos de borda); descontinuidade próxima aos 

proporções, etc ... dados condicionantes; pouca informação a respeito da escolha da programação de resfriamento e 
como preparar a função objetivo; lentidão se a função o~etivo for complexa; falta de arcabouço 
teórico consistente; dúvidas sobre o espaço de incerteza coberto. 

Algoritmo Genético Idêntico ao SA Dependente da função de Idêntico ao SA; permite a paralelização; 
(Contínuo ou adaptação escolhida. pouca informação sobre a definição das taxas de probabilidade de mutação, crossing-over e seleção; 
discreto) elevada dependência da população inicial; elevado tempo CPU. 
Métodos Iterativos Variogramas e Estacionaridade de 2' Velocidade; 
(Contínuo ou histogramas ordem. convergência não é garantida; realizações muito similares (espaço de incerteza);possibilidade de não 
discreto) honrar os histogramas. 
Campo de Variograma; ccdfs Similaridade entre o Rapidez; possibilidade de animação de incerteza; fácil integração de dados soft; pode ser usada como 
Probabilidade geradas por outros variograma do campo um pós-processador; possibilidade de utilizar ccdfs geradas por algoritmos não geoestatísticos 
(Contínuo ou algoritmos geoes- uniforme e o de probabi- (sísmica); separa a estimação das ccdfs da amostragem da mesmas; 
Discreto) tatísticos ou não !idades; hipóteses forte dependência da qualidade das ccdfs obtidas previamente; dados condicionantes tornam-se 

geoestatísticos. relacionadas ao método extremos locais (variável contínua); falta de um embasamento teórico bem fundamentado. 
de geração das ccdfs. 

Campos Markovianos Probabilidades A ocorrência de um Capacidade de modelar complexos padrões de heterogeneidades; facilidade de implementação de 
(Contínuo ou condicionais (de estado depende basica- associação de fácies; 
discreto) mudança) mente das fácies que parâmetros de entrada dificeis de serem manipulados por um uão especialista; inferência dos 

ocorrem em uma deter- parâmetros a partir de dados esparsos é dificil; dificil condicionamento para dados soft; 
minada vizinhança. complexidade do modelo aumenta exponencialmente com o aumento do número de fácies e do 

tamanho da vizinhanca. 
Booleanos Atributos de forma Representatividade dos Simulação de geometrias complexas; 
(Discreto) e orientação dos dados de afloramento ou grande apelo visual; 

objetos; curvas de reservatório similar; os parâmetros de entrada são mais próximos do trabalho do geólogo; 
proporção; regras poços interceptam os em algnma implementações, o conhecimento geoestatístico exigido é mínimo (sic); 
de atração, repu!- objetos em posições formas dos objetos bastante simplificadas; dependência da representatividade dos dados de 
são e erosão. aleatórias; fornms bem afloramento; reduzida velocidade quando o conjunto de dados condicionantes é elevada; dificuldade 

definidas para os objetos. de definir as regras de interação entre os objetos por um não especialista (algoritmos mais 
C()IllJllexos); dificuldades em integrar dados oriundos da sísmica e de testes. 



6.4 Representações de Incertezas 

V árias opções são convencionalmente usadas para apresentar a informação da 

incerteza de um conjunto de realizações possíveis. 

Neste tópico serão abordadas algumas figuras de incerteza que são mais adequadas 

às propriedades do reservatório consideradas aditivas, por exemplo, relativas ao volume de 

rocha, ou poroso, ou de hidrocarbonetos. 

Com o intuito de utilizar as diversas representações de incertezas oriundas das 

simulações estocásticas, será utilizado o mesmo conjunto de dados da AMOCO (74 poços) 

que deram origem ao caso base na análise da incerteza na krigagem. 

Portanto será utilizada a variável H&lt;j&gt; (produto espessura x porosidade), mas poderia 

ter sido a espessura, a porosidade, a saturação de fluidos ou outra combinação das mesmas. 

Inicialmente foi utilizado o algoritmo da SGS condicional do ISATIS para se obter 

100 realizações do atributo H&lt;j&gt;. A primeira idéia que se tem de incerteza quando da utilização 

da simulação estocástica é a diferença apresentada entre diversas realizações (figura 6.1). Os 

mapas da figura 6.1 correspondem a quatro das 100 realizações incluindo as que resultaram no 

maior e no menor volume poroso total (VPT) para o reservatório. 

Figura 6-1: Realizações estocásticas utilizando SGS. 

86 



Os softwares comerciais possibilitam a utilização de representações alternativas de 

incerteza. Por exemplo, com o ISATIS pode-se obter a média e variância em cada bloco 

(pixel) das 100 realizações obtidas. A variância do valor simulado em cada bloco tem sido 

utilizada como uma estimativa da incerteza local. Na figura 6.2 estão a média e o desvio 

padrão (raiz quadrada da variância) das 100 realizações. No mapa do desvio padrão, observa-

se que as áreas com os maiores valores correspondem às áreas com um número menor de 

dados na vizinhança, por exemplo, o extremo sudeste. 

Figura 6-2: Média e desvio padrão das 100 simulações SGS. 

&gt;=2: 
1.8 
1.1&gt; 

·1.4 
1.2: 
1 
0.8 
CU&gt; 
&lt;0.4 

Uma outra possibilidade é a construção do mapa do coeficiente de variação (razão 

entre o desvio padrão e a média) que representaria uma medida de dispersão relativa. Na figura 

6-3 está o mapa do coeficiente de variação. Neste mapa, os dados condicionantes são 

facilmente visualizados, pois eles constituem 'ilhas' de coeficiente zero. Neste caso, as áreas 

de elevado coeficiente de variação correspondem a áreas com poucos dados condicionantes ou 

com valor baixo na média das 100 simulações. 

0.3 
0.27 
0.24 
0.21 

. 0.18 
0.15 
0.:12 
o. os 
0.06 
0.03 
o 

Figura 6-3: Coeficiente de variação das 100 Simulações SGS. 

Na tabela 6-3 estão as estatísticas da média, da pior e da melhor realização. Os 

termos 'pior' e 'melhor' significam as realizações que resultaram respectivamente no menor e 

87 



maior volume poroso total para o reservatório. Verifica-se que as estatísticas da média das 

100 realizações são bem similares às obtidas através da krigagem correspondente ao caso base. 

Tabela 6-J:Estatística das Realizações 

Realizações Volume (Mm3 ) (H&lt;j&gt; )b mínimo (H&lt;j&gt; )b máximo (H&lt;P )b médio Variância (H~b 
Pior Realização 18920 0.3589 2.0950 1.2253 0.0737 
Média das 100 20002 0.4023 2.0818 1.2954 0.0338 
Melhor Realização 20854 0.3718 2.1024 1.3506 0.0771 
Krigagem 19994 0.9087 1.8335 1.2949 0.0310 

Obs: (H&lt;j&gt; )b é o valor do atributo (H&lt;j&gt;) por bloco em metros. 

Uma outra alternativa é a utilização de mapas de probabilidade (figura 6.4) que 

indicam a probabilidade do valor simulado em cada bloco do modelo ser superior/inferior que 

um determinado valor limite. No caso em análise, os mapas de probabilidade reportam em cada 

bloco, o percentual de imagens que apresentaram valores superiores ou inferiores a um 

determinado valor de cuto.ff Os mapas de probabilidade intervalares que correspondem à 

probabilidade de, em cada bloco (pixel), o valor simulado estar entre dois limites. 

Figura 6-4: Mapas de probabilidade. 

Os mapas de quantis (figura 6-5), por sua vez, apresentam o valor correspondente a 

um determinado quantil (percentil) em cada bloco do modelo. Pode-se também construir 

mapas de interquantis ou interquartis, que em cada bloco (pixel), apresentam a diferença entre 

dois valores simulados correspondentes a dois percentis preestabelecidos. 

Os mapas de desvio padrão, variância, coeficiente de variação ou interquantis são 

todos medidas da dispersão que refletem algum aspecto da incerteza. Onde essas estatísticas 

são baixas é porque se tem um alto grau de certeza sobre o atributo e vice-versa. 

Segundo Srivastava (1994a), embora as representações acima citadas seJam 

convencionais em geoestatística, a maior falha reside no fato de que seus formatos não são 

intuitivos. Isto é, requerem por parte dos usuários do modelo um entendimento de corno 

podem representar a incerteza. 

88 



Figura 6-5: Mapas de quantis. 

Embora não muito comuns, a adoção de representações híbridas pode tornar o 

entendimento da incerteza mais intuitivo. Por exemplo sobrepor aos mapas das realizações, um 

mapa que ressalte a informação de incerteza, como por exemplo uma medida de dispersão. 

Com os recentes recursos gráficos, esta alternativa fica bastante facilitada: as duas informações 

podem ser visualizadas simultaneamente, facilitando a identificação das áreas com as maiores e 

menores incertezas. 

6.5 Flutuações Ergódicas 

A ocorrência das flutuações ergódicas, amplamente reportadas na literatura, poucas 

vezes tem sua importância relacionada à incerteza. Na figura 6.6 estão os semivariogramas do 

modelo inicial, das 100 imagens simuladas, da média das 100 simulações e do mapa krigado. 

450 900 1350 
H m 

1SOO 2250 2 

Figura 6-6: Semivariogramas das simulações e da krigagem. 

Verifica-se que algumas imagens apresentam semivariogramas muito diferentes do 

utilizado para gerá-las, isto é, do modelo inicial. Essas flutuações, denominadas ergódicas, 

ocorrem porque o tamanho do domínio a ser simulado é da ordem de grandeza do integral 

range para o modelo de semivariograma adotado. Um critério que deveria ser adotado quando 

89 



da seleção de imagens é a verificação se o semivariograma da imagem simulada não se 

distancia muito do considerado representativo. As flutuações ergódicas podem ser 

consideradas úteis no sentido de cobrir alguma incerteza que se tem no modelo de 

semivariograma escolhido. Porém, quanto maior a confiabilidade que se tem no modelo e nos 

parâmetros do semivariograma escolhido, menores deverão ser as flutuações ergódicas aceitas. 

Figura 6-7: Comparação entre os mapas krigado e o da média das 100 simulações. 

Para o caso analisado, o semivariograma da média das simulações, bloco a bloco, 

tende ao semivariograma da imagem krigada, à medida que aumenta o número de realizações. 

Também a média das simulações tende à imagem krigada (figura 6-7), o que resulta em 

volumes porosos totais para o reservatório bastante similares para as duas condições. 

6.6 Simulação Condicional, Não Condicional e Krigagem 

Os resultados semelhantes entre a média das simulações condicionais e a krigagem, 

como obtido no item anterior, têm muitas vezes confundido o usuário que, às vezes, 

incorretamente generaliza o resultado para todas as situações. Exemplos podem ser 

encontrados na literatura, para os quais esta relação não é verdadeira. 

Tem-se o exemplo da estimativa do comprimento de um cabo submarino a ser 

lançado dispondo de alguns valores das cotas batimétricas do fundo do mar e da correlação 

espacial da mesma. Construiu-se um caso base em que os pontos extremos distam 1 O km. 

Deste caso base foram retiradas 21 amostras distanciadas de SOm. Foram utilizadas a 

krigagem, simulação estocástica condicional e não condicional. Os resultados estão listados na 

tabela 6.4. 

A estimativa obtida através da krigagem resultou bastante diferente dos valores 

obtidos através da simulações condicionais e não condicionais que apresentaram resultados 

mais próximos ao considerado verdadeiro. A krigagem apresentou a tendência de suavização 

da estimativa do relevo do fundo do mar, o que levou a subestimativas para o comprimento do 

cabo a ser lançado. 

90 



Tabela 6-4: Simulação condicional, não condicional e krigagem 

Resultados de Simulação 
20 Simulações Condicional Não Condicional 
Máximo 17.66 17.98 
Média 17.11 17.26 
Mínimo 16.31 16.21 
Desvio Padrão 0.28 0.49 

Obs: Valores em km. Krigagem 10.29 km e Valor de Referência 16.64 km. 

Conclui-se que a média das simulações tenderá ao valor obtido através da krigagem a 

depender dos objetivos para o qual o modelo é construído. Caso o objetivo do estudo fosse a 

determinação da cota batimétrica média naquela mesma região, a média das simulações 

tenderia à realização da krigagem, à medida que se aumentasse o número de realizações. 

Neste exemplo acadêmico ainda deve ser ressaltado que se o único objetivo do 

trabalho fosse determinar o comprimento do cabo a ser lançado, a simulação não condicional 

substituiria a condicional com mesma performance em termos de resultados, sem considerar a 

maior rapidez com que se pode obtê-la. 

Para o exemplo do cabo submarino, foi aplicada uma função de transferência que 

consistia em realizar uma integral de linha ao longo da superficie do fundo do mar, que foi 

realmente o atributo simulado ou estimado através da krigagem. 

Figura 6-8: Esquema ilustrativo para cálculo do HCIP. 

Exemplos semelhantes podem ser encontrados na literatura geoestatística voltada para 

reservatórios petrolíferos. Com os mesmos dados das I 00 simulações SGS e da krigagem da 

variável Hcj&gt; correspondente ao produto porosidade x espessura foi construído um exemplo 

demonstrativo. Foi suposto que a variável krigada e simulada correspondesse a profundidade 

do topo de um reservatório (em km) com espessura constante e igual a 200 metros. Em 

seguida, foram adotados 3 contatos óleo/água diferentes (figura 6. 8) a II 00, 1300 e 1500 m, 

sendo calculado o volume de óleo in place (VOIP) para as imagens simuladas e a krigada. Para 

91 



efeito de cálculo, foram utilizadas porosidade de 20 % e saturação de óleo acima do contato 

óleo/água igual a 75%. Os resultados estão apresentados nos histogramas da figura 6. 9, onde 

o valor obtido através da krigagem está indicado com uma cruz. Em nenhuma das situações a 

krigagem corresponde à média das simulações. Pode também ser observado o efeito de 

suavização da krigagem. Para o contato óleo/água muito alto, a krigagem tendeu a indicar um 

VOIP muito baixo, no caso inferior ao mínimo obtido através das simulações estocásticas. Já 

para o contato óleo/água muito baixo o resultado com a krigagem ficou próximo ao maior 

valor obtido através das simulações. 

Nestes dois exemplos foram aplicadas funções de transferência a um conjunto de 

imagens simuladas e à imagem krigada. A idéia preconcebida de que o resultado obtido através 

da krigagem deve ficar em tomo da média dos resultados obtidos através de todas as 

simulações é, muitas vezes, incorreta. 

~ B • • ~ oo m • oo 100 ,. 
Vo!\lmo do 0ito{Miil6ti do M3l· Contot&lt;&gt; 1 

l:lJ&amp;lt;00 110 1!10 IW 700 J10 2:20 }J(l 2ot0 m 100 :\IQ l:20 J:l{] l&lt;Q l'&gt;O lBO 110 100 100 400 
Volurre deÓlec:l (Mi~ deMl)· ContalO 2 Vol\,tmo do Oito (~.HMH&amp;lt;kM31· Con!oto 3 

Figura 6-9: Resultados do cálculo dos VOIPs simulados e krigados 

Por exemplo, Rodrigues (1996) submeteu ao simulador de fluxo 30 imagens de 

permeabilidade obtidas através de SGS e uma imagem krigada de um campo real. As funções 

de transferência envolvidas no simulador de fluxo são bem mais complexas que as dos dois 

exemplos acima citados. Na análise de Rodrigues, os resultados obtidos com a imagem krigada 

não correspondem à média dos resultados obtidos com as imagens estocásticas quando 

submetidas ao simulador de fluxo. 

6. 7 Ergodicidade 

Um conceito muitas vezes mal entendido pelo usuário de simulação estocástica é a 

ergodicidade e como ela se relaciona com os parâmetros escolhidos para o modelo. 

Para exemplificar como os parâmetros do modelo determinam a ocorrência de 

flutuações ergódicas em relação à media, foram realizadas 30 simulações com bandas rotativas 

92 



não condicionais em um domínio igual ao utilizado nas simulações condicionais, utilizando um 

semívariograma com uma estrutura esférica com alcance de 1837 m. Espera-se que os campos 

simulados gaussianos apresentem distribuição N(O, I). Porém, são observadas flutuações nestas 

estatísticas devido a não ergodicidade do modelo. Para avaliar o impacto de alguns parâmetros 

do modelo na ocorrência das flutuações ergódicas foram realizadas 30 simulações não 

condicionais para cada uma das seguintes condições: redução do alcance de 183 7 para 225 m; 

alteração do modelo de semívariograma de esférico para gaussiano; aumento do domínio a ser 

simulado em 25 vezes, isto é 5 vezes em cada direção do domínio bidimensional. 

Nas figuras 6-lOa/c estão os gráficos resultantes destas comparações que confirmam 

que quanto mais contínuo for o modelo de semívariograma, maior for o alcance e menor for o 

domínio, maiores serão as flutuações ergódicas. 

Hi 

~ 
õ 

' o; 

' ' 8 
" 8 -W5Q 
li 
'g _,_ou 
&gt; 

I L8~;r.ós (b) 

\---- R•!P.clilt,a·M•1taOn 'g ~ 
Vaoo,;r•m•E•Ieo&lt;o A }§ i 

~~~~11 I i "'I ', 
j '(; \ 1 ~.\·· \tri~\·d 'i '"1.~~.~ .· • ! ~y v i I li Wl'· t IJ I' \ 1 v '~ \. ~ '·"11 ~ \1 

li ~ i 
l ' 

(o) 

r 
I 
"' 

\ 

I 
H~ .D~o-t! -~--,-__.,.-·,----, 

1ú :m '~ JU tO :l\l 
Sim~tações oom Bandas RotaHvliS Simulações cem Bandas Ro1&lt;11iv~s Simulagões com ~ Rctati&gt;o&lt;as 

Figura 6-lO:Ergodicidade versus a) Alcance; b) Modelo de Semivariograma; 
c) Tamanho do Domínio 

A partir do modelo de semívariograma utilizado, pode-se determinar o integral range 

que é um parâmetro intimamente relacionado à ergodicidade. A rigor, o domínio a ser 

simulado tem que ser muito maior que o integral range para que se verifique ergodicidade da 

média. 

Tabela 6-5: Expressões do integral range em função do alcance. 

Modelo de Integral range 
Semívariograma Domínio 2D Domínio 3D 
Esférico (n/5)R2 (n/6)R3 

Exponencial (2n/9)R2 (8n/27)R3 

Gaussiano (n/3)R2 (n/J)3'2R3 

Para alguns modelos de sermvanogramas eXJstem expressões analíticas para o integral 

range. Na tabela 6-5 estão algumas expressões considerando modelo de semívariograma 

isotrópico com alcance R 

93 



Quando não se observa ergodicidade da média, não será observada a ergodicidade do 

semivariograma ou de qualquer outro momento de ordem superior. Nas modelagens de 

reservatórios petrolíferos, a ocorrência das flutuações ergódicas tanto da média quanto do 

semivariograma é bastante normal, uma vez que o integral range dos semivariogramas 

modelados são muitas vezes da mesma ordem de grandeza do tamanho do domínio a ser 

simulado. 

6.8 Número de Realizações Necessárias 

Um interessante e curioso aspecto na determinação do número de simulações 

estocásticas necessárias para cobrir o espaço de incertezas é a pouca referência às flutuações 

ergódicas. Lantuéjoul (1994) reporta que quanto maior for o integral range, maior será este 

número. Isto porque maior será a magnitude das flutuações ergódicas. Contudo, não é 

respondida a questão principal: quantas imagens são necessárias? Os trabalhos na literatura 

geralmente utilizam números cabalísticos como 100 e 50 imagens. 

Porém, são encontradas várias referências que apresentam resultados e conclusões, 

baseando-se em um número bastante limitado de imagens (inferiores a 10), sem se preocupar 

sobre a representatividade das imagens em termos de parâmetros estatísticos (histograma e 

semivariograma) e se as mesmas cobriam o espaço de incerteza do atributo. Por exemplo, 

Alabert e Modot (1992) compararam a SGS, Truncada Gaussiana e a SIS com dados de um 

reservatório turbidítico do Gabão. As conclusões reportadas por esses autores foram baseadas 

em apenas 5 simulações para cada uma das metodologias. De qualquer forma, quando da 

análise de incerteza do próprio atributo simulado ou mesmo quando as imagens simuladas são 

submetidas à simulação de fluxo, selecionar imagens segundo critério de flutuações ergódicas 

não tem sido uma prática comum. 

Trabalhos mais recentes já demonstram uma preocupação com o número de imagens 

e os critérios de seleção a serem adotados. 

No último congresso de Geoestatística, Journel (1997) reportou a metodologia por 

ele empregada para a questão. Inicialmente ele utiliza um conjunto de 100 realizações, para as 

quais são avaliados os resultados. Journel claramente reporta que o número 100 é cabalístico, e 

sua escolha é meramente para suscitar menos questionamentos do que por exemplo 99 ou 76. 

Em seguida são obtidas mais 100 realizações e os resultados destas são comparadas com os do 

primeiro conjunto. Se os resultados se mantiverem constantes, devem ser usadas as 200 

realizações. Caso contrário, o processo é reiniciado gerando 200 realizações e assim 

94 



sucessivamente. Journel esclarece que a metodologia se baseia em um princípio elementar de 

que o tempo de CPU não é problema. Isto não se verifica, principalmente quando as 

realizações serão submetidas a simuladores de fluxo. 

Algumas propostas de seleção das imagens representativas e a determinação do 

número de imagens necessárias para se cobrir o espaço de incerteza da previsão de 

comportamento do reservatório envolvem a utilização de parâmetros oriundos do ajuste de 

histórico e/ou da própria previsão de comportamento. 

Por exemplo, Rodrigues ( 1996) utilizou como critério para determinação do número 

de imagens estocásticas, a estabilização da variância da produção acumulada final de água na 

simulação de fluxo a que as imagens estocásticas eram submetidas. Para o caso analisado por 

Rodrigues (1996) foram necessárias 30 realizações. Para a seleção das imagens 

representativas, Rodrigues ( 1996) utilizou parâmetros comparativos entre a resposta através 

da simulação de fluxo e o histórico de produção para compor uma função objetivo. As imagens 

estocásticas que apresentaram os menores valores da função objetivo foram selecionadas para 

prosseguir a análise e realizar a previsão de produção. Rodrigues dividiu o histórico de 

produção em duas etapas, e verificou que imagens selecionadas considerando a parte inicial do 

histórico de produção apresentavam resultados discrepantes, em termos de performance de 

produção, quando considerando todo o histórico. Esses resultados reforçam a idéia de se 

utilizar uma abordagem probabilística do reservatório e que a depender da disponibilidade de 

novos dados sejam eles poços, interpretação sísmica, dados de produção, a modelagem do 

reservatório e as previsões de comportamento derivadas da mesma devem ser revistas. 

Campozana (1997) utilizou uma metodologia semelhante à Rodrigues (1996) para 

determinação do número de imagens através da avaliação da estabilização da diferença entre o 

maior e o menor fator de recuperação e da variância do mesmo, considerando o aumento do 

número de simulações estocásticas submetidas ao simulador de fluxo. 

Em um caso real, para o qual ainda não se dispõe de um considerável conjunto de 

dados de produção, parâmetros da previsão de produção podem ser usados para determinação 

do número de imagens necessárias. 

De qualquer forma, os estudos apontam geralmente para soluções específicas para 

cada caso que está sendo analisado. Não se vislumbra, por enquanto, a definição de uma regra 

universal que sirva para qualquer situação que estiver sendo modelada com diferentes 

mecanismos de produção (capa de gás, influxo de água, expansão de fluidos, etc) e diferentes 

métodos de recuperação secundária e terciária (injeção de água, gás, vapor, etc). A 

95 



transferência das incertezas que se tem na fase de construção dos modelos estocásticos do 

reservatório para a previsão de performance é uma questão que envolve uma grande 

diversidade de parãmetros. 

6.9 Simulação Campo de Probabilidade 

Com o mesmo conjunto de dados do reservatório da AMOCO utilizado para a SGS, 

foi implementada a simulação p-field conforme proposta por Srivastava (1992). Os resultados 

das 100 SGS condicionais foram utilizadas para compor as ccdfs em cada bloco. Para efeito de 

simplificação, as ccdfs foram discretizadas em 1,2,5,8, ... ,92,95,98, 100%. 

Para obtenção dos campos uniformes, foram realizadas 30 simulações de bandas 

rotativas não condicionais (ISATIS) com o mesmo semivariograma utilizado para gerar as 100 

simulações SGS condicionais. Foi elaborado um programa em FORTRAN que inicialmente faz 

a conversão dos campos gaussianos obtidos das simulações das bandas rotativas para o campo 

uniforme. 

Construídos os campos uniformes/campos de probabilidades, foi implementado uma 

rotina que faz a amostragem das ccdfs, baseando-se no valor do campo de probabilidade do 

respectivo bloco. Como as ccdfs estavam discretizadas, foi necessário realizar interpolação 

durante a amostragem das mesmas, que por motivo de simplicidade foi considerada linear. 

Devido ao fato de que o domínio a ser simulado é da ordem de grandeza do integral 

range do semivariograma modelado, flutuações ergódicas ocorreram, como já evidenciado na 

simulação gaussiana seqüencial. As estatísticas das 30 realizações estão na tabela 6-6. 

Tabela 6-6: Estatística das Realizações 

Realizações Volume (Mm3 ) (H&lt;f&gt;)h mínimo (Hij&gt;)b máximo I (H&lt;!J), médio Variância (H&lt;!J)b 
Pior Realização 17931 0.3600 2.0818 1.1613 0.0550 
Média das 30 20046 0.4023 2.0818 1.2982 0.0346 
Melhor Realização 21871 0.3591 2.0988 1.4165 0.1123 
Krigagem 19994 0.9087 1.8335 1.2949 0.0310 

Obs: (H&lt;j&gt; )b e o valor do atnbuto H&lt;j&gt; por bloco em metros. 

Em comparação com a SGS, observa-se que a simulação p-jield apresentou um 

intervalo de incerteza (diferença entre o maior e o menor volume) bem mais dilatado. Isto 

também reforça a idéia de que diferentes algoritmos de simulação levam a diferentes 

distribuições de incerteza. Em relação à média das 30 simulações, verifica-se uma coerência 

com a média obtida das 100 simulações SGS e com a krigagem. 

96 



6.1 O Animação de Incerteza 

Uma possibilidade para facilitar a visualização da incerteza é adotar uma sistemática 

que mostre um conjunto maior de realizações simultaneamente sem estar limitado ao tamanho 

da página. Uma opção é utilizar recursos de animação de forma que várias realizações 

minimamente diferentes sejam mostradas em uma rápida sucessão como em num desenho 

animado. Esta animação facilitaria a visualização das áreas do reservatório onde se tem as 

maiores incertezas. A possibilidade de geração de imagens minimamente diferentes é um dos 

subprodutos da técnica de simulação estocástica campo de probabilidades. 

Para permitir a geração de imagens minimamente diferentes, adotou-se uma 

sistemática igual a abordagem descrita no item anterior só alterando o tamanho do gríd do 

campo de probabilidades para 26lx245 blocos. 

Grid com as 
:__.... ccdfs locais i 

i·F=====a• 

I 

Campo de Probabilidades 

Figura 6-ll: Geração de imagens minimamente diferentes. 

Foi implementada uma rotina em FORTRAN que faz o grid de tamanho real 6lx45 

blocos (ccdf em cada bloco) deslizar sobre um outro de tamanho maior (campo de 

probabilidades). Assim, deslocando coluna a coluna (deslocamento em x) e linha a linha 

(deslocamento em y) foram construídas 200 realizações em cada uma das direções paralelas às 

bordas do grid do campo de probabilidades, obtendo um total de 800 simulações (figura 6-11 ). 

Não foi implementado nenhum caminho com direções aleatórias em cada um dos movimentos 

sobre o grid maior. 

Para se obter uma realização após uma movimentação sobre o grid com o campo de 

probabilidades, o valor correspondente a probabilidade em cada bloco é levado ao grid com as 

ccdfs para a realização da amostragem. Na figura 6-12, está o gráfico dos volumes porosos 

totais no reservatório obtido a partir de 800 simulações com variações mínimas entre cada 

realização. 

97 



23-

200 400 600 800 
Número da Simula ão 

Figura 6-12: Volumes Porosos Totais obtidos com a Simulação P:field. 

O intervalo de incerteza do volume poroso total obtido a partir das 800 simulações 

minimamente diferentes (4.51 MMm3) é maior que o obtido a partir das 30 simulações com 

diferentes campos de probabilidade (3.94 MMm\ 
Na figura 6-13 estão 8 mapas de realizações minimamente diferentes, parte do 

conjunto total de 800 realizações. Como tratava-se de um domínio ZD, optou-se por utilizar 

representações tridimensionais em que o atributo simulado é a terceira dimensão. 

Pode ser visualizado (seta) um dado condicionante que fica destacado e passa a 

constituir um extremo local. Observa-se que o volume poroso total é ligeiramente diferente 

em cada realização. Com recursos de computação gráfica cada vez mais avançados, poderia se 

fazer a animação das imagens minimamente diferentes. 

A geração de imagens minimamente diferentes só faz sentido no contexto de 

animação de incertezas para visualização. Em quaisquer outras situações, deseja-se amostrar 

convenientemente o espaço de incertezas com realizações bem diferentes umas das outras. 

6.11 Proposta Alternativa Para a Simulação P-field. 

Uma proposta alternativa à simulação p-jíeld (Oliveira e Remacre, 1997) é a adoção 

do próprio campo gaussiano para a amostragem das ccdfs construídas via algoritmo de 

simulação estocàstica ou krigagem paramétrica (figura 6-14). A abordagem se baseia na 

hipótese de que o campo a ser simulado apresenta distribuição multivariada gaussiana, isto é, 

podem ser obtidas ccdfs gaussianas completamente caracterizadas por sistemas de krigagens 

paramétricas como na SGS. 

98 



VPT =19.146 Mll4m3 VPT=19.161 MMm3 

VPT =19 .200 MMm3 VPT=19.201 MMm3 

VPT =19.160h1Mm3. 

VPT=19.158 MMm3 VPT=19.183 MMm3 

Figura 6-13: Realizações P-.freld minimamente diferentes. 

A idéia básica do método é a seguinte: 

I - Obter uma ccdf que possa ser expressa por dois parâmetros: a estimativa (a 

média) e um desvio padrão (a dispersão). 

99 



2 - Fazer a amostragem desta ccdf, baseando-se no campo gaussiano. 

zog- mcg 
-"---~=z,, 

cr"' 

onde Z, é o valor simulado, m, e cr, são respectivamente a média o desvio padrão que 

representam a ccdf em cada nó; onde z,. é o valor do campo gaussiano a ser utilizado para a 

amostragem, m,. e cr '" são respectivamente a média e o desvio padrão do campo gaussiano 

que é considerado N(O, 1 ). 

' (f"i.a i) z. --..Zsi=tti+ai*Zgi--
"' • ' 2 Geração do Campo 

Campo Gaussiano [-5,51 

Figura 6-14: Proposta Alternativa para a P-field. 

Simulação Estocástica 
P-field 

A proposta se baseia na construção de uma ccdf local a partir da estimativa e do 

desvio padrão da krigagem dos dados transformados. De qualquer forma, a proposta implica 

em assmrur que os dados apresentam características multivariadas gaussianas. Após a 

amostragem das ccdfs transformadas, os valores sofrem a transformação de volta. Os 

resultados com esta abordagem estão na tabela 6-7. 

Tabela 6-7: Estatísticas das Simulações com AbordagemP:field Alternativa 

Realizações Volume (Mm3 ) (H&lt;j&gt; )b mínimo (H&lt;j&gt; )h máximo (H&lt;j&gt; )h médio Variância (H&lt;j&gt; )h 
Pior Realização 17843 0.3602 2.0697 1.1556 0.0518 
Média das 30 20008 0.8919 1.8259 1.2958 0.0327 
Melhor Realização 21909 0.3589 2.1433 1.4190 0.1123 
Krigagem 19994 0.9087 1.8335 1.2949 0.0310 

Obs: (H&lt;j&gt; )b e o valor do atnbuto H&lt;j&gt; por bloco em metros. 

As estatísticas de cada realização obtida com a abordagem alternativa, usando campo 

gaussiano, são bastante similares às estatísticas da respectiva realização obtida com a 

abordagem tradicional, com os campos de probabilidade oriundos da transformação uniforme 

100 



dos mesmos campos gaussianos. Na figura 6-15 estão os valores simulados de volume poroso 

total para o reservatório em 30 simulações com as duas abordagens. 

Uma observação importante é a extrema dependência dos resultados da simulação 

campo de probabilidade, tanto da abordagem alternativa quanto a tradicional, em relação ao 

campo de probabilidade uniforme/gaussiano. Na figura 6-15 estão os gráficos dos valores de 

volume poroso total médio obtidos das simulações com as duas abordagens para cada um dos 

3 O campos de probabilidade construídos e o gráfico da média do campo de probabilidade 

usado. Verifica-se fator de correlação da ordem de 0.97 entre os valores totais médios em cada 

simulação e a média do campo uniforme (gaussiano) para as duas abordagens. Isto evidencia 

que desde que as ccdfs locais sejam representativas, os resultados das abordagens de 

simulação campo de probabilidade modificada e tradicional são dominados pelo campo 

gaussiano e uniforme, respectivamente. 

Após a esquematização e testes da proposta alternativa para a p-field, foram 

encontradas referências que enfocam parte da mesma. Bourgau!t e Journel (1996) e Bourgault 

( 1996), utilizaram ccdfs construídas a partir de krigagens paramétricas dos dados originais 

transformados (gaussiana) e o conceito do campo de probabilidades com objetivo de gerar 

uma estimativa alternativa à cokrigagem e pós processar realizações que apresentem ruídos, 

respectivamente. Assim, a real inovação da abordagem alternativa proposta se reduz apenas a 

utilização do próprio campo gaussiano para realizar a amostragem de ccdfs baseadas em 

modelos gaussianos como os da SGS. 
22.5 

• 
~ 

~! f\ f\~ i 
" 21.5 " '!I ~ 

~ 
o. 
• m 20.5 

o, ~ l /l ! 1, ~ I 
u 

.~ 8. 
~ E 
E 

i v . \1 \1 v v ll E 19.5 o ~ u o ~ n 
" ]ii o 185 o. E • ! li: &gt; Legenda 

17.5 • 

07l 
0.6---i 

i 
0.5-+ 

--8- Abordagem Tradicional • :g 
Abordagem Alternativa " 16.5 

10 20 30 10 20 30 
NUmero da Simulação Simulações 

Figura 6-15: Volume poroso total e média/variância do campo uniforme em cada simulação. 

6.12 Incertezas nos Parâmetros e no Modelo 

Um problema comum na obtenção da distribuição univariada das propriedades do 

reservatório é a ocorrência de agrupamentos (clustering). Os poços são perfurados 

101 



preferencialmente nas áreas onde se acredita, através do modelo geológico, nas melhores 

possibilidades de sucesso. Mas mesmo nestas áreas, o espaçamento entre poços é geralmente 

muito grande impossibilitando a definição do comportamento do semivariograma na origem. 

Verticalmente, as amostras retiradas dos testemunhos para análises petrofisicas geralmente 

privilegiam as melhores fácies, deixando as piores precariamente amostradas. O efeito da 

amostragem preferencial é que a distribuição univariada não corresponderá à do reservatório, 

tendo um alto primeiro momento (média elevada, maior densidade de poços nas áreas de 

maiores espessuras permoporosas) e um baixo segundo momento (baixa variabilidade das 

amostras). 

Outro problema comum é que os dados disponíveis são insuficientes para inferir as 

estatísticas das propriedades a serem simuladas. Geralmente é grande a incerteza nos 

parâmetros do semivariograma (alcance, patamar e efeito pepita) e até no modelo do mesmo. 

Toledo (1990) reporta a importância do aumento do número de dados condicionantes e da 

melhor definição dos parâmetros do semivariograma na obtenção de modelos geoestatísticos 

mais representativos do reservatório. 

Em seu estudo, Rodrigues (1996), por sua vez, reporta que não ocorreram variações 

significativas nas respostas de fluxo das imagens estocásticas em função de alterações no 

modelo variográfico, quando comparado com os resultados de todas as imagens simuladas. 

Segundo, Rodrigues ( 1996) este comportamento pode ser atribuído ao fato de que, em sua 

interpretação, as alterações no modelos eram limitadas e consistiram basicamente em modificar 

o alcance e o patamar nos modelos representativos dos variogramas experimentais, dentro dos 

limites de incertezas existentes. 

Campozana ( 1997) demonstrou através da utilização de dados sintéticos a influência 

do aumento do número de dados condicionantes, admitindo que o semivariograma já era 

conhecido. Campozana ( 1997) construiu um modelo sintético para fazer esta análise. 

Constatou-se melhoria no fator de correlação entre as imagens simuladas e o caso base (real) 

com o aumento do número de dados condicionantes. Com relação à distribuição de resposta 

das realizações quando submetidas ao simulador de fluxo, Campozana ( 1997) também 

verificou que o aumento do número de dados condicionantes, no caso poços, também reduz a 

incerteza. Campozana ( 1997) reportou melhoria na obtenção de intervalos de incertezas mais 

estreitos quando se considera informações adicionais vindas de outras fontes como a de dados 

de testes. 

102 



É razoável acreditar que maior integração de dados leva a realizações que são mais 

próximas da realidade. Seria natural também esperar que a medida que mais dados são 

disponibilizados e integrados ao algoritmo de modelagem, menores seriam os intervalos de 

incertezas, conforme reportado por Campozana (1997). Para Galli et ai. (1997), esta hipótese 

nem sempre se verifica. Dubrule (1994) esclarece de forma bastante didática esta questão. 

Uma vez que se tem definido um modelo probabilístico com os seus parâmetros bem 

identificados, à medida que aumenta o número de dados, a variabilidade entre as realizações 

diminui e consequentemente o intervalo de incertezas. São encontradas várias referências na 

literatura que reportam a influência do aumento do número de dados condicionantes e a 

diminuição das incertezas, só que na maioria das vezes baseando-se em um modelo 

probabilístico fixo. Dubrule (1994) explica que em muitas situações reais, a disponibilidade de 

novas informações leva a intervalos de incerteza maiores, porque algumas vezes implica em 

alteração drástica no modelo ou em seus parâmetros. 

A necessidade de incorporar dados de diferentes fontes e qualidade tem resultado em 

uma gama de propostas de alterações nos antigos e novos algoritmos de simulação estocástica 

visando principalmente dados oriundos de levantamentos sísmicos. Trata-se de utilizar toda a 

informação disponível oriunda da geofisica, que até bem pouco tempo era voltada 

exclusivamente para a arquitetura externa do reservatório, com intuito de obter descrições e 

modelagens de propriedades internas do reservatório cada vez mais representativas. Quanto à 

utilização de dados dinâmicos de produção (por exemplo, testes em poços), as principais 

aplicações reportadas na literatura abordam a questão com utilização da simulated annealing. 

Portanto, quando da utilização de simulação estocástica para modelagem de 

reservatórios é crucial a integração de toda a informação disponível considerada relevante. 

Assim, a seleção do algoritmo de simulação estocástica depende, dentre outras coisas, da 

habilidade das pessoas envolvidas em lidar com as informações oriundas da geofisica, da 

geologia ou da engenharia no software geoestatístico disponível. O mal estar gerado por uma 

distribuição de incerteza sobre a resposta do reservatório mais imprecisa quando da adição de 

novas informações, como por exemplo, um novo levantamento sísmico, pode levar algumas 

pessoas a questionar a modelagem estocástica, pois de um ponto de vista imediatista isto é 

contraproducente. É preciso que os usuários de simulação estocástica se convençam e saibam 

convencer as pessoas que fazem tais argumentações que a adição de mais informações pode 

resultar em alterações do próprio modelo utilizado na simulação estocástica e que, desprezar 

esta informação é adotar um modelo que, agora, é sabidamente errado. 

103 



7. Conclusões 

Apesar do inquestionável sucesso da geoestatística enquanto ferramenta de 

modelagem de reservatórios, não se pode esquivar de uma reflexão sobre suas falhas ou 

limitações. Tópicos e problemas específicos sobre avaliação de incertezas foram analisados 

nesta dissertação. A partir de uma análise crítica e de uma profunda reflexão sobre incertezas 

na modelagem de reservatórios com utilização das ferramentas geoestatísticas, algumas 

conclusões se fazem pertinentes. Para alguns dos problemas analisados, a geoestatística não 

tem uma solução específica. Ao chamar a atenção para estes problemas, eu espero 

simplesmente catalisar ações, novos estudos ou no mínimo promover o debate. 

Em relacão à geoestatística: 

a) A diversidade de notação geoestatística prejudica o entendimento e a disseminação 

das novas propostas. Não existe consenso da notação, bem como da terminologia 

geoestatística. A comunidade geoestatística deve envidar esforços no sentido de uniformizar 

notações e terminologias. 

b) A krigagem além de ser uma ferramenta geoestatística de estimativa, que pode ter 

sua utilização, a depender dos objetivos do estudo, também é parte integrante dos vários 

algoritmos de simulação estocástica que se baseiam em variogramas. 

c) Cada metodologia de simulação estocástica e estimativa tem seus ferrenhos 

defensores, os seus próprios criadores, que na maioria das vezes só ressaltam as vantagens, 

deixando que as desvantagens e possibilidades de melhoria sejam investigadas e publicadas por 

outros autores. 

d) Nenhum algoritmo de simulação estocástica ou estimativa é o melhor qualquer que 

seja a situação que se deseja analisar. O conhecimento das técnicas disponíveis, suas limitações 

e faixa de aplicação são essenciais para o sucesso do trabalho de modelagem. A escolha de um 

particular algoritmo geoestatístico deve basear principalmente no objetivo do estudo, na 

qualidade dos dados disponíveis, na habilidade do usuário em utilizar a metodologia escolhida, 

da disponibilidade de tempo e recursos computacionais. 

104 



Em relação à krigagem: 

a) O grande número de tipos de krigagem, algumas vezes obscurecidas por notações 

matemáticas complexas, pode mascarar a simplicidade do algoritmo básico: todas são técnicas 

de regressão que diferem apenas nos tipos particulares de funções, obtidas a partir dos dados, 

que estão sendo recombinadas para a obtenção da estimativa. 

b) Intervalos de incerteza derivados de krigagem paramétricas exercem um enorme 

fascínio devido à extrema facilidade para gerá-los. É de domínio dos geoestatísticos, as 

hipóteses sobre as quais eles se fundamentam, porém muitas vezes, isto é pouco transparente 

para o usuário. Apesar do conhecimento, a nivel da comunidade geoestatística, sobre as 

limitações da abordagem paramétrica dos intervalos de incerteza, ainda são encontradas 

referências recentes na bibliografia, baseando-se em hipóteses algumas vezes questionáveis, 

principalmente a nível local, e o que é pior, sem enfatizá-las e sem explicitar o significado das 

mesmas. Intervalos de incerteza derivados de krigagens não paramétricas baseadas em 

indicatrizes são mais trabalhosos. É questionável a vantagem de não assumir nenhuma 

distribuição a priori. 

c) A abordagem proposta por Roth e Armstrong (1995) para obtenção de intervalos 

de incerteza locais a partir de krigagens paramétricas resultam em ICs com assimetria reversa e 

dependentes do valor da estimativa. A nível de incerteza local, a abordagem de Roth e 

Armstrong (1995) é um grande avanço em relação à abordagem tradicional. Verificou-se 

também que, para as situações em que a variância de krigagem é pequena em relação à 

estimativa, a utilização desta abordagem leva a intervalos de incerteza globais muito mais 

conservativos que a abordagem tradicional. 

d) Com o desenvolvimento e aumento da utilização das técnicas indicatrizes, observa-

se a retomada das pesquisas direcionadas à correção dos pesos negativos da krigagem, com 

várias alternativas sendo propostas nos últimos anos. Ressalta-se que estas novas alternativas 

visam prioritariamente obter ponderadores que possam ser utilizados como percentuais na 

construção das ccdfs. Não se objetiva criar um substituto para a estimativa através da 

krigagem tradicional. Uma caracteristica reforçada por alguns autores é que estas abordagens 

devem ter praticidade, isto é, não devem ser computacionalmente intensivas. Em todas as 

abordagens que garantem a positividade dos ponderadores o que é perdido é a condição de 

mínima variância de krigagem. 

105 



Em relacão à simulação estocástica: 

a) A simulação p-field é basicamente um pós processador de outros métodos de 

simulação estocástica e estimativa. É bastante fácil de implementar a partir dos softwares 

geoestatísticos comerciais. Ela apresenta como subproduto a possibilidade de gerar realizações 

minimamente diferentes. A abordagem alternativa para a simulação p-field basicamente elimina 

a conversão do campo gaussiano não condicional em campo de probabilidades e possibilita a 

utilização de krigagens paramétricas usuais, porém é restrita a domínios gaussianos. 

b) Apesar do tema ergodicidade estar difundido entre os geoestatísticos, poucos são 

os trabalhos que verificam a reprodução das estatísticas do modelo nas realizações obtidas. Na 

maioria das vezes, as realizações são submetidas a um simulador de fluxo sem o cuidado 

adicional de verificar a representatividade da mesma frente ás estatísticas do modelo inicial. 

Pode-se usar as eventuais flutuações ergódicas das estatísticas para considerar as incertezas 

que se tem nos parâmetros do modelo. Porém, algumas realizações poderão apresentar 

flutuações ergódicas das estatísticas do modelo inicial (média e semívariograma) muito além da 

incerteza que se tem na definição desses parâmetros. 

c) Ergodicidade é uma característica do modelo probabilístico e não dos dados ou 

fenômeno sob estudo. Quanto mais contínuo for o modelo de semivariograma e quanto menor 

for a relação entre o integral range e as dimensões do domínio onde se realizará a simulação, 

maiores serão as flutuações ergódicas verificadas. 

d) Se faz necessários estudos que chequem a equiprobabilidade das realizações 

obtidas com os diferentes algoritmos de simulação estocástica. 

Em relacão à utilização de dados sísmicos e de produção: 

a) Vários são os trabalhos e algoritmos geoestatísticos que envolvem a utilização de 

dados sísmicos na caracterização de reservatórios. Trata-se de aplicar os dados de 

levantamento sísmicos para mapear propriedades internas do reservatório. 

b) A inclusão dos dados dinâmicos de produção na modelagem estocástica tem sido 

realizada sobretudo com a adoção da técnica de simulated annealing ou alguma técnica de 

otimização considerando uma formulação de transferência de escala baseada principalmente 

nas médias potenciais. Se faz necessário que novas pesquisas se realizem no sentido de ampliar 

os horizontes da utilização dos dados dinâmicos face a importância dos mesmos, pois 

representam um retrato atualizado do comportamento do reservatório em situações reais de 

produção. 

106 



Em relação à simulação estocástica e a modelagem de reservatórios: 

a) A adoção de critérios relacionados com a distribuição de resposta da performance 

das imagens estocásticas submetidas aos simuladores de fluxo tem dado bons resultados. 

Portanto, constitui uma abordagem válida para a definição do número de imagens necessárias 

para cobrir adequadamente o espaço de incertezas. Não se vislumbra, por enquanto, a 

determinação de uma regra universal para a determinação do número de imagens necessárias 

para cobrir o espaço de incertezas seja de um atributo, seja da resposta do reservatório 

submetido ao simulador de fluxo. 

b) É essencial o entendimento de que, qualquer que seja a abordagem escolhida 

para a modelagem estocástica do reservatório, importantes hipóteses e simplificações serão 

adotadas. É importante que o usuário saiba como as diferenças nas hipóteses podem influenciar 

a modelagem do reservatório. É imprescindível também que todas as hipóteses feitas para a 

escolha do modelo sejam documentadas, uma vez que as mesmas podem estar equivocadas, e 

isto ser observável quando mais dados se tornarem disponíveis. 

c) Durante todo o processo de caracterização e simulação de reservatórios várias 

fontes de variabilidade envolvem o julgamento subjetivo por parte do usuário: seja na coleta e 

utilização dos dados considerados relevantes, seja nos diferentes usos que se pode dar aos 

mesmos dados como por exemplo diferentes processamentos sísmicos, análise de testes, 

abordagens de simulação geoestatística e numérica, etc. Pode-se dizer que a primeira grande 

incerteza é a do próprio usuário. 

d) Em sentido holistico, pode-se dizer que a incerteza é devido a nossa ignorância e 

inabilidade para modelar com suficientes precisão e acurácia as distribuições das propriedades 

de rocha e fluidos do reservatório, e os fenômenos fisicos e químicos que envolvem o fluxo de 

fluidos. O maior desafio dos profissionais envolvidos em um trabalho de caracterização e 

simulação de reservatórios é minimizar a incerteza que é inevitável. Esta tarefa requer equipe 

coesa e com sinergismo entre os profissionais das diversas especialidades que atuam na área. 

!07 



Referências Bibliográficas 
ALABERT, F. G.; MODOT, V. Stochastic Models ofReservoir Heterogeneity Impact on 

Connectivity and Average Permeabilities. In: ANNUAL TECHNICAL 

CONFERENCE AND EXHIBITION OF THE SPE 67, Washington, USA, 1992. 

p.355-370. (SPE Paper 24893) 

ALMEIDA, A. S.; JOURNEL, A. G. Joint simulation ofMultiple Variables with a Markov-

Type Coregionalization Model. Mathematical Geology, v.26, n.5, p.565-588, 1994. 

ARMSTRONG, M. Is Research in Mining Geostats as Dead as a Dodo. ln: 

DIMITRAKOPOULUS, R. (ed.), Geostatistics for the Next Century. Dordrecht, 

Holland: Kluwer Acadernics Publishers, 1994. p.303-312. 

BARNES, R. J.; JOHNSON, T. B. Positive Kriging. ln VERL Y, G. et al. (eds.), 

Geostatistics for N aturai Resources Characterization. Dordrecht, Holland: D. 

Reidel, 1984. p.231-244. 

BARNES, R. J.; YOU, K. Adding Bounds to Kriging. Mathematical Geology, V.24, n.2, 

p.171-176, 1992. 

BEUCHER, H.; GALLI, A.; LE LOC'H, G.; RA VENNE, C. Including a Regional Trend in 

Reservoir Modeling Using the Truncated Gaussian Method. ln: SOARES, A. (ed.), 

Geostatistics Tróia'92. Dordrecht, Holland: Kluwer Acadernics Publishers, 1993. 

p.555-566. 

BOURGAULT, G. Robusteness of Noise Filtering by Kriging Analysis. In: Stanford 

Center for Reservoir Forecasting. Stanford, USA: Stanford University, 1995. 

(Report 8) 

BOURGAULT, G. Probability Field for the Post-processing of Stochastic Simulations. 

Mathematical Geology, V.28, n.6, p.723-734, 1996. 

BOURGAULT, G.; JOURNEL, A. G. Unsmoothed Estimation with Dense Secondary 

lnformation Using Probability Field Technique. In: Stanford Center for Reservoir 

Forecasting. Stanford, USA: Stanford University, 1996. (Report 9) 

BOURGAULT, G. Statistical Declustering and Convex Estimation Using Deterrninant of 

Redundancy Matrix. In: BAAFI, E. Y.; SCHOFIELD, N. A. (eds.), Geostatistics 

Wollongong'96. Dordrecht, Holland: Kluwer Acadernics Publishers, 1997. p. 103-114. 

CAMPOZANA, F. P. Incorporating Dynamic Data Into Geostatistical Reservoir 

Modeling. Austin, Texas, 1997. 281p. Dissertation Ph.D., University ofTexas. 

CHU, J.; XU, W.; ZHU, H.; JOURNEL, A. G. The Amoco Case Study. ln: Stanford 

Center for Reservoir Forecasting. Stanford, USA: Stanford University, 1991. 

(Report 4) 

108 



CHU, J.; XU, W.; ZHU, H; JOURNEL, A G. 3-D Implementation of Geostatistical 

Analyses - The Amoco Case Study. ln: Y ARUS, J. M.; CHAMBERS, R. L. (eds.), 

Stochastic Modeling and Geostatistics. Tulsa, USA: AAPG, 1994. p.201-216. 

(Computer Applications in Geology, n.3) 

CRESSIE, N. Statistics for Spatial Data. New York, USA: Wiley lnterscience, 1993. 

900p. (Wiley Series in Probability and Mathematical Statistics) 

DAMSLETH, E.; HOLDEN, L. Mixed Reservoir Characterization Methods, ln: TULSA 

CENTENNIAL PETROLEUM ENGINEERING SYMPOSIUM, Tulsa, USA, 

1994. p.129-143. (SPE Paper 27969) 

DAVID, M. Handbook of Applied Advanced Geoestatistical Ore Reserve Estimation. 

New York, USA: Elsevier Scientific Publishing Company, 1988. 216p. (Developments 

in Geomathematics 6) 

DEUTSCH, C. V. The Relationship Between Universal Kriging, Kriging With an Externa! 

Drift, and Cokriging. ln: Stanford Center for Reservoir Forecasting. Stanford, USA: 

Stanford University, 1991. (Report 4) 

DEUTSCH, C. V.; JOURNEL, A G. Annealing Techniques Applied to the lntegration of 

Geological and Engineering Data, Stanford Center for Reservoir Forecasting. 

Stanford, USA: Stanford University, 1992. (Report 5) 

DEUTSCH, C. V.; COCKERHAM, P.W. Practical Considerations in the Application of 

Simulated Annealing to Stochastic Simulation. Mathematical Geology, V.26, n.1, 

p.67-82, 1994. 

DEUTSCH, C. V.; JOURNEL, A G. GSLffi Geostatistical Software Library and 

User's Guide. 2. ed., New York, USA: Oxford University Press, 1996. 360p. 

DEUTSCH, C. V. Correcting For Negative Weights in Ordinary Kriging. Computers &amp;amp; 

Geosciences, v.22, n.7, p.765-773, 1996. 

DEUTSCH, C. V. Direct Assessment ofLocal Accuracy and Precision. ln: BAAFI, E. Y.; 

SCHOFIELD, N. A (eds.), Geostatistics Wollongong'96. Dordrecht, Holland: 

Kluwer Acadernics Publishers, 1997. p. 115-125. 

DOWD, P.A A Review of Recent Development in Geostatistics. Computers &amp;amp; 

Geosciences, v.17, n.IO, p.1481-1500, 1992. 

DUBRULE, 0.; KOSTOV, C. An Interpolation Method Taking lnto Account Inequality 

Constraints I. Methodology. Mathematical Geology, v.l8, n.1, p.33-51, 1986. 

DUBRULE, O. A Review of Stochastic Models for Petroleum Reservoirs. ln: 

ARMSTRONG, M. (ed.), Geostatistics. Dordrecht, Holland: Kluwer Acadernics 

Publishers, 1989, p.493-506. 

109 



DUBRULE, O. Estimating or Choosing a Geostatistical Model?. ln: 

DIMITRAKOPOULUS, R. (ed.), Geostatistics for the Next Century. Dordrecht, 

Holland: Kluwer Academics Publishers, 1994. p.3-14. 

ENGLUND, E. J. A Variance of Geostatisticians. Mathematical Geology, v.22, n.4, 

p.417-455, 1990. 

FROIDEVEAUX, R. Constrained Kriging as an Estimator ofLocal Distribution Functions. 

ln: CAPASSO, V. et al. (eds.), Statistics of Spatial Processes: Theory and 

Applications, 1993. p.106-118. 

FROIDEVEAUX, R. Probability Field Simulation. ln: SOARES, A (ed.), Geostatistics 

Tróia'92. Dordrecht, Holland: Kluwer Academics Publishers, 1993. p.73-83. 

GALLI, A; BEUCHER, H.; LE LOC'H, G.; DOLIGEZ, B. The Pros and Cons of the 

Truncated Gaussian Method. ln: ARMSTRONG, M.; DOWD, P.A. (eds.), 

Geostatistical Simulations. Dordrecht, Holland: Kluwer Academics Publishers, 1994. 

p.217-233. 

GALLI, A.; BEUCHER, H. Stochastic Models for Reservoir Characterization a User-

Friendly Review. ln: LACPEC 5, Rio de Janeiro, 1997. (SPE Paper 38999) 

GEOV ARIANCES. Manuais do Software IS A TIS, versão 3 .I. Fontainebleau, France: 

Geovariances, 1996. 

GÓMEZ-HERNÁNDEZ, J. J.; JOURNEL, A G. Joint Simulation ofMultigaussian Fields. 

ln: SOARES, A ( ed. ), Geostatistics Tróia'92. Dordrecht, Holland: Kluwer 

Academics Publishers, 1993. p.85-94. 

GOOV AERTS, P. Comparative Performance of lndicator Algorithms for Modeling 

Conditional Probability Distribution Functions. Mathematical Geology, v.26, n.3, 

p.389-411, 1994. 

GOTWAY, C. A; RUTHERFORD B. M. Stochastic Simulation for lmaging Spatial 

Uncertainty Comparison and Evaluation of Available Algorithms. ln: ARMSTRONG, 

M.; DOWD, P.A (eds.), Geostatistical Simulations. Dordrecht, Holland: Kluwer 

Academics Publishers, 1994. p.1-21. 

HALDORSEN, H. H.; LAKE, L. W. A New Approach to Shale Management in Field-Scale 

Models. SPE Journal, p.447-457, Aug. 1984. 

HALDORSEN, H. H.; MACDONALD, C. J. Stochastic Modeling of Underground 

Reservoir Facies (SMURF). ANNUAL TECHNICAL CONFERENCE AND 

EXHIDITION OF THE SPE 62, Dallas, USA, 1987, p.99-113. (SPE Paper 16751) 

HALDORSEN, H. H.; DAMSLETH, E. Challenges in Reservoir Characterization. AAPG 

BULLETIN, v.77, n.4, p.S41-551, 1993. 

110 



HARBAUGH, J. W.; DA VIS, J. C.; WENDEBOURG, J. Computing Risk for Oil 

Prospects; principies e programs. New York, USA: Pergamon, 1995. 452p. 

(Computer Methods in the Geosciences) 

lSAAKS, E. H.; SRIVASTAVA, R M. Applied Geostatistics. New York, USA Oxford 

University Press, 1989. 561p. 

JOHNSEN, G.; TJOLSEN, C.; RYSETH, A; DAMSLETH, E. Use of Seisrnic Data as a 

Guide in Stochastic Modelling. ln: BAAFI, E. Y.; SCHOFIELD, N. A (eds.), 

Geostatistics Wollongong'96. Dordrecht, Holland: Kluwer Acadernics Publishers, 

1997. p.362-373. 

JOURNEL, A G.; HUiffiREGTS, C. J. Mining Geostatistics. London, England: 

Acadernic Press, 1978. 600p. 

JOURNEL, AG. The Place ofNon-Parametric Geostatistics. ln: VERLY, G. et ai. (eds.), 

Geostatistics for Natural Resources Characterization. Dordrecht, Holland: D. 

Reidel, 1984. p.307-355. 

JOURNEL, A. G. Geostatistics Models and Tools for the Earth Sciences. Mathematical 

Geology, v.18, n.1, p.ll9-140, 1986a. 

JOURNEL, A G. Constrained lnterpolation And Qualitative lnformation - The Soft 

Kriging Approach. Mathematical Geology, v.18, n.3, p.269-286, 1986b. 

JOURNEL, A G.; ALABERT, F. Non-Gaussian Data Expansion in the Earth Sciences. 

Terra Nova, n.1, p.123-134,1989. 

JOURNEL, A G; ZHU, H. lntegrating Soft Seisrnic Data Markov-Bayes Updating, an 

Altemative to Cokriging and Tradicional Regression. ln: Stanford Center for 

Reservoir Forecasting. Stanford, USA Stanford University, 1990. (Report 3) 

JOURNEL, A G.; DEUTSCH, C. V. Entropy and Spatial Disorder. Mathematical 

Geology, v.25, n.3, p.329-355, 1993. 

JOURNEL, A G. Modeling Uncertainty Some Conceptual Thoughts. ln: 

DIMITRAKOPOULUS, R. (ed.), Geostatistics for the Next Century. Dordrecht, 

Holland: Kluwer Acadernics Publishers, 1994, p.30-43. 

JOVRNEL, A G.; RAO, S. E. Deriving Conditional Distributions form Ordinary Kriging. 

Stanford Center for Reservoir Forecasting. Stanford, USA: Stanford University, 

1996. (Report 9) 

JOURNEL, A G. The Abuse ofPrinciples in Model Building and Quest for Objectivity, ln: 

BAAFl, E. Y.; SCHOFIELD, N. A (eds.), Geostatistics Wollongong'96. Dordrecht, 

Holland: Kluwer Acadernics Publishers, 1997. p.3-14. 

KOSTOV, C.; JOURNEL, A G. Coding e Extrapolating Expert lnformation for Reservoir 

Description. ln: LAKE, L. W.; CARROL, H B. (eds.), Reservoir Characterization. 

San Diego, USA: Acadernic Press, 1986. p.249-264. 

111 



LANTUÉJOUL, C. Ergodicity e Integral Range. Journal of Microscopy, v.161, p.387-

403, 1991. 

LANTUÉJOUL, C. Non Conditional Simulation of Stationary Isotropic Multigaussian 

Random Functions. In: ARMSTRONG, M.; DOWD, P.A. eds, Geostatistical 

Simulations. Dordrecht, Holland: Kluwer Academics Publishers, 1994. p.14 7-177. 

LIMIC, N.; MIKELIC, A. Constrained Kriging Using Quadratic Programming. 

Mathematical Geology, v.16, n.4, p.423-429, 1984. 

MADUREIRA, C. M.; CAVALHEIRO, A. A. T.; FIUZA, A. M. A. Geostatistics as the 

Art ofMaking Statistical Inference Upon a Sing1e Samp1e, Geosistemas, n.3, p.49-67, 

1994. 

MATHERON, G. et ai. Conditional Simulation of the Geometry of Fluvio-Deltaic 

Reservoirs. ANNUAL TECHNICAL CONFERENCE AND EXHmiTION OF 

THE SPE 62, Dallas, 1987. p.123-131. (SPE Paper 16753) 

MATHERON, G. Estimating and Choosing. Tradução por A. M. Hasofer, Berlin, 

Germany: Springer-Verlag, 1989. 141p. 

OLIVEIRA, M. L.; REMACRE, A. Z. Glossário Geoestatístico Básico. Campinas, 

UNICAMP/AGP, 1997. (publicação interna, preprint) 

OLIVEIRA, M. L; REMACRE, A. Z. Simulação P-field: uma proposta alternativa. 

WORKSHOP SOBRE CARACTERIZAÇÃO E ENGENHARIA DE 

RESERVATÓRIOS 2. Campinas, UNICAMP, 1997. p.12-14. 

PAPOULIS, A. Probability, Random Variables and Stocbastic Processes. New York, 

USA: McGraw-Hill Book Company, 1965. 583p. 

REMACRE, A. Z. Krigagem da Média, Krigagem Simples e Krigagem Ordinária. 

Campinas, UNICAMP, 1995. p.1-6. (Notas de aula) 

REMACRE, A. Z. Correção dos Pesos da .Krigagem Comparação da Proposição de 

Journel, Froideveaux e uma nova Proposta. WORKSHOP SOBRE 

CARACTERIZAÇÃO E ENGENHARIA DE RESERVATÓRIOS 2. Campinas, 

UNICAMP,1997. p.7-9. 

RODRIGUES, L. G. Consideração das Incertezas na Caracterização de Reservatórios 

Utilizando Ajuste de Histórico e Simulação Estocástica. Campinas, 1996. 130p. 

Dissertação de Mestrado em Geoengenharia de Reservatórios , UNICAMP. 

ROTH, C.; ARMSTRONG, M. Confidence Intervals for Local estimation Application to 

the Witwatersrand Basin. APCOM Proceedings 26. Fontainebleau, France: Centre de 

Géostatistique, 1995. 

SRIV AST A V A, R. M. Reservoir Characterization With Probability Field Simulation. 

ANNUAL TECHNICAL CONFERENCE AND EXHmiTION OF THE SPE 67, 

Washington, USA, 1992. p.927-938. (SPE Paper 24753) 

112 



SRlV ASTA V A, R. M. The Visualization of Spatial Uncertainty. ln: Y ARUS, J. M.; 

CHAMBERS, R. L. (eds.), Stochastic Modeling and Geostatistics. Tulsa, USA: 

AAPG, 1994a. p.339-345. (Computer Applications in Geology, n.3) 

SRlV ASTA V A, R. M. An Overview of Stochastic Methods for Reservoir Characterization. 

ln: YARUS, J. M.; CHAMBERS, R. L. eds, Stochastic Modeling and Geostatistics. 

Tulsa, USA: AAPG, 1994b. p.3-16. (Computer Applications in Geology, n.3) 

SRlVASTAV A, R. M. Matheronian Geostatistics Where is it Going. ln: BAAFl, E. Y.; 

SCHOFIELD, N. A (eds.), Geostatistics Wollongong'96. Dordrecht, Holland: 

Kluwer Academics Publishers, 1997. p.53-68. 

STARKS, T. H.; FANG, J. H. The Effect ofthe Drift on the Experimental Sernivariograrn. 

Mathematical Geology, v.14, n.4, p.309-319, 1982. 

SURO-PÉREZ, V.; JOURNEL, A G. Stochastic Simulation of Lithofacies for Reservoir 

Characterization. ln: Stanford Center for Reservoir Forecasting. Stanford, USA: 

Stanford University, 1990. (Report 3) 

SURO-PÉREZ, V.; JOURNEL, A G. lndicator Principal Component Kriging. 

Mathematical Geology, v.23, n.S, p.759-788, 1991. 

SZIDAROVSZKY, F.; BAAFl, E. Y.; KIM, Y. C. Kriging without Negative Weights. 

Mathematical Geology, v.19, n.6, p.549-559, 1987. 

TOLEDO, J. P. Caracterização Geoestatística em Simuladores Numéricos de 

Reservatório. Campinas, 1990. 117p. Dissertação de Mestrado em Engenharia de 

Petróleo, UNICAMP. 

TRAN, T. Variogram Reproduction On Dense Simulation Grids. ln: Stanford Center for 

Reservoir Forecasting. Stanford, USA: Stanford University, 1993. (Report 6) 

VERL Y, G. Sequential Gaussian Co-Simulation A Simulation Method lntegrating Severa! 

Types of lnformation. ln: SOARES, A (ed.), Geostatistics Tróia'92. Dordrecht, 

Holland: Kluwer Acadernics Publishers, 1993. p.543-554. 

XU, W.; TRAN, T.; SRIVASTAVA, R. M.; JOURNEL, AG. lntegrating Seisrnic Data in 

Reservoir Modeling. ANNUAL TECHNICAL CONFERENCE AND 

EXHIDITION OF THE SPE 67, Washington, USA, 1992. p.887-902. (SPE Paper 

24742) 

XU, W.; JOURNEL, A G. GTSIM- Gaussian Truncated Simulations of Lithofacies, ln: 

Stanford Center for Reservoir Forecasting. Stanford, USA: Stanford University, 

1993. (Report 6) 

ZHU, H.; JOURNEL, A Formating and lntegrating Soft Data Stochastic lmaging via the 

Markov-Bayes Algorithm. ln: SOARES, A (ed.), Geostatistics Tróia'92. Dordrecht, 

Holland: Kluwer Academics Publishers, 1993. p.1-12. 

113 



Bibliografia 
CRESSIE, N. The Origins ofKriging. Mathematical Geology, v.22, n.3, p.239-252, 1990. 

DAVID, M. Geoestatistical Ore Reserve Estimation. New York, USA: Elsevier 

Scientific, 1977. 364p. (Developments in Geomathematics 2) 

DA VIS, J. C. Statistics and Data Analysis. 2. ed. New York, USA: John Wiley &amp;amp; Sons, 

1973. 646p. 

DOWD, P.A. Some Observations on Confidence Intervals and Kriging Errors. ln: 

ARMSTRONG, M. (ed.), Geostatistics, 1988. Dordrecht, Holland: K.luwer Academics 

Publishers, 1989. p.861-874. 

DUBRULE, O. Introducing More Geology in Stochastic Reservoir Modeling. ln: 

SOARES, A. (ed.), Geostatistics Tróia'92. Dordrecht, Holland: Kluwer Academics 

Publishers, 1993. p.351-370. 

FAYERS, F. J.; HEWETT, T. A. A Review of Current Trends in Petroleum Reservoir 

Description and Assessment ofthe Impacts on Oil Recovery. ln: Stanford Center for 

Reservoir Forecasting. Stanford, USA: Stanford University, 1993. (Report 6) 

GALLI, A; NEUILLET, F. G.; DADOU, C. Factorial Kriging Analysis A Substitute to 

Spectral Analysis of Magentic Data. ln: VERL Y, G. et al. (eds.), Geostatistics for 

Natural Resources Characterization. Dordrecht, Holland: D. Reide1, 1984. p.543-

558. 

GEOV ARIANCES. Manuais do Software !SATIS, versão 2.2. Fontainebleau, France: 

Geovariances, 1994. 

GÓMEZ-HERNÁNDEZ, J. J.; CASSIRAGA, E. F. Theory and Practice of Sequential 

Simulation. ln: ARMSTRONG, M.; DOWD, P.A. (eds.), Geostatistical Simulations. 

Dordrecht, Holland: K.luwer Academics Publishers, 1994. p.111-124. 

HEWETT, T. A. Geostatistical Reservoir Characterization. Campinas, UNICA.MP, 

1992. (Apostila de Seminário) 

HOHN, M. E. Geostatistics and Petroleum Geology. New York, USA: Van Nostrand 

Reinhold, 1988. 264p. (Computer Methods in the Geosciences) 

JOURNEL, A. G. Geostatistics for the Environmental Sciences. Stanford, USA: 

Stanford University, Applied Earth Science Department, 1987. 135p. 

JOURNEL, A G. Fundamentais of Geostatistics in Five Lessons. Stanford, USA: 

Stanford University, Applied Earth Science, 1988. 

JOURNEL, A G.; ROSSI, M. E. When do We Need a Trend Model in Kriging. 

Mathematical Geology, v.21, n.7, p.715-739, 1989. 

114 



JOURNEL, A G.; XU, W.; TRAN, T. Integrating Seismic Data in Reservoir Modeling 

The Collocated Cokriging Alternative. ln: Stanford Center for Reservoir 

Forecasting. Stanford, USA: Stanford University, 1992. (Report 5) 

JOURNEL, A. Geostatistics Roadblocks and Challenges. ln: SOARES, A (ed.), 

Geostatistics Tróia'92. Dordrecht, Holland: K.luwer Academics Publishers, p.213-224. 

1993. 

KOV ÁCS, Z. L. Teoria da Probabilidade e Processos Estocásticos. São Paulo: Edição 

Acadêmica, 1996. 120p. 

LANTUÉJOUL, C. Random Sets and Functions from Models to Conditional 

Simulations. Campinas, UNICAMP, 1995. 14lp. (Apostila de Seminário) 

REMACRE, A. Z. Coestimativas. Campinas, UNICAMP, 1995, p.1-13. (Notas de aula) 

RIPLEY, B. D. Stochastic Simulation. New York, USA: John Wiley &amp;amp; Sons 1987. 237p. 

(Wiley Series in Probability and Mathematical Statistics) 

SEN, M. K.; STOFFA, P.L.; POPE, G. A. Stochastic reservoir Modeling Using Simulated 

Annealing and Genetic Algorithm. ANNUAL TECHNICAL CONFERENCE AND 

EXHIDmON OF THE SPE 67, Washington, USA, 1992. p.939-950. (SPE Paper 

24754) 

STOYAN, D.; KENDALL, W. S.; MECKE, J. Stochastic Geometry and its 

Applications. Berlin, Germany: John Wiley &amp;amp; Sons, 1987. 345p. (Probability and 

Mathematical Statistics Applied) 

WACKERNAGEL, H. Multivariate Geostatistics; an introduction with applications. 

Berlin, Germany: Springer-Verlag, 1995. 257p. 

WALPOLE, R. E.; MYERS, R. H. Probability and Statistics for Engineers and 

Scientists. 3. ed. New York, USA: MacMillan Publishing Company, 1985. 639p. 

ZIMMERMAN, D. A.; WILSON, J. L. Description of and User's Manual for TUBA a 

Computer Code for Generating Two-dimensional Random fields via the Turning 

Bands Method. Albuquerque, USA: SEASOFT, 1990. 114p. 

115 




</field>
	</doc>
</add>