<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.10671</field>
		<field name="filename">15824_000759735.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">
UNIVERSIDADE ESTADUAL PAULISTA
Faculdade de Ciências e Tecnologia de Presidente Prudente

Programa de Pós-Graduação em Matemática Aplicada e Computacional

Análise Bayesiana de Dados Composicionais na
Presença de Covariáveis

Taciana Kisaki Oliveira Shimizu
Orientador: Prof. Dr. Jorge Alberto Achcar

Coorientador: Prof. Dr. Mário Hissamitsu Tarumoto

Presidente Prudente, Fevereiro de 2014



UNIVERSIDADE ESTADUAL PAULISTA
Faculdade de Ciências e Tecnologia de Presidente Prudente

Programa de Pós-Graduação em Matemática Aplicada e Computacional

Análise Bayesiana de Dados Composicionais na
Presença de Covariáveis

Taciana Kisaki Oliveira Shimizu
Orientador: Prof. Dr. Jorge Alberto Achcar

Coorientador: Prof. Dr. Mário Hissamitsu Tarumoto

Dissertação apresentada ao Programa de
Pós-Graduação em Matemática Aplicada e
Computacional da Faculdade de Ciências
e Tecnologia da UNESP para obtenção do
título de Mestre em Matemática Aplicada e
Computacional.

Presidente Prudente, Fevereiro de 2014



 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

FICHA CATALOGRÁFICA 
 

  
Shimizu, Taciana Kisaki Oliveira. 

S559a Análise Bayesiana de dados composicionais na presença de covariáveis / 
Taciana Kisaki Oliveira Shimizu. - Presidente Prudente : [s.n], 2014 

 111 f. 
  
 Orientador: Jorge Alberto Achcar 

Coorientador: Mário Hissamitsu Tarumoto 
 Dissertação (mestrado) - Universidade Estadual Paulista, Faculdade de 

Ciências e Tecnologia 
 Inclui bibliografia 
  
 1. Dados Composicionais. 2. Inferência Bayesiana. 3. MCMC. I. Achcar, 

Jorge Alberto. II. Tarumoto, Mário Hissamitsu. III. Universidade Estadual 
Paulista. Faculdade de Ciências e Tecnologia. IV. Análise Bayesiana de 
dados composicionais na presença de covariáveis. 

  
  

 





Aos meus pais, Rosa e Gilmar e
ao meu marido Marcelo (Hiro)
pelo amor, paciência,
incentivo e companheirismo.



i

Agradecimentos

Agradeço a todos que diretamente ou indiretamente contribuiram para a realização
desse trabalho, de forma especial:

À Deus por estar sempre presente na minha vida, proporcionando proteção, sabedoria
em todos os momentos.

Aos meus pais Gilmar e Rosa, com amor e carinho dedicaram-se na minha educação,
aos meus irmãos Emanuelle e Renan, pelo amor fraternal, apoio e alegrias que passamos
juntos.

Ao meu marido Marcelo (Hiro) pelo amor, companheirismo, respeito, paciência e por
sempre me apoiar à conquistar meus objetivos pessoais e profissionais. Obrigada!

À toda minha família, inclusive à família do meu marido pela ajuda em todos os
momentos que necessitei.

Ao meu tio Paulo Shigueru Kisaki, pelo incentivo nos meus estudos desde criança.

Ao meu orientador Prof. Dr. Jorge Alberto Achcar pela orientação, dedicação, paci-
ência e apoio oferecidos para a elaboração desse trabalho, e sobretudo pela oportunidade
de aprender e trabalhar juntamente com um exemplo de profissional.

Ao meu coorientador Prof. Dr. Mário Hissamitsu Tarumoto e a Profa. Olga Lyda
Anglas Rosales Tarumoto, por tudo que me ensinaram, pela amizade desde do período
de graduação, conselhos, orientação, incentivo em todas as atividades que realizei após a
graduação.

À FAPESP (Fundação de Amparo à Pesquisa do Estado de São Paulo), pelo apoio
financeiro oferecido, possibilitando a minha dedicação exclusiva ao desenvolvimento desse
trabalho.

Aos professores que contribuiram com a minha formação acadêmica e também me
auxiliaram no mestrado, em especial, Profa. Aparecida Doniseti Pires de Souza, Profa.
Vilma Mayumi Tachibana, Prof. Messias Meneguette Júnior, Prof. Josmar Mazucheli,
Profa. Vanessa Avansini Botta Pirani.



Agradecimentos ii

Aos professores da banca de qualificação, Dr. Josmar Mazucheli e Dra. Vilma Mayumi
Tachibana pelas contribuições relevantes para o trabalho.

Aos professores Dra. Renata Maria Coimbra Libório e Dr. Everaldo Santos Me-
lazzo que colaboraram com o meu crescimento científico, por terem dado a oportunidade
de aplicar a Estatística em projetos de pesquisas acadêmicas, conviver e aprender com
profissionais de outras áreas.

À amiga Elizabeth Mie Hashimoto, pela sua amizade desde da graduação e sua dis-
posição em me ajudar no que fosse preciso.

Aos colegas do curso de mestrado, Ana, Débora, Leandro, Pedro e Renato, pela
amizade e experiências trocadas.

À FCT/UNESP, aos funcionários da Seção de Pós Graduação: Cinthia, André e
Ivonete, em especial à Aparecida Tamae Otsuka pela ajuda fundamental no processo de
pedido de bolsa e na prestação de contas à FAPESP.



SHIMIZU, T. K. O. Análise Bayesiana de Dados Composicionais na Presença
de Covariáveis. Dissertação de mestrado - Faculdade de Ciências e Tecnologia - FCT,
UNESP, Presidente Prudente - SP, 2014.

Resumo

Dados composicionais consistem em vetores conhecidos como composições cujos compo-
nentes são positivos e definidos no intervalo (0,1) representando proporções ou frações de
um “todo”. A soma desses componentes deve ser igual a um. Os dados composicionais
estão presentes em diferentes áreas, como na geologia, ecologia, economia, medicina entre
muitas outras. Desta forma há um grande interesse em novas abordagens de modelar
dados composicionais. Neste estudo, introduzimos as transformações logaritmo da razão
(alr) e Box-Cox em modelos usados para dados composicionais, assumindo erros normais
não correlacionados. O objetivo principal deste trabalho é aplicar métodos Bayesianos
para estes modelos utilizando os métodos padrões de Monte Carlo via Cadeias de Markov
(MCMC) para simular amostras da posteriori conjunta de interesse. Nós aplicamos a
metodologia proposta em dois conjuntos de dados, sendo que um deles é sobre um expe-
rimento de medidas repetidas na qual introduzimos uma variável de efeito aleatório para
capturar a dependência para os dados longitudinais e, além disso, a introdução de dois
efeitos aleatórios extras no modelo. Estes resultados de modelagem podem ser de grande
interesse em trabalhos aplicados que lidam com conjuntos de dados composicionais.

Palavras-chave: Dados Composicionais, Inferência Bayesiana, MCMC.



SHIMIZU, T. K. O. Bayesian Analysis of Compositional Data in Presence of Co-
variates. Dissertação de mestrado - Faculdade de Ciências e Tecnologia - FCT, UNESP,
Presidente Prudente - SP, 2014.

Abstract

Compositional data consist of known compositions vectors whose components are positive
and defined in the interval (0,1) representing proportions or fractions of a “whole”. The
sum of these components must be equal to one. Compositional data is present in different
areas, as in ecology, economy, medicine among many others. In this way, there is a great
interest in new modeling approaches for compositional data. In this study we introduced
additive log-ratio (alr) and Box-Cox transformations models used for compositional data,
under uncorrelated normal errors. The main objective of this project is to apply Bayesian
methods to these models using standard Markov Chain Monte Carlo (MCMC) methods
to simulate samples of the joint posterior of interest. We apply the proposed methodology
in two data sets, whereas one of them is about an experiment of repeated measures where
we introduced a random effect variable to capture the dependence for the longitudinal
data and also the introduction of two extra random effects in the model. These modeling
results could be of great interest in the applied work dealing with compositional data sets.

Keywords: Compositional data, Bayesian Inference, MCMC.



i

Lista de Figuras

4.1 Box plots para os componentes dos pontos dos times da Superliga de vôlei. 16

4.2 Densidades a posteriori e traços a posteriori para os parâmetros de inter-
cepto do modelo 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

4.3 Densidades a posteriori e traços a posteriori para os parâmetros de incli-
nação do modelo 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

4.4 Densidades a posteriori e traços a posteriori para os desvios padrões do
modelo 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25

4.5 Densidades a posteriori e traços a posteriori para os parâmetros de inter-
cepto do modelo 2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34

4.6 Densidades a posteriori e traços a posteriori para os parâmetros de incli-
nação do modelo 2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35

4.7 Densidades a posteriori e traços a posteriori para os desvios padrões do
modelo 2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

4.8 Densidades a posteriori e traços a posteriori para os parâmetros ? do
modelo 2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

4.9 Gráficos dos valores observados e ajustados dos componentes do vôlei de
acordo com o modelo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

5.1 Box plots dos componentes do leite para os grupos antes e depois da dieta. 43

5.2 Densidades a posteriori e traços a posteriori para os parâmetros ?0’s no
modelo 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51

5.3 Densidades a posteriori e traços a posteriori para os parâmetros ?1’s no
modelo 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52

5.4 Densidades a posteriori e traços a posteriori para os parâmetros de vari-
ância no modelo 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53



Lista de Figuras ii

5.5 Densidades a posteriori e traços a posteriori para os parâmetros de vari-
ância no modelo 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

5.6 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?0’s no modelo 4. . . . . . . . . . . . . . . . . . . . . . . . . 63

5.7 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?1’s no modelo 4. . . . . . . . . . . . . . . . . . . . . . . . . 64

5.8 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 4. . . . . . . . . . . . . . . . . . . . 65

5.9 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 4. . . . . . . . . . . . . . . . . . . . 66

5.10 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?’s no modelo 4. . . . . . . . . . . . . . . . . . . . . . . . . 67

5.11 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?0’s no modelo 5. . . . . . . . . . . . . . . . . . . . . . . . . 75

5.12 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?1’s no modelo 5. . . . . . . . . . . . . . . . . . . . . . . . . 76

5.13 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 5. . . . . . . . . . . . . . . . . . . . 77

5.14 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 5. . . . . . . . . . . . . . . . . . . . 78

5.15 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?0’s no modelo 6. . . . . . . . . . . . . . . . . . . . . . . . . 86

5.16 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?1’s no modelo 6. . . . . . . . . . . . . . . . . . . . . . . . . 87

5.17 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?’s no modelo 6. . . . . . . . . . . . . . . . . . . . . . . . . 88

5.18 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 6. . . . . . . . . . . . . . . . . . . . 89

5.19 Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 6. . . . . . . . . . . . . . . . . . . . 90



Lista de Figuras iii

5.20 Gráficos dos valores observados e ajustados dos componentes do leite de
acordo com o modelo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95



iv

Lista de Tabelas

1.1 Transformações logísticas elementares de Sg para Rg. . . . . . . . . . . . . 3

4.1 Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke
- Modelo 1. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

4.2 Estimativas das proporções dos componentes - Modelo 1. . . . . . . . . . . 22

4.3 Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke
- Modelo 2. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

4.4 Estimativas das proporções dos componentes - Modelo 2. . . . . . . . . . . 33

4.5 Estimativas dos parâmetros do modelo 1 - Método Clássico . . . . . . . . . 38

4.6 Estimativas dos parâmetros do modelo de Regressão Dirichlet . . . . . . . 39

4.7 Critério DIC - Modelos 1 e 2. . . . . . . . . . . . . . . . . . . . . . . . . . 39

4.8 Soma do quadrado das diferenças entre os valores observados e os valores
ajustados. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

5.1 Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke
- Modelo 3. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50

5.2 Estimativas das proporções dos componentes - Modelo 3. . . . . . . . . . . 55

5.3 Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke
- Modelo 4. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62

5.4 Estimativas das proporções dos componentes - Modelo 4. . . . . . . . . . . 68

5.5 Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke
- Modelo 5. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74

5.6 Estimativas das proporções dos componentes - Modelo 5. . . . . . . . . . . 79

5.7 Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke
- Modelo 6. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85

5.8 Estimativas das proporções dos componentes - Modelo 6. . . . . . . . . . . 91



Lista de Tabelas v

5.9 Estimativas dos parâmetros do modelo 3 - Método Clássico . . . . . . . . . 92

5.10 Estimativas dos parâmetros do modelo de Regressão Dirichlet . . . . . . . 93

5.11 Critério DIC - Modelos 3, 4, 5 e 6. . . . . . . . . . . . . . . . . . . . . . . 93

5.12 Soma do quadrado das diferenças entre os valores observados e os valores
ajustados. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94

A.1 Conjunto de dados referente aos jogos da Superliga de vôlei masculina
2011/2012. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102

B.1 Composições alimentares do leite de 30 vacas (pr=proteína, mf=gordura
do leite, ch=carboidrato, Ca=cálcio, Na=sódio, K=potássio) antes e depois
de uma nova dieta. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103



vi

Sumário

1 Introdução 1

2 Introdução aos Métodos Bayesianos 6

2.1 Teorema de Bayes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6

2.2 Distribuições a Priori e a Posteriori . . . . . . . . . . . . . . . . . . . . . 7

2.3 Diagnóstico de Convergência . . . . . . . . . . . . . . . . . . . . . . . . . . 8

2.3.1 Diagnóstico de Geweke . . . . . . . . . . . . . . . . . . . . . . . . . 8

2.4 Estimação . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9

2.4.1 Estimação Pontual . . . . . . . . . . . . . . . . . . . . . . . . . . . 9

2.4.2 Estimação por Intervalos . . . . . . . . . . . . . . . . . . . . . . . . 10

2.5 Critério de Seleção de Modelos . . . . . . . . . . . . . . . . . . . . . . . . . 10

2.5.1 Critério DIC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

3 Transformações e Modelo de Regressão Dirichlet para Dados Composi-
cionais 12

3.1 Transformações Logaritmo da Razão (alr) e Box-Cox . . . . . . . . . . . . 12

3.2 Modelo de Regressão Dirichlet . . . . . . . . . . . . . . . . . . . . . . . . . 13

4 Análise Bayesiana para os Dados da Superliga de Vôlei Masculina 15

4.1 Transformação alr - Modelo 1 . . . . . . . . . . . . . . . . . . . . . . . . . 16

4.1.1 Análise Bayesiana - Modelo 1 . . . . . . . . . . . . . . . . . . . . . 18

4.2 Transformação Box-Cox - Modelo 2 . . . . . . . . . . . . . . . . . . . . . . 25

4.2.1 Análise Bayesiana - Modelo 2 . . . . . . . . . . . . . . . . . . . . . 28



Sumário vii

4.3 Análise clássica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

4.4 Discussão dos Resultados . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

5 Análise Bayesiana para Dados Longitudinais 42

5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 . . . . . . 43

5.1.1 Análise Bayesiana - Modelo 3 . . . . . . . . . . . . . . . . . . . . . 46

5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 . . 55

5.2.1 Análise Bayesiana - Modelo 4 . . . . . . . . . . . . . . . . . . . . . 58

5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 . . . . 69

5.3.1 Análise Bayesiana - Modelo 5 . . . . . . . . . . . . . . . . . . . . . 70

5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 . 79

5.4.1 Análise Bayesiana - Modelo 6 . . . . . . . . . . . . . . . . . . . . . 80

5.5 Análise Clássica . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91

5.6 Discussão dos Resultados . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93

6 Considerações Finais 96

Referências 98

Apêndice A -- Conjunto de Dados da Superliga de Vôlei Masculina 102

Apêndice B -- Conjunto de Dados Longitudinais 103

Apêndice C -- Programas 104

C.1 OPENBUGS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104

C.1.1 Programa - Modelo 1 . . . . . . . . . . . . . . . . . . . . . . . . . . 104

C.1.2 Programa - Modelo 2 . . . . . . . . . . . . . . . . . . . . . . . . . . 105

C.1.3 Programa - Modelo 3 . . . . . . . . . . . . . . . . . . . . . . . . . . 106

C.1.4 Programa - Modelo 4 . . . . . . . . . . . . . . . . . . . . . . . . . . 108

C.2 SAS - Proc NLMIXED . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110



Sumário viii

C.2.1 Programa - Dados Superliga de Vôlei . . . . . . . . . . . . . . . . . 110

C.2.2 Programa - Dados Longitudinais (qualidade do leite) . . . . . . . . 110

C.3 R - Modelo de Regressão Dirichlet . . . . . . . . . . . . . . . . . . . . . . . 111



1

1 Introdução

O estudo adequado da teoria de dados composicionais desenvolveu-se na década de 80
após os trabalhos de Aitchison e Shen [7] e Aitchison [2], que contribuiram com alguns dos
princípios necessários para a análises de dados composicionais e com a natureza especial
do seu espaço amostral.

Desde então, a metodologia de dados composicionais vem sendo aplicada em estudos
de diversas áreas do conhecimento, com ênfase na geologia, ciências do solo, ciências
sociais, medicina, genética, entre outras.

Segundo Aitchison [3], os dados composicionais são definidos como um vetor x com
elementos positivos x1, . . . ,xG que representam proporções de um “todo”, tais que a soma
de todos os elementos do vetor é igual a um, ou seja, x1 +. . .+xG = 1, em que G representa
o número total de componentes dos dados composicionais.

Os métodos multivariados usuais raramente são adequados para a análise de dados
composicionais e há uma carência relativa de técnicas alternativas adequadas para o
mesmo. Além disso, a presença de covariáveis acrescenta a complexidade da situação,
de acordo com Iyengar e Dey [28].

O espaço amostral denominado Simplex desempenha um papel importante quando
se requer interpretações para esses dados. A definição do espaço amostral dos dados
composicionais no Simplex, denotado por SG?1 é dado por,

SG?1 = {(x1, . . . ,xG) : x1 &gt; 0, . . . ,xG &gt; 0; x1 + . . . + xG = 1}.

Dessa forma, podemos denominar um vetor x no espaço Simplex como uma compo-
sição, os elementos desse vetor como componentes e o conjunto dos vetores são definidos
como dados composicionais [2].

O tratamento estatístico para esse tipo de dados mostra-se complicado devido à au-



1 Introdução 2

sência de conceitos de independência e de classes paramétricas no Simplex.

Com isso, várias distribuições têm sido sugeridas para a modelagem de dados com-
posicionais, dentre elas a distribuição Dirichlet Dg(?) no espaço amostral Sg, em que
g = G? 1 é definida por

?(?1 + . . . + ?g+1)
?(?1) . . . ?(?g+1)

x?1?11 . . .x
?g?1
g (1 ?x1 ? . . .?xg)

?g+1?1

em que x ? Sg, ? ? Rg+1+ e ?(.) é a função Gama.

Porém, segundo Aitchison [3], a estrutura de correlação de uma composição Dirichlet
é completamente negativa, com corr(xi,xj) &amp;lt;0 para todo i 6= j. Assim, tornando-a
inadequada para o padrão dos dados composicionais, os quais possuem algumas de suas
correlações definitivamente positivas.

Nesse contexto, novas alternativas para satisfazer as restrições existentes na análise de
dados composicionais é proposto em Aitchison [2] através de transformações adequadas
que levam do espaço amostral restrito Sg para o espaço bem definido Rg.

A ideia sobre a indução de classes de distribuições bem estabelecidas em espaços
amostrais complicados é antiga, sendo que em McAlister [35] considerou y ? R com dis-
tribuição N(µ,?2) expressando a sua ideia em termos de inversa, ou seja, a transformação
y = log(x) induziu a uma distribuição ?(µ,?2) nos R+, denotando essa nova classe de
distribuições lognormal.

Aitchison e Shen [7] desenvolveram a classe de distribuições Normal-logística a qual
induziu de Sg para a classe de distribuições Ng(µ, ?) dos Rg através da transformação
logaritmo da Razão (alr) e apresentaram a simplicidade da sua aplicação em vários pro-
blemas.

Na Tabela 1.1, apresentamos outras duas transformações elementares: a logística
multiplicativa e a logística híbrida, além da transformação alr já citada.



1 Introdução 3

Tabela 1.1: Transformações logísticas elementares de Sg para Rg.

Transformações Inversas

logaritmo da razão alr yi = log
xi
xg+1

logística multiplicativa yi = log
xi

1 ?
i?

k=1
xk

logística híbrida
y1 = log

x1
1 ?x1

;

yi = log
xi(

1 ?
i?1?
k=1

xk

)(
1 ?

i?
k=1

xk

), i = 2, . . . ,g

Recentemente, alguns trabalhos sobre a aplicação da teoria de dados composicionais
vêm sendo desenvolvidos. Por exemplo, podemos citar o trabalho de Aitchison e Greenacre
[6] que desenvolveram técnicas de biplots composicionais sendo um avanço importante
no estudo de dados composicionais, pois a sua adaptação é simples e representa uma
ferramenta útil e exploratória.

Em Hijazi e Jernigan [27], considerou-se uma comparação entre os modelos de re-
gressão Dirichlet e a transformação logaritmo da razão (alr) para averiguar qual deles
se adequam melhor na presença de uma covariável observada, concluindo que o modelo
de regressão Dirichlet é uma alternativa à transformação alr para o conjunto de dados
analisado no artigo e, que além disso, parece controlar a variabilidade do componente de
uma forma mais verdadeira. Em Gueorguieva et al. [24] aplicou-se o modelo de regressão
Dirichlet em dados médicos, mais especificamente, em dados psiquiátricos.

Os métodos Bayesianos tornaram-se uma alternativa relevante para a análise de dados
composicionais, considerando ainda a aplicação dos métodos de Monte Carlo via cadeias
de Markov (MCMC). Sob esse enfoque, um modelo geoestatístico bivariado de dados
composicionais foi proposto por Martins et al. [34]. Achcar e Obage [1] estudaram os
dados composicionais utilizando métodos Bayesianos, considerando as transformações alr
e Box-Cox, em que assumem erros correlacionados com distribuição Normal.

A transformação Box-Cox tem como objetivo contornar problemas relativos a dados
com falta de normalidade, assim essa transformação foi sugerida para dados composi-
cionais em Aitchison [3] e adotada em Rayens e Srinivasan [44, 45] como um meio de
desenvolver modelos mais confiáveis, além de incorporar a transformação alr quando o



1 Introdução 4

parâmetro ? ? 0 (transformação Box-Cox).

Aitchison e Egozcue [5] fizeram um levantamento de trabalhos realizados nessa teoria
durante os últimos vinte anos e sugeriram possibilidades de pesquisas futuras, que venham
a acrescentar o estudo de dados composicionais.

Dentre eles, estão os trabalhos relacionados a análise de dados composicionais com
a presença de componentes iguais a zero, que representa um dos principais obstáculos
enfrentados quando aplica-se a transformação alr e o modelo de regressão Dirichlet, de
acordo com Hijazi [26], em que propôs uma nova técnica baseada no algoritmo EM para
substituir os componentes de valor zero sob o modelo de regressão Dirichlet. Podemos
citar outros trabalhos que abordaram a presença de componentes igual a zero, sendo eles
Martín-Fernández et al. [33] e Neocleous et al. [39].

Em virtude do exposto, existe a necessidade de mais estudos acerca da teoria, princi-
palmente em modelos de regressão para dados composicionais.

Deste modo, o objetivo principal do presente trabalho é a aplicação da transforma-
ção dos dados composicionais, sendo elas a transformação alr e Box-Cox, realizando uma
comparação entre elas e aplicando a metodologia proposta em dois conjuntos de dados,
em que vale ressaltar que a abordagem de dados composicionais na análise desses dados
é inédita. Utilizamos os métodos Bayesianos considerando métodos de Monte Carlo via
cadeias de Markov (MCMC), aplicando os algoritmos amostrador de Gibbs e Metropolis-
Hastings nos modelos propostos. Além disso, os resultados obtidos dos modelos em que
foram aplicados a transformação alr são comparados aos obtidos pelos métodos de infe-
rência clássica e aos obtidos com o modelo de regressão Dirichlet clássico (conforme em
Hijazi e Jernigan [27]).

O trabalho está organizado da seguinte maneira. No Capítulo 2, apresentamos uma
síntese dos métodos Bayesianos, descrevendo alguns conceitos importantes como a estima-
ção pontual e intervalar, o diagnóstico de convergência de Geweke e o critério de seleção
de modelos DIC.

No Capítulo 3, apresentamos as definições das transformações alr, Box-Cox e o modelo
de regressão Dirichlet aplicados em dados composicionais.

No Capítulo 4, aplicamos uma análise Bayesiana em modelos de regressão utilizando
os métodos MCMC, mais especificamente, o amostrador de Gibbs e o algoritmo de
Metropolis-Hastings, utilizando as transformações alr e Box-Cox para dados composi-
cionais considerando erros não correlacionados com distribuição Normal, sendo que para



1 Introdução 5

efeito de comparação, foram calculadas as estimativas dos parâmetros dos modelos pro-
postos através da inferência clássica, e também para o modelo de regressão Dirichlet
clássico. O conjunto de dados reais trata-se de 128 jogos da Superliga de Vôlei Masculina
Brasileira 2011/2012.

No Capítulo 5, apresentamos uma análise Bayesiana em modelos de regressão utili-
zando os métodos MCMC, aplicando as transformações alr e Box-Cox ao conjunto de
dados longitudinais referente a um experimento de tentativa de melhora na qualidade do
leite de vaca, nas quais trinta vacas receberam composições de dieta diferentes antes e de-
pois de uma dieta controlada. Inserimos um efeito aleatório no primeiro modelo proposto
para capturar a dependência entre as medidas repetidas para cada indivíduo e no segundo
modelo introduzimos dois efeitos aleatórios, sendo um efeito para capturar a dependência
entre as medidas repetidas para o grupo 1 (antes de receber a dieta) e o segundo efeito
para capturar a dependência entre as medidas repetidas para o grupo 2 (depois de receber
a dieta). Da mesma forma que no Capítulo 4, apresentamos as estimativas dos parâmetros
através da inferência clássica e do modelo de regressão Dirichlet clássico.

Por fim, no Capítulo 6, apresentamos as principais considerações dos resultados obti-
dos no trabalho e algumas sugestões para pesquisas futuras.



6

2 Introdução aos Métodos
Bayesianos

Os métodos Bayesianos tornaram-se uma ferramenta importante em modelagem es-
tatística e análise de dados, pois ao contrário da inferência clássica, não fazem uso da
teoria assintótica [19]. Dessa forma, podemos considerar que a inferência Bayesiana é
uma alternativa interessante em relação à inferência clássica. A principal diferença entre
as teorias é que a inferência Bayesiana trata um parâmetro qualquer, denotado por ?
como uma variável aleatória, assumindo que possui uma distribuição de probabilidade,
que é caracterizada com uma distribuição a priori, denotada por p(?). Esta distribuição
deve representar (probabilisticamente) o conhecimento que se tem sobre o parâmetro ?
antes da realização do experimento, ou seja, através de prioris informativas, em que se
conhecem previamente os parâmetros de interesse; e de prioris não-informativas, onde há
pouco ou nenhum conhecimento acerca dos parâmetros de interesse.

A fundamentação da teoria de inferência Bayesiana é baseada no teorema de Bayes,
que associa a função de verossimilhança (informação oriunda dos dados) e a distribuição
a priori de ? (informação prévia de ?). Logo, estas duas fontes de informações são
combinadas resultando na distribuição denominada distribuição a posteriori de ?. Como
a distribuição a posteriori contém toda informação de ?, partindo dela podemos realizar
processos inferenciais para a obtenção de informações referente à ?.

2.1 Teorema de Bayes

Considere uma quantidade de interesse desconhecida ? (tipicamente não observável).
A informação de que dispomos sobre ?, resumida probabilisticamente através de p(?),
pode ser aumentada observando-se uma quantidade aleatória X relacionada com ?. A
distribuição amostral p(x|?) define esta relação. A ideia de que após observar X = x a
quantidade de informação sobre ? aumenta é bastante intuitiva e o teorema de Bayes é a



2.2 Distribuições a Priori e a Posteriori 7

regra de atualização utilizada para quantificar este aumento de informação,

p(?|x) =
p(?,x)
p(x)

=
p(x|?)p(?)
p(x)

=
p(x|?)p(?)?
p(?,x)d?

Podemos notar que 1/p(x) não depende de ?, podendo ser considerado como uma
constante normalizadora de p(?|x). Para um valor fixo de x, a função L(?; x) = p(x|?)
fornece a verossimilhança de cada um dos possíveis valores de ? enquanto que p(?) é
chamada de distribuição a priori de ?. Associando estas duas fontes de informação,
obtemos a distribuição a posteriori de ?, p(?|x). Assim, podemos reescrever o teorema de
Bayes, sob o ponto de vista Bayesiano, da seguinte forma

p(?|y) ? L(?)p(?),

em que y refere-se ao conjunto de observações de x.

2.2 Distribuições a Priori e a Posteriori

A utilização de informação a priori em inferência Bayesiana requer a especificação
de uma distribuição a priori para a quantidade de interesse ?. Esta distribuição deve
representar (probabilisticamente) o conhecimento que se tem sobre ? antes da realização
do experimento.

Dessa forma, obtendo informação a priori do pesquisador, podemos aplicar distribui-
ções a priori informativas. Entretanto, podemos nos deparar com situações em que não
possuímos informações suficientes a priori sobre ?, assim especificamos distribuições a
priori não informativas. Nesse contexto, é natural que diferentes pesquisadores possam
ter diferentes graus de incerteza sobre ? (especificando modelos distintos).

Por outro lado, a distribuição a posteriori contém toda a informação do parâmetro
a ser estimado ?, pois é resultado da combinação da distribuição a priori e a função de
verossimilhança, podendo assim realizar processos inferenciais para obter informações a
respeito de ?. Estes processos inferenciais envolvem a integração de funções, muitas vezes
complexas, em que o núcleo da densidade a posteriori não apresenta forma conhecida e,
portanto, tornando a utilização de métodos numéricos importantes para a aproximação



2.3 Diagnóstico de Convergência 8

da distribuição a posteriori de interesse.

Nas últimas décadas, as técnicas de simulação estocástica mais utilizadas foram as
técnicas de Monte Carlo via cadeias de Markov (MCMC) que contribuiram para a pro-
pagação e desenvolvimento da teoria Bayesiana.

Na inferência Bayesiana, a metodologia MCMC é uma alternativa aos métodos não
iterativos em problemas complexos, sendo que possui a vantagem de obter a amostra da
densidade desejada e apresentando grande importância devido a alta complexidade das
densidades a posteriori. Entre os métodos MCMC mais utilizados temos: o algoritmo de
Metropolis-Hastings e o amostrador de Gibbs.

O algoritmo de Metropolis-Hastings foi inicialmente proposto por Metropolis et al. [37]
e generalizado por Hastings [25]. O propósito do método é obter amostras das distribui-
ções condicionais que não apresentam formas conhecidas. Caso tenhamos distribuições
condicionais com formas conhecidas, podemos utilizar o método amostrador de Gibbs,
que é um caso especial do algoritmo de Metropolis-Hastings. O amostrador de Gibbs foi
introduzido por Geman e Geman [22] e tornou-se popular através de Gelfand e Smith [20].

2.3 Diagnóstico de Convergência

O diagnóstico da convergência das cadeias das amostras das distribuições a posteriori
de interesse é um importante procedimento para investigar quando aplica-se os algoritmos
MCMC. Existem métodos formais e informais de identificação e monitoração de conver-
gência (ver por exemplo, Gamerman e Lopes [18]).

Os métodos informais são baseados nas técnicas gráficas em que analisa-se a trajetória
das cadeias geradas e verifica se houve convergência para o mesmo ponto de estabilidade.
Porém, essas técnicas devem ser utilizadas com cautela, e devem ser acompanhadas de
alguma fundamentação teórica.

Os métodos formais diagnosticam a convergência baseados na exploração de propri-
edades estatísticas da cadeia observada. Muitos testes de diagnóstico formais têm sido
desenvolvidos na literatura, dentre eles o diagnóstico proposto por Geweke [23].

2.3.1 Diagnóstico de Geweke

Geweke [23] propôs um diagnóstico de convergência baseado na aplicação de técnicas
usuais em séries temporais para checar convergência da cadeia gerada. Seja um número



2.4 Estimação 9

n suficientemente grande de iterações. O objetivo é testar a igualdade das médias ?a
e ?b calculadas através das na primeiras iterações e nb últimas iterações. Se a cadeia é
estacionária, logo a média ?a deverá ser similar à média ?b.

Considerando que V? ar(?a) e V? ar(?b) são os respectivos estimadores das variâncias
assintóticas de ?a e ?b, assumindo que as razões na/n e nb/n são fixas e n ??, pode-se
mostrar que,

zG =
?a ??b?

V? ar(?a) + V? ar(?b)
d? N(0, 1).

Assim, valores extremos para a diferença padronizada entre as médias ergódicas in-
dicam falta de convergência. Ou seja, mais especificamente, parâmetros com |zG| &gt; 1, 96
indicam não convergência da cadeia. Geweke [23] sugeriu o uso dos valores na = 0, 1n e
nb = 0, 5n para tentar fornecer um diagnóstico poderoso.

2.4 Estimação

Há a necessidade de resumir a informação contida na distribuição a posteriori através
de valores numéricos. O caso mais simples é a estimação pontual de ? na qual resume
toda a distribuição a posteriori em um único valor, denotado por ??.

Outra forma de sumarizar a informação contida é através de intervalos que fornecem
a região de credibilidade de valores de ?. A seguir são apresentados os conceitos de
estimação pontual e por intervalos sob o ponto de vista Bayesiano.

2.4.1 Estimação Pontual

Um estimador Bayesiano para ? dado por ?? = d(x) é obtido ao minimizar o erro espe-
rado (função de risco) com respeito à distribuição a posteriori para ?. Vamos considerar
uma função de perda quadrática dada por

L(d; ?) = (d(x) ??)2.

Assim, devemos encontrar d(x) que minimiza o risco Bayesiano definido como



2.5 Critério de Seleção de Modelos 10

R(d(x); ?) = E?|x[L(d; ?)]

=
?
?
(d(x) ??)2?(?|x)d?.

Sendo d(x) uma função diferenciável, o estimador de Bayes com respeito à função de
perda quadrática é dada por

dR(d(x); ?)
d(d)

= 2
?

(d(x) ??)?(?|x)d? = 0,

ou seja, ?? = d(x) = E(?|x), que é a média a posteriori de ?.

2.4.2 Estimação por Intervalos

A definição de intervalos de credibilidade a posteriori para ? é dada por:

Seja C ? ?, C caracteriza uma região de 100(1 ? ?)% de credibilidade para ? se
P(? ? C|x) ? 1 ??. Neste caso, 1 ?? é chamado de nível de credibilidade.

Assim, quanto menor for o tamanho do intervalo mais concentrada é a distribuição
do parâmetro, ou seja, o tamanho do intervalo informa sobre a dispersão de ?.

Outro aspecto importante é que os intervalos de credibilidade são invariantes a trans-
formações 1 a 1, ?(?). Ou seja, se C = [a,b] é um intervalo de credibilidade 100(1 ??)%
para ?, então [?(a),?(b)] é um intervalo de credibilidade 100(1 ??)% para ?(?).

2.5 Critério de Seleção de Modelos

O avanço dos métodos MCMC possibilitou a construção de modelos com maior com-
plexidade, fazendo com que a escolha entre os modelos tornasse fundamental na análise
estatística. Vários critérios de seleção de modelos são propostos sob o enfoque Bayesiano.
A seguir destacaremos o critério Deviance Information Criterion (DIC).



2.5 Critério de Seleção de Modelos 11

2.5.1 Critério DIC

Spiegelhalter et al. [46] propuseram o critério DIC considerado como uma generaliza-
ção do critério AIC (Akaike’s Information Criterion), sendo aplicado especialmente em
métodos de Monte Carlo via cadeias de Markov. O critério DIC é baseado na distribuição
a posteriori, denominado desvio, dada por

D(?) = ?2lnL(?),

em que ? é um vetor de parâmetros desconhecidos do modelo e L(?) é a função de
verossimilhança. Dessa forma, o DIC é definido como

DICk = Dk(??) + 2pDk
= Dk + pDk,

em que Dk(??) é o desvio calculado na média a posteriori ?? = E(?|x), pDk = Dk?Dk(??) é
o número efetivo de parâmetros no k?ésimo modelo e também é associado a complexidade
do modelo, em que Dk = E[Dk(?)|x] é a média a posteriori do desvio que corresponde a
qualidade do ajuste dos dados ao modelo.

Assim, menores valores do DIC indicam o melhor ajuste do modelo e esses valores
podem ser negativos.



12

3 Transformações e Modelo de
Regressão Dirichlet para Dados
Composicionais

Neste capítulo, apresentamos as transformações logaritmo da razão (alr) e Box-Cox
em dados composicionais para modelos de regressão na presença de uma covariável pro-
posto em Iyengar e Dey [28]. Além disso, também descrevemos o modelo de regressão
Dirichlet proposto em Hijazi e Jernigan [27], em que aplicamos a transformação alr para
os dados composicionais e os parâmetros para esse modelo foram estimados através da in-
ferência clássica nos dois conjuntos de dados apresentados com o objetivo de compararmos
os resultados obtidos com o enfoque Bayesiano.

3.1 Transformações Logaritmo da Razão (alr ) e Box-
Cox

Para este trabalho, utilizamos a aplicação de modelos de regressão em dados compo-
sicionais, na qual a variável resposta do modelo é o vetor com as proporções dos compo-
nentes e zi é o vetor das variáveis explicativas (covariável). A restrição existente da soma
dos componentes do vetor da variável resposta ser igual a um é o que difere dos outros
modelos de regressão.

Dessa forma, podemos considerar o modelo de regressão (ver por exemplo, Iyengar e
Dey [28]) dado por

yi = ?0 + zi?1 + ?i, para i = 1, . . . ,n, (3.1)

em que zi é um vetor (1 ×p) de covariáveis associadas à i-ésima amostra; ?0 é um vetor
(1 × g) de interceptos; ?1 é um vetor (p × g) de coeficientes de regressão; ?i é o vetor



3.2 Modelo de Regressão Dirichlet 13

de erros, yi = (yi1, . . . ,yig) é um vetor (1 × g) em que g = G? 1, sendo G o número de
componentes dos dados composicionais.

De acordo com Achcar e Obage [1], podemos considerar yij = H(xij/xiG), i = 1, ...,n
e j = 1, ...,g, sendo H(•) a função de transformação escolhida para assegurar que o vetor
resultante tenha componentes reais, em que xij representa a i-ésima observação para o

j-ésimo componente, tal que xi1 &gt; 0, . . . ,xiG &gt; 0 e
G?
j=1

xij = 1, para i = 1, ...,n.

A transformação logaritmo da razão (alr) para a análise de dados composicionais é
dada por

yij = H
(
xij
xiG

)
= log

(
xij
xiG

)
. (3.2)

Alternativamente, podemos utilizar a transformação Box-Cox em dados composicio-
nais, que é dada por

yij = H
(
xij
xiG

)
=

????????
???????

( xij
xiG

)?j ? 1
?j

se ?j 6= 0,

log
(
xij
xiG

)
se ?j = 0.

(3.3)

Nota-se que a transformação alr é um caso especial da transformação Box-Cox quando
? = 0.

Deve-se enfatizar que para o modelo de regressão composicional, a permutação é inva-
riante, ou seja, uma diferente escolha do componente no denominador da transformação
alr ou Box-Cox conduzirá à resultados compatíveis. Neste trabalho, utilizamos como
denominador o último componente de ambos os conjuntos de dados aplicados.

3.2 Modelo de Regressão Dirichlet

Campbell e Mosimann [12] abordaram uma extensão da distribuição Dirichlet para
uma classe de modelos de regressão Dirichlet. Eles mostraram que essa classe de modelos
pode ser desenvolvida através de reparametrização dos parâmetros da distribuição Diri-
chlet em termos da covariável associada e, além disso, que a estrutura de covariância para



3.2 Modelo de Regressão Dirichlet 14

os modelos de regressão Dirichlet não são necessariamente negativos, como no caso da
distribuição Dirichlet [27].

Assim, podemos assumir x = (xi1, . . . ,xiG) um vetor positivo (1 × G) com distri-
buição Dirichlet com parâmetros positivos (?1, . . . ,?G) em que sua função densidade de
probabilidade é dada por

f(x) =
?
??(?)/ G?

j=1
?(?j)

?
? G?
j=1

x
?j?1
j ,

em que
G?
j=1

xj = 1 e ? =
G?
j=1

?j.

O modelo de regressão Dirichlet é facilmente obtido permitindo que os parâmetros de
uma distribuição Dirichlet mudem com covariáveis associadas [11]. Para um dado vetor
de covariável zi, i = 1, . . . ,n, cada parâmetro ?j pode ser escrito como uma combinação
linear ?(zi) da covariável zi, ou seja,

?j(zi) = zi,1?1,j + zi,2?2,j + . . . + zi,C?C,j = zi?j (3.4)

em que os parâmetros a serem estimados são ? = (?k,j,j = 1, . . . ,G,k = 1, . . . ,C).

Para o presente estudo, podemos reecrever (3.4) da seguinte forma

?j(zi) =
?
i

?
j

zi,1?1,j = zi?j, (3.5)

em que i = 1, . . . ,n e j = 1, . . . ,G.



15

4 Análise Bayesiana para os Dados
da Superliga de Vôlei Masculina

Neste capítulo apresentamos a análise Bayesiana aplicada em modelos de regressão
com dados composicionais que foram ajustadas à um conjunto de dados referente aos jogos
da Superliga de Vôlei Masculina Brasileira 2011/2012 (Apêndice A, disponível em [15]).
Mais especificamente, aos times que jogaram e venceram nos 1o e 2o turnos, nos quais os
pontos do time vencedor de cada jogo foram definidos como composição e os fundamentos
ataque, bloqueio, saque e erro do adversário como proporções de cada composição.

Os pontos do time vencedor em cada jogo é formado por quatro componentes, sendo
que denotamos xi1 como a proporção dos pontos em ataque, xi2 a proporção dos pontos
em bloqueio, xi3 a proporção dos pontos em saque e xi4 a proporção dos pontos em erros
do adversário. A covariável associada ao i-ésimo jogo é definida por

zi =

??
? 1, se o time ganhou pelo menos uma vez a Superliga nos últimos 12 anos0, caso contrário.

O objetivo é verificar se há dependência entre as proporções dos componentes (ataque,
bloqueio, saque, erro adversário) e se o time que venceu o i-ésimo jogo já venceu pelo
menos uma vez a Superliga nos últimos 12 anos.

Na Figura 4.1 apresentamos os componentes dos pontos dos jogos de vôlei da Superliga
de acordo com a covariável associada, sendo que 0 representa que o time não ganhou
nenhuma vez a Superliga de vôlei e 1 representa que o time já ganhou pelo menos uma vez
nos últimos 12 anos. Observando-a, percebe-se que apenas para o componente bloqueio
há evidência de uma pequena diferença entre os times que não venceram e os times que
já venceram a Superliga.



4.1 Transformação alr - Modelo 1 16

0 1

0.
0

0.
1

0.
2

0.
3

0.
4

0.
5

0.
6

ataque

0 1

0.
0

0.
1

0.
2

0.
3

0.
4

0.
5

0.
6

bloqueio

0 1

0.
0

0.
1

0.
2

0.
3

0.
4

0.
5

0.
6

saque

0 1

0.
0

0.
1

0.
2

0.
3

0.
4

0.
5

0.
6

erro.adversário

Figura 4.1: Box plots para os componentes dos pontos dos times da Superliga de vôlei.

4.1 Transformação alr - Modelo 1

Para análise dos dados composicionais apresentados no Apêndice A, xi1, xi2, xi3 e
xi4, para i = 1, . . . ,n, consideramos a transformação alr apresentada em (3.2). Com isso,
obtemos

yi1 = log
(
xi1
xi4

)
, yi2 = log

(
xi2
xi4

)
e yi3 = log

(
xi3
xi4

)
.

Conforme apresentado em (3.1), o modelo de regressão para os dados transformados
yi1, yi2 e yi3, denominado por modelo 1, é dado por

yi1 = ?01 + ?11zi + ?i1,

yi2 = ?02 + ?12zi + ?i2 e (4.1)

yi3 = ?03 + ?13zi + ?i3,

em que yi representa a proporção transformada dos pontos do j-ésimo componente (ata-
que, bloqueio, saque, erro adversário) no i-ésimo jogo, zi é uma variável dummy, em que
zi = 0 indica que o time não venceu a Superliga e zi = 1 indica que o time já ganhou
pelo menos uma vez a Superliga nos últimos 12 anos. Além disso, ?0j representa a média



4.1 Transformação alr - Modelo 1 17

da proporção de pontos no j-ésimo componente em relação ao componente xi4 erro do
adversário para o time que não venceu a Superliga, ?1j indica se há ou não efeito da
covariável associada ao i-ésimo jogo e ?i representa o vetor de erros.

Assumiremos ?i ? N(0, ?), em que 0 é o vetor de zeros e ? é a matriz de variâncias
e covariâncias especificada por

? =

?
????
?21 0 0
0 ?22 0
0 0 ?23

?
???? .

Considerando o modelo apresentado em (4.1), assumiremos que os erros ?i1, ?i2 e ?i3
são mutuamente independentes. Desta forma, obtém-se

?i1 = yi1 ??01 ??11zi,

?i2 = yi2 ??02 ??12zi e

?i3 = yi3 ??03 ??13zi.

Além disso, podemos estimar as proporções dos componentes ?i1,?i2,?i3,?i4, em que
?i1 + ?i2 + ?i3 + ?i4 = 1, com ?i1 &gt; 0,?i2 &gt; 0,?i3 &gt; 0 e ?i4 &gt; 0, quando utiliza a
transformação alr, obtendo a seguinte relação a partir de (4.1)

log
(
?i1
?i4

)
= ?01 + ?11zi,

log
(
?i2
?i4

)
= ?02 + ?12zi e (4.2)

log
(
?i3
?i4

)
= ?03 + ?13zi.

Aplicando a função exponencial em (4.2), temos que

?i1
?i4

= e?01+?11zi;
?i2
?i4

= e?02+?12zi e
?i3
?i4

= e?03+?13zi,

assim



4.1 Transformação alr - Modelo 1 18

?????
????
?i1 = ?i4(e?01+?11zi)
?i2 = ?i4(e?02+?12zi)
?i3 = ?i4(e?03+?13zi).

(4.3)

Sabemos que ?i1 + ?i2 + ?i3 + ?i4 = 1, ou seja, ?i4 = 1 ? (?i1 + ?i2 + ?i3) ?
?i1 + ?i2 + ?i3 = 1 ??i4.

Então, a partir de (4.3), obtemos a seguinte relação

?i1 + ?i2 + ?i3 = ?i4
(
e?01+?11zi + e?02+?12zi + e?03+?13zi

)
.

Dessa forma, podemos reescrever a expressão 1 ??i4 como

1 ??i4 = ?i4
(
e?01+?11zi + e?02+?12zi + e?03+?13zi

)
?

1 = ?i4
(
1 + e?01+?11zi + e?02+?12zi + e?03+?13zi

)
?

?i4 =
1

(1 + e?01+?11zi + e?02+?12zi + e?03+?13zi)
. (4.4)

Logo, substituindo (4.4) em (4.3), obtemos as proporções verdadeiras dos componentes
para a transformação alr,

?ij =
e?0j+?1jzi

(1 + e?01+?11zi + e?02+?12zi + e?03+?13zi)
e (4.5)

?i4 =
1

(1 + e?01+?11zi + e?02+?12zi + e?03+?13zi)
,

em que i = 1, . . . , 128 e j = 1, 2, 3. De acordo com Achcar e Obage [1], a parametrização
?i1 &gt; 0, ?i2 &gt; 0, ?i3 &gt; 0 e ?i4 &gt; 0 pode ser usada para obter inferências sobre as
composições em cada valor da covariável.

4.1.1 Análise Bayesiana - Modelo 1

A função densidade de probabilidade conjunta de y1,y2,y3 dado o vetor de parâme-
tros ?1 = (?01,?02,?03,?11,?12,?13,?21,?

2
2,?

2
3 ) é dada por



4.1 Transformação alr - Modelo 1 19

f(y1,y2,y3|?1) =
3?
j=1

1?
2??2j

exp
[
?

1
2?2j

(yij ??0j ??1jzi)2
]
,

pois, as suposições de normalidade e independência foram consideradas, e ainda, yij ?
N(?0j + ?1jzi,?2j ), para j = 1, 2, 3 e i = 1, . . . ,n.

Assim, assumindo o modelo (4.1), a função de verossimilhança para os parâmetros
?0 = (?01,?02,?03), ?1 = (?11,?12,?13) e ?2 = (?21,?

2
2,?

2
3 ) é dada por

L(?1) =
3?
j=1

(?2j )
?n/2exp

(
?

1
2?2j

n?
i=1

?2ij

)
, (4.6)

em que
n?
i=1

?2ij =
n?
i=1

(yij ??0j ??1jzi)2, para j = 1, 2, 3.

Para a estimação dos parâmetros do modelo (4.1), as seguintes distribuições a priori
para ?0 = (?01,?02,?03), ?1 = (?11,?12,?13) e ?2 = (?21,?

2
2,?

2
3 ) são consideradas

?0j ? N(a0j,b20j),

?1j ? N(a1j,b21j), (4.7)

?2j ? IG(cj,dj),

em que N(a,b2) denota uma distribuição Normal com média a e variância b2, IG(c,d)
denota uma distribuição Gama inversa com média d/(c?1) e variância d2/[(c?1)2(c?2)],
c &gt; 2; e a0j,b0j,a1j,b1j,cj e dj são hiperparâmetros conhecidos, para j = 1, 2, 3. Além
disso, assumimos independência a priori entre os parâmetros.

Desta forma, a partir do teorema de Bayes que associa a função de verossimilhança
(4.6) com as distribuições a priori (4.7), obtemos a distribuição a posteriori conjunta para
os parâmetros ?0 = (?01,?02,?03), ?1 = (?11,?12,?13) e ?2 = (?21,?

2
2,?

2
3 ) dada por



4.1 Transformação alr - Modelo 1 20

?(?0,?1,?2|y) ?
3?
j=1

exp
[
?

1
2b20j

(?0j ?a0j)2
]
×

3?
j=1

exp
[
?

1
2b21j

(?1j ?a1j)2
]

×
3?
j=1

(?2j )
?(cj+1)exp

(
?
dj
?2j

)
×

3?
j=1

(
?2j
)?n/2

exp
(
?

1
2?2j

n?
i=1

?2ij

)
.

Consequentemente, as distribuições a posteriori condicionais utilizadas para o amos-
trador de Gibbs (Gelfand e Smith [20]) são dadas por:

i) ?(?0j|?1,?2,y) ? exp
[
?

1
2b20j

(?0j ?a0j)
2
]
× exp

[
?

1
2?2j

n?
i=1

(?0j ?µ
(j)
i )

2
]
,

em que µ(j)i = yij ??1jzi; i = 1, . . . ,n e j = 1, 2, 3.

Logo,

?(?0j|?1,?2,y) ? N

?
?????
a0j?

2
j + b0j

n?
i=1

µ
(j)
i

?2j + nb20j
,

b20j?
2
j

?2j + nb20j

?
????? . (4.8)

ii) ?(?1j|?0,?2,y) ? exp
[
?

1
2b2ij

(?1j ?a1j)2
]
× exp

[
?

1
2?2j

n?
i=1

(
?1jzi ??

(j)
i

)2]
,

em que ?(j)i = yij ??0j; i = 1, . . . ,n e j = 1, 2, 3.

Logo,

?(?1j|?0,?2,y) ? N

?
?????
a1j?

2
j + b1j

n?
i=1

zi?
(j)
i

?2j + b21j
n?
i=1

z2i

,
b21j?

2
j

?2j + b21j
n?
i=1

z2i

?
????? . (4.9)



4.1 Transformação alr - Modelo 1 21

iii) ?(?2j |?0,?1,y) ? (?
2
j )
?(cj+1)exp

(
?
dj
?2j

)
× (?2j )

?n/2exp
(
?

1
2?2j

n?
i=1

?2ij

)

? (?2j )
?(cj+n/2+1)exp

[
?

1
?2j

(
dj +

1
2

n?
i=1

?2ij

)]
,

em que ?ij = yij ??0j ??1jzi; i = 1, . . . ,n e j = 1, 2, 3.

Logo,

?(?2j |?0,?1,y) ? IG
[
cj +

n

2
,dj +

1
2

n?
i=1

?2ij

]
. (4.10)

Podemos observar que as distribuições a posteriori condicionais (4.8), (4.9) e (4.10)
apresentaram formas fechadas e, portanto, obtemos as estimativas dos parâmetros do
modelo (4.1) através do algoritmo amostrador de Gibbs. A implementação do algoritmo
foi realizada no software OPENBUGS (Lunn et al., [32]).

Para a análise Bayesiana dos dados apresentados no Apêndice A, considera-se a trans-
formação alr com erros normais não correlacionados para o modelo proposto (4.1).

Assumindo distribuições a priori não informativas para ?0j,?1j,?2j com hiperparâme-
tros cujos valores foram a0j = 0,b0j = b1j = 100,cj = 0, 001 e dj = 0, 001, j = 1, 2, 3,
geramos no software OPENBUGS 210.000 iterações, nas quais foram descartadas as 10.000
iterações iniciais (“burn-in”). Após o período de “‘burn-in”, consideramos saltos de ta-
manho 20 para obtermos amostras não correlacionadas, na qual resultou uma amostra
final de tamanho 10.000 para cada parâmetro. A convergência do algoritmo foi verificada
pelos gráficos dos traços a posteriori das amostras de Gibbs simuladas e pelo diagnóstico
de Geweke (Geweke, [23]) implementado no software R através do pacote CODA.

Na Tabela 4.1 apresentamos os sumários a posteriori dos parâmetros do modelo (4.1)
e os valores correspondentes da estatística de teste para o diagnóstico de convergência
Geweke.

Podemos verificar na Tabela 4.1 que houve efeito significativo do time ter vencido
pelo menos uma vez a Superliga para a proporção de pontos de bloqueio (intervalo de
credibilidade não inclui o zero no parâmetro ?12), sendo que o valor de ?12 é negativo,
indicando que os times que não venceram nenhuma vez a Superliga fizeram mais pontos
no bloqueio.



4.1 Transformação alr - Modelo 1 22

Tabela 4.1: Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke -
Modelo 1.

Parâmetro Média Desvio Intervalo de zGPadrão Credibilidade (95%)
?01 0,622 0,033 (0,557; 0,685) 0,151
?02 -0,989 0,053 (-1,092; -0,886) 0,345
?03 -1,902 0,073 (-2,047; -1,758) 1,925
?11 -0,045 0,047 (-0,139; 0,047) -0,312
?12 -0,171 0,074 (-0,318; -0,024) 0,067
?13 0,013 0,104 (-0,189; 0,219) -1,463
?1 0,070 0,009 (0,054; 0,089) -1,389
?2 0,184 0,024 (0,143; 0,237) -0,536
?3 0,346 0,044 (0,269; 0,440) -0,883

Analisando os interceptos do modelo (Tabela 4.1), observamos que ?01 é positivo,
indicando que a média da proporção do componente ataque em relação ao componente
erro do adversário tem uma tendência crescente, o que não ocorre com os interceptos dos
componentes bloqueio e saque que são negativos, apresentando uma tendência decrescente
em relação ao componente erro do adversário xi4.

A Tabela 4.2 apresenta as estimativas das proporções verdadeiras para os componentes
ataque, bloqueio, saque e erros do adversário para cada valor da covariável zi considerando
a transformação alr. Observamos que as estimativas das proporções para todos os com-
ponentes (ataque, bloqueio, saque e erros do adversário) não houve diferença em relação
aos times terem vencido ou não a Superliga de vôlei, pois apresentaram o mesmo com-
portamento, ou seja, os valores das estimativas foram bem semelhantes, conforme mostra
a Tabela 4.2.

Tabela 4.2: Estimativas das proporções dos componentes - Modelo 1.
Proporções z = 0 z = 1

?1 0,550 0,548
?2 0,110 0,097
?3 0,044 0,047
?4 0,296 0,308

As Figuras 4.2, 4.3 e 4.4 apresentam as densidades a posteriori e o comportamento da
cadeia gerada para os parâmetros do modelo proposto. Através dessas figuras, percebe-
se que há uma certa uniformidade nos traços a posteriori dos parâmetros estimados,
indicando possível convergência. Com a aplicação do diagnóstico de Geweke (Tabela
4.1), verificamos que as cadeias geradas apresentaram convergência, pois os valores da
estatística do teste zG encontram-se no intervalo (-1,96; 1,96).



4.1 Transformação alr - Modelo 1 23

0.50 0.55 0.60 0.65 0.70 0.75

0
2

4
6

8
1

0
1

2

?01

0 1000 2000 3000 4000 5000

0
.5

0
0

.6
0

0
.7

0

Iteração

?1.2 ?1.1 ?1.0 ?0.9 ?0.8

0
1

2
3

4
5

6
7

?02

0 1000 2000 3000 4000 5000

?
1

.1
?

1
.0

?
0

.9
?

0
.8

Iteração

?2.2 ?2.1 ?2.0 ?1.9 ?1.8 ?1.7

0
1

2
3

4
5

?03

0 1000 2000 3000 4000 5000

?
2

.1
?

1
.9

?
1

.7

Iteração

Figura 4.2: Densidades a posteriori e traços a posteriori para os parâmetros de intercepto
do modelo 1.



4.1 Transformação alr - Modelo 1 24

?0.2 ?0.1 0.0 0.1

0
2

4
6

8

?11

0 1000 2000 3000 4000 5000

?
0

.2
0

?
0

.1
0

0
.0

0
0

.1
0

Iteração

?0.4 ?0.3 ?0.2 ?0.1 0.0 0.1

0
1

2
3

4
5

?12

0 1000 2000 3000 4000 5000

?
0

.4
?

0
.2

0
.0

Iteração

?0.4 ?0.2 0.0 0.2 0.4

0
1

2
3

4

?13

0 1000 2000 3000 4000 5000

?
0

.4
?

0
.2

0
.0

0
.2

0
.4

Iteração

Figura 4.3: Densidades a posteriori e traços a posteriori para os parâmetros de inclinação
do modelo 1.



4.2 Transformação Box-Cox - Modelo 2 25

0.04 0.06 0.08 0.10

0
1

0
2

0
3

0
4

0

?1

0 1000 2000 3000 4000 5000

0
.0

5
0

.0
7

0
.0

9
0

.1
1

Iteração

0.10 0.15 0.20 0.25 0.30

0
5

1
0

1
5

?2

0 1000 2000 3000 4000 5000

0
.1

5
0

.2
0

0
.2

5
0

.3
0

Iteração

0.2 0.3 0.4 0.5 0.6

0
2

4
6

8

?3

0 1000 2000 3000 4000 5000

0
.3

0
.4

0
.5

0
.6

Iteração

Figura 4.4: Densidades a posteriori e traços a posteriori para os desvios padrões do
modelo 1.

4.2 Transformação Box-Cox - Modelo 2

Nesta seção, é desenvolvido uma aplicação da transformação Box-Cox (3.3) nos dados
composicionais apresentados no Apêndice A, xi1, xi2, xi3 e xi4, para i = 1, . . . ,n.

Para a obtenção das amostras simuladas a posteriori foram utilizados os métodos
Bayesianos baseados no amostrador de Gibbs e no algoritmo de Metropolis-Hastings.

Considerando a transformação Box-Cox para os dados da Superliga de Vôlei, obtemos



4.2 Transformação Box-Cox - Modelo 2 26

y
(?1)
i1 =

????????
???????

(xi1
xi4

)?1 ? 1
?1

se ?1 6= 0,

log
(
xi1
xi4

)
se ?1 = 0

y
(?2)
i2 =

????????
???????

(xi2
xi4

)?2 ? 1
?2

se ?2 6= 0,

log
(
xi2
xi4

)
se ?2 = 0

y
(?3)
i3 =

????????
???????

(xi3
xi4

)?3 ? 1
?3

se ?3 6= 0,

log
(
xi3
xi4

)
se ?3 = 0.

Vale ressaltar que a transformação alr é um caso especial da transformação Box-Cox
quando ?1 = ?2 = ?3 = 0.

Utilizando os dados transformados y(?1)i1 , y
(?2)
i2 e y

(?3)
i3 , e assumindo o modelo (4.1),

podemos especificar

y
(?1)
i1 = ?01 + ?11zi + ?i1,

y
(?2)
i2 = ?02 + ?12zi + ?i2 e (4.11)

y
(?3)
i3 = ?03 + ?13zi + ?i3.

em que i = 1, . . . , 128 e ?i é o vetor de erros. Da mesma forma, que em (4.2), assumiremos
?i ? N(0, ?), em que 0 é o vetor de zeros e ? é a matriz de variâncias e covariâncias.

Considerando o modelo apresentado em (4.11), assumiremos que os erros ?i1, ?i2 e ?i3
são mutuamente independentes. Assim, obtém-se



4.2 Transformação Box-Cox - Modelo 2 27

?i1 = y
(?1)
i1 ??01 ??11zi,

?i2 = y
(?2)
i2 ??02 ??12zi e

?i3 = y
(?3)
i3 ??03 ??13zi.

As suposições de normalidade e independência foram consideradas, e ainda, y(?j)ij ?
N(?0j + ?1jzi,?2j ), para j = 1, 2, 3 e i = 1, . . . , 128.

Além disso, podemos considerar ?i1,?i2,?i3,?i4 as estimativas das proporções dos
componentes, em que ?i1 + ?i2 + ?i3 + ?i4 = 1, com ?i1 &gt; 0,?i2 &gt; 0,?i3 &gt; 0 e ?i4 &gt; 0,
quando utiliza a transformação Box-Cox, obtendo a seguinte relação a partir de (4.11),

(?i1/?i4)?1 ? 1
?1

= ?01 + ?11zi,

(?i2/?i4)?2 ? 1
?2

= ?02 + ?12zi e (4.12)

(?i3/?i4)?3 ? 1
?3

= ?03 + ?13zi.

Reescrevendo (4.12), temos que

(
?i1
?i4

)?1
= ?1(?01 + ?11zi) + 1 ?

(
?i1
?i4

)?1. 1?1 = [?1(?01 + ?11zi) + 1] 1?1 ,(
?i2
?i4

)?2
= ?2(?02 + ?12zi) + 1 ?

(
?i2
?i4

)?2. 1?2 = [?2(?02 + ?12zi) + 1] 1?2 ,(
?i3
?i4

)?3
= ?3(?03 + ?13zi) + 1 ?

(
?i3
?i4

)?3. 1?3 = [?3(?03 + ?13zi) + 1] 1?3 ,

ou seja,

?i1 = ?i4 [?1(?01 + ?11zi) + 1]
1
?1 ,

?i2 = ?i4 [?2(?02 + ?12zi) + 1]
1
?2 e (4.13)

?i3 = ?i4 [?3(?03 + ?13zi) + 1]
1
?3 .

Sabemos que ?i1 + ?i2 + ?i3 + ?i4 = 1, ou seja, ?i4 = 1 ? (?i1 + ?i2 + ?i3) ?



4.2 Transformação Box-Cox - Modelo 2 28

?i1 + ?i2 + ?i3 = 1 ??i4.

Assim, de (4.13), obtemos a seguinte relação

?i1 + ?i2 + ?i3 = ?i4
{

[?1(?01 + ?11zi) + 1]
1
?1 + [?2(?02 + ?12zi) + 1]

1
?2 + [?3(?03 + ?13zi) + 1]

1
?3

}
,

Dessa forma, podemos reescrever a expressão 1 ??i4 como

1 ??i4 = ?i4
{

[?1(?01 + ?11zi) + 1]
1
?1 + [?2(?02 + ?12zi) + 1]

1
?2 + [?3(?03 + ?13zi) + 1]

1
?3

}
?

1 = ?i4
{

1 + [?1(?01 + ?11zi) + 1]
1
?1 + [?2(?02 + ?12zi) + 1]

1
?2 + [?3(?03 + ?13zi) + 1]

1
?3

}
?

?i4 =
1{

1 + [?1(?01 + ?11zi) + 1]
1
?1 + [?2(?02 + ?12zi) + 1]

1
?2 + [?3(?03 + ?13zi) + 1]

1
?3

}.
(4.14)

Logo, substituindo (4.14) em (4.13), obtemos os estimadores das proporções verda-
deiras dos componentes para a transformação Box-Cox,

?ij =
[?j(?0j + ?1jzi) + 1]

1
?j{

1 + [?1(?01 + ?11zi) + 1]
1
?1 + [?2(?02 + ?12zi) + 1]

1
?2 + [?3(?03 + ?13zi) + 1]

1
?3

} e
?i4 =

1{
1 + [?1(?01 + ?11zi) + 1]

1
?1 + [?2(?02 + ?12zi) + 1]

1
?2 + [?3(?03 + ?13zi) + 1]

1
?3

},
(4.15)

em que i = 1, . . . , 128 e j = 1, 2, 3.

4.2.1 Análise Bayesiana - Modelo 2

A função densidade de probabilidade conjunta de y(?1)1 ,y
(?2)
2 ,y

(?3)
3 dado o vetor de

parâmetros ?2 = (?01,?02,?03,?11,?12,?13,?21,?
2
2,?

2
3,?1,?2,?3) é dada por

f(y(?1)1 ,y
(?2)
2 ,y

(?3)
3 |?2) =

3?
j=1

1?
2??2j

exp
[
?

1
2?2j

(
y

(?j)
ij ??0j ??1jzi

)2]
.



4.2 Transformação Box-Cox - Modelo 2 29

Por outro lado, a função densidade de probabilidade das observações não transforma-
das (variáveis originais) [Box &amp;amp; Tiao [9]], yi1 = xi1/xi4, yi2 = xi2/xi4 e yi3 = xi3/xi4 é
dada por

f(y1,y2,y3|?2) =
3?
j=1

1?
2??2j

exp
[
?

1
2?2j

(
y

(?j)
ij ??0j ??1jzi

)2]??dy(?j)ij
dyij

?
? ,

em que
dy(?j)ij
dyij

=
?jy

?j?1
ij

?j
= y?j?1ij são os elementos da diagonal da matriz Jacobiano, para

j = 1, 2, 3 .

Assim, assumindo o modelo (4.11), a função de verossimilhança para os parâmetros
?0 = (?01,?02,?03), ?1 = (?11,?12,?13), ?2 = (?21,?

2
2,?

2
3 ) e ? = (?1,?2,?3) é dada por

L(?0,?1,?2,?) =
3?
j=1

[
(?2j )

?n/2
(

n?
i=1

y
?j?1
ij

)
exp

(
?

1
2?2j

n?
i=1

?2ij

)]
, (4.16)

em que
(

n?
i=1

y
?j?1
ij

)
são os produtos do Jacobiano, e

?ij = y
(?j)
ij ??0j ??1jzi em que y

(?j)
ij =

(xij/xi4)?j ? 1
?j

se ?j 6= 0, para j = 1, 2, 3.

Para a estimação dos parâmetros do modelo (4.11), as seguintes distribuições a priori
para ?0 = (?01,?02,?03), ?1 = (?11,?12,?13), ?2 = (?21,?

2
2,?

2
3 ) e ? = (?1,?2,?3) são

consideradas,

?0j ? N(a0j,b20j),

?1j ? N(a1j,b21j),

?2j ? IG(cj,dj) e (4.17)

?j ? N(ej,f2j ),

em que N(a,b2) denota uma distribuição Normal com média a e variância b2, IG(c,d)
denota uma distribuição Gama inversa com média d/(c?1) e variância d2/[(c?1)2(c?2)],
c &gt; 2; e a0j,b0j,a1j,b1j,cj, dj, ej e fj são hiperparâmetros conhecidos, para j = 1, 2, 3.
Para este caso, também assumimos independência a priori entre os parâmetros.



4.2 Transformação Box-Cox - Modelo 2 30

Desta forma, a partir do teorema de Bayes que associa a função de verossimilhança
(4.16) com as distribuições a priori (4.17), obtemos a distribuição a posteriori conjunta
para os parâmetros ?0 = (?01,?02,?03), ?1 = (?11,?12,?13), ?2 = (?21,?

2
2,?

2
3 ) e ? =

(?1,?2,?3) que é dada por

?(?0,?1,?2,?|y(?)) ?
3?
j=1

exp
[
?

1
2b20j

(?0j ?a0j)2
]
×

3?
j=1

exp
[
?

1
2b21j

(?1j ?a1j)2
]

×
3?
j=1

(?2j )
?(cj+1)exp

(
?
dj
?2j

)
×

3?
j=1

exp
[
?

1
2f2j

(?j ?ej)2
]

×
(

n?
i=1

y?1?1i1

)(
n?
i=1

y?2?1i2

)(
n?
i=1

y?3?1i3

) 3?
j=1

(
?2j
)?n/2

exp
(
?

1
2?2j

n?
i=1

?2ij

)
.

(4.18)

Considerando a distribuição a posteriori conjunta (4.18), as distribuições a posteri-
ori condicionais utilizadas para o amostrador de Gibbs (Gelfand e Smith [20]) e para o
algoritmo de Metropolis-Hastings são dadas por:

i) ?(?0j|?1,?2,?,y(?)) ? exp
[
?

1
2b20j

(?0j ?a0j)
2
]
× exp

[
?

1
2?2j

n?
i=1

(?0j ?µ
(j)
i )

2
]
,

em que µ(j)i = y
(?j)
ij ??1jzi; i = 1, . . . ,n e j = 1, 2, 3.

Logo,

?(?0j|?1,?2,?,y(?)) ? N

?
?????
a0j?

2
j + b0j

n?
i=1

µ
(j)
i

?2j + nb20j
,

b20j?
2
j

?2j + nb20j

?
????? . (4.19)

ii) ?(?1j|?0,?2,?,y(?)) ? exp
[
?

1
2b2ij

(?1j ?a1j)2
]
× exp

[
?

1
2?2j

n?
i=1

(
?1jzi ??

(j)
i

)2]
,

em que ?(j)i = y
(?j)
ij ??0j; i = 1, . . . ,n e j = 1, 2, 3.

Logo,



4.2 Transformação Box-Cox - Modelo 2 31

?(?1j|?0,?2,?,y(?)) ? N

?
?????
a1j?

2
j + b1j

n?
i=1

zi?
(j)
i

?2j + b21j
n?
i=1

z2i

,
b21j?

2
j

?2j + b21j
n?
i=1

z2i

?
????? . (4.20)

iii) ?(?2j |?0,?1,?,y
(?)) ? (?2j )

?(cj+1)exp
(
?
dj
?2j

)
× (?2j )

?n/2 × exp
(
?

1
2?2j

n?
i=1

?2ij

)

? (?2j )
?(cj+n/2+1)exp

[
?

1
?2j

(
dj +

1
2

n?
i=1

?2ij

)]
,

em que ?ij = y
(?j)
ij ??0j ??1jzi; i = 1, . . . ,n e j = 1, 2, 3.

Logo,

?(?2j |?0,?1,?,y
(?)) ? IG

[
cj +

n

2
,dj +

1
2

n?
i=1

?2ij

]
. (4.21)

iv) ?(?j|?0,?1,?2,y(?)) ? exp
[
?

1
2f2j

(?j ?ej)2
]
?j(?0,?1,?2,?), (4.22)

em que

?j(?0,?1,?2,?) = exp
[
(?j ? 1)

n?
i=1

ln yij +
1
?2j

n?
i=1

(
y

(?j)
ij ? (?0j + ?1j)

)2]

= exp
[
(?j ? 1)

n?
i=1

ln yij +
1
?2j

(
n?
i=1

y
(?j)2
ij ? 2?0j

n?
i=1

y
(?j)
ij ? 2?1j

n?
i=1

y
(?j)
ij zi

)]

e j = 1, 2, 3.

Podemos observar que as distribuições a posteriori condicionais (4.19), (4.20) e (4.21)
apresentaram formas fechadas e, portanto, obtemos as estimativas dos parâmetros do
modelo (4.11) através do algoritmo amostrador de Gibbs. Por outro lado, para a distri-
buição a posteriori condicional (4.22) utilizamos o algoritmo de Metropolis-Hastings, por
não apresentar forma fechada.

Assim, considerando a transformação Box-Cox com erros normais não correlaciona-
dos para o modelo (4.11), assumimos as distribuições a priori não informativas para



4.2 Transformação Box-Cox - Modelo 2 32

?0j,?1j,?
2
j , ?j com hiperparâmetros cujos valores foram a0j = a1j = ej = 0,b0j = b1j =

1.000,cj = 0, 01, dj = 0, 01 e fj = 100, j = 1, 2, 3, geramos no software OPENBUGS
210.000 iterações, em que foram descartadas as 10.000 iterações iniciais (“burn-in”). Após
o período de “‘burn-in”, consideramos saltos de tamanho 20 para obtermos amostras não
correlacionadas, na qual resultou uma amostra final de tamanho 10.000 para cada parâ-
metro. A convergência do algoritmo foi verificada pelos gráficos dos traços a posteriori
das amostras de Gibbs simuladas e pelo diagnóstico de Geweke implementado no software
R através do pacote CODA.

Na Tabela 4.3 apresentamos os sumários a posteriori dos parâmetros do modelo (4.11)
e os valores correspondentes da estatística de teste para o diagnóstico de convergência
Geweke.

Tabela 4.3: Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke -
Modelo 2.

Parâmetro Média Desvio Intervalo de zGPadrão Credibilidade (95%)
?01 0,632 0,068 (0,515; 0,780) 0,716
?02 -1,014 0,128 (-1,297; -0,798) 0,210
?03 -1,830 0,266 (-2,428; -1,380) -1,449
?11 -0,034 0,050 (-0,136; 0,065) -1,118
?12 0,006 0,072 (-0,135; 0,153) 0,327
?13 0,133 0,103 (-0,044; 0,363) -0,304
?1 0,078 0,026 (0,040; 0,143) 0,434
?2 0,164 0,073 (0,067; 0,349) 0,533
?3 0,275 0,157 (0,088; 0,680) 1,241
?1 0,043 0,244 (-0,441; 0,523) 0,570
?2 0,113 0,183 (-0,246; 0,466) -0,180
?3 0,089 0,131 (-0,167; 0,350) -1,706

Os resultados da Tabela 4.3 apresentam os sumários a posteriori dos parâmetros
estimados do modelo (4.11). Podemos verificar que não houve efeito significativo para
nenhuma proporção de pontos de ataque, bloqueio e saque (o intervalo de credibilidade
inclui o zero nos parâmetros ?11, ?12 e ?13). Também, os intervalos de credibilidade
para os parâmetros ?j, j = 1, 2, 3 está incluído o valor zero, ou seja, como a aplicação da
transformação Box-Cox é um caso especial da transformação alr quando ? = 0, indica que
a transformação alr é mais adequada para esses dados do que a transformação Box-Cox.

A Tabela 4.4 apresenta as estimativas das proporções verdadeiras para os componentes
ataque, bloqueio, saque e erros do adversário para cada valor da covariável zi considerando
a transformação Box-Cox. Da mesma forma que na transformação alr, não houve diferença



4.2 Transformação Box-Cox - Modelo 2 33

em relação aos times terem vencido ou não a Superliga de vôlei para as estimativas das
proporções para todos os componentes (ataque, bloqueio, saque e erros do adversário).

Tabela 4.4: Estimativas das proporções dos componentes - Modelo 2.
Proporções z = 0 z = 1

?1 0,558 0,546
?2 0,102 0,104
?3 0,041 0,048
?4 0,299 0,302

As Figuras 4.5, 4.6, 4.7 e 4.8 apresentam as densidades a posteriori e o comporta-
mento da cadeia gerada para os parâmetros do modelo (4.11). Podemos observar que
os traços a posteriori apresentaram certa uniformidade, indicando possível convergência,
sendo confirmado através do diagnóstico de Geweke (Tabela 4.3) em que para todos os
parâmetros os valores do teste zG encontram-se no intervalo (-1,96; 1,96).



4.2 Transformação Box-Cox - Modelo 2 34

0.4 0.5 0.6 0.7 0.8 0.9 1.0

0
1

2
3

4
5

?01

0 2000 4000 6000 8000 10000

0
.5

0
.7

0
.9

Iteração

?1.4 ?1.2 ?1.0 ?0.8 ?0.6

0
1

2
3

?02

0 2000 4000 6000 8000 10000

?
1

.4
?

1
.2

?
1

.0
?

0
.8

Iteração

?3.0 ?2.5 ?2.0 ?1.5 ?1.0

0
.0

0
.5

1
.0

1
.5

?03

0 2000 4000 6000 8000 10000

?
3

.0
?

2
.5

?
2

.0
?

1
.5

?
1

.0

Iteração

Figura 4.5: Densidades a posteriori e traços a posteriori para os parâmetros de intercepto
do modelo 2.



4.2 Transformação Box-Cox - Modelo 2 35

?0.3 ?0.2 ?0.1 0.0 0.1

0
2

4
6

8

?11

0 2000 4000 6000 8000 10000

?
0

.3
?

0
.2

?
0

.1
0

.0
0

.1

Iteração

?0.6 ?0.4 ?0.2 0.0 0.2

0
1

2
3

4
5

?12

0 2000 4000 6000 8000 10000

?
0

.6
?

0
.4

?
0

.2
0

.0
0

.2

Iteração

?0.4 ?0.2 0.0 0.2 0.4

0
1

2
3

4
5

?13

0 2000 4000 6000 8000 10000

?
0

.4
0

.0
0

.2
0

.4

Iteração

Figura 4.6: Densidades a posteriori e traços a posteriori para os parâmetros de inclinação
do modelo 2.



4.2 Transformação Box-Cox - Modelo 2 36

0.05 0.10 0.15 0.20 0.25 0.30

0
5

1
0

1
5

?1

0 2000 4000 6000 8000 10000

0
.0

5
0

.1
5

0
.2

5

Iteração

0.0 0.2 0.4 0.6

0
2

4
6

?2

0 2000 4000 6000 8000 10000

0
.1

0
.3

0
.5

0
.7

Iteração

0.0 0.5 1.0 1.5

0
1

2
3

?3

0 2000 4000 6000 8000 10000

0
.0

0
.4

0
.8

1
.2

Iteração

Figura 4.7: Densidades a posteriori e traços a posteriori para os desvios padrões do
modelo 2.



4.3 Análise clássica 37

?1.0 ?0.5 0.0 0.5 1.0

0
.0

0
.5

1
.0

1
.5

?1

0 2000 4000 6000 8000 10000

?
0

.5
0

.0
0

.5
1

.0

Iteração

?0.5 0.0 0.5

0
.0

0
.5

1
.0

1
.5

2
.0

?2

0 2000 4000 6000 8000 10000

?
0

.6
?

0
.2

0
.2

0
.6

Iteração

?0.4 ?0.2 0.0 0.2 0.4 0.6

0
.0

1
.0

2
.0

3
.0

?3

0 2000 4000 6000 8000 10000

?
0

.4
0

.0
0

.2
0

.4
0

.6

Iteração

Figura 4.8: Densidades a posteriori e traços a posteriori para os parâmetros ? do modelo
2.

4.3 Análise clássica

Com o objetivo de comparação, os dados composicionais do Apêndice A foram também
analisados através de métodos clássicos aplicando a transformação alr em que utilizou-se
a rotina PROC NLMIXED do software SAS para a estimação dos parâmetros do modelo
(4.1).

As estimativas dos parâmetros e seus respectivos intervalos de confiança são apresen-
tados na Tabela 4.5.



4.3 Análise clássica 38

Tabela 4.5: Estimativas dos parâmetros do modelo 1 - Método Clássico

Parâmetro Estimativa Desvio Intervalo dePadrão Confiança (95%)
?01 0,270 0,014 (0,243; 0,298)
?02 -0,429 0,023 (-0,474; -0,385)
?03 -0,827 0,031 (-0,888; -0,765)
?11 -0,020 0,020 (-0,059; 0,020)
?12 -0,074 0,032 (-0,138; -0,010)
?13 0,006 0,044 (-0,081; 0,093)
?1 0,113 0,007 (0,099; 0,127)
?2 0,183 0,011 (0,161; 0,206)
?3 0,251 0,016 (0,220; 0,282)

Como foram utilizadas distribuições a priori não-informativas para a modelagem
Bayesiana, percebe-se que as estimativas da Tabela 4.5 apresentaram resultados seme-
lhantes às estimativas Bayesianas (Tabela 4.1), ou seja, houve efeito significativo do time
que venceu pelo menos uma vez a Superliga de vôlei (z) em relação à proporção de pontos
de bloqueio (?12). Porém, a sua estimativa é negativa, indicando que o time que não
venceu nenhuma vez a Superliga fez mais pontos de bloqueio no jogo.

A vantagem do método Bayesiano deve-se ao fato da possibilidade de inserir informa-
ções adicionais, representadas pela distribuição a priori informativa, juntamente com a
verossimilhança para a estimação dos parâmetros. Por outro lado, os métodos clássicos
necessitam de resultados assintóticos e algumas vezes sem boa precisão, devido à situações
com amostras pequenas.

Prosseguindo com a análise dos dados da Superliga de vôlei, ajustamos um modelo
de regressão Dirichlet sob o enfoque clássico em que as estimativas de máxima veros-
similhança para os parâmetros do modelo proposto (3.4) foram obtidas no software R,
através do pacote DirichletReg. Os resultados da estimação dos parâmetros do modelo de
regressão Dirichlet estão dispostos na Tabela 4.6.

Na Tabela 4.6, podemos verificar que nenhum parâmetro do modelo de regressão
Dirichlet foi significativo em relação à covariável do time ter ganho pelo menos uma vez a
Superliga de vôlei, com exceção dos interceptos, que apresentaram estimativas positivas,
diferente dos outros modelos ajustados anteriormente.



4.4 Discussão dos Resultados 39

Tabela 4.6: Estimativas dos parâmetros do modelo de Regressão Dirichlet

Parâmetro Estimativa Desvio Intervalo dePadrão Confiança (95%)
?01 3,752 0,103 (3,550; 3,950)
?02 2,186 0,105 (1,980; 2,392)
?03 1,350 0,108 (1,139; 1,561)
?04 3,140 0,104 (2,937; 3,343)
?11 -0,068 0,147 (-0,356; 0,220)
?12 -0,183 0,150 (-0,477; 0,111)
?13 -0,009 0,153 (-0,309; 0,292)
?14 -0,023 0,148 (-0,313; 0,266)

4.4 Discussão dos Resultados

Para a seleção de modelos, pode-se utilizar alguns critérios de discriminação de mo-
delos, sendo que destacamos o critério DIC (Spiegelhalter et al., [46]). Os valores de
DIC foram obtidos através do software OPENBUGS e menores valores do DIC indicam
o modelo mais adequado. Na tabela 4.7, temos os valores de DIC para os modelos 1
(transformação alr) e 2 (transformação Box-Cox), modelos que abordaram os métodos
Bayesianos.

Tabela 4.7: Critério DIC - Modelos 1 e 2.

Modelo DIC
Modelo 1 402,90
Modelo 2 -197,70

Tabela 4.8: Soma do quadrado das diferenças entre os valores observados e os valores
ajustados.

Modelo
n?
i=1

3?
j=1

(yij ? y?ij)2

Modelo 1 (transformação alr - Bayesiano) 0,995
Modelo 2 (transformação Box-Cox - Bayesiano) 1,014
Modelo (transformação alr - Análise Clássica) 5,741
Modelo de Regressão Dirichlet clássico 0,983

Podemos observar na Tabela 4.7 que o melhor ajuste dos dados da Superliga de vôlei
foi para o modelo 2 (transformação Box-Cox), que apresentou menor valor de DIC. Porém,
vale ressaltar que os intervalos de credibilidade de ?1,?2,?3 incluem o valor zero, indicando
que para esse conjunto de dados a transformação alr seria a mais apropriada do que a
transformação Box-Cox.



4.4 Discussão dos Resultados 40

Além disso, calculou-se a soma do quadrado das diferenças entre os valores observados
e os valores ajustados dos modelos e são apresentados na Tabela 4.8. Analisando os resul-
tados obtidos na Tabela 4.8, percebe-se que o modelo de regressão Dirichlet apresentou
menor valor da soma do quadrado das diferenças entre os valores observados e os valores
ajustados, ou seja, é o melhor que se ajusta aos dados. Em termos de predição, apesar
da estimativa do DIC ser maior para o modelo 1 (transformação alr), observa-se que seu
valor na Tabela 4.8 foi muito similar ao valor do modelo de regressão Dirichlet.

A Figura 4.9 apresenta as estimativas de cada componente do vôlei para cada valor
da covariável associada aos modelos ajustados.

0.0 0.2 0.4 0.6 0.8 1.0

0
.3

5
0

.4
0

0
.4

5
0

.5
0

0
.5

5

Time ganhou a Superliga

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 a

ta
q

u
e

alr
Box?Cox
clássica
Regressão Dirichlet
Média observada

0.0 0.2 0.4 0.6 0.8 1.0

0
.1

0
0

.1
2

0
.1

4
0

.1
6

0
.1

8
0

.2
0

Time ganhou a Superliga

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 b

lo
q

u
e

io
alr
Box?Cox
clássica
Regressão Dirichlet
Média observada

0.0 0.2 0.4 0.6 0.8 1.0

0
.0

4
0

.0
6

0
.0

8
0

.1
0

0
.1

2

Time ganhou a Superliga

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 s

a
q

u
e

alr
Box?Cox
clássica
Regressão Dirichlet
Média observada

0.0 0.2 0.4 0.6 0.8 1.0

0
.2

8
0

.2
9

0
.3

0
0

.3
1

0
.3

2

Time ganhou a Superliga

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 e

rr
o

alr
Box?Cox
clássica
Regressão Dirichlet
Média observada

Figura 4.9: Gráficos dos valores observados e ajustados dos componentes do vôlei de
acordo com o modelo



4.4 Discussão dos Resultados 41

Observa-se que para todos os componentes, as estimativas das proporções dos com-
ponentes do método clássico está mais distante da média observada.



42

5 Análise Bayesiana para Dados
Longitudinais

O segundo conjunto de dados (Apêndice B) é referente a uma tentativa de melhorar a
qualidade do leite de vaca, nas quais trinta vacas foram avaliadas antes e depois de uma
dieta rigorosamente controlada durante um período de oito semanas. Apesar de variações
sazonais na qualidade do leite terem sido insignificantes neste período, decidiu-se por
um grupo controle de trinta vacas nas mesmas condições, mas em um regime regular
estabelecido.

O propósito do experimento foi determinar se o novo regime produziu alguma mudança
significativa na composição do leite, que é composto por seis componentes, sendo que
denotamos por: xi1 a proporção de proteína (pr), xi2 a proporção da gordura do leite
(mf), xi3 a proporção de carboidrato (ch), xi4 a proporção de cálcio (Ca), xi5 a proporção
de sódio (Na) e xi6 a proporção de potássio (K).

A covariável associada à i-ésima vaca é definida por,

zi =

??
? 0, pertence ao grupo 1 (antes da dieta)1, pertence ao grupo 2 (depois da dieta).

Estes dados foram introduzidos em Aitchison [4](pág. 73 e 74).

Como uma análise preliminar, verificamos se há uma indicação de diferenças para as
respostas entre os dois grupos (antes e depois). Na Figura 5.1 apresentamos os box-plots
dos dados originais denotando grupo 1 por 0 e grupo 2 por 1.



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 43

0 1

0.
10

0.
15

0.
20

0.
25

0.
30

proteína

0 1

0.
10

0.
15

0.
20

0.
25

0.
30

gordura.do.leite

0 1

0.
10

0.
15

0.
20

0.
25

0.
30

carboidrato

0 1

0.
10

0.
15

0.
20

0.
25

0.
30

cálcio

0 1

0.
10

0.
15

0.
20

0.
25

0.
30

sódio

0 1

0.
10

0.
15

0.
20

0.
25

0.
30

potássio

Figura 5.1: Box plots dos componentes do leite para os grupos antes e depois da dieta.

Analisando a Figura 5.1, temos uma indicação preliminar que há diferenças nos com-
ponentes proteína xi1, gordura xi2, cálcio xi4 e potássio xi6 em relação aos dois grupos.

5.1 Transformação alr Considerando um Efeito Ale-
atório - Modelo 3

Para a análise dos dados composicionais do Apêndice B, xi1, xi2, xi3, xi4, xi5 e xi6
para i = 1, . . . , 60, consideramos a transformação alr apresentada em (3.2). Com isso,
obtemos

yi1 = log
(
xi1
xi6

)
, yi2 = log

(
xi2
xi6

)
, yi3 = log

(
xi3
xi6

)
yi4 = log

(
xi4
xi6

)
, yi5 = log

(
xi5
xi6

)
.

O modelo de regressão para os dados longitudinais transformados yij, para j =
1, . . . , 5, denominado por modelo 3, é dado por

yi = ?0 + ?1zi + wi + ?i, (5.1)

em que yi é o vetor de variáveis resposta, para j = 1, . . . , 5 e i = 1, . . . , 60 (n = n1 + n2,
em que n1 = 30 para o grupo 1 e n2 = 30 para o grupo 2), zi representa a covariável



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 44

associada ao i-ésimo indivíduo (variável indicadora em que zi = 0 para o grupo 1 e zi = 1
para o grupo 2), wi é um efeito aleatório (variável latente não observável) que captura a
dependência entre as medidas repetidas para cada indivíduo assumindo wi ? N(0,?2w) e
?i é o vetor de erros. Assumiremos ?i ? N(0, ?), em que 0 é o vetor de zeros e ? é a
matriz de variâncias e covariâncias especificada por

? =

?
????????

?21 0 . . . 0
0 ?22 . . . 0
...

... ...
...

0 0 . . . ?25

?
????????
.

Considerando o modelo apresentado em (5.1), assumiremos que os erros ?i são mutu-
amente independentes. Desta forma, obtém-se

?i1 = yi1 ??01 ??11zi ?wi,
...

?i5 = yi5 ??05 ??15zi ?wi.

Além disso, podemos estimar as proporções verdadeiras dos componentes do leite
?i1, . . . ,?i6, em que ?i1 + . . . + ?i6 = 1, com ?i1 &gt; 0, . . . ,?i6 &gt; 0 e a transformação alr,
obtendo a seguinte relação a partir de (5.1),

log
(
?i1
?i6

)
= ?01 + ?11zi + wi,

... (5.2)

log
(
?i5
?i6

)
= ?05 + ?15zi + wi.

Aplicando a função exponencial em (5.2), temos que

?i1
?i6

= e?01+?11zi+wi; . . . ;
?i5
?i6

= e?05+?15zi+wi.



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 45

Assim,

??????
?????
?i1 = ?i6(e?01+?11zi+wi),

...
?i5 = ?i6(e?05+?15zi+wi).

(5.3)

Sabemos que ?i1 + . . . + ?i6 = 1, ou seja,

?i6 = 1 ? (?i1 + . . . + ?i5) ? ?i1 + . . . + ?i5 = 1 ??i6.

De (5.3), obtemos a seguinte relação,

?i1 + . . . + ?i5 = ?i6
(
e?01+?11zi+wi + . . . + e?05+?15zi+wi

)
,

ou seja,

1 ??i6 = ?i6
(
e?01+?11zi+wi + . . . + e?05+?15zi+wi

)
?

1 = ?i6
(
1 + e?01+?11zi+wi + . . . + e?05+?15zi+wi

)
?

?i6 =
1

(1 + e?01+?11zi+wi + . . . + e?05+?15zi+wi)
. (5.4)

Logo, substituindo (5.4) em (5.3), obtemos os estimadores das proporções verdadeiras
dos componentes do grupo 1 (antes da dieta) quando zi = 0 e do grupo 2 (depois da
dieta) quando zi = 1, para a transformação alr,

?ij =
e?0j+?1jzi+wi

(1 + e?01+?11zi+wi + e?02+?12zi+wi + . . . + e?05+?15zi+wi)
,

... (5.5)

?i6 =
1

(1 + e?01+?11zi+wi + e?02+?12zi+wi + . . . + e?05+?15zi+wi)
,

em que i = 1, . . . , 60 (n = n1 + n2, onde n1 = 30 para o grupo 1 e n2 = 30 para o grupo
2) e j = 1, . . . , 5.



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 46

A parametrização ?i1 &gt; 0, . . . ,?i6 &gt; 0 pode ser usada para obter inferências sobre as
composições em cada valor da covariável.

5.1.1 Análise Bayesiana - Modelo 3

A função densidade de probabilidade conjunta de y1, . . . ,y5 dado o vetor de parâme-
tros ?3 = (?01, . . . ,?05,?11, . . . ,?15,?21, . . . ,?

2
5,?

2
w) é dada por

f(y1, . . . ,y5|?3) =
5?
j=1

1?
2?(?2j + ?2w)

exp
{
?

1
2(?2j + ?2w)

[yij ? (?0j + ?1jzi)]
2
}
,

pois, as suposições de normalidade e independência foram consideradas, e ainda, se os
parâmetros de regressão ?1j são diferentes de zero para j = 1, . . . , 5 e i = 1, . . . , 60,
yij ? N(?0j + ?1jzi; ?2j + ?

2
w), ou seja,

E(yij|zi) = E(E(yij|zi,wi))

= E(?0j + ?1jzi + wi)

= ?0j + ?1jzi,

e

var(yij|zi) = var [E(yij|zi,wi)] + E [var(yij|zi,wi)]

= var(?0j + ?1jzi + wi) + E(?2j )

= ?2w + ?
2
j .

A função de verossimilhança para os parâmetros ?0 = (?01, . . . ,?05), ?1 = (?11, . . . ,?15),
?2 = (?21, . . . ,?

2
5 ) e ?

2
w do modelo (5.1) é dada por

L(?0,?1,?2,?2w) =
5?
j=1

(?2j + ?
2
w)
?n/2exp

(
?

1
2(?2j + ?2w)

60?
i=1

?2ij

)
. (5.6)

em que



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 47

60?
i=1

?2ij =
60?
i=1

(yij ? (?0j + ?1jzi))2, j = 1, . . . , 5.

Também poderíamos considerar a função de verossimilhança sob uma análise Baye-
siana com as quantidades aleatórias, ?0j,?1j,?j e ?w, i = 1, . . . ,n. Dessa forma, ob-
teríamos a distribuição a posteriori conjunta via métodos Bayesianos hierárquicos para
?0j,?1j,?j,?w, i = 1, . . . ,n.

Para uma análise Bayesiana hierárquica, assumimos as seguintes distribuições a priori
para ?0 = (?01, . . . ,?05), ?1 = (?11, . . . ,?15), ?2 = (?21, . . . ,?

2
5 ) para a estimação dos

parâmetros do modelo (5.1),

?0j ? N(a0j,b20j),

?1j ? N(a1j,b21j), (5.7)

?2j ? IG(cj,dj),

em que N(a,b2) denota uma distribuição Normal com média a e variância b2, IG(c,d)
denota uma distribuição Gama inversa com média d/(c?1) e variância d2/[(c?1)2(c?2)],
c &gt; 2; e a0j,b0j,a1j,b1j,cj e dj são hiperparâmetros conhecidos, para j = 1, . . . , 5.

Para o segundo estágio da análise Bayesiana hierárquica, assumimos a seguinte dis-
tribuição a priori para ?2w da variável latente wi,

?2w ? IG(cw,dw), (5.8)

em que cw e dw são hiperparâmetros conhecidos. Além disso, assumimos independência
a priori entre os parâmetros.

Desta forma, a partir do teorema de Bayes que associa a função de verossimilhança
(5.6) com as distribuições a priori (5.7) e (5.8), obtemos a distribuição a posteriori con-
junta para os parâmetros ?0 = (?01, . . . ,?05), ?1 = (?11, . . . ,?15), ?2 = (?21, . . . ,?

2
5 ) e ?

2
w

dada por



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 48

?(?0,?1,?2,?2w|y) ?
5?
j=1

exp
[
?

1
2b20j

(?0j ?a0j)2
]
×

5?
j=1

exp
[
?

1
2b21j

(?1j ?a1j)2
]

×
5?
j=1

(?2j )
?(cj+1)exp

(
?
dj
?2j

)
×

5?
j=1

(?2w)
?(cw+1)exp

(
?
dw
?2w

)

×
5?
j=1

(?2j + ?
2
w)
?n/2exp

(
?

1
2(?2j + ?2w)

n?
i=1

?2ij

)
.

Consequentemente, as distribuições a posteriori condicionais utilizadas para o amos-
trador de Gibbs (Gelfand e Smith, [20]) e para o Metropolis-Hastings são dadas por:

i) ?(?0j|?1,?2,?2w,y) ? exp
[
?

1
2b20j

(?0j ?a0j)
2
]
exp

[
?

1
2(?2j + ?2w)

n?
i=1

(?0j ?µ
(j)
i )

2
]
,

em que µ(j)i = yij ??1jzi; i = 1, . . . ,n e j = 1, . . . , 5.

Logo,

?(?0j|?1,?2,y) ? N

?
?????
a0j(?2j + ?2w) + b0j

n?
i=1

µ
(j)
i

(?2j + ?2w) + nb20j
,

b20j(?2j + ?2w)
(?2j + ?2w) + nb20j

?
????? . (5.9)

ii) ?(?1j|?0,?2,?2w,y) ? exp
[
?

1
2b2ij

(?1j ?a1j)2
]
exp

[
?

1
2(?2j + ?2w)

n?
i=1

(
?1jzi ??

(j)
i

)2]
,

em que ?(j)i = yij ??0j; i = 1, . . . ,n e j = 1, . . . , 5.

Logo,

?(?1j|?0,?2,?2w,y) ? N

?
?????
a1j(?2j + ?2w) + b1j

n?
i=1

zi?
(j)
i

(?2j + ?2w) + b21j
n?
i=1

z2i

,
b21j(?2j + ?2w)

(?2j + ?2w) + b21j
n?
i=1

z2i

?
????? . (5.10)



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 49

iii) ?(?2j |?0,?1,?
2
w,y) ? (?

2
j )
?(cj+1)exp

(
?
dj
?2j

)

× (?2j + ?
2
w)
?n/2exp

[
?

1
2(?2j + ?2w)

n?
i=1

?2ij

]

? (?2j )
?(cj+1)(?2j + ?

2
w)
?n/2?1(?0,?1,?2,?2w), (5.11)

em que ?1(?0,?1,?2,?2w) = exp
[
?
dj
?2j
?

1
2(?2j + ?2w)

n?
i=1

?2ij

]
; i = 1, . . . ,n e j = 1, . . . , 5.

iv) ?(?2w|?0,?1,?
2,y) ? (?2w)

?(cw+1)exp
(
?
dw
?2w

)

× (?2j + ?
2
w)
?n/2exp

[
?

1
2(?2j + ?2w)

n?
i=1

?2ij

]

? (?2w)
?(cw+1)(?2j + ?

2
w)
?n/2?2(?0,?1,?2,?2w), (5.12)

em que ?2(?0,?1,?2,?2w) = exp
[
?
dw
?2w
?

1
2(?2j + ?2w)

n?
i=1

?2ij

]
; i = 1, . . . ,n e j = 1, . . . , 5.

Podemos observar que as distribuições a posteriori condicionais (5.9) e (5.10) apre-
sentaram formas fechadas e, portanto, obtemos as estimativas dos parâmetros do modelo
(5.1) através do algoritmo amostrador de Gibbs. Para a distribuição a posteriori condi-
cional (5.11) e (5.12) utilizamos o algoritmo de Metropolis-Hastings, por não apresentar
forma fechada.

Para a análise Bayesiana dos dados apresentados no Apêndice B, considera-se a trans-
formação alr com erros normais não correlacionados para o modelo proposto (5.1). Assu-
mindo distribuições a priori para ?0j,?1j,?2j ,?

2
w com hiperparâmetros cujos valores foram

a0j = 1, a1j = 0, b0j = b1j = 1.000.000, cj = dj = aw = bw = 1.000, geramos no software
OPENBUGS 205.000 iterações, nas quais foram descartadas as 5.000 iterações iniciais
(“burn-in”). Após o período de “‘burn-in”, consideramos saltos de tamanho 20 para ob-
termos amostras não correlacionadas, na qual resultou uma amostra final de tamanho
10.000 para cada parâmetro. A convergência do algoritmo foi verificada pelos gráficos
dos traços a posteriori das amostras de Gibbs simuladas e pelo diagnóstico de Geweke
(Geweke, [23]).

Na Tabela 5.1 apresentamos os sumários a posteriori dos parâmetros do modelo (5.1)
e os valores correspondentes da estatística de teste para o diagnóstico de convergência



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 50

Geweke. Dos resultados da Tabela 5.1, observamos que há evidências de diferenças signi-
ficativas nos grupos antes e depois da dieta nos seguintes componentes do leite: proteína,
carboidrato e cálcio, pois os intervalos de credibilidade para ?11,?13 e ?14 não incluem o
valor zero.

Tabela 5.1: Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke -
Modelo 3.

Parâmetro Média Desvio Intervalo de zGPadrão Credibilidade (95%)
?01 -0,060 0,042 (-0,143; 0,022) -0,374
?02 0,079 0,042 (-0,003; 0,162) -0,979
?03 -0,058 0,031 (-0,119; 0,003) -0,473
?04 0,070 0,022 (0,027; 0,114) 0,593
?05 -0,150 0,034 (-0,150; -0,082) 0,452
?11 0,365 0,059 (0,247; 0,482) 0,111
?12 -0,083 0,060 (-0,206; 0,035) 0,946
?13 0,170 0,044 (0,082; 0,258) -1,006
?14 0,415 0,032 (0,353; 0,478) 0,405
?15 0,090 0,048 (-0,003; 0,182) -0,267
?1 0,050 0,010 (0,034; 0,073) 0,163
?2 0,052 0,011 (0,035; 0,077) 0,623
?3 0,027 0,006 (0,018; 0,041) -0,760
?4 0,012 0,003 (0,008; 0,019) 0,426
?5 0,033 0,007 (0,022; 0,048) -0,785
?w 0,002 0,001 (0,001; 0,006) -0,156

As densidades a posteriori e o comportamento da cadeia gerada para os parâmetros do
modelo (5.1) são apresentadas nas Figuras 5.2 a 5.5. Podemos observar que aparentemente
o comportamento das cadeias para todos os parâmetros apresentam certa uniformidade.

Além disso, a convergência dos algoritmos amostrador de Gibbs e Metropolis-Hastings
foram verificadas utilizando o diagnóstico de Geweke para todos os parâmetros. Assim,
observa-se que os valores da estatística do teste zG estão no intervalo (-1,96; 1,96) indi-
cando convergência para todos os parâmetros do modelo (5.1).



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 51

?0.20 ?0.10 0.00 0.05 0.10

0
2

4
6

8

?01

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.2

0
?0

.1
0

0.
00

0.
10

Iteração

? 0
1

?0.1 0.0 0.1 0.2

0
2

4
6

8

?02

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.1

0
0.

00
0.

10
0.

20

Iteração

? 0
2

?0.20 ?0.10 0.00 0.05 0.10

0
2

4
6

8
10

12

?03

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.2

0
?0

.1
0

0.
00

Iteração

? 0
3

0.00 0.05 0.10 0.15

0
5

10
15

?04

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0.
05

0.
10

0.
15

Iteração

? 0
4

?0.30 ?0.20 ?0.10 0.00

0
2

4
6

8
10

12

?05

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.3

0
?0

.2
0

?0
.1

0
0.

00

Iteração

? 0
5

Figura 5.2: Densidades a posteriori e traços a posteriori para os parâmetros ?0’s no
modelo 3.



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 52

0.1 0.2 0.3 0.4 0.5 0.6

0
1

2
3

4
5

6
7

?11

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
2

0.
3

0.
4

0.
5

0.
6

Iteração

? 1
1

?0.3 ?0.2 ?0.1 0.0 0.1 0.2

0
1

2
3

4
5

6
7

?12

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.3

?0
.1

0.
0

0.
1

Iteração

? 1
2

0.0 0.1 0.2 0.3 0.4

0
2

4
6

8

?13

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0.
10

0.
20

0.
30

Iteração

? 1
3

0.30 0.35 0.40 0.45 0.50

0
2

4
6

8
10

12

?14

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
30

0.
35

0.
40

0.
45

0.
50

Iteração

? 1
4

?0.1 0.0 0.1 0.2 0.3

0
2

4
6

8

?15

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.1

0.
0

0.
1

0.
2

0.
3

Iteração

? 1
5

Figura 5.3: Densidades a posteriori e traços a posteriori para os parâmetros ?1’s no
modelo 3.



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 53

0.02 0.04 0.06 0.08 0.10

0
10

20
30

40

?1

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
04

0.
06

0.
08

0.
10

Iteração

? 1

0.02 0.04 0.06 0.08 0.10 0.12

0
10

20
30

40

?2

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
04

0.
08

0.
12

Iteração

? 2

0.01 0.02 0.03 0.04 0.05 0.06

0
20

40
60

?3

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
02

0.
04

0.
06

Iteração

? 3

Figura 5.4: Densidades a posteriori e traços a posteriori para os parâmetros de variância
no modelo 3.



5.1 Transformação alr Considerando um Efeito Aleatório - Modelo 3 54

0.005 0.010 0.015 0.020 0.025 0.030

0
50

10
0

15
0

?4

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

5
0.

01
5

0.
02

5

Iteração

? 4

0.02 0.04 0.06 0.08

0
10

20
30

40
50

60

?5

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
02

0.
04

0.
06

0.
08

Iteração

? 5

0.000 0.004 0.008 0.012

0
50

15
0

25
0

?w

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0
0.

00
4

0.
00

8
0.

01
2

Iteração

? w

Figura 5.5: Densidades a posteriori e traços a posteriori para os parâmetros de variância
no modelo 3.

A Tabela 5.2 apresenta as estimativas das proporções verdadeiras para os componentes
de proteína, gordura do leite, carboidrato, cálcio, sódio e potássio para zi = 0 (Grupo 1 -
antes da dieta) e para zi = 1 (Grupo 2 - depois da dieta), considerando a transformação
alr e um efeito aleatório no modelo.



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 55

Tabela 5.2: Estimativas das proporções dos componentes - Modelo 3.
Componentes do Proporções z = 0 Proporções z = 1leite (Grupo 1) (Grupo 2)
proteína ?1 0,159 ?7 0,193
gordura do leite ?2 0,183 ?8 0,141
carboidrato ?3 0,160 ?9 0,159
cálcio ?4 0,182 ?10 0,231
sódio ?5 0,146 ?11 0,134
potássio ?6 0,169 ?12 0,142

Os resultados da Tabela 5.2 mostram que após a dieta balanceada houve um aumento
para as proporções estimadas dos seguintes componentes do leite: proteína e cálcio. Por
outro lado, para os componentes gordura do leite e potássio as proporções estimadas
diminuiram. E finalmente, para os componentes carboidrato e sódio, aparentemente não
houve diferença depois da dieta estabelecida nas proporções estimadas.

5.2 Transformação Box-Cox Considerando um Efeito
Aleatório - Modelo 4

Nesta seção, é desenvolvido uma aplicação da transformação Box-Cox (3.3) nos dados
composicionais do Apêndice B, xi1, xi2, xi3, xi4, xi5 e xi6 para i = 1, . . . , 60.

Para a obtenção das amostras simuladas a posteriori foram utilizados os métodos
Bayesianos baseados no amostrador de Gibbs e no algoritmo de Metropolis-Hastings.

Considerando a transformação Box-Cox, obtemos

y
(?1)
i1 =

?????
????

(xi1
xi6

)?1 ? 1
?1

se ?1 6= 0,

log
(
xi1
xi6

)
se ?1 = 0

, y
(?2)
i2 =

?????
????

(xi2
xi6

)?2 ? 1
?2

se ?2 6= 0,

log
(
xi2
xi6

)
se ?2 = 0

y
(?3)
i3 =

?????
????

(xi3
xi6

)?3 ? 1
?3

se ?3 6= 0,

log
(
xi3
xi6

)
se ?3 = 0

, y
(?4)
i4 =

?????
????

(xi4
xi6

)?4 ? 1
?4

se ?4 6= 0,

log
(
xi4
xi6

)
se ?4 = 0



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 56

y
(?5)
i5 =

?????
????

(xi5
xi6

)?5 ? 1
?5

se ?5 6= 0,

log
(
xi5
xi6

)
se ?5 = 0

Como já descrito na Seção 4.2, a transformação Box-Cox é um caso especial da trans-
formação alr quando ?j = 0 para j = 1, . . . , 5.

Utilizando os dados transformados y(?1)i1 , . . . ,y
(?5)
i5 , i = 1, . . . , 60, e assumindo o modelo

(5.1), o modelo 4 é dado por

yi
(?) = ?0 + ?1zi + wi + ?i, (5.13)

em que yi é o vetor de variáveis resposta, para j = 1, . . . , 5 e i = 1, . . . , 60 (n = n1 + n2,
em que n1 = 30 para o grupo 1 e n2 = 30 para o grupo 2), zi representa a covariável
associada ao i-ésimo indivíduo (variável indicadora em que zi = 0 para o grupo 1 e zi = 1
para o grupo 2), wi é um efeito aleatório (variável latente não observável) que captura a
dependência entre as medidas repetidas para cada indivíduo e ?i é o vetor de erros.

Da mesma forma, que em (5.2), assumiremos para a variável latente não observável,
wi ? N(0,?2w) e ?i ? N(0, ?), em que 0 é o vetor de zeros e ? é a matriz de variâncias e
covariâncias.

Considerando o modelo apresentado em (5.13), assumiremos que os erros ?i1, . . . ,?i5
são mutuamente independentes. Assim, obtém-se,

?i1 = y
(?1)
i1 ??01 ??11zi ?wi,

...

?i5 = y
(?1)
i5 ??05 ??15zi ?wi.

Consideramos as suposições de normalidade e independência, e ainda, y(?j)ij ? N(?0j +
?1jzi,?

2
j + ?

2
w), para j = 1, . . . , 5 e i = 1, . . . , 60.

Além disso, podemos considerar ?i1, . . . ,?i6 as proporções verdadeiras dos componen-
tes, em que ?i1 + . . . + ?i6 = 1, com ?i1 &gt; 0, . . . ,?i6 &gt; 0 e a transformação Box-Cox,
obtendo a seguinte relação a partir de (5.13),



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 57

(?i1/?i6)?1 ? 1
?1

= ?01 + ?11zi + wi,

... (5.14)
(?i5/?i6)?5 ? 1

?5
= ?05 + ?15zi + wi.

Reescrevendo (5.14), temos que

(
?i1
?i6

)?1
= ?1(?01 + ?11zi + wi) + 1 ?

(
?i1
?i6

)?1. 1?1 = [?1(?01 + ?11zi + wi) + 1] 1?1
...(

?i5
?i6

)?5
= ?5(?05 + ?15zi + wi) + 1 ?

(
?i5
?i6

)?5. 1?5 = [?5(?05 + ?15zi + wi) + 1] 1?5 ,

ou seja,

??????
?????
?i1 = ?i6 [?1(?01 + ?11zi + wi) + 1]

1
?1

...
?i5 = ?i6 [?5(?05 + ?15zi + wi) + 1]

1
?5 .

(5.15)

Sabemos que ?i1 + . . . + ?i6 = 1, ou seja,

?i6 = 1 ? (?i1 + . . . + ?i5) ? ?i1 + . . . + ?i5 = 1 ??i6.

De (5.15), obtemos a seguinte relação,

?i1 + . . . + ?i5 = ?i6
{

[?1(?01 + ?11zi + wi) + 1]
1
?1 + . . . + [?5(?05 + ?15zi + wi) + 1]

1
?5

}
,

ou seja,



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 58

1 ??i6 = ?i6
{

[?1(?01 + ?11zi + wi) + 1]
1
?1 + . . . + [?5(?05 + ?15zi + wi) + 1]

1
?5

}
?

1 = ?i6
{

1 + [?1(?01 + ?11zi + wi) + 1]
1
?1 + . . . + [?5(?05 + ?15zi + wi) + 1]

1
?5

}
?

?i6 =
1{

1 + [?1(?01 + ?11zi + wi) + 1]
1
?1 + . . . + [?5(?05 + ?15zi + wi) + 1]

1
?5

}.
(5.16)

Logo, substituindo (5.16) em (5.15), obtemos os estimadores das proporções verda-
deiras dos componentes do grupo 1 (antes da dieta) quando zi = 0 e do grupo 2 (depois
da dieta) quando zi = 1, para a transformação Box-Cox,

?ij =
[?j(?0j + ?1jzi + wi) + 1]

1
?j{

1 + [?1(?01 + ?11zi + wi) + 1]
1
?1 + . . . + [?5(?05 + ?15zi + wi) + 1]

1
?5

},
...

?i6 =
1{

1 + [?1(?01 + ?11zi + wi) + 1]
1
?1 + . . . + [?5(?05 + ?15zi + wi) + 1]

1
?5

}, (5.17)

em que i = 1, . . . , 60 (n = n1 + n2, em que n1 = 30 para o grupo 1 e n2 = 30 para o grupo
2) e j = 1, . . . , 5.

5.2.1 Análise Bayesiana - Modelo 4

A função densidade de probabilidade conjunta de y(?1)1 , . . . ,y
(?5)
5 dado o vetor de

parâmetros ?4 = (?01, . . . ,?05,?11, . . . ,?15,?21, . . . ,?
2
5,?

2
w,?1, . . . ,?5) é dada por

f(y(?1)1 , . . . ,y
(?5)
5 |?4) =

5?
j=1

1?
2?(?2j + ?2w)

exp
{
?

1
2(?2j + ?2w)

[
y

(?j)
ij ? (?0j + ?1jzi)

]2}
.

Por outro lado, a função densidade de probabilidade das observações não transforma-
das (variáveis originais) [Box &amp;amp; Tiao (1973)], yi1 = xi1/xi6, yi2 = xi2/xi6, yi3 = xi3/xi6,
yi4 = xi4/xi6, yi5 = xi5/xi6 é dada por



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 59

f(y1, . . . ,y5|?4) =
5?
j=1

1?
2?(?2j + ?2w)

n?
i=1

exp
[
?

1
2(?2j + ?2w)

(
y

(?j)
ij ??0j ??1jzi

)2]??dy(?j)ij
dyij

?
? ,

em que para j = 1, . . . , 5,
dy(?j)ij
dyij

=
?jy

?j?1
ij

?j
= y?j?1ij são os elementos da diagonal da

matriz Jacobiano.

A função de verossimilhança para ?0 = (?01, . . . ,?05), ?1 = (?11, . . . ,?15), ?2 =
(?21, . . . ,?

2
5 ), ?

2
w e ? = (?1, . . . ,?5) do modelo (5.13) é dada por

L(?0,?1,?2,?2w,?) =
5?
j=1

(?2j + ?
2
w)
?n/2

(
n?
i=1

y
?j?1
ij

)
exp

[
?

1
2(?2j + ?2w)

60?
i=1

?2ij

]
, (5.18)

em que
(

n?
i=1

y?1?1i1

)
, . . . ,

(
n?
i=1

y?5?1i5

)
são os produtos do Jacobiano, e

60?
i=1

?2ij =
60?
i=1

[
y

(?j)
ij ? (?0j + ?1jzi)

]2
, j = 1, . . . , 5.

Para uma análise Bayesiana hierárquica com os dados transformados através da trans-
formação Box-Cox, assumimos as mesmas distribuições a priori para ?0 = (?01, . . . ,?05),
?1 = (?11, . . . ,?15), ?2 = (?21, . . . ,?

2
5 ) e ?

2
w dadas em (5.7) e (5.8) para a estimação dos

parâmetros do modelo (5.13).

Para ? = (?1, . . . ,?5), assumimos a distribuição a priori,

?j ? N(ej,f2j ), (5.19)

em que j = 1, . . . , 5 e ej e fj são hiperparâmetros conhecidos.

Desta forma, a partir do teorema de Bayes que associa a função de verossimilhança
(5.18) com as distribuições a priori (5.7), (5.8) e (5.19), obtemos a distribuição a posteriori
conjunta para os parâmetros ?0 = (?01, . . . ,?05), ?1 = (?11, . . . ,?15), ?2 = (?21, . . . ,?

2
5 ),

?2w e ? = (?1, . . . ,?5) dada por



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 60

?(?0,?1,?2,?2w,?|y) ?
5?
j=1

exp
[
?

1
2b20j

(?0j ?a0j)2
]
×

5?
j=1

exp
[
?

1
2b21j

(?1j ?a1j)2
]

×
5?
j=1

(?2j )
?(cj+1)exp

(
?
dj
?2j

)
×

5?
j=1

(?2w)
?(cw+1)exp

(
?
dw
?2w

)

×
5?
j=1

exp
[
?

1
2f2j

(?j ?ej)2
]
×

?
? 5?
j=1

n?
i=1

y
?j?1
ij

?
?

×
5?
j=1

(?2j + ?
2
w)
?n/2exp

[
?

1
2(?2j + ?2w)

n?
i=1

?2ij

]
. (5.20)

Considerando a distribuição a posteriori conjunta (5.20), as distribuições a posteriori
condicionais utilizadas para o amostrador de Gibbs (Gelfand e Smith, [20]) e para o
algoritmo de Metropolis-Hastings são dadas por:

i) ?(?0j|?1,?2,?2w,?,y
(?)) ? exp

[
?

1
2b20j

(?0j ?a0j)
2
]

× exp
[
?

1
2(?2j + ?2w)

n?
i=1

(?0j ?µ
(j)
i )

2
]
,

em que µ(j)i = y
(?j)
ij ??1jzi; i = 1, . . . ,n e j = 1, . . . , 5.

Logo,

?(?0j|?1,?2,?2w,?,y
(?)) ? N

?
?????
a0j(?2j + ?2w) + b0j

n?
i=1

µ
(j)
i

(?2j + ?2w) + nb20j
,

b20j(?2j + ?2w)
(?2j + ?2w) + nb20j

?
????? . (5.21)

ii) ?(?1j|?0,?2,?2w,?,y
(?)) ? exp

[
?

1
2b2ij

(?1j ?a1j)2
]

× exp
[
?

1
2(?2j + ?2w)

n?
i=1

(
?1jzi ??

(j)
i

)2]
,

em que ?(j)i = y
(?j)
ij ??0j; i = 1, . . . ,n e j = 1, . . . , 5.

Logo,



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 61

?(?1j|?0,?2,?2w,?,y
(?)) ? N

?
?????
a1j(?2j + ?2w) + b1j

n?
i=1

zi?
(j)
i

(?2j + ?2w) + b21j
n?
i=1

z2i

,
b21j(?2j + ?2w)

(?2j + ?2w) + b21j
n?
i=1

z2i

?
????? .
(5.22)

iii) ?(?2j |?0,?1,?
2
w,?,y

(?)) ? (?2j )
?(cj+1)exp

(
?
dj
?2j

)

× (?2j + ?
2
w)
?n/2exp

[
?

1
2(?2j + ?2w)

n?
i=1

?2ij

]
(5.23)

? (?2j )
?(cj+1)(?2j + ?

2
w)
?n/2?1(?0,?1,?2,?2w,?),

em que ?1(?0,?1,?2,?2w,?) = exp
[
?
dj
?2j
?

1
2(?2j + ?2w)

n?
i=1

?2ij

]
e

?2ij = [y
(?j)
ij ? (?0j + ?1jzi)]

2; i = 1, . . . ,n e j = 1, . . . , 5.

iv) ?(?2w|?0,?1,?
2,?,y(?)) ? (?2w)

?(cw+1)exp
(
?
dw
?2w

)

× (?2j + ?
2
w)
?n/2exp

[
?

1
2(?2j + ?2w)

n?
i=1

?2ij

]
(5.24)

? (?2w)
?(cw+1)(?2j + ?

2
w)
?n/2?2(?0,?1,?2,?2w,?),

em que ?2(?0,?1,?2,?2w,?) = exp
[
?
dw
?2w
?

1
2(?2j + ?2w)

n?
i=1

?2ij

]
; i = 1, . . . ,n e j = 1, . . . , 5.

v) ?(?j|?0,?1,?2,?2w,y
(?)) ? exp

[
?

1
2f2j

(?j ?ej)2
]
?j(?0,?1,?2,?2w,?), (5.25)

em que

?j(?0,?1,?2,?2w,?) = exp
{

(?j ? 1)
n?
i=1

lnyij +
1

(?2j + ?2w)

n?
i=1

[
y

(?j)
ij ? (?0j + ?1j)

]2}

= exp
[
(?j ? 1)

n?
i=1

lnyij +
1

(?2j + ?2w)

(
n?
i=1

y
(?j)2
ij ? 2?0j

n?
i=1

y
(?j)
ij ? 2?1j

n?
i=1

y
(?j)
ij zi

)]
,

para i = 1, . . . ,n e j = 1, . . . , 5.



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 62

Podemos observar que as distribuições a posteriori condicionais (5.21) e (5.22) apre-
sentaram formas fechadas e, portanto, obtemos as estimativas dos parâmetros do modelo
(5.13) através do algoritmo amostrador de Gibbs. Por outro lado, para as distribuições
a posteriori condicionais (5.23), (5.24) e (5.25) utilizamos o algoritmo de Metropolis-
Hastings, por não apresentarem formas fechadas.

Assim, considerando a transformação Box-Cox com erros normais não correlacionados
para o modelo (5.13), assumimos as distribuições a priori para ?0j,?1j,?2j , ?

2
w e ?j com

hiperparâmetros cujos valores foram a0j = 1; b0j = b1j = fj = 1.000.000, a1j = ej = 0,
cj = dj = aw = bw = 1.000, geramos no software OPENBUGS 205.000 iterações, nas quais
foram descartadas as 5.000 iterações iniciais (“burn-in”). Após o período de “‘burn-in”,
consideramos saltos de tamanho 20 para obtermos amostras não correlacionadas, na qual
resultou uma amostra final de tamanho 10.000 para cada parâmetro.

Na Tabela 5.3 apresentamos os sumários a posteriori dos parâmetros do modelo (5.13)
e os valores correspondentes da estatística de teste zG para o diagnóstico de convergência
Geweke.

Tabela 5.3: Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke -
Modelo 4.

Parâmetro Média
Desvio Intervalo de

zGPadrão Credibilidade (95%)
?01 -0,060 0,043 (-0,144; 0,026) 0,037
?02 0,076 0,046 (-0,013; 0,166) 1,514
?03 -0,069 0,032 (-0,132; -0,004) 1,636
?04 0,064 0,013 (0,039; 0,092) 1,207
?05 -0,156 0,038 (-0,234; -0,085) -0,180
?11 0,373 0,065 (0,249; 0,503) 0,860
?12 -0,084 0,062 (-0,208; 0,036) -1,067
?13 0,166 0,044 (0,079; 0,252) -1,868
?14 0,274 0,040 (0,206; 0,365) -1,346
?15 0,092 0,049 (-0,004; 0,188) 0,308
?1 0,054 0,012 (0,035; 0,082) -0,281
?2 0,055 0,011 (0,037; 0,081) 0,759
?3 0,028 0,006 (0,019; 0,041) -0,441
?4 0,004 0,002 (0,002; 0,009) -0,814
?5 0,035 0,009 (0,022; 0,057) -0,399
?w 0,001 0,0007 (0,0003; 0,003) -0,770
?1 0,075 0,381 (-0,681; 0,822) -0,228
?2 -0,184 0,506 (-1,170; 0,829) -0,676
?3 -0,723 0,610 (-1,940; 0,466) 0,635
?4 -1,523 0,483 (-2,446; -0,518) -1,132
?5 -0,205 0,627 (-1,440; 1,012) -0,119



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 63

?0.2 ?0.1 0.0 0.1

0
2

4
6

8

?01

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.2

?0
.1

0.
0

0.
1

Iteração

? 0
1

?0.1 0.0 0.1 0.2

0
2

4
6

8

?02

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.1

0
0.

00
0.

10
0.

20

Iteração

? 0
2

?0.20 ?0.15 ?0.10 ?0.05 0.00 0.05

0
2

4
6

8
10

12

?03

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.1

5
?0

.0
5

0.
05

Iteração

? 0
3

0.00 0.04 0.08 0.12

0
5

10
15

20
25

30

?04

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0.
04

0.
08

0.
12

Iteração

? 0
4

?0.30 ?0.20 ?0.10 0.00

0
2

4
6

8
10

?05

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.3

0
?0

.2
0

?0
.1

0
0.

00

Iteração

? 0
5

Figura 5.6: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?0’s no modelo 4.



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 64

0.1 0.2 0.3 0.4 0.5 0.6 0.7

0
1

2
3

4
5

6

?11

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
1

0.
3

0.
5

0.
7

Iteração

? 1
1

?0.3 ?0.2 ?0.1 0.0 0.1 0.2

0
1

2
3

4
5

6

?12

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.3

?0
.1

0.
0

0.
1

Iteração

? 1
2

0.0 0.1 0.2 0.3 0.4

0
2

4
6

8

?13

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
0

0.
1

0.
2

0.
3

Iteração

? 1
3

0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50

0
2

4
6

8
10

?14

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
20

0.
30

0.
40

0.
50

Iteração

? 1
4

?0.1 0.0 0.1 0.2 0.3

0
2

4
6

8

?15

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.1

0.
0

0.
1

0.
2

0.
3

Iteração

? 1
5

Figura 5.7: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?1’s no modelo 4.



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 65

0.02 0.04 0.06 0.08 0.10 0.12 0.14

0
10

20
30

?1

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
04

0.
08

0.
12

Iteração

? 1

0.02 0.04 0.06 0.08 0.10 0.12

0
10

20
30

40

?2

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
04

0.
06

0.
08

0.
10

0.
12

Iteração

? 2

0.01 0.02 0.03 0.04 0.05 0.06

0
20

40
60

?3

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
02

0.
03

0.
04

0.
05

0.
06

Iteração

? 3

Figura 5.8: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 4.



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 66

0.000 0.005 0.010 0.015 0.020

0
50

10
0

20
0

30
0

?4

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0
0.

01
0

0.
02

0

Iteração

? 4

0.02 0.04 0.06 0.08

0
10

20
30

40
50

?5

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
02

0.
04

0.
06

0.
08

Iteração

? 5

0.000 0.002 0.004 0.006

0
20

0
40

0
60

0
80

0

?w

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0
0.

00
2

0.
00

4
0.

00
6

Iteração

? w

Figura 5.9: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 4.



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 67

?1.5 ?1.0 ?0.5 0.0 0.5 1.0 1.5

0.
0

0.
2

0.
4

0.
6

0.
8

1.
0

?1

0 2000 4000 6000 8000 10000

?1
.0

0.
0

0.
5

1.
0

1.
5

Iteração

?2 ?1 0 1 2

0.
0

0.
2

0.
4

0.
6

0.
8

?2

0 2000 4000 6000 8000 10000

?2
?1

0
1

Iteração

?3 ?2 ?1 0 1 2

0.
0

0.
2

0.
4

0.
6

?3

0 2000 4000 6000 8000 10000

?2
?1

0
1

Iteração

?3 ?2 ?1 0

0.
0

0.
2

0.
4

0.
6

0.
8

?4

0 2000 4000 6000 8000 10000

?3
.0

?2
.0

?1
.0

0.
0

Iteração

?3 ?2 ?1 0 1 2

0.
0

0.
2

0.
4

0.
6

?5

0 2000 4000 6000 8000 10000

?2
?1

0
1

2

Iteração

Figura 5.10: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?’s no modelo 4.



5.2 Transformação Box-Cox Considerando um Efeito Aleatório - Modelo 4 68

De acordo com os resultados da Tabela 5.3, observamos que as diferenças entre os
dois grupos (antes e depois da dieta) dos componentes (pr/k), (ch/k) e (Ca/k) foram
significativas, pois os intervalos de credibilidade para ?11,?13 e ?14 não incluem o valor
zero, levando ao mesmo resultado obtido através da transformação alr (Seção 5.1.1).

Podemos observar que apenas o ?4 apresentou significância, indicando que para a
maioria dos ?’s a transformação alr, que é um caso especial da transformação Box-Cox,
seria mais adequada para os casos em que o intervalo de credibilidade incluem o valor
zero (? = 0).

Os valores das estatísticas de teste zG do diagnóstico de convergência de Geweke são
apresentados na Tabela 5.3, os gráficos das densidades a posteriori e o comportamento
da cadeia gerada são apresentados nas Figuras 5.6, 5.7, 5.8, 5.9 e 5.10 para os parâme-
tros do modelo (5.13). Podemos observar que os traços a posteriori apresentaram certa
uniformidade, indicando possível convergência, sendo confirmado através do diagnóstico
de Geweke.

A Tabela 5.4 apresenta as estimativas das proporções verdadeiras para os componentes
do leite: proteína, gordura do leite, carboidrato, cálcio, sódio e potássio para zi = 0
(Grupo 1 - antes da dieta) e para zi = 1 (Grupo 2 - depois da dieta), considerando a
transformação Box-Cox com um efeito aleatório.

Tabela 5.4: Estimativas das proporções dos componentes - Modelo 4.
Componentes do Proporções z = 0 Proporções z = 1leite (Grupo 1) (Grupo 2)
proteína ?1 0,160 ?7 0,194
gordura do leite ?2 0,183 ?8 0,142
carboidrato ?3 0,159 ?9 0,158
cálcio ?4 0,182 ?10 0,229
sódio ?5 0,146 ?11 0,134
potássio ?6 0,170 ?12 0,143

Percebe-se que os resultados da Tabela 5.4 são semelhantes aos resultados obtidos na
Tabela 5.2, em que considerou a transformação alr com um efeito aleatório no modelo.
Ou seja, as proporções dos componentes apresentam mesma tendência de aumentar ou
diminuir após a dieta estabelecida no experimento.



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 69

5.3 Transformação alr Considerando Três Efeitos Ale-
atórios - Modelo 5

Nesta seção, consideramos a transformação alr para os dados composicionais (Apên-
dice B) e generalizando o modelo (5.1) com a introdução de dois efeitos aleatórios extras:
v1i que captura a dependência entre as medidas repetidas para o grupo 1 (antes de receber
a dieta) para i = 1, . . . , 30 e v2i que captura a dependência entre as medidas repetidas
para o grupo 2 (depois de receber a dieta) para i = 1, . . . , 30. Desta forma, teremos três
efeitos aleatórios no modelo, que é dado por

yi = ?0 + ?1zi + wi + ajv1i + (1 ?aj)v2j + ?i, (5.26)

em que aj = 1 (Grupo 1) e aj = 0 (Grupo 2) para j = 1, . . . , 5. Assumimos a distribuição
Normal N(0,?2v1) e N(0,?

2
v2), para v1i e v2i, respectivamente. Também assumimos as

mesmas suposições consideradas para o modelo (5.1) e independência entre as quantidades
aleatórias wi, v1i, v2i e ?ji, i = 1, . . . , 60; j = 1, . . . , 5. Denotamos o modelo definido em
(5.26) como modelo 5.

Da mesma forma, que em (5.2), assumiremos ?i ? N(0, ?), em que 0 é o vetor de
zeros e ? é a matriz de variâncias e covariâncias.

Considerando o modelo apresentado em (5.13), assumiremos que os erros ?i1, . . . ,?i5
são mutuamente independentes. Assim, obtém-se,

?i1 = yi1 ??01 ??11zi ?wi ?ajv1i ? (1 ?aj)v2j,
...

?i5 = yi5 ??05 ??15zi ?wi ?ajv1i ? (1 ?aj)v2j.

Assim,

yij ? N
(
?0j + ?1jzi,?2j + ?

2
w + ?

2
v1

)
, (Grupo 1 - antes da dieta);

yij ? N
(
?0j + ?1jzi,?2j + ?

2
w + ?

2
v2

)
, (Grupo 2 - depois da dieta),

para j = 1, . . . , 5 e i = 1, . . . , 60 (n = n1 + n2, em que n1 = 30 para o Grupo 1 e n2 = 30
para o Grupo 2).

De acordo com o resultado obtido em (5.5) dos estimadores das proporções verda-



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 70

deiras dos componentes, podemos estendê-lo para o modelo 5 (5.26) que considera a
transformação alr com três efeitos aleatórios.

Desse modo, obtemos as estimativas das proporções verdadeiras dos componentes do
leite, ?i1, . . . ,?i6.

Logo,

?ij =
e?0j+?1jzi+wi+ajv1i+(1?aj)v2j(

1 + e?01+?11zi+wi+ajv1i+(1?aj)v2j + . . . + e?05+?15zi+wi+ajv1i+(1?aj)v2j
),

...

?i6 =
1(

1 + e?01+?11zi+wi+ajv1i+(1?aj)v2j + . . . + e?05+?15zi+wi+ajv1i+(1?aj)v2j
),

(5.27)

em que i = 1, . . . , 60 (n = n1 + n2, onde n1 = 30 para o grupo 1 e n2 = 30 para o grupo
2) e j = 1, . . . , 5.

5.3.1 Análise Bayesiana - Modelo 5

A função densidade de probabilidade conjunta de y1, . . . ,y5 dado o vetor de parâme-
tros ?5 = (?01, . . . ,?05,?11, . . . ,?15,?21, . . . ,?

2
5,?

2
w,?

2
v1,?

2
v2) é dada por

f(y1, . . . ,y5|?5) =
5?
j=1

1?
2?(?2j + ?2w + ?2v1)

exp
{
?

1
2(?2j + ?2w + ?2v1)

[yij ? (?0j + ?1jzi)]2
}

×
5?
j=1

1?
2?(?2j + ?2w + ?2v2)

exp
{
?

1
2(?2j + ?2w + ?2v2)

[yij ? (?0j + ?1jzi)]2
}
,

em que ?2v1 é a variância do efeito aleatório v1i que captura a dependência entre as medidas
repetidas do grupo 1 (antes da dieta) e ?2v2 é a variância do efeito aleatório v2i que captura
a dependência entre as medidas repetidas do grupo 2 (depois da dieta).

A função de verossimilhança para os parâmetros ?0 = (?01, . . . ,?05), ?1 = (?11, . . . ,?15),
?2 = (?21, . . . ,?

2
5 ), ?

2
w, ?

2
v1 e ?

2
v2 do modelo (5.26) é dada por



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 71

L(?0,?1,?2,?2w,?
2
v1,?

2
v2) =

5?
j=1

(?2j + ?
2
w + ?

2
v1)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v1)

30?
i=1

?2ij

]

×
5?
j=1

(?2j + ?
2
w + ?

2
v2)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v2)

30?
i=1

?2ij

]
,

(5.28)

em que
30?
i=1

?2ij =
30?
i=1

[yij ? (?0j + ?1jzi)]
2.

Para a análise Bayesiana do modelo 5, consideramos as mesmas distribuições a priori
dadas em (5.7) e (5.8). Para ?2vl, assumimos a seguinte distribuição a priori,

?2vl ? IG(avl,bvl), (5.29)

em que avl e bvl são hiperparâmetros conhecidos, l = 1, 2. Assumimos independência a
priori entre os parâmetros.

Desta forma, a partir do teorema de Bayes que associa a função de verossimilhança
(5.28) com as distribuições a priori (5.7), (5.8) e (5.29), obtemos a distribuição a posteriori
conjunta para os parâmetros ?0 = (?01, . . . ,?05), ?1 = (?11, . . . ,?15), ?2 = (?21, . . . ,?

2
5 ),

?2w, ?
2
v1 e ?

2
v2 dada por

?(?0,?1,?2,?2w,?
2
v1,?

2
v2|y) ?

5?
j=1

exp
[
?

1
2b20j

(?0j ?a0j)2
]
×

5?
j=1

exp
[
?

1
2b21j

(?1j ?a1j)2
]

×
5?
j=1

(?2j )
?(cj+1)exp

(
?
dj
?2j

)
×

5?
j=1

(?2w)
?(cw+1)exp

(
?
dw
?2w

)

×
5?
j=1

(?2v1)
?(av1+1)exp

(
?
bv1
?2v1

)
×

5?
j=1

(?2v2)
?(av2+1)exp

(
?
bv2
?2v2

)

×
5?
j=1

(?2j + ?
2
w + ?

2
v1)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v1)

n?
i=1

?2ij

]

×
5?
j=1

(?2j + ?
2
w + ?

2
v2)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v2)

n?
i=1

?2ij

]
.

As distribuições a posteriori condicionais utilizadas para o amostrador de Gibbs (Gel-
fand e Smith, [20]) e para o Metropolis-Hastings são dadas por:



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 72

i) ?(?0j|?1,?2,?2w,?
2
v1,?

2
v2,y) ? N

(
a0j,b

2
0j

)
exp

[
?

1
2(?2j + ?2w)

n?
i=1

(?0j ?µ
(j)
i )

2
]

×
2?
l=1

exp
[
?

1
2(?2j + ?2w + ?2vl)

n?
i=1

(?0j ?µ
(j)
i )

2
]
, (5.30)

em que µ(j)i = yij ??1jzi; i = 1, . . . ,n, j = 1, . . . , 5 e l = 1, 2.

ii) ?(?1j|?0,?2,?2w,?
2
v1,?

2
v2,y) ? N

(
a1j,b

2
1j

) 2?
l=1

exp
[
?

1
2(?2j + ?2w + ?2vl)

n?
i=1

(
?1jzi ??

(j)
i

)2]
,

(5.31)

em que ?(j)i = yij ??0j; i = 1, . . . ,n, j = 1, . . . , 5 e l = 1, 2.

iii) ?(?2j |?0,?1,?
2
w,?

2
v1,?

2
v2,y) ? (?

2
j )
?(cj+1)exp

(
?
dj
?2j

)

×
2?
l=1

exp
[
?

1
2(?2j + ?2w + ?2vl)

n?
i=1

?2ij

]
, (5.32)

para i = 1, . . . ,n, j = 1, . . . , 5 e l = 1, 2.

iv) ?(?2w|?0,?1,?
2,?2v1,?

2
v2,y) ? (?

2
w)
?(cw+1)exp

(
?
dw
?2w

)

×
2?
l=1

(?2j + ?
2
w + ?

2
vl)
?n/2exp

[
?

1
2(?2j + ?2w + ?2vl)

n?
i=1

?2ij

]
,

(5.33)

para i = 1, . . . ,n, j = 1, . . . , 5 e l = 1, 2.



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 73

v) ?(?2v1|?0,?1,?
2,?2w,?

2
v2,y) ? (?

2
v1)
?(av1+1)exp

(
?
bv1
?2v1

)

× (?2j + ?
2
w + ?

2
v1)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v1)

n?
i=1

?2ij

]
,

(5.34)

para i = 1, . . . ,n e j = 1, . . . , 5.

vi) ?(?2v2|?0,?1,?
2,?2w,?

2
v1,y) ? (?

2
v2)
?(av2+1)exp

(
?
bv2
?2v2

)

× (?2j + ?
2
w + ?

2
v2)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v2)

n?
i=1

?2ij

]
,

(5.35)

para i = 1, . . . ,n e j = 1, . . . , 5.

Podemos observar que as distribuições a posteriori condicionais (5.30), (5.31), (5.32),
(5.33), (5.34) e (5.35) não apresentaram formas fechadas e, portanto, obtemos as estima-
tivas dos parâmetros do modelo (5.26) através do algoritmo de Metropolis-Hastings.

Para a análise Bayesiana dos dados do Apêndice B, considera-se a transformação alr
com erros normais não correlacionados para o modelo proposto (5.26).

Assumindo as distribuições a priori para ?0j,?1j,?2j ,?
2
w,?

2
v1,?

2
v2 com hiperparâmetros

cujos valores foram a0j = 1; b0j = b1j = 1.000.000, a1j = 0, cj = dj = aw = bw = av1 =
bv1 = av2 = bv2 = 1.000, geramos no software OPENBUGS 205.000 iterações, em que
foram descartadas as 5000 iterações iniciais (“burn-in”). Após o período de “‘burn-in”,
consideramos saltos de tamanho 20 para obtermos amostras não correlacionadas, na qual
resultou uma amostra final de tamanho 10.000 para cada parâmetro. A convergência
do algoritmo foi verificada pelos gráficos dos traços a posteriori das amostras de Gibbs
simuladas e pelo diagnóstico de Geweke (Geweke, [23]).

Na Tabela 5.5 apresentamos os sumários a posteriori dos parâmetros do modelo (5.26)
e os valores correspondentes da estatística de teste para o diagnóstico de convergência
Geweke.



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 74

Dos resultados da Tabela 5.5 observamos que para os componentes do leite proteína,
carboidrato e cálcio há diferenças significativas nos grupos antes e depois da dieta, sendo
que os intervalos de credibilidade dos parâmetros ?11,?13 e ?14 não incluem o valor zero.

As densidades a posteriori e o comportamento da cadeia gerada para os parâmetros
do modelo (5.26) são apresentadas nas Figuras 5.11, 5.12, 5.13 e 5.14, em que observa-se
que há uma certa uniformidade no comportamento das cadeias geradas.

A convergência dos algoritmos amostrador de Gibbs e Metropolis-Hastings foram
verificadas utilizando o diagnóstico de Geweke para todos os parâmetros. Observamos que
os valores da estatística do teste zG estão no intervalo (-1,96; 1,96) indicando convergência
para todos os parâmetros estimados.

Tabela 5.5: Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke -
Modelo 5.

Parâmetro Média
Desvio Intervalo de

zGPadrão Credibilidade (95%)
?01 -0,060 0,041 (-0,143; 0,021) 1,929
?02 0,079 0,042 (-0,003; 0,159) 1,715
?03 -0,058 0,030 (-0,177; 0,002) 1,582
?04 0,070 0,020 (0,030; 0,111) 1,323
?05 -0,150 0,036 (-0,221; -0,080) -0,438
?11 0,366 0,060 (0,249; 0,486) -0,771
?12 -0,082 0,060 (-0,199; 0,036) -0,263
?13 0,170 0,045 (0,081; 0,259) -1,481
?14 0,416 0,032 (0,354; 0,479) -0,543
?15 0,091 0,053 (-0,015; 0,196) 1,737
?1 0,049 0,010 (0,033; 0,072) 0,630
?2 0,050 0,010 (0,034; 0,073) -0,255
?3 0,025 0,005 (0,016; 0,037) -0,812
?4 0,010 0,003 (0,005; 0,017) -0,499
?5 0,036 0,008 (0,024; 0,053) 0,761
?w 0,001 0,0009 (0,0003; 0,004) 0,635
?v1 0,001 0,0009 (0,0003; 0,004) 1,884
?v2 0,006 0,004 (0,001; 0,016) -0,143



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 75

?0.20 ?0.10 0.00 0.05 0.10

0
2

4
6

8
10

?01

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.2

0
?0

.1
0

0.
00

0.
10

Iteração

? 0
1

?0.1 0.0 0.1 0.2

0
2

4
6

8

?02

D
en

si
da

de

0 2000 4000 6000 8000 10000?
0.

10
0.

00
0.

10
0.

20

Iteração

? 0
2

?0.20 ?0.15 ?0.10 ?0.05 0.00 0.05

0
2

4
6

8
10

12

?03

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.1

5
?0

.0
5

0.
05

Iteração

? 0
3

0.00 0.05 0.10 0.15

0
5

10
15

20

?04

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0.
05

0.
10

0.
15

Iteração

? 0
4

?0.30 ?0.20 ?0.10 0.00

0
2

4
6

8
10

?05

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.2

5
?0

.1
5

?0
.0

5

Iteração

? 0
5

Figura 5.11: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?0’s no modelo 5.



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 76

0.1 0.2 0.3 0.4 0.5 0.6

0
1

2
3

4
5

6

?11

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
1

0.
2

0.
3

0.
4

0.
5

0.
6

Iteração

? 1
1

?0.3 ?0.2 ?0.1 0.0 0.1 0.2

0
1

2
3

4
5

6
7

?12

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.3

?0
.1

0.
0

0.
1

Iteração

? 1
2

0.0 0.1 0.2 0.3

0
2

4
6

8

?13

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0.
10

0.
20

0.
30

Iteração

? 1
3

0.30 0.35 0.40 0.45 0.50 0.55

0
2

4
6

8
10

12

?14

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
30

0.
40

0.
50

Iteração

? 1
4

?0.1 0.0 0.1 0.2 0.3

0
2

4
6

?15

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.1

0.
0

0.
1

0.
2

0.
3

Iteração

? 1
5

Figura 5.12: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?1’s no modelo 5.



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 77

0.02 0.04 0.06 0.08 0.10

0
10

20
30

40

?1

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
04

0.
06

0.
08

0.
10

Iteração

? 1

0.02 0.04 0.06 0.08 0.10

0
10

20
30

40

?2

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
04

0.
06

0.
08

0.
10

Iteração

? 2

0.01 0.02 0.03 0.04 0.05 0.06

0
20

40
60

80

?3

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
01

0.
03

0.
05

Iteração

? 3

0.000 0.005 0.010 0.015 0.020 0.025

0
20

60
10

0
14

0

?4

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

5
0.

01
5

0.
02

5

Iteração

? 4

Figura 5.13: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 5.



5.3 Transformação alr Considerando Três Efeitos Aleatórios - Modelo 5 78

0.02 0.04 0.06 0.08

0
10

20
30

40
50

?5

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
02

0.
04

0.
06

0.
08

Iteração

? 5

0.000 0.002 0.004 0.006 0.008

0
20

0
40

0
60

0

?w

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0
0.

00
4

0.
00

8

Iteração

? w

0.000 0.002 0.004 0.006 0.008 0.010

0
20

0
40

0
60

0

?v1

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0
0.

00
4

0.
00

8

Iteração

? v
1

0.00 0.01 0.02 0.03 0.04

0
20

40
60

80
12

0

?v2

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0.
01

0.
02

0.
03

0.
04

Iteração

? v
2

Figura 5.14: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 5.

A Tabela 5.6 apresenta as estimativas das proporções verdadeiras para os componentes
de proteína, gordura do leite, carboidrato, cálcio, sódio e potássio para zi = 0 (Grupo 1 -
antes da dieta) e para zi = 1 (Grupo 2 - depois da dieta), considerando a transformação
alr com três efeitos aleatórios.



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 79

Tabela 5.6: Estimativas das proporções dos componentes - Modelo 5.
Componentes do Proporções z = 0 Proporções z = 1leite (Grupo 1) (Grupo 2)
proteína ?1 0,160 ?7 0,193
gordura do leite ?2 0,183 ?8 0,142
carboidrato ?3 0,160 ?9 0,159
cálcio ?4 0,182 ?10 0,231
sódio ?5 0,146 ?11 0,134
potássio ?6 0,169 ?12 0,142

Mais uma vez, percebe-se que os resultados da Tabela 5.6 são semelhantes aos resul-
tados obtidos nas Tabelas 5.2 e 5.4, considerando as transformações alr e Box-Cox com
um efeito aleatório no modelo, respectivamente.

5.4 Transformação Box-Cox Considerando Três Efei-
tos Aleatórios - Modelo 6

Consideramos uma aplicação da transformação Box-Cox (3.3) nos dados composicio-
nais do Apêndice B, xi1, xi2, xi3, xi4, xi5 e xi6 para i = 1, . . . , 60.

Conforme apresentado na Seção 5.2, obtemos y(?1)i1 , . . . ,y
(?5)
i5 através da definição da

transformação de Box-Cox (3.3).

Para os dados transformados y(?1)i1 , . . . ,y
(?5)
i5 , podemos definir o modelo 6 como

yi
(?) = ?0 + ?1zi + wi + ajv1i + (1 ?aj)v2j + ?i, (5.36)

em que aj = 1 (Grupo 1) e aj = 0 (Grupo 2) para j = 1, . . . , 5. Assumimos a distribuição
Normal N(0,?2v1) e N(0,?

2
v2), para v1i e v2i, respectivamente. Também assumimos as

mesmas suposições consideradas para o modelo (5.1) e independência entre as quantidades
aleatórias wi, v1i, v2i e ?ji, i = 1, . . . , 60; j = 1, . . . , 5.

Considerando o modelo apresentado em (5.36), assumiremos que os erros ?i1, . . . ,?i5
são mutuamente independentes. Assim, obtém-se,



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 80

?i1 = y
(?1)
i1 ??01 ??11zi ?wi ?ajv1i ? (1 ?aj)v2j,

...

?i5 = y
(?5)
i5 ??05 ??15zi ?wi ?ajv1i ? (1 ?aj)v2j,

y
(?j)
ij ? N

(
?0j + ?1jzi; ?2j + ?

2
w + ?

2
v1

)
, (Grupo 1 - antes da dieta); e

y
(?j)
ij ? N

(
?0j + ?1jzi; ?2j + ?

2
w + ?

2
v2

)
, (Grupo 2 - depois da dieta),

para j = 1, . . . , 5 e i = 1, . . . , 60 (n = n1 + n2, onde n1 = 30 para o Grupo 1 e n2 = 30
para o Grupo 2).

De acordo com os resultados obtidos em (5.17) e (5.27) dos estimadores das proporções
verdadeiras dos componentes, podemos estendê-los para o modelo 6 (5.36) que considera a
transformação Box-Cox com três efeitos aleatórios. Desse modo, obtemos os estimadores
das proporções verdadeiras dos componentes do leite, ?i1, . . . ,?i6.

Logo,

?ij =
[?j(?0j + ?1jzi + wi + ajv1i + (1 ?aj)v2j) + 1]

1
?j{

1 + [?1(?01 + ?11zi + wi + ajv1i + (1 ?aj)v2j) + 1]
1
?1 + . . . + [?5(?05 + ?15zi + wi + ajv1i + (1 ?aj)v2j) + 1]

1
?5

} ,
...

?i6 =
1{

1 + [?1(?01 + ?11zi + wi + ajv1i + (1 ?aj)v2j) + 1]
1
?1 + . . . + [?5(?05 + ?15zi + wi + ajv1i + (1 ?aj)v2j) + 1]

1
?5

} ,

em que aj = 1 (Grupo 1 - antes da dieta), aj = 0 (Grupo 2 - depois da dieta) para
j = 1, . . . , 5 e i = 1, . . . , 60 (n = n1 + n2, em que n1 = 30 para o grupo 1 e n2 = 30 para
o grupo 2).

5.4.1 Análise Bayesiana - Modelo 6

A função densidade de probabilidade conjunta para os dados transformados y(?1)1 , . . . ,
y

(?5)
5 dado o vetor de parâmetros ?6 = (?01, . . . ,?05,?11, . . . ,?15,?21, . . . ,?25,?1, . . . ,?5,?2w,?2v1,?2v2)

é dada por



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 81

f(y(?1)1 , . . . ,y
(?5)
5 |?6) =

5?
j=1

1?
2?(?2j + ?2w + ?2v1)

exp
{
?

1
2(?2j + ?2w + ?2v1)

[yij ? (?0j + ?1jzi)]2
}

×
5?
j=1

1?
2?(?2j + ?2w + ?2v2)

exp
{
?

1
2(?2j + ?2w + ?2v2)

[(yij ? (?0j + ?1jzi)]2
}

Por outro lado, a função densidade de probabilidade das observações não transfor-
madas (variáveis originais) [Box &amp;amp; Tiao [9]], yi1 = xi1/xi6, yi2 = xi2/xi6, yi3 = xi3/xi6,
yi4 = xi4/xi6 e yi5 = xi5/xi6 é dada por

f(y1, . . . ,y5|?6) =
5?
j=1

1?
2?(?2j + ?2w + ?2v1)

exp
[
?

1
2(?2j + ?2w + ?2v1)

(
y

(?j)
ij ??0j ??1jzi

)2]

×
5?
j=1

1?
2?(?2j + ?2w + ?2v2)

exp
[
?

1
2(?2j + ?2w + ?2v2)

(
y

(?j)
ij ??0j ??1jzi

)2]

×
5?
j=1

?
?dy(?j)ij

dyij

?
? ,

em que para j = 1, . . . , 5,
dy(?j)ij
dyij

=
?jy

?j?1
ij

?j
= y?j?1ij são os elementos da diagonal da

matriz Jacobiano.

A função de verossimilhança para os parâmetros ?0 = (?01, . . . ,?05), ?1 = (?11, . . . ,?15),
?2 = (?21, . . . ,?

2
5 ), ? = (?1, . . . ,?5), ?

2
w, ?

2
v1 e ?

2
v2 do modelo (5.36) é dada por

L(?0,?1,?2,?,?2w,?
2
v1,?

2
v2) =

5?
j=1

(?2j + ?
2
w + ?

2
v1)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v1)

30?
i=1

?2ij

]

×
5?
j=1

(?2j + ?
2
w + ?

2
v2)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v2)

30?
i=1

?2ij

]

×
(

n?
i=1

y
?j?1
ij

)
, (5.37)

em que
30?
i=1

?2ij =
30?
i=1

(
y

(?j)
ij ? (?0j + ?1jzi)

)2
.

Para a análise Bayesiana do modelo (5.36), consideramos as mesmas distribuições
a priori dadas em (5.7), (5.8) e (5.29) e a função de verossimilhança (5.37). Dessa



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 82

forma, a distribuição a posteriori conjunta para os parâmetros ?0 = (?01, . . . ,?05),
?1 = (?11, . . . ,?15), ?2 = (?21, . . . ,?

2
5,?

2
w,?

2
v1,?

2
v2) e ? = (?1, . . . ,?5) é dada por

?(?0,?1,?,?2,?2w,?
2
v1,?

2
v2|y

(?)) ?
5?
j=1

exp
[
?

1
2b20j

(?0j ?a0j)2
] 5?
j=1

exp
[
?

1
2b21j

(?1j ?a1j)2
]

×
5?
j=1

(?2j )
?(cj+1)exp

(
?
dj
?2j

) 5?
j=1

(?2w)
?(cw+1)exp

(
?
dw
?2w

)

×
5?
j=1

(?2v1)
?(av1+1)exp

(
?
bv1
?2v1

) 5?
j=1

(?2v2)
?(av2+1)exp

(
?
bv2
?2v2

)

×
5?
j=1

exp
[
?

1
2f2j

(?j ?ej)2
]
×

?
? 5?
j=1

n?
i=1

y
?j?1
ij

?
?

×
5?
j=1

(?2j + ?
2
w + ?

2
v1)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v1)

n?
i=1

?2ij

]

×
5?
j=1

(?2j + ?
2
w + ?

2
v2)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v2)

n?
i=1

?2ij

]
.

As distribuições a posteriori condicionais são dadas por:

i) ?(?0j|?1,?2,?2w,?
2
v1,?

2
v2,?,y

(?)) ? N
(
a0j,b

2
0j

)
×

2?
l=1

exp
[
?

1
2(?2j + ?2w + ?2vl)

n?
i=1

(?0j ?µ
(j)
i )

2
]
,

(5.38)

em que µ(j)i = y
(?j)
ij ??1jzi; i = 1, . . . ,n, j = 1, . . . , 5 e l = 1, 2.

ii) ?(?1j|?0,?2,?2w,?
2
v1,?

2
v2,?,y

(?)) ? N
(
a1j,b

2
1j

)
×

2?
l=1

exp
[
?

1
2(?2j + ?2w + ?2vl)

n?
i=1

(
?1jzi ??

(j)
i

)2]
,

(5.39)

em que ?(j)i = y
(?j)
ij ??0j; i = 1, . . . ,n, j = 1, . . . , 5 e l = 1, 2.



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 83

iii) ?(?2j |?0,?1,?
2
w,?

2
v1,?

2
v2,?,y

(?)) ? (?2j )
?(cj+1)exp

(
?
dj
?2j

)

×
2?
l=1

exp
[
?

1
2(?2j + ?2w + ?2vl)

n?
i=1

?2ij

]
, (5.40)

para i = 1, . . . ,n, j = 1, . . . , 5 e l = 1, 2.

iv) ?(?2w|?0,?1,?
2,?2v1,?

2
v2,?,y

(?)) ? (?2w)
?(cw+1)exp

(
?
dw
?2w

)

×
2?
l=1

(?2j + ?
2
w + ?

2
vl)
?n/2exp

[
?

1
2(?2j + ?2w + ?2vl)

n?
i=1

?2ij

]
,

(5.41)

para i = 1, . . . ,n, j = 1, . . . , 5 e l = 1, 2.

v) ?(?2v1|?0,?1,?
2,?2w,?

2
v2,?,y

(?)) ? (?2v1)
?(av1+1)exp

(
?
bv1
?2v1

)

× (?2j + ?
2
w + ?

2
v1)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v1)

n?
i=1

?2ij

]
,

(5.42)

para i = 1, . . . ,n e j = 1, . . . , 5 (Grupo 1 - antes da dieta).

vi) ?(?2v2|?0,?1,?
2,?2w,?

2
v1,?,y

(?)) ? (?2v2)
?(av2+1)exp

(
?
bv2
?2v2

)

× (?2j + ?
2
w + ?

2
v2)
?n/2exp

[
?

1
2(?2j + ?2w + ?2v2)

n?
i=1

?2ij

]
,

(5.43)

para i = 1, . . . ,n e j = 1, . . . , 5 (Grupo 2 - depois da dieta).



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 84

vii) ?(?j|?0,?1,?2,?2w,?
2
v1,?

2
v2,y

(?)) ? N
(
ej,f

2
j

) 2?
l=1

?
(l)
j (?0,?1,?

2,?2w,?
2
vl,?),

(5.44)

em que

?
(l)
j (?0,?1,?

2,?2w,?
2
vl,?) = exp

[
(?j ? 1)

n?
i=1

ln yij +
1

(?2j + ?2w + ?
2
vl)

n?
i=1

(
y

(?j)
ij ? (?0j + ?1j)

)2]

= exp
[
(?j ? 1)

n?
i=1

lnyij +
1

(?2j + ?2w + ?2vl)

(
n?
i=1

y
(?j)2
ij ? 2?0j

n?
i=1

y
(?j)
ij ? 2?1j

n?
i=1

y
(?j)
ij zi

)]
,

para j = 1, . . . , 5 e l = 1, 2.

Podemos observar que as distribuições a posteriori condicionais (5.38), (5.39), (5.40),
(5.41), (5.42), (5.43) e (5.44) não apresentaram formas fechadas e, portanto, obtemos as
estimativas dos parâmetros do modelo (5.36) através do algoritmo de Metropolis-Hastings.

Para a análise Bayesiana dos dados do Apêndice B, considera-se a transformação
Box-Cox com erros normais não correlacionados para o modelo proposto (5.36).

Assumindo a transformação Box-Cox para o modelo (5.36), e as distribuições a priori
para ?0j,?1j,?2j ,?j,?

2
w,?

2
v1,?

2
v2 com hiperparâmetros cujos valores foram a0j = 1; b0j =

b1j = fj = 1.000.000, a1j = ej = 0 e cj = dj = aw = bw = av1 = bv1 = av2 = bv2 =
1.000, geramos no software OPENBUGS 205.000 iterações, nas quais foram descartadas
as 5.000 iterações iniciais (“burn-in”). Após o período de “‘burn-in”, consideramos saltos
de tamanho 20 para obtermos amostras não correlacionadas, na qual resultou uma amostra
final de tamanho 10.000 para cada parâmetro. A convergência do algoritmo foi verificada
pelos gráficos dos traços a posteriori das amostras de Gibbs simuladas e pelo diagnóstico
de Geweke (Geweke, [23]).

Na Tabela 5.7 apresentamos os sumários a posteriori dos parâmetros do modelo (5.26)
e os valores correspondentes da estatística de teste para o diagnóstico de convergência
Geweke.



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 85

Tabela 5.7: Resumos a posteriori e Estatística de Teste para o Diagnóstico de Geweke -
Modelo 6.

Parâmetro Média Desvio Intervalo de zGPadrão Credibilidade (95%)
?01 -0,059 0,044 (-0,145; 0,029) 0,369
?02 0,075 0,045 (-0,013; 0,165) 1,762
?03 -0,067 0,032 (-0,129; -0,004) -0,751
?04 0,066 0,015 (0,037; 0,097) 0,166
?05 -0,158 0,040 (-0,241; -0,083) -0,986
?11 0,371 0,066 (0,244; 0,502) -1,649
?12 -0,084 0,062 (-0,205; 0,038) -0,776
?13 0,166 0,045 (0,079; 0,254) -0,638
?14 0,304 0,047 (0,218; 0,406) -0,097
?15 0,091 0,053 (-0,012; 0,197) -0,629
?1 0,053 0,012 (0,034; 0,081) -0,240
?2 0,053 0,011 (0,036; 0,079) 1,346
?3 0,027 0,006 (0,018; 0,040) 0,812
?4 0,004 0,002 (0,001; 0,010) 0,764
?5 0,039 0,010 (0,023; 0,063) -0,873
?w 0,0009 0,0006 (0,0002; 0,002) -0,042
?v1 0,0009 0,0006 (0,0002; 0,002) 0,720
?v2 0,003 0,002 (0,0005; 0,009) -0,125
?1 0,066 0,383 (-0,684; 0,826) 0,130
?2 -0,163 0,507 (-1,143; 0,839) 1,713
?3 -0,608 0,604 (-1,818; 0,549) 0,542
?4 -1,114 0,491 (-2,143; -0,170) 0,294
?5 -0,328 0,647 (-1,623; 0,920) -0,209

As densidades a posteriori e o comportamento da cadeia gerada para os parâmetros
do modelo (5.36) são apresentadas nas Figuras 5.15, 5.16, 5.17, 5.18 e 5.19. Além disso, a
convergência do algoritmo foi verificada utilizando o diagnóstico de Geweke. Sendo assim,
podemos observar que os valores da estatística do teste zG estão no intervalo (-1,96;1,96)
indicando convergência para todos os parâmetros estimados.



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 86

?0.2 ?0.1 0.0 0.1

0
2

4
6

8

?01

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.2

0
?0

.1
0

0.
00

0.
10

Iteração

? 0
1

?0.1 0.0 0.1 0.2

0
2

4
6

8

?02

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.0

5
0.

05
0.

15
0.

25

Iteração

? 0
2

?0.20 ?0.10 0.00 0.05

0
2

4
6

8
10

12

?03

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.2

0
?0

.1
0

0.
00

Iteração

? 0
3

0.02 0.04 0.06 0.08 0.10 0.12 0.14

0
5

10
15

20
25

30

?04

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
02

0.
06

0.
10

0.
14

Iteração

? 0
4

?0.35 ?0.25 ?0.15 ?0.05

0
2

4
6

8
10

?05

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.3

0
?0

.2
0

?0
.1

0

Iteração

? 0
5

Figura 5.15: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?0’s no modelo 6.



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 87

0.2 0.3 0.4 0.5 0.6 0.7

0
1

2
3

4
5

6

?11

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
2

0.
3

0.
4

0.
5

0.
6

0.
7

Iteração

? 1
1

?0.3 ?0.2 ?0.1 0.0 0.1 0.2

0
1

2
3

4
5

6

?12

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.3

?0
.1

0.
0

0.
1

Iteração

? 1
2

0.0 0.1 0.2 0.3

0
2

4
6

8

?13

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0.
10

0.
20

0.
30

Iteração

? 1
3

0.2 0.3 0.4 0.5

0
2

4
6

8

?14

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
20

0.
30

0.
40

0.
50

Iteração

? 1
4

?0.1 0.0 0.1 0.2 0.3

0
2

4
6

?15

D
en

si
da

de

0 2000 4000 6000 8000 10000

?0
.1

0.
0

0.
1

0.
2

0.
3

Iteração

? 1
5

Figura 5.16: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?1’s no modelo 6.



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 88

?1.5 ?1.0 ?0.5 0.0 0.5 1.0 1.5

0.
0

0.
2

0.
4

0.
6

0.
8

1.
0

?1

D
en

si
da

de

0 2000 4000 6000 8000 10000

?1
.5

?0
.5

0.
5

1.
5

Iteração

? 1

?2 ?1 0 1 2

0.
0

0.
2

0.
4

0.
6

0.
8

?2

D
en

si
da

de

0 2000 4000 6000 8000 10000

?2
?1

0
1

Iteração

? 2

?3 ?2 ?1 0 1 2

0.
0

0.
2

0.
4

0.
6

?3

D
en

si
da

de

0 2000 4000 6000 8000 10000

?3
?2

?1
0

1

Iteração

? 3

?3 ?2 ?1 0

0.
0

0.
2

0.
4

0.
6

0.
8

?4

D
en

si
da

de

0 2000 4000 6000 8000 10000

?3
.0

?2
.0

?1
.0

0.
0

Iteração

? 4

?3 ?2 ?1 0 1 2

0.
0

0.
2

0.
4

0.
6

?5

D
en

si
da

de

0 2000 4000 6000 8000 10000

?2
?1

0
1

2

Iteração

? 5

Figura 5.17: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros ?’s no modelo 6.



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 89

0.02 0.04 0.06 0.08 0.10 0.12 0.14

0
10

20
30

?1

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
04

0.
08

0.
12

Iteração

? 1

0.02 0.04 0.06 0.08 0.10 0.12

0
10

20
30

40

?2

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
04

0.
06

0.
08

0.
10

0.
12

Iteração

? 2

0.01 0.02 0.03 0.04 0.05 0.06

0
20

40
60

?3

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
02

0.
04

0.
06

Iteração

? 3

0.000 0.005 0.010 0.015 0.020 0.025

0
50

10
0

15
0

20
0

?4

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0
0.

01
0

0.
02

0

Iteração

? 4

Figura 5.18: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 6.



5.4 Transformação Box-Cox Considerando Três Efeitos Aleatórios - Modelo 6 90

0.02 0.04 0.06 0.08 0.10 0.12

0
10

20
30

40

?5

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
02

0.
06

0.
10

Iteração

? 5

0.000 0.002 0.004 0.006

0
20

0
40

0
60

0
80

0

?w

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0
0.

00
2

0.
00

4
0.

00
6

Iteração

? w

0.000 0.002 0.004 0.006

0
20

0
40

0
60

0
80

0

?v1

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0
0.

00
2

0.
00

4
0.

00
6

Iteração

? v
1

0.000 0.005 0.010 0.015 0.020

0
50

10
0

15
0

20
0

?v2

D
en

si
da

de

0 2000 4000 6000 8000 10000

0.
00

0
0.

01
0

0.
02

0

Iteração

? v
2

Figura 5.19: Densidades a posteriori via amostrador de Gibbs e traços a posteriori para
os parâmetros de variância no modelo 6.

Dos resultados da Tabela 5.7 observamos que as diferenças entre os dois grupos (antes
e depois da dieta) para os componentes proteína (pr), carboidrato (ch) e cálcio (Ca) foram
significativas, pois os intervalos de credibilidade para ?11, ?13 e ?14 não incluem o valor
zero.



5.5 Análise Clássica 91

Os parâmetros ?1,?2,?3 e ?5 não foram significativos, indicando que a transforma-
ção alr, que é um caso especial da transformação Box-Cox, para esses casos seria mais
adequada (? = 0).

A Tabela 5.8 apresenta as estimativas das proporções para os componentes de pro-
teína, gordura do leite, carboidrato, cálcio, sódio e potássio para zi = 0 (Grupo 1 - antes
da dieta) e para zi = 1 (Grupo 2 - depois da dieta), considerando a transformação Box-Cox
com três efeitos aleatórios.

Tabela 5.8: Estimativas das proporções dos componentes - Modelo 6.
Componentes do Proporções z = 0 Proporções z = 1leite (Grupo 1) (Grupo 2)
proteína ?1 0,160 ?7 0,194
gordura do leite ?2 0,183 ?8 0,141
carboidrato ?3 0,159 ?9 0,158
cálcio ?4 0,182 ?10 0,230
sódio ?5 0,146 ?11 0,133
potássio ?6 0,170 ?12 0,143

Podemos observar que os valores das estimativas não se alteraram em comparação aos
resultados já apresentados nas Tabelas 5.2, 5.4 e 5.6, sendo que houve um aumento nas
proporções para os componentes proteína e cálcio e uma diminuição das proporções de
gordura do leite e potássio após a dieta balanceada.

5.5 Análise Clássica

Da mesma forma que no Capítulo 4, os dados composicionais do Apêndice B foram
também analisados através de métodos clássicos aplicando a transformação alr em que
utilizou-se a rotina PROC NLMIXED do software SAS para a estimação dos parâmetros
do modelo (5.1) com o objetivo de comparação entre os métodos de estimação Bayesiano
e clássico.

Para ilustrar a comparação, considerou-se o modelo (5.1), ou seja, o modelo com um
efeito aleatório.

As estimativas dos parâmetros e seus respectivos intervalos de confiança são apresen-
tados na Tabela 5.9.



5.5 Análise Clássica 92

Tabela 5.9: Estimativas dos parâmetros do modelo 3 - Método Clássico

Parâmetro Estimativa Desvio Intervalo dePadrão Confiança (95%)
?01 -0,026 0,017 (-0,062; 0,009)
?02 0,034 0,018 (-0,002; 0,071)
?03 -0,025 0,013 (-0,053; 0,002)
?04 0,030 0,009 (0,012; 0,049)
?05 -0,065 0,014 (-0,093; -0,037)
?11 0,159 0,025 (0,109; 0,210)
?12 -0,036 0,025 (-0,088; 0,016)
?13 0,074 0,019 (0,035; 0,113)
?14 0,180 0,013 (0,155; 0,206)
?15 0,039 0,019 (0,0001; 0,078)
?1 0,095 0,009 (0,077; 0,114)
?2 0,098 0,009 (0,079; 0,118)
?3 0,073 0,007 (0,059; 0,087)
?4 0,049 0,005 (0,039; 0,058)
?5 0,074 0,007 (0,060; 0,088)
?w 0,012 0,008 (-0,004; 0,027)

Apesar de utilizar distribuições a priori não-informativas para a modelagem Bayesi-
ana, os resultados da Tabela 5.9 não foram tão semelhantes com relação às estimativas
Bayesianas. Além de apresentar diferenças antes e depois da dieta para os componentes
proteína, carboidrato e cálcio, ?15 foi significativo, ou seja, o componente sódio diferen-
ciou após a dieta quando modelamos os dados através da inferência clássica. Percebe-se
que o limite inferior do intervalo de confiança do ?w é negativo, indicando problemas na
estimação clássica para esse parâmetro.

Prosseguindo com a análise dos dados longitudinais referente a qualidade do leite
após uma dieta estabelecida, ajustamos um modelo de regressão Dirichlet, sob o enfoque
clássico em que as estimativas de máxima verossimilhança para os parâmetros do modelo
proposto (3.4) foram obtidos no software R, através do pacote DirichletReg. Os resultados
da estimação dos parâmetros do modelo estão dispostos na Tabela 5.10.

Na Tabela 5.10, podemos verificar que para os componentes gordura do leite, carboi-
drato, sódio e potássio, os coeficientes de regressão foram significativos, ou seja, houve
diferença nesses componentes do leite após a aplicação da dieta. Podemos notar que
esses coeficientes apresentaram valores negativos, indicando que a proporção para esse
componentes no leite diminuiu após a dieta.



5.6 Discussão dos Resultados 93

Tabela 5.10: Estimativas dos parâmetros do modelo de Regressão Dirichlet

Parâmetro Estimativa Desvio Intervalo dePadrão Confiança (95%)
?01 3,818 0,118 (3,587; 4,048)
?02 3,957 0,117 (3,727; 4,187)
?03 3,821 0,118 (3,590; 4,051)
?04 3,948 0,117 (3,718; 4,178)
?05 3,73 0,118 (3,499; 3,960)
?06 3,878 0,117 (3,648; 4,108)
?11 -0,225 0,167 (-0,552; 0,101)
?12 -0,668 0,167 (-0,996; -0,341)
?13 -0,419 0,167 (-0,746; -0,091)
?14 -0,177 0,166 (-0,503; 0,149)
?15 -0,497 0,167 (-0,825; -0,168)
?16 -0,586 0,167 (-0,914; -0,259)

5.6 Discussão dos Resultados

Para a seleção de modelos, pode-se utilizar alguns critérios de discriminação de mo-
delos, sendo que destacamos Deviance Information Criterion (DIC) (Spiegelhalter et
al., [46]). Menores valores do DIC indicam o melhor modelo. Os valores de DIC foram
obtidos através do software OPENBUGS.

Na Tabela 5.11, temos os valores de DIC para o modelo 3 (transformação alr consi-
derando um efeito aleatório), modelo 4 (transformação Box-Cox considerando um efeito
aleatório), modelo 5 (transformação alr considerando três efeitos aleatórios) e o modelo
6 (transformação Box-Cox considerando três efeitos aleatórios).

Tabela 5.11: Critério DIC - Modelos 3, 4, 5 e 6.

Modelo DIC
Modelo 3 -162,5
Modelo 4 -123,1
Modelo 5 -169,6
Modelo 6 -124,7

De acordo com os resultados da Tabela 5.11, podemos observar que o melhor ajuste dos
dados composicionais do Apêndice B foi para o modelo 5 (transformação alr considerando
três efeitos aleatórios), que apresentou menor valor de DIC. E ainda, observa-se que os
modelos que consideraram a transformação alr apresentaram menores valores do critério
DIC que os modelos que abordaram a tranformação Box-Cox.



5.6 Discussão dos Resultados 94

Além disso, calculou-se a soma do quadrado das diferenças entre os valores observados
e os valores ajustados dos modelos são apresentados na Tabela 5.12.

Tabela 5.12: Soma do quadrado das diferenças entre os valores observados e os valores
ajustados.

Modelo
n?
i=1

6?
j=1

(yij ? y?ij)2

Modelo 3 (transformação alr com 1 efeito aleatório - Bayesiano) 0,220812
Modelo 4 (transformação Box-Cox com 1 efeito aleatório - Bayesiano) 0,220743
Modelo 5 (transformação alr com 3 efeitos aleatórios - Bayesiano) 0,220705
Modelo 6 (transformação Box-Cox com 3 efeitos aleatórios - Bayesiano) 0,220877
Modelo (transformação alr com 1 efeito aleatório - Análise Clássica) 0,300242
Modelo de Regressão Dirichlet clássico 0,220714

Analisando os resultados obtidos, percebe-se que há pouca diferença entre os valores
da Tabela 5.12.

Por outro lado, podemos afirmar que dentre os modelos ajustados, o modelo 5 (alr
com 3 efeitos aleatórios) se ajusta melhor aos dados longitudinais (qualidade do leite)
através do critério DIC e também pela soma do quadrado das diferenças entre os valores
observados e os valores ajustados em que apresentou menor valor (diferença mínima em
relação aos outros modelos). É importante salientar que os menores valores da Tabela
5.12 foram para os modelos em que os parâmetros foram estimados através da inferência
Bayesiana.

A Figura 5.20 apresenta os valores ajustados e observados dos componentes do leite
(proteína, gordura do leite, carboidrato, cálcio, sódio e potássio) para cada modelo pro-
posto. Podemos observar que os valores ajustados através da inferência clássica são os
mais distantes em relação à média observada.



5.6 Discussão dos Resultados 95

0.0 0.2 0.4 0.6 0.8 1.0

0
.1

4
0

.1
5

0
.1

6
0

.1
7

0
.1

8
0

.1
9

0
.2

0

Antes (z=0) e depois (z=1) da dieta

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 p

ro
te

ín
a

alr?1 efeito
alr?3 efeitos
Box?Cox?1 efeito
Box?Cox?3 efeitos
clássica
Regressão Dirichlet
Média observada

0.0 0.2 0.4 0.6 0.8 1.0

0
.1

4
0

.1
5

0
.1

6
0

.1
7

0
.1

8
0

.1
9

Antes (z=0) e depois (z=1) da dieta

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 g

o
rd

u
ra

 d
o

 le
ite

alr?1 efeito
alr?3 efeitos
Box?Cox?1 efeito
Box?Cox?3 efeitos
clássica
Regressão Dirichlet
Média observada

0.0 0.2 0.4 0.6 0.8 1.0

0
.1

5
0

0
.1

5
5

0
.1

6
0

0
.1

6
5

0
.1

7
0

Antes (z=0) e depois (z=1) da dieta

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 c

a
rb

o
id

ra
to alr?1 efeito

alr?3 efeitos
Box?Cox?1 efeito
Box?Cox?3 efeitos
clássica
Regressão Dirichlet
Média observada

0.0 0.2 0.4 0.6 0.8 1.0

0
.1

7
0

.1
9

0
.2

1
0

.2
3

Antes (z=0) e depois (z=1) da dieta

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 c

á
lc

io

alr?1 efeito
alr?3 efeitos
Box?Cox?1 efeito
Box?Cox?3 efeitos
clássica
Regressão Dirichlet
Média observada

0.0 0.2 0.4 0.6 0.8 1.0

0
.1

3
0

0
.1

4
0

0
.1

5
0

0
.1

6
0

Antes (z=0) e depois (z=1) da dieta

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 s

ó
d

io

alr?1 efeito
alr?3 efeitos
Box?Cox?1 efeito
Box?Cox?3 efeitos
clássica
Regressão Dirichlet
Média observada

0.0 0.2 0.4 0.6 0.8 1.0

0
.1

4
0

.1
5

0
.1

6
0

.1
7

0
.1

8

Antes (z=0) e depois (z=1) da dieta

E
st

im
a

tiv
a

 d
a

 p
ro

p
o

rç
ã

o
 d

e
 p

o
tá

ss
io

alr?1 efeito
alr?3 efeitos
Box?Cox?1 efeito
Box?Cox?3 efeitos
clássica
Regressão Dirichlet
Média observada

Figura 5.20: Gráficos dos valores observados e ajustados dos componentes do leite de
acordo com o modelo



96

6 Considerações Finais

Neste trabalho, realizamos um estudo de dados composicionais aplicados em modelos
de regressão sob o enfoque Bayesiano. Uma das restrições que os dados composicionais
possui e que difere dos dados multivariados usuais, é que eles são definidos como um vetor
em que seus elementos são positivos e correspondem à proporções ou frações, tal que a
soma de todos eles é igual a 1. No entanto, essa restrição não deve ser ignorada para que
os resultados da análise estatística não se tornem imprecisos.

Foram abordados transformações em dados composicionais, sendo elas, a transforma-
ção alr e Box-Cox, em que foram considerados erros não correlacionados com distribuição
Normal para a modelagem estatística. A metodologia proposta foi aplicada em dois con-
juntos de dados, sendo que um deles refere-se à dados longitudinais. Vale ressaltar que a
abordagem da metodologia de dados composicionais para a análise dos dois conjuntos de
dados do presente trabalho é inédita. Além disso, para efeito de comparação, abordamos
o método clássico e o modelo de regressão Dirichlet (clássico).

Para o conjunto de dados referente aos jogos da Superliga de vôlei masculina, o mo-
delo que obteve melhor ajuste foi o modelo de regressão Dirichlet, apesar de que o modelo
1 (transformação alr) apresentou melhor ajuste dentre os modelos que utilizou métodos
Bayesianos. Para o conjunto de dados longitudinais (Apêndice B), o modelo 5 que consi-
derou a transformação alr com três efeitos aleatórios foi mais adequado aos dados, seguido
do modelo de regressão Dirichlet.

Há muitas dificuldades na obtenção de resultados na inferência clássica para tais
modelos, principalmente quando há presença de um vetor de covariáveis. Com isso, a
aplicação dos métodos Bayesianos para dados composicionais mostrou ser uma alterna-
tiva vantajosa para a sua análise, especialmente relacionados às restrições que a variável
resposta possui, considerando ainda a aplicação dos métodos MCMC.

O uso do software OPENBUGS proporcionou facilidade na implementação dos al-
goritmos amostrador de Gibbs e Metropolis-Hastings para as aplicações apresentadas,



6 Considerações Finais 97

juntamente com o software R através do pacote CODA para a construção dos gráficos e
dos resultados obtidos do diagnóstico de convergência de Geweke e o software SAS para a
obtenção das estimativas através da inferência clássica. Os software utilizados mostraram
ser ferramentas computacionais importantes para a obtenção dos resultados de interesse.

Como perspectiva futura de trabalho, uma delas envolve o estudo de modelos apro-
priados quando há presença de zeros em dados composicionais, assumir outros tipos de
estrutura para os erros dos modelos, como por exemplo, distribuições assimétricas, t-
Student multivariada.



98

Referências

[1] ACHCAR, J. A.; OBAGE, S. C. Uma abordagem Bayesiana para dados composi-
cionais considerando erros correlacionados. Revista de Matemática e Estatística, v.
23, n. 2, p. 95-107, 2005.

[2] AITCHISON, J. The statistical analysis of compositional data. Journal of the Royal
Statistical Society. Series B (Methodological), v. 44, n. 2, p. 139-177, 1982.

[3] AITCHISON, J. The statistical analysis of compositional data. Chapman &amp;amp; Hall,
1986.

[4] AITCHISON, J. A Concise Guide to Compositional Data Analysis. CDA Workshop,
Girona, 2005.

[5] AITCHISON, J.; EGOZCUE, J. J. Compositional data analysis: Where are we and
where should we be heading? Mathematical Geology, v. 37, n. 7, p. 829-850, 2005.

[6] AITCHISON, J.; GREENACRE, M. Biplots of Compositional Data. Journal of the
Royal Statistical Society. Series C (Applied Statistics). v. 51, n. 4, p. 375-392, 2002.

[7] AITCHISON, J.; SHEN, S. M. Logistic-normal distributions: Some properties and
uses. Biometrika. v. 67, n. 2, p. 261-272, 1980.

[8] BOX, G. E. P.; COX, D. R. An analysis of transformations. Journal of the Royal
Statistical Society. Series B (Methodological), v. 26, n. 2, p. 211-252, 1964.

[9] BOX, G. E. P.; TIAO, G. C. Bayesian inference in statistical analysis. Reading:
Addison-Wesley, 1973.

[10] BREHM, J.; GATES, S.; GOMEZ, B. A Monte Carlo Comparison of Methods for
Compositional Data Analysis. Political Methodology Society Annual Meetings, San
Diego, 1998.

[11] CAMARGO, A. P.; STERN; J. M.; LAURETTO, M. S. Estimation and Model
Selection in Dirichlet Regression. In: AIP Conference Proceedings, v. 1443, p. 206-
213, 2012.

[12] CAMPBELL, G.; MOSIMANN, J. Multivariate methods for proportional shape.
ASA Proceedings of the Section on Statistical Graphics, 10-17, 1987.

[13] CASELLA, G; BERGER, R. L. Statistical Inference. 2a ed., Pacific Grove: Duxbury
Advanced Series, 2002.

[14] CASELLA, G.; GEORGE, E. I. Explaining the Gibbs Sampler. The American Sta-
tistician, v. 46, n. 3, p. 167-174, 1992.



Referências 99

[15] CBV - Confederação Brasileira de Voleibol. Dados Superliga de Vôlei Mas-
culina. Disponível em: http://www.cbv.com.br/v1/superliga-1112/m-tabela.asp.
Acesso em: 23 de agosto de 2012.

[16] CONGDON, P. Bayesian Statistical Modelling. Second edition, John Wiley &amp;amp; Sons,
2006.

[17] EHLERS, R. S. Introdução à Inferência Bayesiana. 5a ed, 2007.

[18] GAMERMAN, D.; LOPES, H. F. Markov Chain Monte Carlo: Stochastic Simula-
tion for Bayesian Inference. Chapman &amp;amp; Hall/CRC, 2006.

[19] GAMERMAN, D.; MIGON, H. S. Inferência Estatística: Uma abordagem integrada.
Universidade Federal do Rio de Janeiro, 1997.

[20] GELFAND, A. E.; SMITH, A. F. M. Sampling based approaches to calculating
marginal densities. Journal of the American Statistical Association, v. 85, n. 410, p.
398-409, 1990.

[21] GELMAN, A.; RUBIN, D. B. Inference from Iterative Simulation Using Multiple
Sequences. Statistical Science, v. 7, n. 4, p. 457-472, 1992.

[22] GEMAN, S.; GEMAN, D. Stochastic Relaxation, Gibbs Distributions and the Baye-
sian Restoration of Images. IEEE Transactions on Pattern Analysis and Machine
Intelligence, n. 6, p. 721-741, 1984.

[23] GEWEKE, J. Evaluating the Accuracy of Sampling-Based Approaches to Calculating
Posterior Moments. In Bayesian Statistics 4, Oxford University Press, 1992.

[24] GUEORGUIEVA, R.; ROSENHECK, R.; ZELTERMAN, D. Dirichlet component
regression and its applications to psychiatric data. Computational Statistics and
Data Analysis, v. 52, n. 12, p. 5344-5355, 2008.

[25] HASTINGS, W. K. Monte Carlo Sampling Methods Using Markov Chains and Their
Applications. Biometrika, v. 57, n. 1, p. 97-109, 1970.

[26] HIJAZI, R. An EM-Algorithm Based Method to Deal with Rounded Zeros in
Compositional Data under Dirichlet Models. Proceedings of the 4th International
Workshop on Compositional Data Analysis, 2011.

[27] HIJAZI, R.; JERNIGAN, R. W. Modelling compositional data using Dirichlet re-
gression models. Journal of Applied Probability &amp;amp; Statistics, v. 4, n. 1, p. 77-91,
2009.

[28] IYENGAR, M.; DEY, D. K. Bayesian analysis of compositional data. Department
of Statistics, University of Connecticut, Storrs, CT 06269-3120, 1996.

[29] IYENGAR, M.; DEY, D. K. Box-Cox transformations in Bayesian analysis of com-
positional data. Environmetrics, v. 9, n. 6, p. 657-671, 1998.

[30] JOHNSON, D. S.; HOETING, J. A.; POFF, N. L. Biological Monitoring: A Baye-
sian Model for multivariate compositional data. Bayesian statistics and its applica-
tions. Anamaya Publishers, New Delhi, India, p. 270-289, 2006.



Referências 100

[31] JOHNSON, R.; WICHERN, D. Applied multivariate statistical analysis. New Jersey:
Prentice Hall, 1998.

[32] LUNN, D.; SPIEGELHALTER, D.; THOMAS, A.; BEST, N. The BUGS project:
Evolution, critique and future directions. Statistics in Medicine, v. 28, n. 25, p.
3049–3067, 2009.

[33] MARTÍN-FERNANDEZ,J. A.; BARCELÓ-VIDAL, C.; PAWLOWSKY-GLAHN,
V. Dealing with zeros and missing values in compositional data sets using nonpara-
metric imputation. Mathematical Geology, v. 35, n. 3, p. 253-278, 2003.

[34] MARTINS, A. B. T.; RIBEIRO Jr, P. J.; BONAT, W. H. Um modelo geoestatístico
bivariado para dados composicionais. Revista de Matemática e Estatística, v. 27, n.
3, p. 456-477, 2009.

[35] McALISTER, D. The law of the geometric mean. Proceedings of the Royal Society
of London, v. 29, p. 367-376, 1879.

[36] MELO, T. F. N.; VASCONCELLOS, K. L. P.; LEMONTE, A. J. Some restriction
tests in a new class of regression models for proportions. Computational Statistics
&amp;amp; Data Analysis, v. 53, n. 12, p. 3972-3979, 2009.

[37] METROPOLIS, N.; ROSENBULTH, A. W.; ROSENBULTH, M. N.; TELLER,
A. H.; TELLER, E. Equation of State Calculations by Fast Computing Machine.
Journal of Chemical Physics, v. 21, n. 6, p. 1087-1092, 1953.

[38] MIGON, H. S.; SOUZA, A. D. P.; SCHMIDT, A. M. Modelos Hierárquicos e Apli-
cações. 18o SINAPE, 279 p., 2008.

[39] NEOCLEOUS, T.; AITKEN, C.; ZADORA, G. Transformations for compositional
data with zeros with an application to forensic evidence evaluation. Chemometrics
and Intelligent Laboratory Systems, v. 1, n. 1, p. 77-85, 2011.

[40] NTZOUFRAS, I. Bayesian Modeling using Winbugs. New Jersey: John Wiley &amp;amp;
Sons, 2009.

[41] PAULINO, C. D.; TURKMAN, M. A. A.; MURTEIRA, B. Estatística Bayesiana.
Fundação Calouste Gulbenkian, Lisboa, 2003.

[42] PAWLOWSKY-GLAHN, V.; EGOZCUE, J. J.; TOLOSANA-DELGADO, R. Lec-
ture Notes on Compositional Data Analysis. Universitat de Girona, Espanha, 2007.

[43] PRESS, S. J. Bayesian Statistics: Principles, Models, and Applications. John Wiley
&amp;amp; Sons, 1989.

[44] RAYENS, W. S.; SRINIVASAN, C. Box-Cox transformations in the analysis of
compositional data. Journal of Chemometrics, v. 5, n. 3, p. 227-239, 1991.

[45] RAYENS, W. S.; SRINIVASAN, C. Estimation in compositional data analysis.
Journal of Chemometrics, v. 5, n. 4, p. 361-374, 1991.

[46] SPIEGELHALTER, D.; BEST, N. G.; CARLIN, B. P.; VAN DER LINDE, A.
Bayesian measures of model complexity and fit. Journal of the Royal Statistical
Society: Series B (Statistical Methodology), v. 64, n. 4, p. 583-639, 2002.



Referências 101

[47] SPIEGELHALTER, D.; THOMAS, A.; BEST, N.; LUNN, D. Winbugs User Ma-
nual: Version 1.4. http://www.mrc-bsu.cam.ac.uk/bugs. Relatório técnico, Cam-
bridge: Medical Research Council Biostatistics, 2003.



102

APÊNDICE A -- Conjunto de Dados da Superliga de Vôlei
Masculina

Tabela A.1: Conjunto de dados referente aos jogos da Superliga de vôlei masculina
2011/2012.

Jogos % ataque % bloqueio % saque % erro z Jogos % ataque % bloqueio % saque % erro z
1 48,00 12,00 2,67 37,33 1 65 53,27 9,35 5,61 31,78 1
2 53,06 14,29 7,14 25,51 1 66 51,09 6,52 4,35 38,04 1
3 44,00 13,33 8,00 34,67 0 67 55,26 6,58 6,58 31,58 1
4 52,63 14,74 7,37 25,26 0 68 55,10 12,24 3,06 29,59 0
5 56,00 8,00 5,33 30,67 1 69 64,94 6,49 5,19 23,38 1
6 65,63 10,16 2,34 21,88 0 70 57,33 10,67 10,67 21,33 1
7 54,67 14,67 2,67 28,00 1 71 56,70 12,37 7,22 23,71 0
8 50,00 12,50 9,62 27,88 1 72 44,74 9,21 7,89 38,16 0
9 52,58 15,46 3,09 28,87 0 73 62,50 13,54 4,17 19,79 1

10 57,33 13,33 4,00 25,33 1 74 56,52 5,22 6,09 32,17 1
11 56,60 11,32 6,60 25,47 0 75 53,19 14,89 4,26 27,66 0
12 49,33 9,33 14,67 26,67 1 76 57,33 9,33 6,67 26,67 1
13 56,67 8,33 6,67 28,33 0 77 50,67 18,67 2,67 28,00 1
14 66,67 4,00 1,33 28,00 1 78 53,95 10,53 6,58 28,95 0
15 56,70 10,31 3,09 29,90 0 79 44,00 16,00 2,67 37,33 1
16 62,67 6,67 4,00 26,67 1 80 48,00 5,33 6,67 40,00 1
17 49,35 5,19 3,90 41,56 1 81 56,00 8,00 2,67 33,33 0
18 48,00 13,33 6,67 32,00 1 82 57,84 11,76 2,94 27,45 0
19 56,12 14,29 4,08 25,51 0 83 47,25 12,09 4,40 36,26 1
20 44,00 9,33 5,33 41,33 0 84 59,81 11,21 3,74 25,23 0
21 54,95 10,81 5,41 28,83 1 85 53,06 11,22 5,10 30,61 1
22 59,34 15,38 3,30 21,98 0 86 54,55 7,27 4,55 33,64 0
23 51,52 12,12 1,01 35,35 0 87 59,18 6,12 3,06 31,63 1
24 57,69 14,10 5,13 23,08 0 88 46,88 13,54 3,13 36,46 1
25 53,33 14,67 2,67 29,33 0 89 57,50 11,67 1,67 29,17 0
26 55,45 13,86 5,94 24,75 1 90 48,00 20,00 8,00 24,00 0
27 48,04 10,78 3,92 37,25 0 91 54,00 13,00 2,00 31,00 1
28 48,00 17,33 9,33 25,33 0 92 54,67 6,67 8,00 30,67 1
29 57,33 8,00 6,67 28,00 1 93 56,12 7,14 3,06 33,67 1
30 53,78 8,40 5,04 32,77 1 94 56,00 8,00 8,00 28,00 1
31 44,74 10,53 7,02 37,72 1 95 50,67 13,33 6,67 29,33 0
32 53,57 13,10 3,57 29,76 1 96 52,00 12,00 1,33 34,67 1
33 59,41 5,94 6,93 27,72 1 97 58,06 10,75 2,15 29,03 0
34 59,21 9,21 6,58 25,00 0 98 45,33 6,67 2,67 45,33 0
35 51,04 13,54 6,25 29,17 0 99 51,90 15,19 2,53 30,38 0
36 50,51 13,13 3,03 33,33 0 100 52,78 15,74 1,85 29,63 1
37 55,34 16,50 4,85 23,30 0 101 54,29 9,52 7,62 28,57 0
38 61,33 4,00 2,67 32,00 0 102 50,67 14,67 5,33 29,33 0
39 48,98 17,35 2,04 31,63 1 103 48,00 20,00 2,67 29,33 1
40 55,32 9,57 5,32 29,79 1 104 62,03 6,33 2,53 29,11 1
41 56,25 7,29 5,21 31,25 1 105 40,00 12,00 9,33 38,67 0
42 56,19 7,62 2,86 33,33 0 106 59,09 8,18 4,55 28,18 1
43 51,72 8,62 6,03 33,62 1 107 49,33 9,33 8,00 33,33 1
44 49,46 13,98 3,23 33,33 1 108 58,25 6,80 3,88 31,07 0
45 47,27 11,82 5,45 35,45 0 109 60,78 9,80 6,86 22,55 0
46 57,33 13,33 1,33 28,00 0 110 55,77 13,46 1,92 28,85 0
47 56,84 14,74 3,16 25,26 0 111 56,00 8,00 4,00 32,00 0
48 60,61 10,10 3,03 26,26 0 112 55,88 10,78 5,88 27,45 0
49 60,18 10,62 3,54 25,66 0 113 64,13 5,43 7,61 22,83 0
50 52,43 9,71 3,88 33,98 0 114 46,67 8,00 9,33 36,00 1
51 50,67 13,33 4,00 32,00 0 115 56,14 8,77 4,39 30,70 1
52 63,30 8,26 4,59 23,85 1 116 49,00 9,00 6,00 36,00 1
53 54,46 4,95 2,97 37,62 1 117 54,67 10,67 5,33 29,33 1
54 56,25 8,33 4,17 31,25 0 118 48,65 18,02 4,50 28,83 1
55 69,89 5,38 5,38 19,35 0 119 64,22 7,34 1,83 26,61 1
56 65,82 15,19 3,80 15,19 0 120 56,58 7,89 11,84 23,68 1
57 57,89 5,26 11,84 25,00 1 121 56,38 14,89 5,32 23,40 0
58 36,84 12,63 7,37 43,16 0 122 48,45 15,46 5,15 30,93 0
59 50,00 14,42 1,92 33,65 0 123 52,83 6,60 6,60 33,96 0
60 52,08 6,25 5,21 36,46 0 124 60,00 5,33 9,33 25,33 0
61 53,33 13,33 5,33 28,00 0 125 59,63 9,17 1,83 29,36 1
62 44,00 16,00 10,67 29,33 1 126 54,67 10,67 1,33 33,33 1
63 58,67 10,67 8,00 22,67 1 127 54,67 6,67 6,67 32,00 0
64 54,00 8,00 5,00 33,00 0 128 46,91 6,17 4,94 41,98 1



103

APÊNDICE B -- Conjunto de Dados Longitudinais

Tabela B.1: Composições alimentares do leite de 30 vacas (pr=proteína, mf=gordura do
leite, ch=carboidrato, Ca=cálcio, Na=sódio, K=potássio) antes e depois de uma nova
dieta.

Antes Depois
Animal pr mf ch Ca Na K pr mf ch Ca Na K

1 0,1389 0,2278 0,1553 0,1699 0,1400 0,1680 0,1753 0,1459 0,1552 0,2122 0,1642 0,1473
2 0,1377 0,1661 0,1540 0,2066 0,1549 0,1807 0,2090 0,0937 0,1313 0,2341 0,1717 0,1603
3 0,1464 0,1525 0,1672 0,1976 0,1572 0,1792 0,2387 0,1207 0,1497 0,1832 0,1652 0,1426
4 0,1950 0,1564 0,1562 0,1993 0,1163 0,1768 0,2398 0,1345 0,1726 0,2310 0,0896 0,1326
5 0,1988 0,1423 0,1507 0,1869 0,1470 0,1742 0,1173 0,1647 0,1535 0,2482 0,1577 0,1586
6 0,1498 0,1979 0,1858 0,1782 0,1237 0,1645 0,1701 0,1063 0,1524 0,2508 0,1826 0,1379
7 0,1467 0,1552 0,1828 0,1778 0,1564 0,1812 0,2018 0,1109 0,1166 0,2800 0,1471 0,1436
8 0,1109 0,2690 0,1466 0,2046 0,0996 0,1693 0,2142 0,0944 0,1472 0,2488 0,1536 0,1418
9 0,1198 0,2005 0,1351 0,1984 0,1654 0,1807 0,1890 0,1622 0,2066 0,2182 0,0965 0,1274
10 0,2164 0,1624 0,1687 0,1818 0,1111 0,1597 0,2097 0,1431 0,1706 0,2082 0,1435 0,1249
11 0,1792 0,1585 0,1358 0,1907 0,1645 0,1713 0,1562 0,1611 0,1901 0,2452 0,1126 0,1349
12 0,1650 0,1836 0,1401 0,1896 0,1477 0,1740 0,1292 0,2046 0,1977 0,2104 0,1313 0,1268
13 0,1744 0,1999 0,1742 0,1608 0,1310 0,1597 0,2538 0,1314 0,1499 0,1665 0,1655 0,1328
14 0,1319 0,1689 0,1338 0,2055 0,1713 0,1886 0,1959 0,1289 0,1612 0,2324 0,1370 0,1448
15 0,1482 0,2426 0,1544 0,1524 0,1476 0,1549 0,2154 0,1707 0,1713 0,2456 0,0875 0,1095
16 0,1857 0,1891 0,1810 0,1829 0,1042 0,1571 0,1748 0,1715 0,1458 0,1959 0,1795 0,1326
17 0,1497 0,1552 0,1419 0,2027 0,1623 0,1883 0,1446 0,1634 0,1757 0,2265 0,1375 0,1523
18 0,1518 0,1703 0,1412 0,1656 0,2064 0,1646 0,1690 0,1918 0,1625 0,2510 0,0992 0,1264
19 0,1582 0,1437 0,1682 0,1852 0,1733 0,1713 0,1791 0,1607 0,1792 0,1990 0,1221 0,1599
20 0,1683 0,1832 0,1618 0,1659 0,1643 0,1565 0,2149 0,1210 0,1446 0,2589 0,1090 0,1516
21 0,1394 0,2128 0,1999 0,1619 0,1336 0,1523 0,1799 0,1545 0,1605 0,2272 0,1408 0,1371
22 0,1687 0,1570 0,1399 0,1883 0,1632 0,1829 0,1723 0,1566 0,1638 0,2460 0,1299 0,1314
23 0,1988 0,1436 0,1529 0,1809 0,1537 0,1700 0,1778 0,1285 0,1905 0,2468 0,1161 0,1403
24 0,1870 0,1770 0,1561 0,1754 0,1424 0,1622 0,2045 0,1670 0,1612 0,2124 0,1248 0,1301
25 0,1243 0,2008 0,1520 0,2043 0,1346 0,1840 0,2063 0,1206 0,1428 0,2287 0,1461 0,1555
26 0,1686 0,2286 0,1465 0,1641 0,1373 0,1549 0,2709 0,1018 0,1207 0,2491 0,1226 0,1349
27 0,1512 0,1692 0,1658 0,1865 0,1508 0,1766 0,2099 0,1188 0,1450 0,2617 0,1047 0,1598
28 0,2033 0,2042 0,1676 0,1460 0,1344 0,1445 0,2046 0,1370 0,1325 0,2779 0,1111 0,1369
29 0,1455 0,1817 0,1783 0,1519 0,1798 0,1628 0,2808 0,1252 0,1390 0,1813 0,1328 0,1408
30 0,1451 0,2350 0,1886 0,1696 0,1195 0,1422 0,1245 0,1871 0,1554 0,2084 0,1573 0,1672



104

APÊNDICE C -- Programas

Este Apêndice apresenta alguns dos programas computacionais utilizados para a es-
timação dos parâmetros através do MCMC no OPENBUGS e a análise clássica realizada
nos software SAS na Procedure NLMIXED e R para a estimação dos parâmetros do mo-
delo de regressão Dirichlet.

C.1 OPENBUGS

C.1.1 Programa - Modelo 1

model

{

for(i in 1:n) {

y1[i]&amp;lt;- log(x1[i]/x4[i])

y2[i]&amp;lt;- log(x2[i]/x4[i])

y3[i]&amp;lt;- log(x3[i]/x4[i])

y1[i] ? dnorm(mu1[i], tau[1])

y2[i] ? dnorm(mu2[i], tau[2])

y3[i] ? dnorm(mu3[i], tau[3])

mu1[i]&amp;lt;- beta0[1]+beta1[1]*z1[i]

mu2[i]&amp;lt;- beta0[2]+beta1[2]*z1[i]

mu3[i]&amp;lt;- beta0[3]+beta1[3]*z1[i]

}

beta0[1] ? dnorm(0,0.001)

beta0[2] ? dnorm(0,0.001)

beta0[3] ? dnorm(0,0.001)

beta1[1] ? dnorm(0,0.001)

beta1[2] ? dnorm(0,0.001)

beta1[3] ? dnorm(0,0.001)



C.1 OPENBUGS 105

tau[1] ? dgamma(1.0E-2,1.0E-2)

tau[2] ? dgamma(1.0E-2,1.0E-2)

tau[3] ? dgamma(1.0E-2,1.0E-2)

sigma[1]&amp;lt;- 1/tau[1]

sigma[2]&amp;lt;- 1/tau[2]

sigma[3]&amp;lt;- 1/tau[3]

}

C.1.2 Programa - Modelo 2

model

{

for(i in 1:n) {

L1[i]&amp;lt;- (sqrt(tau[1]/6.283185))*exp(-0.5*tau[1]*pow(dif1[i],2))*pow(y1[i],(lambda[1]-1))

L2[i]&amp;lt;- (sqrt(tau[2]/6.283185))*exp(-0.5*tau[2]*pow(dif2[i],2))*pow(y2[i],(lambda[2]-1))

L3[i]&amp;lt;- (sqrt(tau[3]/6.283185))*exp(-0.5*tau[3]*pow(dif3[i],2))*pow(y3[i],(lambda[3]-1))

L[i]&amp;lt;- L1[i]*L2[i]*L3[i]

}

for(i in 1:n) {

y1[i]&amp;lt;- (x1[i]/x4[i])

y2[i]&amp;lt;- (x2[i]/x4[i])

y3[i]&amp;lt;- (x3[i]/x4[i])

transf1[i]&amp;lt;- (pow(y1[i],lambda[1])-1)/lambda[1]

transf2[i]&amp;lt;- (pow(y2[i],lambda[2])-1)/lambda[2]

transf3[i]&amp;lt;- (pow(y3[i],lambda[3])-1)/lambda[3]

mu1[i]&amp;lt;- beta0[1]+beta1[1]*z1[i]

mu2[i]&amp;lt;- beta0[2]+beta1[2]*z1[i]

mu3[i]&amp;lt;- beta0[3]+beta1[3]*z1[i]

dif1[i]&amp;lt;- transf1[i]-mu1[i]

dif2[i]&amp;lt;- transf2[i]-mu2[i]

dif3[i]&amp;lt;- transf3[i]-mu3[i]

}

beta0[1] ? dnorm(0,1.0E-3)

beta0[2] ? dnorm(0,1.0E-3)

beta0[3] ? dnorm(0,1.0E-3)

beta1[1] ? dnorm(0,1.0E-3)



C.1 OPENBUGS 106

beta1[2] ? dnorm(0,1.0E-3)

beta1[3] ? dnorm(0,1.0E-3)

tau[1] ? dgamma(1.0E-2,1.0E-2)

tau[2] ? dgamma(1.0E-2,1.0E-2)

tau[3] ? dgamma(1.0E-2,1.0E-2)

sigma[1]&amp;lt;- 1/tau[1]

sigma[2]&amp;lt;- 1/tau[2]

sigma[3]&amp;lt;- 1/tau[3]

lambda[1] ? dnorm(0,1.0E-2)

lambda[2] ? dnorm(0,1.0E-2)

lambda[3] ? dnorm(0,1.0E-2)

for(i in 1:n) {

uns[i] ? dbern(L[i])

}

}

C.1.3 Programa - Modelo 3

model

{

for(i in 1:n) {

y1[i]&amp;lt;- log(x1[i]/x6[i])

y2[i]&amp;lt;- log(x2[i]/x6[i])

y3[i]&amp;lt;- log(x3[i]/x6[i])

y4[i]&amp;lt;- log(x4[i]/x6[i])

y5[i]&amp;lt;- log(x5[i]/x6[i])

L1[i]&amp;lt;- (sqrt(tau[1]/6.283185))*exp(-0.5*tau[1]*pow(dif1[i],2))

L2[i]&amp;lt;- (sqrt(tau[2]/6.283185))*exp(-0.5*tau[2]*pow(dif2[i],2))

L3[i]&amp;lt;- (sqrt(tau[3]/6.283185))*exp(-0.5*tau[3]*pow(dif3[i],2))

L4[i]&amp;lt;- (sqrt(tau[4]/6.283185))*exp(-0.5*tau[4]*pow(dif4[i],2))

L5[i]&amp;lt;- (sqrt(tau[5]/6.283185))*exp(-0.5*tau[5]*pow(dif5[i],2))

L[i]&amp;lt;- L1[i]*L2[i]*L3[i]*L4[i]*L5[i]

}

for(i in 1:n)

{

dif1[i]&amp;lt;- y1[i]-mu1[i]



C.1 OPENBUGS 107

dif2[i]&amp;lt;- y2[i]-mu2[i]

dif3[i]&amp;lt;- y3[i]-mu3[i]

dif4[i]&amp;lt;- y4[i]-mu4[i]

dif5[i]&amp;lt;- y5[i]-mu5[i]

mu1[i]&amp;lt;- beta0[1]+beta1[1]*z[i]+w[i]

mu2[i]&amp;lt;- beta0[2]+beta1[2]*z[i]+w[i]

mu3[i]&amp;lt;- beta0[3]+beta1[3]*z[i]+w[i]

mu4[i]&amp;lt;- beta0[4]+beta1[4]*z[i]+w[i]

mu5[i]&amp;lt;- beta0[5]+beta1[5]*z[i]+w[i]

w[i] ? dnorm(0, tau.w)

}

beta0[1] ? dnorm(1,1.0E-6)

beta0[2] ? dnorm(1,1.0E-6)

beta0[3] ? dnorm(1,1.0E-6)

beta0[4] ? dnorm(1,1.0E-6)

beta0[5] ? dnorm(1,1.0E-6)

beta1[1] ? dnorm(0,1.0E-6)

beta1[2] ? dnorm(0,1.0E-6)

beta1[3] ? dnorm(0,1.0E-6)

beta1[4] ? dnorm(0,1.0E-6)

beta1[5] ? dnorm(0,1.0E-6)

sigma[1]&amp;lt;- 1/tau[1]

sigma[2]&amp;lt;- 1/tau[2]

sigma[3]&amp;lt;- 1/tau[3]

sigma[4]&amp;lt;- 1/tau[4]

sigma[5]&amp;lt;- 1/tau[5]

sigma.w&amp;lt;- 1/tau.w

tau[1] ? dgamma(0.001,0.001)

tau[2] ? dgamma(0.001,0.001)

tau[3] ? dgamma(0.001,0.001)

tau[4] ? dgamma(0.001,0.001)

tau[5] ? dgamma(0.001,0.001)

tau.w ? dgamma(0.001,0.001)

for(i in 1:n) {

uns[i] ? dbern(L[i])



C.1 OPENBUGS 108

}

}

C.1.4 Programa - Modelo 4

model

{

for(i in 1:n) {

y1[i]&amp;lt;- (x1[i]/x6[i])

y2[i]&amp;lt;- (x2[i]/x6[i])

y3[i]&amp;lt;- (x3[i]/x6[i])

y4[i]&amp;lt;- (x4[i]/x6[i])

y5[i]&amp;lt;- (x5[i]/x6[i])

transf1[i]&amp;lt;- (pow(y1[i],lambda[1])-1)/lambda[1]

transf2[i]&amp;lt;- (pow(y2[i],lambda[2])-1)/lambda[2]

transf3[i]&amp;lt;- (pow(y3[i],lambda[3])-1)/lambda[3]

transf4[i]&amp;lt;- (pow(y4[i],lambda[4])-1)/lambda[4]

transf5[i]&amp;lt;- (pow(y5[i],lambda[5])-1)/lambda[5]

L1[i]&amp;lt;- (sqrt(tau[1]/6.283185))*exp(-0.5*tau[1]*pow(dif1[i],2))*pow(y1[i],(lambda[1]-1))

L2[i]&amp;lt;- (sqrt(tau[2]/6.283185))*exp(-0.5*tau[2]*pow(dif2[i],2))*pow(y2[i],(lambda[2]-1))

L3[i]&amp;lt;- (sqrt(tau[3]/6.283185))*exp(-0.5*tau[3]*pow(dif3[i],2))*pow(y3[i],(lambda[3]-1))

L4[i]&amp;lt;- (sqrt(tau[4]/6.283185))*exp(-0.5*tau[4]*pow(dif4[i],2))*pow(y4[i],(lambda[4]-1))

L5[i]&amp;lt;- (sqrt(tau[5]/6.283185))*exp(-0.5*tau[5]*pow(dif5[i],2))*pow(y5[i],(lambda[5]-1))

L[i]&amp;lt;- L1[i]*L2[i]*L3[i]*L4[i]*L5[i]

}

for(i in 1:n)

{

dif1[i]&amp;lt;- transf1[i]-mu1[i]

dif2[i]&amp;lt;- transf2[i]-mu2[i]

dif3[i]&amp;lt;- transf3[i]-mu3[i]

dif4[i]&amp;lt;- transf4[i]-mu4[i]

dif5[i]&amp;lt;- transf5[i]-mu5[i]

mu1[i]&amp;lt;- beta0[1]+beta1[1]*z[i]+w[i]

mu2[i]&amp;lt;- beta0[2]+beta1[2]*z[i]+w[i]

mu3[i]&amp;lt;- beta0[3]+beta1[3]*z[i]+w[i]

mu4[i]&amp;lt;- beta0[4]+beta1[4]*z[i]+w[i]



C.1 OPENBUGS 109

mu5[i]&amp;lt;- beta0[5]+beta1[5]*z[i]+w[i]

w[i] ? dnorm(0, tau.w)

}

beta0[1] ? dnorm(1,1.0E-6)

beta0[2] ? dnorm(1,1.0E-6)

beta0[3] ? dnorm(1,1.0E-6)

beta0[4] ? dnorm(1,1.0E-6)

beta0[5] ? dnorm(1,1.0E-6)

beta1[1] ? dnorm(0,1.0E-6)

beta1[2] ? dnorm(0,1.0E-6)

beta1[3] ? dnorm(0,1.0E-6)

beta1[4] ? dnorm(0,1.0E-6)

beta1[5] ? dnorm(0,1.0E-6)

sigma[1]&amp;lt;- 1/tau[1]

sigma[2]&amp;lt;- 1/tau[2]

sigma[3]&amp;lt;- 1/tau[3]

sigma[4]&amp;lt;- 1/tau[4]

sigma[5]&amp;lt;- 1/tau[5]

sigma.w&amp;lt;- 1/tau.w

tau[1] ? dgamma(0.001,0.001)

tau[2] ? dgamma(0.001,0.001)

tau[3] ? dgamma(0.001,0.001)

tau[4] ? dgamma(0.001,0.001)

tau[5] ? dgamma(0.001,0.001)

tau.w ? dgamma(0.001,0.001)

lambda[1] ? dnorm(0,1.0E-6)

lambda[2] ? dnorm(0,1.0E-6)

lambda[3] ? dnorm(0,1.0E-6)

lambda[4] ? dnorm(0,1.0E-6)

lambda[5] ? dnorm(0,1.0E-6)

for(i in 1:n) {

uns[i] ? dbern(L[i])

}

}



C.2 SAS - Proc NLMIXED 110

C.2 SAS - Proc NLMIXED

C.2.1 Programa - Dados Superliga de Vôlei

data volei;

input alr jogos y z;

datalines;

dados;

proc nlmixed data=volei;

parms beta01=1 beta02=1 beta03=1 beta11=0 beta12=0 beta13=0 s1=1 s2=1 s3=1;

mu1=beta01+beta11*z;

mu2=beta02+beta12*z;

mu3=beta03+beta13*z;

if alr=1 then like=1/sqrt(6.283185*(s1**2))*exp(-0.5*(1/(s1**2))*((y-mu1)**2));

if alr=2 then like=1/sqrt(6.283185*(s2**2))*exp(-0.5*(1/(s2**2))*((y-mu2)**2));

if alr=3 then like=1/sqrt(6.283185*(s3**2))*exp(-0.5*(1/(s3**2))*((y-mu3)**2));

ll=log(like);

model y ? general(ll) subject=jogos;

run;

C.2.2 Programa - Dados Longitudinais (qualidade do leite)

data leite;

input alr y vaquinhas z;

datalines;

dados;

proc nlmixed data=leite;

bounds s1&gt;0,s2&gt;0,s3&gt;0,s4&gt;0,s5&gt;0,sw&gt;0;

parms beta01=1 beta02=1 beta03=1 beta04=1 beta05=1 beta11=0 beta12=0 beta13=0

beta14=0 beta15=0 s1=0.1 s2=0.1 s3=0.1 s4=0.1 s5=0.1 sw=0.11;

mu1=beta01+beta11*z+w;

mu2=beta02+beta12*z+w;

mu3=beta03+beta13*z+w;

mu4=beta04+beta14*z+w;

mu5=beta05+beta15*z+w;

if alr=1 then like=(1/sqrt(6.283185*(s1*s1)))*exp(-0.5*(1/(s1*s1))*((y-mu1)**2));



C.3 R - Modelo de Regressão Dirichlet 111

if alr=2 then like=(1/sqrt(6.283185*(s2*s2)))*exp(-0.5*(1/(s2*s2))*((y-mu2)**2));

if alr=3 then like=(1/sqrt(6.283185*(s3*s3)))*exp(-0.5*(1/(s3*s3))*((y-mu3)**2));

if alr=4 then like=(1/sqrt(6.283185*(s4*s4)))*exp(-0.5*(1/(s4*s4))*((y-mu4)**2));

if alr=5 then like=(1/sqrt(6.283185*(s5*s5)))*exp(-0.5*(1/(s5*s5))*((y-mu5)**2));

ll=log(like);

model y ? general(ll);

random w ? normal(0,sw*sw) subject=vaquinhas;

run;

C.3 R - Modelo de Regressão Dirichlet

leite&amp;lt;- read.table(file="Dados leite.csv",header=TRUE,sep=";")

a&amp;lt;- cbind(leite[1:30,],trat=0)

b&amp;lt;- cbind(leite[31:60,],trat=1)

dados.leite&amp;lt;- rbind(a[,],b[,])

dados.leite&amp;lt;- data.frame(dados.leite)

dados.leite[1:30,"trat"]&amp;lt;- "A"

dados.leite[31:60,"trat"]&amp;lt;- "D"

########Regressão Dirichlet##########

library(DirichletReg)

leite_dir&amp;lt;- DR_data(dados.leite[,1:6])

summary(leite_dir)

regdirleite&amp;lt;- DirichReg(leite_dir ? trat, dados.leite)

summary(regdirleite)

confint(regdirleite)

residuals(regdirleite)

fitted(regdirleite)


</field>
	</doc>
</add>