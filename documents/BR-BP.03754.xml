<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-BP.03754</field>
		<field name="filename">BPP_2011_5_2_03_Ajuste_de_historico.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">PALAVRAS-CHAVE:
□	ajuste de histórico
□	análise de incertezas
□	reservas e reservatórios
□	risco
□	modelo de simulação
| Gustavo Gabriel Becerra | André Paoliello Modenesi | Érico Fagundes Anicet Lisboa | Deise Massulo Ferreira | Leandro Costa Reis
Ajuste de histórico e previsão sob incerteza, uma aplicação no Campo de Marimbá / Uncertainty history matching and forecasting, a Marimbá Field case application
resumo
As incertezas de reservatório, econômicas e tecnológicas, influenciam as decisões de gerenciamento das reservas e os planos de desenvolvimento resultantes. Contudo, a quantificação do impacto dessas incertezas permite aumentar a confiabilidade desse processo. Uma dificuldade é a variabilidade e a complexidade dos fluxos de trabalho para gerenciar as incertezas identificadas por meio de modelos dinâmicos de simulação. O escopo deste trabalho é a integração entre o ajuste de histórico de produção e a análise probabilística dos cenários representativos, aplicando uma metodologia que permite o reconhecimento dos modelos mais bem calibrados dentro de uma faixa de aceitação definida. Esse procedimento auxilia a identificar os atributos incertos críticos e
abstract
KEYWORDS:
□	history matching
□	uncertainty assessment
□	reserves and reservoirs
□	risk
□	model simulation
Geological, reservoir, economical and technological uncertainties affect decision making and consequently impact reserves development plans. The impact of these uncertainties can make this process more reliable. One of the big difficulties to achieve in the practice is the variability and complexity of available workflows to manage uncertainty using numerical simulation. This study integrates history matching with the probabilistic analysis of representative scenarios. A methodology is used that facilitates the recognition of well-calibrated models within an acceptable deviation. This procedure helps to identify the critical uncertain parameters and their possible variation to estimate the representative reserve range. The goal is not to find the best deterministic match, but to show how the calibration process points to a mitigation of identified uncertainties. A real case study based on a Campos Basin reservoir in Brazil was used. A 14 year historical period followed by a 12 year forecast period was considered, to check and validate on a global level, the proposed procedure in a complex dynamic model. Two different commercial software tools were
suas possíveis variações, com o intuito de estimar a faixa representativa das reservas a desenvolver. O objetivo não é obter o melhor ajuste determinístico, mas mostrar como o processo de ajuste do período histórico possibilita mitigar as incertezas identificadas. Para a aplicação da metodologia, é usado um caso baseado no reservatório Carapebus do Campo de Marimbá (Bacia de Campos, RJ), descoberto em março de 1984. Foi utilizado o período histórico de 1985 a 1998, e foram analisadas previsões até 2010, permitindo verificar e validar, em nível global, o procedimento proposto num modelo dinâmico complexo. Para isso, empregaram-se os aplicativos Cougar e Cmost, procurando evidenciar as vantagens e limitações de cada abordagem. Foi avaliada a variação das distribuições das respostas no tempo por meio de amostragem Hipercubo Latino e propagações
de Monte Carlo com metamodelos (proxy models). Os métodos aplicados permitem:
1.	reduzir a faixa de modelos possíveis que garantem ajustes de histórico mais confiáveis;
2.	identificar e condicionar a incerteza presente em função dos dados registrados;
3.	diminuir os intervalos de incerteza dos parâmetros críticos identificados;
4.	demarcar os limites do desempenho futuro do reservatório.
Essa metodologia pretende contribuir para o aumento da confiança do uso da simulação como ferramenta auxiliar do processo decisório, com o propósito de diminuir o risco associado e maximizar as oportunidades de desenvolvimento.
used, to demonstrate the advantages and restrictions of each approach. Distribution variations of the calculated responses along time were evaluated by Latin Hypercube sampling and Monte Carlo propagation on validated proxy models. The proposed methodology:
1.	reduces the range of possible models based on the observed data;
2.	identifies the existent uncertainty as a function of observed data;
abstract
3.	reduces the uncertainty range of critical reservoir parameters;
4.	raises confidence in the production forecast.
This study contributes to a quantitative approach to increase the reliability of reservoir simulation as an auxiliary tool in the decision making processes to reduce the associated risk and maximize development opportunities.
(Expanded abstract available at the end of the paper).
introdução
O Campo de Marimbá, descoberto em março de 1984, está situado na Bacia de Campos (RJ), a cerca de 80 quilômetros da costa, em profundidades de água de 320m a 780m. Os reservatórios pertencem à Formação Carapebus e são arenitos predominantemente turbidí-ticos depositados em diferentes períodos geológicos do Terciário ao Cretáceo. O principal reservatório, o Arenito Carapeba, de idade Santoniana/Campaniana, tem boas características petrofísicas (porosidades da ordem de 27% e permeabilidades da ordem de 3.000mD) e óleo de boa qualidade (29°API e viscosidade em torno de 2,1cp sob condições de reservatório).
Estruturalmente, o Campo de Marimbá possui inúmeras falhas normais, configurando vários blocos que têm boa
comunicação hidráulica graças ao elevado teor de arenito dos reservatórios. O bloco de produção principal do campo é o RJS-284, onde se desenvolveu o reservatório Carapeba, subdividido em três zonas estratigráficas, CRP90, CRP100 e CRP200, que constituem a zona de produção CRP-284. São arenitos turbidíticos predominantemente maciços, com feições acanaladas com grande distribuição horizontal. As principais zonas são a CRP100 e a CRP200, que estão separadas por uma discordância mapeada sismicamente, porém comunicadas hidraulicamente. A zona CRP100 é dividida em três subzonas: CRP110, CRP120 e CRP130. Os primeiros poços perfurados foram interligados à plataforma P-15, como forma de produção antecipada. Atualmente, os poços do bloco principal produzem para a P-08, com exceção do poço RJS-284, que continua produzindo para a P-15. A figura 1 mostra a localização do campo e a distribuição dos blocos produtores.
Bloco
MA18
P 15
Bloco
Mrl10
Bloco MA11
Bloco
MA12
Bloco
WJVIA11
Bloco Enchova
^■l Marian Gás I	I Enchova
I	I Carapeba
V, i \
o Campo de óleo •— «Campo de Marimbá 1------------------
Bloco principal (RJS-284)
Figura 1 - Localização e blocos de produção do Campo de Marimbá (em verde estão representadas as acumulações de óleo do Arenito Carapeba).
Figure 1 - Location and production blocks Field Marimbá (green depicts the oil accumulations of Sandstone Carapeba).
O Campo iniciou sua produção em 1985. O período 1985-1999 correspondeu à implantação de várias fases de desenvolvimento do Campo, com a produção mais concentrada na parte norte, sem injeção de água e com a consequente depleção do reservatório. O avanço de água neste período deve-se à atuação do aquífero. O período 1999-2005 correspondeu ao início da injeção de água e à conclusão do desenvolvimento da produção na parte sul do campo. Nos últimos anos, foram feitas várias restaurações de poços, seguindo a estratégia traçada para o campo, que consta do abandono de intervalos inferiores já varridos pelas frentes de deslocamento de água e canho-neio de intervalos superiores.
O reservatório esteve sempre acima da pressão de bolha, de 147kgf/cm2. A pressão vem sendo mantida devido à injeção de água e à atuação do aquífero, sendo a mínima pressão registrada de 158kgf/cm2 no datum (-2.700m), no MA-10 em 2005, localizado na área norte do Campo, e confirmada em 2009 no MA-32, com o valor de 159kgf/cm2. Além disso, nunca houve evidência de aumento de RGO nos poços.
Neste estudo, foi utilizado o histórico de produção entre 1985 e 1998 inclusive. Foram analisadas previsões até 2010, tendo em conta alguns dos eventos mais importantes acontecidos nesse período, permitindo verificar, em nível de resposta global, o procedimento proposto num modelo dinâmico complexo. Não faz parte do escopo deste trabalho validar exaustivamente a faixa de previsões obtidas por meio do histórico real registrado durante o período 1999-2010. Será considerada somente uma parte dos dados históricos reais para poder aplicar a metodologia apresentada neste modelo.
modelo
O modelo de simulação numérica de tipo Black Oil abrange a área do RJS-284 e a área leste. A dimensão da malha do tipo bloco centrado é de 85 x 55 x 12 (fig. 2).
A camada 1 representa a zona estratigráfica CRP90. A zona CRP100 está representada pelas camadas 2 a 4,
Figura 2 - Imagem 3D do Modelo Marimbá. A propriedade apresentada é a espessura porosa com óleo (metros).
Figure 2 - 3D Model Marimbá.The property presented is oil net pay (meters).
enquanto as camadas 6 a 10 correspondem à zona CRP200 (a camada 5 é uma transição entre essas zonas), e as camadas 11 e 12 correspondem à zona Espadarte, basicamente aquífero.
No sistema de blocos, foi considerado um arranjo de falhas verticais extraído da interpretação sísmica e um mapa estrutural do topo do reservatório. Mapas de espessura total, de porosidade, de razões entre as espessuras líquida e a total (net to gross) e de permeabilidade horizontal foram definidos por camada. Foi utilizada uma razão global kv/kh para o cálculo das permeabilidades verticais (fig. 3). Diversos multiplicadores de transmissibilidade de falha são utilizados para representar a incerteza no grau de comunicação entre blocos em contato. O aquífero principal está localizado nas camadas 11 e 12 do modelo,
contando com uma representação analítica que considera conexão lateral pela borda a sudeste. É utilizada uma representação analítica de Carter Tracy de aquífero finito com razão Re/Ro = 6. Além disso, mais duas entradas de água nas zonas CRP90 e CRP100, são representadas por aquíferos analíticos de menor extensão, localizados respectivamente a sudeste e a norte, com conexões parciais nessas bordas. Para o bloco principal é considerada somente uma região de permeabilidades relativas, havendo uma segunda região para o bloco MA-12. Cinco regiões de equilíbrio foram consideradas com contato água-óleo de 2.754m para os blocos RJS-284 e RJS-338, 2.768m para o bloco MA-18, 2.850m para o bloco MA-11 e finalmente 2.875m para o MA-12. O modelo tem 34 poços, dos quais cinco são injetores.
Figura 3 - Imagem 2D (camada 3, CRP100), planta (a) corte leste-oeste (b) do Modelo Marimbá. A propriedade apresentada é a permeabilidade horizontal (mD).
Figure 3 - 2D Image of the 3rd layer. (a) Map (b) East-West cross-section from the model. Horizontal permeability shown.
objetivo
O objetivo deste trabalho é apresentar um exemplo prático de como realizar uma análise de incerteza em nível global em um campo com histórico de produção. São utilizados os aplicativos Cougar (IFP/Beicip-Franlab) e Cmost (CMG), de forma paralela, para trabalhar sobre um modelo do Campo de Marimbá. É proposta uma metodologia para identificação de modelos representativos ajustados dentro de uma faixa de aceitação definida, normalmente limitada por uma tolerância determinada. O propósito não é obter o melhor ajuste determinístico, mas mostrar como o processo de ajuste de histórico probabilístico possibilita uma mitigação das incertezas identificadas (Becerra, 2007). Outro escopo deste estudo é a identificação das limitações, vantagens e desvantagens dos programas utilizados perante a disponibilidade de opções e procedimentos semelhantes.
Na Petrobras, existem diversos estudos sobre análise de incerteza e sobre ajuste de histórico, mas poucos trabalhos abordam os dois problemas de forma conjunta. Reis (2005) propõe uma metodologia utilizando planejamento de experimentos e superfície de resposta, na qual um filtro é aplicado durante a simulação de Monte Carlo de forma a levar em conta apenas os modelos considerados ajustados. Esta metodologia é aplicada por Lisboa e Duarte (2009) no Campo de Albacora Leste em um estudo de viabilidade técnica e econômica para a perfuração de um novo par de poços em uma área onde já havia histórico de produção. Em outro trabalho, Silva e Costa (2009) utilizam modelos representativos para quantificar as incertezas geológicas em campos que possuem histórico de produção. Além desses trabalhos, diversas apresentações e discussões foram realizadas em encontros internos, mas não geraram documentos escritos que possam servir como referência.
A consideração dos dados históricos permite uma mitigação da variação dos parâmetros incertos identificados e conduz à obtenção de um conjunto de modelos representativos do grau de conhecimento do sistema. Propõe-se neste trabalho avaliar a variação das distribuições das respostas influenciadas pelos parâmetros incertos no tempo através de propagações de Monte Carlo para tempos predeterminados utilizando-se metamodelos ou superfícies de resposta (SR). Esses metamodelos são
construídos por meio de planejamentos de experimentos para reduzir o custo computacional envolvido.
Para avaliar o ajuste de determinado modelo, é importante quantificar a qualidade desse ajuste. Neste trabalho e nos aplicativos utilizados, a distância entre os dados observados e simulados é denominada função objetivo (FO), calculada de modo diferente nos dois aplicativos, como será apresentado mais adiante.
No Cougar, rodadas de confirmação foram realizadas, de forma iterativa, para validar as SR em torno dos mínimos da FO, aumentando gradativamente a qualidade da mesma na zona de menor valor da função objetivo. Posteriormente, um filtro aplicado sobre as SRs aprimoradas na zona dos mínimos permite a obtenção dos diferentes modelos representativos ajustados, que são usados para avaliar o grau de espalhamento das respostas no período de previsão. No Cmost, novos intervalos são escolhidos para os parâmetros a partir de um ajuste de histórico determinístico (tratado como um problema de otimização). Em seguida, novas superfícies de resposta são obtidas para cada FO, utilizando um planejamento de experimento baseado nos novos intervalos definidos.
Por último, ao final do período histórico ajustado, um novo plano de desenvolvimento é executado e, portanto, novos parâmetros controláveis devem ser adicionados ao modelo. A variação das curvas de predição final, obtida com ambos os aplicativos, indica o grau de incerteza remanescente, que influencia a obtenção dos percentis e as suas curvas características, que são utilizadas para avaliar o risco do projeto.
considerações sobre ajuste de histórico sob incerteza
Três características são fundamentais na tomada de decisão sob incerteza:
• em cada passo da modelagem, a incerteza é propagada de modelos anteriores, e novas incertezas são agregadas;
•	nas simulações dos modelos dinâmicos, o fato de realizar ajuste de histórico conduz a uma redução da distribuição de incerteza a priori;
•	a incerteza remanescente (resultante das distribuições a posteriori e da inclusão de novos parâmetros controláveis a otimizar) impacta a tomada de decisão sobre os futuros desenvolvimentos do projeto e tem que ser considerada na análise de risco dos investimentos.
Os principais passos a considerar na etapa da modelagem dinâmica sob incerteza são:
•	passo 1: Sensibilidade e análise de incerteza inicial.
O propósito fundamental é identificar e caracterizar a incerteza associada ao problema (bracketing the history). Além disso, procura-se definir os critérios para avaliar e medir um ajuste aceitável dos dados observados (tipo e formulação das funções objetivo) e selecionar aqueles atributos com maior influência no ajuste assistido para a posterior propagação de incerteza na predição da produção;
•	passo 2: Ajuste assistido de histórico com redução de incerteza.
O objetivo principal é a caracterização da incerteza remanescente. Diversas ferramentas podem ser usadas nesta fase, tais como Enable, Mepo, CondorFlow, entre outras, além do Cougar e do Cmost, utilizados neste trabalho;
•	passo 3: Otimização do plano de desenvolvimento sob incerteza remanescente.
O foco nessa etapa é a obtenção da melhor estratégia de tipos e controles de poços.
passo 1: sensibilidade e análise de incerteza
Algumas perguntas frequentes na fase inicial desta etapa são: Os modelos estáticos e dinâmicos são os corretos? É possível reproduzir o comportamento medido? Conheço e considero realmente todos os parâmetros incertos do problema? As faixas de incerteza dos atributos estão corretas?
Um dos principais motivos para a realização de análises de sensibilidade é melhorar o conhecimento do fenômeno e a sua resposta a variações dos parâmetros, bem como reconhecer os parâmetros com maior influência. Além disso, esta etapa permite a quantificação da influência primária e da interação entre os parâmetros que podem afetar o ajuste.
A análise de sensibilidade é definida como a medida do efeito de um dado fator de entrada (parâmetro incerto X) sobre uma saída da resposta (variável de saída Y). A ferramenta é a obtenção dos índices de sensibilidade, lembrando que uma simulação de reservatórios implica uma complexa relação multivariável não linear. Essas análises são feitas:
•	quando muitos atributos incertos são detectados;
•	para quantificar a influência de um parâmetro ou a interação entre eles em uma resposta determinada;
•	quando a relação entre o fenômeno e os atributos do problema não é muito clara.
A análise de sensibilidade global (ASG) é uma análise de influência cruzada (de segunda ordem) dos parâmetros incertos na variável sob estudo. Este tipo de tratamento implica usar uma função de distribuição de probabilidades para cada parâmetro, uma vez que também se baseia em técnicas de amostragem de Monte Carlo. Consequentemente, essa análise requer o uso de meta-modelos sofisticados e com boa qualidade, tornando possível a exploração exaustiva do domínio de variação e a avaliação da inter-relação não linear entre os parâmetros considerados.
Uma segunda fase desse passo é definir os critérios de qualidade para avaliar o grau de ajuste, ou seja, escolher os pesos adequados para as parcelas da FO. Perguntas frequentes são: Que pesos devo aplicar a séries de medição de naturezas diferentes? Quando devo parar um processo de melhoramento de um ajuste? Qual é o valor máximo aceitável de uma FO complexa?
Devemos ter em conta que sempre temos erros de medição e erros intrínsecos da modelagem e considerações subjetivas do analista sobre o grau de confiança na capacidade preditiva do modelo. O problema é como definir um grau de importância a esses erros
que seja similar às medições de variáveis de naturezas diferentes consideradas nos distintos termos da função objetivo composta.
Algumas perguntas que devem ser feitas nesta etapa são: Os componentes da FO estão concordando com a visão do analista do que é necessário considerar para qualificar um bom ajuste? A FO composta definida tem a capacidade de prover resultados comparáveis com os que um analista teria na seleção determinística de seu melhor ajuste?
Para responder a essas perguntas, é importante observar os valores dos desvios padrão das diferentes partes constitutivas da FO como uma medida da importância de cada termo na FO composta (por exemplo, dar a mesma importância aos ajustes de água e pressão). Isso é possível se as parcelas têm desvios padrão próximos nas saídas das FO calculadas. O impacto na variância da resposta é também o critério usado quando efetuamos uma análise de sensibilidade global para selecionar os parâmetros mais influentes a considerar nas etapas seguintes.
A fase final do passo 1 é a seleção dos parâmetros mais influentes. É importante incluir a maior quantidade de parâmetros possível e usar uma ampla faixa de variação que assegure que os resultados obtidos pelas simulações efetuadas, segundo o planejamento de experimentos escolhido, estejam dentro de uma faixa representada pelas incertezas selecionadas. Caso os dados de histórico não se encontrem dentro dessa faixa, é necessário voltar ao passo inicial e redefinir os parâmetros de incerteza, seja pela alteração dos limites ou pela inclusão de novos parâmetros de modo a garantir que os registros históricos estejam dentro da faixa de incerteza.
Análises de sensibilidade global são realizadas nesta etapa sobre diferentes funções objetivo com a finalidade de uma classificação inicial (screening), antes de começar o ajuste de histórico. O planejamento baseado em hiper-cubo latino (LHS), seguido da construção das superfícies de resposta não paramétricas (SRNP) é uma combinação adequada para a modelagem do problema, como será visto adiante. A abordagem com ASG também auxilia na detecção dos parâmetros a otimizar, em primeiro lugar, e também, na estratégia de análise, se devem ser considerados em separado ou em conjunto (essa informação é obtida por meio dos valores dos efeitos de interação entre atributos). A interação entre dois parâmetros com
pouca influência primária independente muitas vezes pode ser relevante na variação da FO.
Um ajuste de histórico manual pode ser usado como ponto de partida para o processo de otimização da FO. Poderia ser utilizado também para descartar valores dos atributos incertos no processo posterior de ajuste assistido. passo 2: ajuste assistido de histórico com redução de incerteza
Nesta etapa, três tipos de abordagem podem ser realizadas segundo a disponibilidade de recursos e tempo.
abordagem 1: otimização determinística
Este tipo de aproximação consiste na avaliação da qualidade das SR representativas das FO analisadas. A partir de um processo iterativo e interativo, rodadas de confirmação vão sendo adicionadas com o intuito de melhorar progressivamente a qualidade das SR com foco nas zonas de valores mínimos. Os parâmetros que não têm influência no ajuste, mas que podem afetar as predições devem ser incluídos apenas na fase de previsão. Esta abordagem será aprofundada mais à frente neste trabalho.
•	vantagens: conceitualmente simples e com controle do analista, requer um custo computacional mais baixo comparado com as outras aproximações;
•	desvantagens: a incerteza mitigada dos parâmetros usados no ajuste do modelo é obtida a partir de filtros que atuam sobre metamodelos aproximados.
abordagem 2: aproximação probabilística
A consideração de uma abordagem do tipo probabilidade bayesiana é usada para obter as faixas de incerteza a posteriori a serem usadas nas predições (Busby e Feraille, 2008). O método de planejamento adaptativo permite reduzir o número de simulações necessárias ao construir uma superfície de resposta precisa e preditiva nas áreas do espaço amostral de onde os valores da FO são baixos (região de soluções aceitáveis). Esta aproximação da FO é logo usada em um algoritmo do tipo Markov Chain Monte Carlo para
computar a distribuição a posteriori dos parâmetros incertos que permitem aproximar as respostas calculadas às medições de produção registradas. No final do período histórico, um novo plano de desenvolvimento é executado, e, portanto, novos parâmetros controláveis devem ser adicionados ao modelo.
•	vantagens: gera o estreitamento dos intervalos de incerteza dos atributos usados no ajuste de histórico de forma automática e permite uma otimização global do problema;
•	desvantagens: grande consumo de tempo computacional com a possibilidade de problemas de convergência.
abordagem 3: otimização determinística seguida de probabilística
Seguindo as técnicas da abordagem 1, é possível obter o melhor ajuste determinístico, que pode ser usado como ponto de partida para a aproximação bayesiana. Esta aproximação permite caracterizar outras soluções aceitáveis e obter as faixas de incerteza remanescentes para a etapa de predição.
•	vantagens: permite uma convergência mais rápida e um melhor ajuste que a abordagem 2;
•	desvantagens: consumo considerável de tempo computacional. O ajuste inicial escolhido na partida do cálculo tem uma influência forte, podendo levar a uma aproximação local do problema quando há mais de uma solução possível para o ajuste (FO possui múltiplos mínimos locais, mas apenas um deles é encontrado pela otimização determinística).
passo 3: otimização do plano de desenvolvimento e predição sob incerteza a posteriori
As decisões num plano de desenvolvimento podem ser classificadas em três classes:
•	tipos de estratégias de desenvolvimento: quando, como e onde aplicar depleção primária, injeção de água, injeção alternada gás-água, injeção de gás ou CO2, etc.;
•	tipos de táticas para os poços: seleção do tipo de poço, objetivos a atingir, espaçamento, tamanho de tubulações, sistemas de elevação, tipo de completação, etc.;
•	tipos de táticas operacionais: taxa de substituição de fluidos em condições de fundo, balanço entre zonas sob injeção, taxa de preenchimento de capa de gás, cronograma de completações, restrições de pressões de fundo e de topo de poços produtores e injetores, limites de vazões de produção e de injeção por zonas.
Também nesta fase podem-se distinguir três tipos de abordagens para o tratamento deste problema:
•	abordagem 1: otimização determinística da resposta por meio da variação de parâmetros de controle usando o melhor ajuste de histórico;
•	abordagem 2: tomada de decisão sob incerteza em que diversas opções de desenvolvimento disponíveis são testadas sob um único modelo sob incerteza para escolher a melhor solução encontrada adequada ao contexto do problema;
•	abordagem 3: otimização sob incerteza. Neste caso, é disponibilizada uma resposta a ser otimizada (modelo sob incerteza), considerando parâmetros controláveis e novos parâmetros de incerteza não considerados no passo 2 (ajuste de histórico). Cenários diferentes podem ser contemplados para estudar a estratégia de desenvolvimento e as táticas associadas para a operação relacionada. Entre eles, podem-se exemplificar os seguintes tipos:
■ cenário 1: Otimização determinística ou seleção seguida de decisão sob incerteza.
Várias estratégias de desenvolvimento e uma única tática de poços são definidas para todas as estratégias com operações otimizadas de forma determinística (usando o melhor ajuste de histórico). Todos os casos são rodados sob incerteza para selecionar o melhor plano de desenvolvimento. Uma vez escolhida a melhor estratégia, diferentes táticas em relação à geometria de poço podem ser abordadas, e novamente é escolhido o melhor conjunto de soluções. Este cenário é bastante custoso em tempo computacional;
■ cenário 2: Otimização probabilística ou seleção seguida de otimização sob incerteza e posterior tomada de decisão.
Este cenário é considerado o mais robusto. São definidas várias estratégias de desenvolvimento para cada modelo ajustado e várias táticas para os poços. Para cada uma das combinações modeladas, as estratégias de operação sob incerteza são otimizadas para permitir a comparação entre os resultados. Nesta abordagem pode-se incluir o caso em que algumas táticas de poço são parame-trizadas (posições de novos poços, por exemplo) e poderiam ser tratadas na otimização sob incerteza de modo separado do resto da operação.
Diversos cenários como os apresentados podem ser imaginados envolvendo várias combinações de otimização determinística, decisão sob incerteza e otimização sob incerteza. Os cenários anteriores servem como exemplos do que pode ser realizado.
fluxo de trabalho
A proposta deste trabalho é aplicar o passo 1 (sensibilidade e análise de incerteza inicial) e a abordagem 1 do passo 2 (ajuste assistido de histórico com redução de incerteza por meio de otimização determinística), sendo que a aplicação do passo 3 (otimização do plano de desenvolvimento sob incerteza remanescente) está fora do escopo da análise pretendida.
O objetivo geral do trabalho é fazer um ajuste de histórico (AH), considerando a incerteza inicial dos parâmetros críticos identificados por intermédio da análise de sensibilidade. Pretende-se obter uma mitigação posterior das faixas de variação desses parâmetros, por meio da minimização das funções objetivo escolhidas, que quantificam o afastamento das variáveis calculadas dos seus valores medidos durante o período de histórico. Finalmente, procura-se obter uma predição probabilística da produção, baseada no estreitamento dos intervalos de variação dos parâmetros incertos.
Os procedimentos para cumprir esses objetivos dependem do aplicativo utilizado. São eles:
1.	analisar a qualidade dos dados históricos, filtrando aqueles de validade duvidosa;
2.	estabelecer critérios de quantificação da qualidade do ajuste atingido (função objetivo);
3.	identificar os parâmetros incertos e seu intervalo de variação;
4.	escolher o planejamento de experimentos e tipo de modelagem da superfície de resposta (SR) para a análise de sensibilidade global;
5.	realizar análise de sensibilidade da FO do ajuste global de pressão, água e óleo no período de histórico;
6.	selecionar os parâmetros críticos mais sensíveis usados no posterior ajuste de histórico;
7.	fazer um planejamento de experimentos com os parâmetros críticos para AH (no Cougar);
8.	fazer uma análise de incerteza a priori, sem considerar dados do histórico de produção. Ponto de referência do grau de incerteza inicialmente presente;
9.	realizar iterações sucessivas com rodadas de confirmação para melhoramento progressivo da qualidade das SR nas zonas de valores mínimos (no Cougar);
10.	investigar os valores dos parâmetros críticos que melhor ajustam o histórico, por meio de uma otimização (no Cmost);
11.	obter as distribuições a posteriori, já mais estreitas, dos parâmetros que afetam o histórico e escolha de novos parâmetros incertos para o período de predição (variação em parâmetros "controláveis" deve ser incluída nesta etapa);
12.	realizar mais um planejamento de experimentos final com as novas distribuições dos parâmetros incertos mais os novos atributos identificados;
13.	fazer uma análise de incerteza final;
14.	abter a distribuição de probabilidades da previsão de produção mediante uma análise de incerteza para múltiplos tempos e selecionar as curvas representando P10, P50 e P90 no tempo final e em tempos intermediários;
15.	identificar os modelos representativos, comuns em todos os tempos, para cada um dos cenários (P10, P50 e P90) selecionados.
parâmetros
Os parâmetros incertos considerados com seus limites e valores padrão são mostrados na tabela 1.
Nome	Mín.		...	Valor	_ Max.	Default	Ovmt»		
AQ100e AQ200	0	0,2	0,0715 e 0,0657	Redução de transmissibilidade na entrada dos aquíferos CRP-100 e CRP-200.
AQRAD	500	5.000	1.000	Raio equivalente do reservatório para cálculo do aquífero analítico.
AQRPOR	0,2	0,4	0,3	Variação da porosidade do aquífero analítico.
CPOR	9,00E-05	1,10E-04	1,00E-04	Compressibilidade de formação.
MULTF (n I/S)	0,1	1	Média 0,185	Multiplicadores para redução de transmissibilidade de falhas.
MULTPI	0,5	2	1	Multiplicador de IP para poços perfurados. Utilizado apenas para previsão.
Permi	0,8	1,8	1,3	Multiplicador da permeabilidade horizontal.
PERMK	0,005	0,05	0,01438	Multiplicador da permeabilidade vertical.
TK	"TK_1", "TK_2", "TK_3"		"TK_3"	Transmissibilidade vertical nula variando segundo valores de cutoff em m apas NTG (discreto).
WOC	2.754	2.758	2.754	Contato A/O.
krow_max	-	-	0,79	Parâmetros da permeabilidade relativa por Corey.
krw_max	0,2	0,5	0,3	
n o	0,5	2,5	1,5	
n w	3,5	6,5	5	
Tabela 1 - Parâmetros incertos considerados no estudo.
Table 1 - Uncertain parameters considered in the study.
planejamento de experimentos
Para as análises mencionadas no fluxo de trabalho, é realizado um planejamento de experimentos com hi-percubo latino (LHS). O Cmost e o Cougar apresentam diferentes tipos de planejamento de experimentos. A seleção do planejamento é muito importante quando se trabalha com modelos de superfície de resposta.
Dentre os tipos, destaca-se a técnica de LHS, que tem sido muito utilizada e recomendada em trabalhos que envolvem planejamento de experimentos (Zubarev, 2009; Bratvold e Begg, 2010). Essa técnica garante que todo o espaço amostral do estudo seja investigado (space filling), por meio do uso da "amostragem estratificada", visando a reduzir o número de simulações necessárias sem diminuir a qualidade da
superfície de resposta. Este tipo de planejamento gera um conjunto de pontos que, apesar de aleatório, permite uma amostragem do modelo levando em conta a distribuição informada para cada parâmetro de incerteza, concentrando a amostragem nas zonas com mais probabilidade de ocorrência.
Por exemplo, consideremos n experimentos (simulações) e dois parâmetros incertos, um com distribuição triangular e o outro com distribuição normal, como mostrado na figura 4. Com base na distribuição de probabilidade acumulada para os dois parâmetros, são propostos n pontos uniformemente distribuídos, a partir da discretização de cada distribuição, que cumprem as seguintes condições:
•	os valores amostrados são aleatoriamente combinados para definir os experimentos da amostra do mesmo modo que em uma simulação de Monte Carlo;
•	as amostras são definidas um número de vezes constante para cada intervalo discreto sem ser repetidas nos experimentos sucessivos, assegurando uma amostragem de todo o intervalo de busca considerado para o atributo;
•	os valores amostrados tendem a se concentrar em torno das maiores probabilidades, indicando a sua característica de dependência do tipo de função de distribuição.
No Cmost, é preciso tomar cuidado ao utilizar este tipo de planejamento de experimentos. Embora a etapa de combinação dos parâmetros siga a metodologia de hipercubo latino, a amostragem de cada parâmetro ocorre de forma diferente. No Cougar, é amostrado qualquer valor dentro da faixa de variação de cada parâmetro para construir os diferentes experimentos, atendendo às condições antes mencionadas, mas o Cmost utiliza por padrão apenas de três a sete valores fixos dentro do intervalo de cada parâmetro. Esta amostragem é suficiente para planejamentos de experimentos clássicos, mas pode ser insuficiente para representar adequadamente problemas não lineares (como o ajuste de histórico) e/ou parâmetros com distribuição não uniforme.
Para mitigar o problema no Cmost, pode-se inserir manualmente um número maior de valores discretos para cada parâmetro incerto, com percentis uniformemente distribuídos. Não é possível utilizar a mesma quantidade de valores usados no Cougar (lembrando que a amostragem neste programa depende de uma discretização interna de cada segmento), mas empregando entre sete e treze valores, pode-se conseguir um resultado representativo para a maioria dos problemas. É importante entender esse tipo de limitação dos programas utilizados perante a disponibilidade de opções semelhantes.
13
i X
12 1 15
11 105
• n
85
8
0
K
distribuição do parâmetro de entrada
selecionar valores discretos
Figura 4 - Figura esquemática do planejamento LHS: dois atributos com distribuições de probabilidades distintas (Zubarev, 2009).
Figure 4 - Latin hypercube experimental design with two parameters (Zubarev, 2009).
respostas analisadas
As respostas de simulação usadas no estudo são as vazões de óleo e de água em diversos tempos ao longo da simulação, as produções acumuladas de óleo e de água no instante final da simulação e a pressão média do reservatório em diversos tempos. A pressão média e as vazões de óleo e de água são utilizadas para avaliar a qualidade do ajuste de histórico. As produções acumuladas são observadas para avaliar a dispersão gerada pelas incertezas consideradas.
definição da função objetivo
Para avaliar a qualidade do ajuste de histórico, é necessário definir uma função objetivo (FO). O aplicativo Cougar utiliza um recurso chamado Objective Function, definido pela seguinte equação:
FOÇx) =
i,j,k
(1)
Onde:
w = diferentes pesos (local, global, temporal) de cada parcela; obs.: significa os dados históricos observados;
sim = os dados simulados.
Para gerar uma FO composta representativa considerando como objetivo as vazões de produção de água e óleo e a pressão média do bloco, os três participando com a mesma importância, é necessário modificar os pesos de cada uma dessas séries de dados para garantir a mesma contribuição em termos de variância para eles. O desvio padrão é um dos indicadores mais utilizados para avaliar o grau de participação de cada variável na FO. A partir do ajuste dos pesos sobre os dados em cada FO é possível obter desvios padrão próximos em cada resposta analisada de forma independente.
Com os pesos utilizados inicialmente pelo programa, no caso do exemplo, a vazão de água seria o objetivo primário, sendo que os erros dos ajustes da vazão de óleo e da pressão não seriam necessariamente reduzidos. Em consequência, é muito importante e recomendável, antes de calcular uma FO composta, avaliar os pesos conforme o critério explicado.
Uma vez alterados os pesos, devem ser controlados os valores dos desvios padrão obtidos em cada caso. Esses valores de cada FO independente devem estar próximos de modo a dar a mesma importância para cada termo da FO composta. No caso da pressão, o intervalo de confiança sugerido pelo Cougar é aproximadamente 22kgf/cm2 (surgido da consideração de 10% em relação ao valor médio). Apesar disso, o peso desta variável é ainda insuficiente para dar significância no processo de ajuste dos dados históricos da pressão em conjunto com a água, por exemplo. Para isso, foram modificados os intervalos de confiança para cada resposta:
•	pressão: foi diminuída de 22 para 7kgf/cm2;
•	água: foi aumentada de 50 para 200m3/d;
•	óleo: foi diminuída de 500 para 200m3/d.
A figura 5 ilustra os valores dos atributos estatísticos obtidos para o cálculo da FO da variável vazão de água. Uma vez feito isso, são computadas as três FO independentes mais uma quarta FO composta considerando as três respostas em conjunto.
No Cmost, a função objetivo para ajuste de histórico é definida de forma um pouco diferente, como se percebe pela fórmula oferecida pelo programa (equação 2):
•100%-tw..
‘•j
(2)
A primeira diferença que se nota é a raiz quadrada que é aplicada à soma dos quadrados dos erros em cada série histórica considerada. Isso resulta em um crescimento mais lento da FO quando o ajuste se torna pior. Para a FO de uma única variável, não há muita diferença, pois os mínimos da função (o melhor ajuste) permanecem inalterados. No entanto, quando calculamos uma FO composta, somando parcelas diferentes, a aplicação da raiz quadrada a cada parcela separadamente pode
Objective Function Module: Sens?
0 Õ CougarProjectíl 0 0ÍCRP284-PRO
□	£ Cumulative Oi SC (m3)
□	£ Cumulative Water SC (m3) 0|^OÍRateSC(m3/day) 0 Water Rate SC (m3/&lt;iay)
± DÉ MACANY-PRO ffi □ ^MANORT-PRO 9 □ÍZP-RJS284P
___________________ OF Values
nÈ	I""ProixbonWaOww/*
OF yams CF.araa-TTO.Water Rate SOW
Sir	MULTF4I	MUITF4S	| MULTF5I	| MULTF5S	PERMI	PEPMK	J- “	TKW£V	knwnax2 j	no	rwv	| OF CRP284-PRO Wdl
												
228	797	0.427	0466	0,229	1.428	0,033	11	2	0.431	0.872	5.396	6.288
229	84	0.587	0.513	0,825	1.142	0.018	il	2	0.313	0.838	5,89	1.985
230	606	0.295	0782	0.626	1.306	0.007	r	1	0.491	1.167	5.214	8.825
231	618	0.778	0 825	0104	1.61	0.023	r	1	0.256	1 348	5.37	0678
232	727	0.56	0665	0,252	0.8	0.01	2	3	0.326	0.535	3,76	
												
Max	
Mean	55
Std	261
Std/Mean	47.442%
	
Controle dos atributos estatísticos da resposta (vazão de água). A variância (desvio padrão) deve ser semelhante em cada componente da FO.
0.5	3.5		0.172	\	
			12.812 '	
	5 1		2.623	
rfÍK	0.87		2,395	1	
±38,656%	±17.395\		±91.287%/	
Figura 5 - Resultados obtidos para um componente da FO composta (vazão de água).
Figure 5 - Statistical analysis and weight adjustment for the water production rate term.
fazer com que os mínimos da FO composta não estejam localizados exatamente na mesma combinação de parâmetros daquela obtida pelo Cougar. Entretanto, o fato de trabalhar com pesos semelhantes para os dois aplicativos de modo a dar a mesma importância às séries de dados tende a minimizar esse problema. Além disso, por ser utilizada na análise uma região em torno do mínimo e não apenas um único ponto. Assim, essa discrepância tende a se diluir.
Outra diferença significativa está na definição dos pesos da FO. Assim como o Cougar, o Cmost calcula um peso default para cada FO (scalei,j). Porém, no caso do Cmost, o usuário não tem acesso a este valor -pode apenas definir um multiplicador à parte (twi,j). Além disso, não é possível definir pesos diferentes para cada tempo das séries temporais. A definição do peso default é bastante complexa e em muitos casos pode levar a resultados mais satisfatórios que no Cougar, pois leva em consideração a variação máxima da série histórica (AY mi,j) em vez de sua média, através das seguintes regras (equação 3):
O termo Merr, j é o erro de medição de cada variável e será considerado nulo nesta discussão. A primeira forma se refere à variação máxima da série, a segunda ao menor valor absoluto, e a última ao maior valor absoluto da série. A figura 6 ilustra estes termos para a série histórica de pressão.
Campo de Marimbá
0
1998
300
1988
2000
—ir-
1986
1996
£
2
u
s
. 100
1
1 200
1990	1992	1994
Tempo (data)

AY.m. + 4 • Merr..
Scale.. = max • z z	0.5* mini	max(y.;()	.minírÜ	l + 4-Merr .
	\	/I	/	\ / \l 1	/	A	‘,J (3)
	0.25 * max	(maxfc		11 + 4- Merr.
Figura 6 - Termos do fator de escala no Cmost para a série histórica de pressão.
Figure 6 - Definition of the three forms of the Cmost scale term for the average pressure time series.
No entanto, é possível ter resultados ruins, especialmente em casos nos quais a média da série é muito maior que sua variação máxima e o peso assume a segunda (ou terceira) forma. No caso em estudo, os pesos default deixaram a vazão de óleo com pouca importância na FO composta. A figura 7a ilustra esse caso, exibindo o valor das FOs para cada experimento. Para obter valores satisfatórios, foi necessário calcular manualmente qual o peso que o Cmost aplicou internamente para cada série e utilizar o peso definido pelo usuário (twi,j) para, simultaneamente, cancelá-lo
e definir um novo peso (foram usados os mesmos valores do Cougar). A figura 7b mostra como as três FOs têm um desvio padrão mais próximo para os novos pesos. Nota-se que, apesar de os pesos serem iguais, a FO composta ainda é diferente nos dois programas, devido à presença da raiz quadrada. Isso explica, em parte, por que os resultados em cada caso não são idênticos. Mais uma vez, o entendimento dos módulos aparentemente semelhantes disponibilizados em diferentes aplicativos é essencial para a interpretação dos resultados obtidos.
40
Erro - Vazão Água
30
20
10
21
41
61
101
121
141
161
201
5
4
3
2
1
21
41
61
81
121
141
161
201
0
1
—I—
101
I
181
—I—
181
—r~
81
0 4-
1
--Erro - Pressão
- Erro - Vazão Óleo
Figure 7 - Individual term values of the OF in Cmost, considering all simulations from the experimental design. Default weights 7a and manually set weights 7b.
Figura 7 - Valor das FOs no Cmost para os pesos default 7a e os pesos alterados 7b.


superfícies de resposta
A superfície de resposta (SR) é um tipo de modelo aproximado das respostas dinâmicas de um modelo de simulação. Embora não seja necessário que a SR substitua o simulador em qualquer caso, quando estamos considerando múltiplos parâmetros incertos interatuando de forma não linear, é necessário usar modelos aproximados (proxy models), matematicamente mais simples, das respostas dinâmicas de interesse e, além disso, é importante que ela forneça resultados confiáveis nas regiões próximas dos valores mínimos da função objetivo.
Essa aproximação pode ser feita por meio de diferentes modelos, tais como regressão polinomial, krigagem, rede neural, etc. O objetivo da SR é ser capaz de representar o comportamento não linear de um modelo real mediante um modelo simplificado e ser de fácil aplicação (Zubarev, 2009). No modelo de regressão polinomial, a equação 4, que descreve a SR, pode ser descrita como:
Í=1	1=1 1=1	Í=1
Í&gt;1
Onde:
x	= vetor das variáveis de entrada,
x i	= termo linear;
xXj	= termo cruzado;
x2 i	= termo quadrático;
Po	= coeficiente de regressão;
Pi	= coeficiente de regressão;
Pj	= coeficiente de regressão;
Pr.	= coeficiente de regressão.
A análise multirresposta somente está disponível no aplicativo Cougar e permite criar SRs em diferentes tempos de forma automática. Esse tipo de análise é importante para avaliar como as incertezas críticas interagem e se propagam no tempo. Cada FO é representada por uma SR, gerada com base nas respostas das simulações rodadas. A figura 8 ilustra um exemplo de seis SRs geradas para a produção acumulada de óleo (Np). Portanto, cada linha representa uma SR, e a distância entre o ponto superior e inferior representa a variabilidade total da FO naquele
tempo. Para cada tempo, é possível identificar o valor de Np para os percentis P10, P50 e P90. Isso quer dizer que existe uma combinação dos atributos incertos de entrada da SR que representa esses percentis para cada um dos seis tempos selecionados e tal combinação pode ser diferente entre os tempos. Este tema será abordado mais adiante.
Figura 8 - Exemplo dos tempos selecionados para a análise de incerteza multirresposta.
Figure 8 - Example of chosen times for multi-response uncertainty analysis.
superfícies de resposta não paramétricas (SRNP)
Em seguida, são criadas as superfícies de respostas não paramétricas de cada objetivo. Apesar de essa etapa ainda ser bastante demorada, deve-se ressaltar que a nova versão do Cougar será por volta de oito vezes mais rápida e mais robusta que a atual.
É importante entender primeiro o que significa uma regressão paramétrica e não paramétrica. A regressão paramétrica se dá quando a forma do relacionamento funcional entre as variáveis dependentes e independentes é conhecida, mas podem existir parâmetros cujos valores são desconhecidos, embora passíveis de serem estimados a partir do conjunto de treinamento (valores da resposta conhecidos). Nesse caso, a regressão corresponde ao processo de aproximação
de um polinômio linear ou quadrático aos valores de respostas sob estudo obtidos das simulações para representar a superfície de resposta paramétrica (SR).
De outro modo, uma regressão não paramétrica se caracteriza pela ausência completa ou quase completa do conhecimento a priori a respeito da forma da função que está sendo estimada. Sendo assim, mesmo que a função continue a ser estimada a partir do ajuste de parâmetros livres, o conjunto de formas que a função pode assumir é muito amplo (classe de funções ou realizações estocásticas que o estimador baseado em krigagem pode prever). Como consequência, pode existir um número elevado de parâmetros (comparado ao número de dados de entrada/ saída para o cálculo), os quais não mais admitem uma interpretação física isolada.
As superfícies de respostas não paramétricas (SRNP) se baseiam na aplicação de Método de Kriging, introduzido por Matheron (1969), inicialmente usado em geoestatís-tica e hoje amplamente usado em outras áreas. Assume a construção da SR como um processo gaussiano (PG) que se caracteriza por uma estrutura de média e covariância, sendo um estimador linear imparcial.
A qualidade das SRNP construídas no passo inicial é da ordem de 0,6 (Q2 = 0,586 com rodadas de confirmação). Isto significa que o modelo não é ainda preditivo o bastante para continuar com a metodologia (fig. 9).
Como vamos avaliar a qualidade do ajuste, precisamos ter confiança nas SRs geradas para tal fim. É importante que a superfície de resposta represente bem o modelo, principalmente nos casos em que um bom ajuste é obtido. Para os casos em que o modelo não se encontra bem ajustado aos dados de produção, não é necessário que a superfície de resposta seja tão precisa.
Cabe ressaltar que a versão de pesquisa do Cougar (Cougar Opt do JIP Cougar, fase IV) possui um recurso chamado "superfície de resposta adaptativa”. Este módulo aborda um novo método iterativo de planejamento experimental hierárquico para melhorar gradativamente a qualidade da SR, ao qual são adicionados experimentos na repetição seguinte, selecionados automaticamente na proximidade das possíveis soluções do problema inverso. Essas soluções são exploradas usando o método de Cadeia de Markov via simulação Monte Carlo (MCMC), seguindo
0.902
0.805
Predictivity wth confirmation ru... 0.586
Predictivity with confirmation ru... 0.451
Mean GP Model
Covariance GP Model
Mean GP Model
Coefficient
Coeffioent
8.523
-2.091
Member of used e .per ments 124
RS Model Quaky
Predktivity (Q?)
0.817
0.867
Predictivity with confirmation run... 0.537
Predctivty with confirmation ru„. 0.42
RSMrtelQjak^^
PredKtrvity (Q^)
Vafcte
2.311
(Intercept)
AQ*A£&gt;
-----------------:
RS Mode Quaky
Predictivity (Q2)
RS Model Quaky
Predictivity (Q2)
Term
(Intercept)_______
AQRAtr2 Í5.O78
Term	Coefficient
(Intercept)	9.48!
AQRAO	-1.142
hwmax2	-2.612
no	3.717
woe	-2.012
MUITF3I~2	■1.781
AQRADrMLl...	0.723
ro AQRPOR	1.786
CPORMUIT...	-1.552
CPOR PERM!	-0.971	I
lwmax2:PE	1.394	\
WOCcrwv	-2.273
	
	
Covariance GP Model
Hyper Parameter	Value	
CdAQRAD	1.16	
Cot AQRPOR	2.083	
Cd CPC*	12.918	
Cot MUITF2I	13.491	
Col MUITF31	14.377	
Cot PERM!	7.401	
Col TK	3.542	
Cot kxwmax2	2.675	
Col no	1.535	
Cd nw	4.073	
Cd WOC	3.845	
P	1.99	
		
Hyper Parameter	value	
“Icot AQRAO	2.561	
Cd AQRPC*	12.362	
ICd CPOR	1.09	
kot MUITF2I	1.619	
Cd MUITF31	16.75	
Cd PERM!	20	
ICdTK	1.23	
led hwmax2	1.182	
|Cdno	0.691	
ULr*’	1.722	
yfdwx	1.554	
r p	1.99	
		
		
Mean GP Model
Term	Coefficient
(Intercept)	6.355
AQ-PAD	-1.545
PER MI	-0.783
l/v*r&gt;a&gt;2	■2.544
no	3.616
nw	1.611
woe	•2.427
AQRAD-2	1.708
TK~2	0.925
no-2	1.433
AQRADiCPC*	0.869
AQRPORiM...	-0.624
CPC*:MUT...	1
MUtTF2!d4...	-0.169	\
nw:W0C	•1.65
	
	
Cd AQRAO	4	
CdAQRPC*	13.334
Cd CPOR	2.384
Cd MUTF21	3862
Cd MUI TF 3!	5.823
Cd PERM!	20
Cd TK	1.178
Cd &gt;/wmax2	o.sir
Cd no	0.664
Cd nw	1.907
Cd WOC	1.039
p	1.99
Figura 9 - Exemplo do resultado do aprimoramento progressivo das SRs. Nota-se um incremento da complexidade com o aumento das iterações.
Figure 9 - Example of the progressive improvement accomplished on RS models. Note the complexity increased when more iterations were considered.
um esquema de probabilidade condicional bayesiana. Isso significa que, em cada iteração, somente alguns novos experimentos são escolhidos a partir da distribuição posterior das melhores soluções calculadas na iteração prévia (Emerick e Reynolds, 2010). O objetivo final deste método é obter uma distribuição da incerteza a posteriori, usando os dados dinâmicos disponibilizados, que não seja influenciada pelos erros da SR. O método concentra as rodadas de confirmação localizadas na região de interesse de maximização da função de verossimilhança (máxima probabilidade de FO mínima), que serviram de base para a construção de uma nova superfície de resposta em um novo passo. Este processo é repetido automaticamente mediante um processo iterativo até que determinada qualidade da superfície de resposta seja atingida.
Como a versão comercial atual não possui o recurso de superfície de resposta adaptativa, o processo foi efetuado manualmente. A partir da SRNP das funções objetivo referentes ao ajuste global, foram obtidas rodadas de confirmação nas regiões onde a SRNP indica uma boa qualidade do ajuste, ou seja, novas simulações são selecionadas na zona do espaço amostral com valores baixos da FO e posteriormente são avaliadas nesses novos pontos. Foram selecionados, em cada passo, alguns modelos possíveis com valores da FO composta menor que dois, que seguidamente foram definidos como rodadas de confirmação para melhorar a qualidade da superfície
de resposta nas regiões em torno destes valores. Caso a resposta da SRNP seja aceitável, pode-se confiar nela e ir para o próximo passo. Caso contrário, uma nova SR é construída, agora levando em conta os novos resultados das rodadas de confirmação. Novas rodadas de confirmação são selecionadas, e o processo é repetido até que se tenha confiança na SR, ou seja, que o indicador Q2 esteja acima de um valor mínimo escolhido.
No caso estudado, foi obtida uma superfície de resposta com o indicador Q2 igual a 0,929 após a quinta iteração. A figura 9 apresenta a evolução da SR (após quatro iterações) da função objetivo com as rodadas de confirmação. Nota-se que as rodadas de confirmação estão concentradas nas regiões onde os valores da FO são baixos. Esta SR será utilizada nos passos posteriores da avaliação dos possíveis modelos ajustados com o programa Cougar.
resultados
análises de sensibilidade
Foi efetuada a análise de sensibilidade global para o ajuste de óleo, de água e da pressão, além da função objetivo composta. Foram detectados os parâmetros com mais influência primária e aqueles com maior inter-relação cruzada com os demais atributos.
Figura 10 - Diagrama de Pareto correspondente à ASG da FO composta.
Figure 10 - Global Sensibility Analysis. Pareto Chart corresponding to the composite OF.
A figura 10 apresenta os resultados obtidos para a FO composta. As barras representam os valores dos índices de sensibilidade primária, dos índices totais e indicam os parâmetros com inter-relação de segunda ordem mais importante.
Um dos resultados obtidos a partir da ASG é a seleção dos parâmetros mais influentes nas respostas desejadas. No nosso caso, estamos avaliando não apenas a qualidade do ajuste de histórico global, mas cada termo em separado.
Os parâmetros que mais influenciam o ajuste global são: krwmax, AQRAD, TK, WOC, Permi, nw, MULTF3I, no, MULTF4S, CPOR e MULTF2I, sendo, por exemplo, importante a interação entre krwmax-AQRAD, krwmax-TK e Permi-TK. Além desses, será considerado também o parâmetro AQRPOR, com influência considerável no ajuste de pressão. Neste estudo comparativo, para manter uma coincidência nos parâmetros identificados com o Cmost e o Cougar, o parâmetro MULTF4S não foi considerado para o ajuste e as análises de incerteza subsequentes.
análise de incerteza a priori
Inicialmente é feita uma análise de incerteza chamada a priori, na qual não são levados em conta os dados do histórico de produção. É necessário realizar uma análise de incerteza antes do ajuste de histórico porque os dados históricos condicionam a dispersão dos modelos calibrados possíveis, servindo como ponto de referência do grau de incerteza inicialmente presente. É importante ter uma quantificação do grau de espalhamento inicial devido à incerteza presente e controlar para que a faixa de variação das respostas esteja relativamente centralizada em relação aos dados históricos. Os parâmetros com maior influência, selecionados na etapa anterior, são combinados seguindo um planejamento hipercúbico latino quadrático. O resultado para a produção acumulada de óleo é mostrado na figura 11, na qual os dados históricos não estão sobre a curva P50, e o espalhamento final varia entre 35 e 53 milhões de m3. Essa análise será comparada com o grau de espalhamento ao final do processo de ajuste.
ajuste de histórico probabilístico
Com os parâmetros críticos do problema identificados e a incerteza inicial já obtida, é preciso buscar os modelos que melhor ajustam os dados de histórico. A função objetivo composta, definida anteriormente, serve como critério quantitativo da qualidade do ajuste, possibilitando trabalhar com um número elevado de casos possíveis e com os aplicativos comerciais. Como mencionado, o objetivo neste trabalho não é encontrar um único modelo que ajuste os dados perfeitamente, mas reduzir o conjunto de possibilidades existentes.
No Cougar, esta investigação é conduzida com superfícies de resposta não paramétricas que modelam a FO de ajuste. No entanto, o planejamento de experimentos inicial pode ser insuficiente para mapear o problema, principalmente próximo aos mínimos da FO. Novos experimentos utilizados para melhorar a qualidade da SRNP são obtidos iterativa-mente, utilizando filtros para selecionar valores baixos da FO. Para auxiliar o processo, superfícies multirresposta são geradas para as varáveis de interesse (vazões de água e óleo e pressão estática do campo), como descrito anteriormente.
Figura 12 - Ajuste de histórico proba-bilístico de vazões de água e de óleo e de pressão estática antes e após o aprimoramento da SRNP (Cougar).
Figure 12 - Probabilistic history matching for water rate, oil rate and static pressures before and after NPRS improvement (Cougar).
Ajuste de vazão de óleo final
Ajuste de vazão de água inicial
Ajuste de vazão de água final
Ajuste de pressão inicial
Ajuste de pressão final
Ajuste de vazão de óleo inicial
12a, 12b e 12c - Espalhamento Pw-P90 inicial
12d, 12e e 12f - Espalhamento Pw-P90 final (após quinta iteração)
Como se pode observar na figura 12, ao final da quinta iteração foi possível obter um estreitamento das curvas dos percentis representativos da incerteza. Outro aspecto importante é que os dados históricos (conforme curva no gráfico) se encontram dentro da faixa P10-P90, agora bem menor em relação ao grau de estreitamento inicial. Assim, foi possível um ajuste do histórico a partir da mitigação progressiva da incerteza por volta dos mínimos da FO com a adição de novas rodadas de confirmação em cada iteração, obtendo um indicador de qualidade da SRNP melhor.
As figuras 12d, 12e e 12f apresentam as distribuições obtidas nos tempos representativos para a qualidade do ajuste, aceita após a quinta iteração. A região de interesse compreende valores da função objetivo mais baixos. O Cougar possui a opção de filtrar os resultados em torno de um valor desejado da FO. Outra situação em que esse recurso é útil é quando desejamos obter um modelo representativo dos cenários P10, P50 e P90,
como será mostrado adiante. Com base na informação gerada por filtros realizados sobre a SRNP, são obtidos modelos representativos que melhor ajustam os dados históricos, cujas combinações de parâmetros incertos possíveis permitiram a obtenção das novas distribuições (a posteriori) desses parâmetros. Essas novas distribuições conduzem a um melhor espalhamento das curvas de produção no período de previsão afetado pela incerteza remanescente.
O Cmost permite somente a construção de superfícies de resposta lineares ou quadráticas, que têm utilidade limitada no caso de um ajuste de histórico. No entanto, são fornecidos métodos de otimização (Designed Exploration Controlled Evolution - DECE, Enxame de Partículas ou Recozimento Simulado) para o ajuste, especialmente eficientes para obter uma única solução ótima determi-nística. Para obter um conjunto de soluções mais abrangente, é preciso incorporar de alguma forma as soluções exploradas pelo algoritmo até chegar ao valor ótimo.
distribuições a posteriori
Uma vez obtida uma superfície de resposta confiável, a distribuição de probabilidades dos parâmetros de entrada é redefinida de modo a selecionar as combinações de parâmetros que respeitam o histórico de produção existente. Para isso, uma propagação das incertezas é efetuada, sendo filtrados apenas os casos com valores baixos da SRNP da função objetivo composta. A partir desses casos filtrados, são traçados histogramas com as faixas dos parâmetros de entrada, que permitem a redefinição de suas distribuições de probabilidades.
A descrição completa das distribuições a posteriori deveria ser determinada como uma distribuição conjunta dos parâmetros, devido à possibilidade de haver interações entre eles. No entanto, as ferramentas empregadas permitem utilizar somente distribuições marginais para realizar uma propagação. Além disso, para obter uma descrição aceitável em um espaço de elevada dimensionalidade, seria necessário gerar um número mais elevado de casos. Por essas razões, o trabalho atual considera somente as distribuições marginais.
A versão atual do Cougar não permite armazenar as distribuições obtidas para futura utilização. Esse passo foi, portanto, feito em uma planilha separada, que permitiu definir as novas distribuições. A figura 13 apresenta os histogramas e as faixas de valores selecionadas para a distribuição a posteriori obtidas logo após a filtragem da superfície de resposta na região de interesse.
No Cmost, como desejamos restringir as distribuições dos parâmetros (e não obter uma única solução ótima determinística), é preciso propor uma forma de aproveitar os resultados dos métodos de otimização. São propostos três métodos, cuja premissa básica é considerar somente os casos que respeitem o histórico de produção, dada determinada tolerância (controlada pela FO composta).
Uma primeira alternativa é utilizar o resultado do histórico somente para redefinir os valores máximo e mínimo dos parâmetros. Quando se utiliza o método padrão de otimização do Cmost (DECE), o programa apresenta como parte do resultado intervalos ótimos para os parâmetros. Entretanto, esses intervalos normalmente são muito estreitos para utilização em uma análise de incerteza. Uma forma de obter intervalos mais amplos é estabelecer um critério
Figura 13 - Histogramas e faixas de variação a posteriori dos parâmetros após a propagação do filtro sobre as FO minimizadas (Cougar).
Figure 13 - Histograms and a posteriori parameters variation ranges after the propagation of the filter over the minimized FO.
Parâmetros de mapa de status:
► AQRAD	500	950	1.400	1850	2.300	2.750	3.200	3.650	4.100	4.550	5.000		
AQRPOR	0,2	0.23333	0.26667	0,3	0,33333	0,36667	0,4						
CPOR	9E-05	9.25E-...	9 5E-05	9 75E-...	0,0001	0,0001...	0.000105	000010...	0.00011				
MULTF2I	0	0,125	0,25	0,375	0.5	0.625	075	0875	1				
MULTF3I	0	0125	0.25	0,375	0,5	0,625	0.75	0 875	1				
Permi	0.8	0 925	1 05	1.175	1,	1 425	1 55	1,675	1,8				
TK	"TK 1"	"TK 2"	"TK 3"										
WOC	2.754	2.755	2756	2757	2758								
krw_max	0.2	0.225	0.25	0,275	0,3	0.325	0.35	0 375	0,4	0425	0.45	0475	05
no	0,5	0.75	1	1.25	1.5	1.75	2	2.25	2,5				
nw	3,5	3.8	4,1	4,4	4,7	5	5,3	5,6	5,9	6,2	6,5		
Figura 14 - Cmost exibe intervalos válidos para os parâmetros (valores em branco).
Figure 14 - Valid ranges (values in white frames) shown in Cmost.
de parada quando, por exemplo, for obtido determinado número de soluções com FO abaixo de certo valor. A figura 14 ilustra essa interface do Cmost para o caso de Marimbá.
Esse método é simplificado - como são obtidos apenas intervalos, é preciso assumir distribuições uniformes, ou ao menos simétricas, para os parâmetros.
O segundo método considerado consiste em trabalhar externamente com uma planilha para obter histogramas dos casos simulados, limitando a FO composta em algum valor máximo. Porém, é necessário algum cuidado com esse procedimento:
1.	o processamento é feito sobre casos simulados, e não sobre uma análise de Monte Carlo gerada com SRs. Consequentemente, há menos casos a se analisar (ainda que, para os casos existentes, a resposta seja mais confiável), resultando em um histograma menos fidedigno;
2.	os casos não seguem as distribuições a priori dos parâmetros, como ocorreria em uma simulação de Monte Carlo. Em vez disso, os casos são determinados pelo algoritmo de busca utilizado. Ironicamente, quanto mais rápida a convergência do algoritmo, menos casos estarão disponíveis para análise.
Finalmente, uma terceira alternativa é fazer o ajuste de histórico utilizando um planejamento por hipercubo
latino e superfícies de resposta. Esse procedimento é muito mais limitado que no Cougar, uma vez que não estão disponíveis superfícies não paramétricas, nem é possível incorporar novas rodadas ao planejamento. Para melhorar o resultado final, é possível restringir os parâmetros de acordo com o resultado obtido e realizar um novo ajuste, duas ou três vezes, restringindo gradativamente as soluções a uma região menor em torno do mínimo. Utilizando o segundo ou terceiro método, é possível obter histogramas que indiquem quais distribuições adotar. Porém, como já foi dito, deve-se tomar algum cuidado, pois esses histogramas não correspondem exatamente a distribuições de probabilidade. Na figura 15, pode-se observar como o algoritmo DECE tende a restringir demais os valores, devido a sua convergência mais rápida. O uso de superfícies de resposta permite obter distribuições mais abertas e suaves, enquanto o método Enxame de Partículas exibe um comportamento intermediário. A figura 16 apresenta os histogramas e as faixas de valores selecionadas para a distribuição a posteriori no caso do Cmost, com base em um ajuste de histórico feito por Enxame de Partículas. É importante ressaltar que os histogramas não são utilizados diretamente como distribuições de probabilidade dos parâmetros, mas, sim, como guia para definir os intervalos e picos de distribuições mais suaves.
Figura 15 - Histogramas para os parâmetros krw max e Permi. (a) e (b) - DECE; (c) e (d) - Enxame de Partículas;
(e)	e (f) - hipercubo latino.
Figure 15 - Histograms for Krw-max and Permi parameters. (a) and (b) DECE method; (c) and (d) Particle swarm; (e) and
(f)	Latin Hypercube.
AQRAD
TK
AQRPOR
krw_max
CPOR
Figura 16 - Histogramas dos parâmetros no Cmost utilizando o método Enxame de Partículas.
Figure 16 - Parameter histograms derived from Particle Swarm method.
MULTF21
MULTF31
WOC
Permi
análise de incerteza a posteriori
Os dados históricos servem para mitigar parte da incerteza inicial e condicionar a dispersão dos modelos possíveis. Com as distribuições a posteriori, uma nova análise de incerteza é realizada, para que seja obtido o grau de espalhamento após o ajuste probabilístico. Esse grau de espalhamento é comparado com o obtido usando as distribuições definidas a priori, com as mesmas condições da análise de incerteza já realizada.
Os parâmetros incertos redefinidos na etapa anterior são combinados novamente, segundo um planejamento de experimentos baseado na amostragem por hipercubo latino, agora usando as distribuições a posteriori. A partir dos resultados da amostragem, são geradas superfícies de resposta para os resultados de interesse, que são a função objetivo composta e as funções objetivo parciais, além da pressão e das vazões de óleo e de água ao longo do tempo. Também são consideradas as respostas escalares (pressão e produção acumulada de óleo e de água)
para os tempos 5.022 dias (1998) e 9.405 dias (2010) para observar variações na influência dos parâmetros.
São realizadas as mesmas análises de incerteza efetuadas com as distribuições a priori, ou seja, análise de incerteza ao longo do tempo para obter a envolvente dos percentis P10 a P90 das variáveis e simulação de Monte Carlo sobre as respostas escalares a 5.022 e 9.405 dias. As curvas envolventes dos percentis P10 a P90 das produções acumuladas de óleo correspondentes às análises a posteriori são apresentadas na figura 17. Comparada com a figura 11 (análise de incerteza a priori), pode-se ver um notável estreitamento de mais de 12 milhões de m3 no tempo final da previsão (2010) e uma diferença pouco significativa entre P10 a P90 até o final do histórico, indicando que todos os modelos probabilísticos ajustam os dados de produção medidos. A figura 18 também evidencia o estreitamento da distribuição no tempo final de previsão, bem como a exclusão dos casos mais pessimistas para o modelo estudado.
Np (m3)
Figura 18 - Distribuição de Np no tempo final para Análise de Incerteza a priori e a posteriori.
Figure 18 - Comparison of S curve between prior and posterior uncertainty assessment. Response: Np (m3) at final time.
análise de incerteza final
Uma vez comparados os resultados, é efetuada a análise de incerteza final, considerando as distribuições a posteriori, além de outros parâmetros que não impactam o ajuste de histórico, mas têm bastante influência sobre a predição da produção. Os parâmetros adicionados nessa etapa são:
•	AQ200 - redução de transmissibilidade no aquífero CRP200;
•	MULTF4S - multiplicador de transmissibilidade de falhas;
•	MULTPI - multiplicador do IP dos poços, variando de 0,5 a 2,0;
•	STL e STW - controles de vazão de líquido e de injeção dos poços com entrada após 1998.
A análise é realizada seguindo o mesmo procedimento adotado na análise de incerteza a posteriori, com planejamento de experimentos por hipercubo latino e geração das superfícies de resposta. As envolventes finais obtidas dos percentis P10 a P90 das variáveis são apresentadas na figura 19. Nessa figura, pode-se constatar que os dados históricos continuam sendo honrados, passando sobre a curva representativa da P50, conservando uma faixa P10-P90
estreita nesse período. No entanto, essa faixa sofre um novo espalhamento devido à incerteza remanescente, que representa o risco final do projeto.
O espalhamento final da produção de óleo acumulada Np, probabilisticamente obtido no Cougar, varia de 41 a 49 milhões de m3, com todos os modelos possíveis calibrados. No Cmost, o espalhamento da mesma análise é um pouco maior, de 39 a 53 milhões de m3, devido a diferenças na
modelagem das distribuições dos parâmetros e ao fato de o planejamento de experimentos do Cmost ter utilizado mais casos. A figura 20 mostra como as distribuições de Np obtidas nos dois aplicativos são semelhantes, apesar da diferença nos valores extremos.
identificação dos modelos P10, P50 e P90
Um equívoco comum é a seleção de um modelo representativo baseado apenas na resposta final de interesse (por exemplo, a produção de óleo acumulada em determinada data). Tal modelo pode não ser representativo das demais respostas desejadas para aquele cenário, como, por exemplo, produção de água ou produções acumuladas de óleo em outros instantes.
Os percentis P10, P50 e P90 são utilizados para representar o modelo otimista, provável e pessimista. Como já comentado, é possível que a combinação que resultou no valor de Np para o percentil P10 no tempo t1 seja diferente da combinação no tempo t2. Deseja-se encontrar uma única combinação de parâmetros (modelo representativo) que represente todos os valores obtidos para cada uma das SRs obtidas em cada tempo. Para isso, é aplicado um filtro para cada percentil e, dependendo da tolerância estipulada, pode-se encontrar mais de uma combinação.
Figura 21 - Exemplo do filtro usado para identificar os modelos representativos para P10, P50 e P90.
Figure 21 - Identification of representative models for P10, P50 and P90 using filter.
A figura 21 ilustra um exemplo em que duas combinações diferentes de parâmetros (curvas externas) foram encontradas para representar as SRs para seis tempos distintos de determinado percentil (curva central). Observa-se que ambas as combinações estão dentro da tolerância escolhida. O problema pode ser ainda mais complexo quando se deseja selecionar modelos representativos que contemplem duas ou mais respostas, como produção de água e de óleo simultaneamente.
validação e seleção dos modelos representativos
Cada modelo representativo dos percentis de referência (P10, P50 e P90) selecionado no passo anterior deve ser validado mediante uma nova simulação de reservatório (rodadas de confirmação finais). Os parâmetros incertos determinados na etapa anterior são utilizados no modelo de simulação, e a curva obtida pela SR é comparada com a obtida por meio do modelo de simulação. É importante que os resultados sejam semelhantes.
Para o modelo provável, são escolhidos valores próximos ao percentil P50, tanto para Np quanto para Wp. Já para os modelos pessimista e otimista, essa escolha não é tão clara. É razoável que um modelo otimista produza menos água que um modelo pessimista. Por essa razão, optou-se por considerar para o modelo pessimista o P90 para Np e o P10 para Wp, ou seja, 90% das combinações possíveis de produção de óleo superam esse valor, e somente existem 10% de casos com produção mais alta de água. Da mesma forma, para o modelo otimista considerou-se o P10 para Np e o P90 para Wp.
No Cougar, são selecionados por meio de filtros alguns modelos próximos aos percentis mencionados, tanto para o Np quanto para Wp em forma conjunta. Os modelos identificados são exportados para uma planilha externa e são apresentados em gráficos para cada tempo representativo na etapa de previsão.
A figura 22 mostra os diversos modelos dispersos em um gráfico onde o eixo X é a produção de óleo acumulada nos tempos 6.483, 7.944 e 9.405 dias, e o eixo Y é a produção de água acumulada nos mesmos
tempos. Nota-se que o modelo selecionado para cada um dos cenários (P10, P50 e P90) continua sendo o mesmo em todos os tempos e se encontra próximo do percentil desejado tanto para o óleo acumulado quanto para a água acumulada.
No Cmost, a seleção dos modelos representativos tem de ser feita de forma essencialmente manual, não havendo uma ferramenta que permita uma análise de forma expedita.
Não existe a opção de análise multirresposta do Cougar - embora seja possível criar FOs da mesma variável em diferentes datas, este procedimento se torna impraticável para muitas datas. Por esta razão, não é possível gerar gráficos com as envoltórias das curvas P10 a P90.
As superfícies de resposta quadráticas utilizadas pelo Cmost têm uma capacidade limitada de representação, insuficiente para problemas complexos. Consequentemente, escolher modelos com base nos valores dos parâmetros na simulação de Monte Carlo não funciona bem, uma vez que os valores de Np e Wp e a qualidade do ajuste ao rodar a simulação de fluxo podem diferir drasticamente dos valores esperados. Além disto, na versão atual do aplicativo, os valores dos parâmetros para a nova simulação têm de ser inseridos manualmente.
Assim, considera-se que a forma mais prática para selecionar os modelos representativos no Cmost é escolhê-los com base nos casos simulados do planejamento de experimentos. Para que haja casos próximos aos percentis desejados, é necessário ter um número razoável de casos simulados, dependente da complexidade do problema (foi utilizado um desenho com cerca de 400 modelos no caso apresentado). Modelos que atendam simultaneamente aos percentis de mais de uma variável podem ser escolhidos graficamente, da mesma forma que no Cougar, como ilustrado na figura 23.
No entanto, é importante verificar graficamente se o modelo respeita o histórico de produção, o que pode não acontecer com todos os casos. A figura 24 apresenta as curvas de produção acumulada da seleção dos possíveis modelos P10, P50 e P90 de óleo e de água consideradas em conjunto.
©
Valores Percentis Calculados (T=6.483) Modelos Representativos
Valores Percentis Calculados (T=7.944) Modelos Representativos
Modelos Representativos
4,00E+07
e3,50E+07- .
■°3,00E+07-
q-2,00E+07
1,50E+07
3,50E+07 3,70E+07 3,90E+07 4,10E+07 4,30E+07 4,50E+07 4,70E+07 4,90E+07 5,10E+07
Produção acumulada de óleo (m3)
S2,50E+07
*	Hipercubo latino
■ Confirmação *P10
+ P50
♦	P90
Figura 22 - Produção de água acumulada versus produção de óleo acumulada para os tempos 22a) 6.483 dias, 22b) 7.944 dias e 22c) 9.405 dias. Os pontos indicam os modelos representativos para os cenários otimista, provável e pessimista.
Figure 22 - Cumulative water production versus cumulative oil production for the times 22a) 6.483 days, 22b) 7.944 days and 22c) 9.405 days. The marks indicate the corresponding models for optimistic, probable and pessimistic scenarios.
Figura 23 - Np versus Wp após 9.405 dias para os casos do planejamento de experimentos do Cmost.
Figure 23 - Np versus Wp after
9.405 days for Cmost experimental design cases.
4,00E+07
Valores Percentis Calculados (tempo final) Modelos Representativos
3,50E+07
3,00E+07
2,00E+07
Produção acumulada de óleo (m3)
* *
• L
1,50E+07
3,50E+07 3,70E+07 3,90E+07 4,10E+07 4,30E+07 4,50E+07 4,70E+07 4,90E+07 5,10E+07
ra 2,50E+07
conclusões
Constata-se que os aplicativos Cougar e Cmost são mais diferentes do que uma análise superficial deixa transparecer e que é preciso ter uma visão crítica dos resultados apresentados pelos aplicativos. Ambos permitem obter uma análise de incerteza condicionada ao histórico de produção, se tomados alguns cuidados.
O Cmost é mais eficiente para se realizar um ajuste de histórico por meio de uma otimização determinís-tica, mas tem recursos limitados para o tratamento de análise de incerteza. O fluxo de trabalho em Cmost é simples e intuitivo, com uma interface gráfica amigável para o usuário e uma comunicação transparente com os demais programas da plataforma de simulação numérica da CMG. Além disso, é fácil de configurar para o lançamento de rodadas múltiplas com vários processadores usando clusters externos (LSF), redes de computadores (MSCC) ou o próprio CMG Drone Scheduler. Outra vantagem é a disponibilidade irrestrita de licenças desse software no caso da Petrobras.
Por outro lado, o Cougar tem uma curva de aprendizado mais lenta e uma configuração complexa, o que inibe sua utilização por usuários inexperientes, mas aborda melhor os princípios teóricos envolvidos. Destacam-se as opções para aprimorar a qualidade das SRs geradas e para
definir as rodadas de confirmação necessárias para tal fim. Além disso, esse aplicativo tem uma considerável flexibilidade na análise de incerteza, permitindo a obtenção de modelos representativos, considerando a variação do intervalo P10-P90 para múltiplos tempos de forma simultânea.
As principais diferenças identificadas entre os aplicativos se resumem aos seguintes pontos:
1.	amostragem do planejamento de experimentos por hipercubo latino;
2.	possibilidade de utilização de SGA para investigar inter-relação e SRNP no Cougar;
3.	diferente equacionamento da FO composta, podendo resultar em pontos ótimos ligeiramente distintos;
4.	abordagens distintas para ajuste de histórico (SR vs. algoritmos estocásticos de otimização);
5.	no Cougar, há opções para aumentar a represen-tatividade do proxy model gerado e controle para criar novas rodadas de confirmação;
6.	recursos para identificação e escolha das curvas características de produção dos modelos representativos.
Os procedimentos para se obter uma análise de incerteza sob ajuste de histórico ainda precisam de mais pesquisa e desenvolvimento e não existe um único caminho a seguir. A metodologia apresentada é apenas uma das
muitas abordagens possíveis. Embora a teoria básica que motiva condicionar a previsão aos dados de produção esteja bem estabelecida, a sua aplicação na prática ainda esbarra em algumas dificuldades.
A abordagem bayesiana, mais correta do ponto de vista teórico, possui um custo computacional proibitivo quando associada à simulação da maioria dos modelos de reservatório utilizados na prática. Mesmo a abordagem apresentada neste artigo, consideravelmente mais leve, exige um esforço significativo, tanto em processamento quanto em horas de trabalho. Parte desse custo se deve aos aplicativos comerciais empregados, que ainda não se encontram inteiramente adequados ao fluxo de trabalho utilizado.
A "arte" de se obter uma boa análise de incerteza condicionada pelo histórico baseia-se em identificar parâmetros críticos que tenham efeito significativo sobre a previsão sem prejudicar a qualidade do ajuste. Ao mesmo tempo, esses parâmetros devem ser plausíveis do ponto de vista da geologia do reservatório. Por essa razão, para obter um resultado satisfatório, é importante que o processo de ajuste de histórico envolva não apenas o engenheiro, mas também o geólogo e o geofísico responsáveis pelo campo.
Também se deve manter em mente que se trata de um processo de redução e não eliminação completa de incertezas. Um único modelo determinístico, mesmo que ajuste com perfeição um longo período de produção, não garante uma boa previsibilidade (ainda que seja uma opção melhor que um modelo desajustado).
Mesmo com todas as restrições apresentadas, o processo de se condicionar as previsões sob incerteza ao histórico conhecido traz um ganho considerável no comportamento preditivo do projeto e deve ser aplicado sempre que possível. Somente aderindo ao princípio em todos os projetos em que seja aplicável, e com a constante troca de experiências entre profissionais envolvidos, é que poderemos chegar a um processo consistente e eficiente de redução de incertezas por ajuste de histórico.
agradecimentos
Os autores agradecem a todos os profissionais que contribuíram na elaboração do modelo estático e dinâmico do Campo de Marimbá, que serviu como caso de estudo para a concretização da metodologia proposta neste artigo.
referências bibliográficas
I BECERRA, G. G. Mitigação de incertezas através da integração com ajuste de histórico de produção. 2007. 192 p. Dissertação (Mestrado) - Universidade Estadual de Campinas, São Paulo, 2007.
1 BRATVOLD, R. B.; BEGG, S. H. Making good decisions. Richardson: Society of Petroleum Engineers, 2010. 207 p.
1 BUSBY, D; FERAILLE, M. Adaptive design of experiments for calibration of complex simulators: an application to uncertainty quantication of a mature oil field. Journal of physics: conference series, Paris, v. 135, n. 1, p. 012026, Nov. 2008. Trabalho apresentado na 6th International Conference on Inverse Problems in Engineering: Theory and Practice, Dourdan, France, 2008.
I CMOST STUDIO. 1.0 User's Guide. Version 2010. Calgary, Alberta: CMG, 2010.
I COUGAR SOFTWARE. Version 2010.1: user manual. 2010. Rueil-Malmaison, France: IFPEN; Beicip-Franlab, 2010.
I EMERICK, A. A.; REYNOLDS, A. C. EnKF-MCMC. In: SPE EUROPEC/ EAGE ANNUAL CONFERENCE AND EXHIBITION, 2010, Barcelona, Espanha. Proceedings... Richardson: Society of Petroleum Engineers, 2010. SPE 131375. 18 p.
I LISBOA, E. A.; DUARTE, R. B. Análise de incertezas considerando o histórico de produção: avaliação da área a sul do poço RJS510 em Albacora Leste. In: SEMINÁRIO DE RESERVAS E RESERVATÓRIOS - SRR, 2009, Rio de Janeiro. Anais... Rio de Janeiro: Petrobras, 2009.
I MATHERON, G. Le krigeage universel. Fontainebleau, France: L'Ecole Nationale Supérieure des Mines de Paris, 1969. Fascicule 1.
referências bibliográficas
I REIS, L. C. Quantificação de incertezas volumétricas condicionada aos dados dinâmicos observados. In: SEMINÁRIO DE RESERVAS E RESERVATÓRIOS - SRR, 2005, Salvador. Anais... Rio de Janeiro: Petrobras, 2005.
1 SILVA, F. R. C.; COSTA, A. P. A. Utilização de modelos representativos na tomada de decisão do desenvolvimento complementar em campos
onshore/offshore. In: SEMINÁRIO DE RESERVAS E RESERVATÓRIOS -SRR, 2009, Rio de Janeiro. Anais... Rio de Janeiro: Petrobras, 2009.
I ZUBAREV, D. I. Pros and cons of applying proxy-models as a substitute for full reservoir simulations. In: SPE ANNUAL TECHNICAL CONFERENCE AND EXHIBITION, 2009, Louisiana, USA. Proceedings... Richardson: Society of Petroleum Engineers, 2009. SPE 124815.
autores
I Centro de Pesquisas da Petrobras (Cenpes)
I P&amp;amp;D em Geoengenharia e Engenharia de Poço
I Gerência de Simulação e Avaliação de Reservatórios
gustavo.becerra@petrobras.com.br
Gustavo Gabriel Becerra
André Paoliello Modenesi
I E&amp;amp;P Engenharia de Produção
I Reservas e Reservatórios
I Gerência de Engenharia de Reservatórios
andremodenesi@petrobras.com.br
Gustavo Gabriel Becerra é engenheiro de reservatórios sênior na Petrobras Energia S.A. (PESA), trabalhando desde 2008 no grupo de simulação desta gerência. Coordena a linha de pesquisa de análise de incertezas e participa de projetos relacionados com o padrão de quantificação de incerteza envolvendo a problemática do ajuste de histórico. Participa do projeto sobre heterogeneidades críticas nos reservatórios do Pré-Sal. Atua como responsável técnico do nó Unicamp da Rede de Simulação e Gerenciamento de Reservatórios (Siger), além de representar a Petrobras nos projetos multiclientes com o Instituto Francês do Petróleo (IFP) e empresas no exterior. Atuou como engenheiro de reservatórios na Petrobras Venezuela e no Centro de Tecnologia Aplicada (CTA) em Neuquén, Argentina. Possui mestrado em Engenharia de Petróleo pela Universidade Estadual de Campinas (Unicamp), em 2007 e graduação em Engenharia Civil e Hidráulica pela Universidade Nacional de La Plata (Argentina), em 1991.
André Paoliello Modenesi é engenheiro eletricista, formado pela Universidade Federal de Minas Gerais (UFMG), em 2008. Ingressou na Petrobras em 2009, trabalhando na área de engenharia de reservatórios desta gerência, com atuação em temas como análise de incertezas, ajuste de histórico, campos digitais e gerenciamento de reservatórios. Trabalhou como pesquisador e desenvolvedor de software nas áreas de visão e inteligência computacional.
autores
Érico Fagundes Anicet Lisboa
I Unidade de Operações de Exploração e Produção do Rio de Janeiro
I Reservatórios
I Gerência de Geofísica, Geologia e Engenharia de Reservatórios
ericolisboa@petrobras.com.br
Leandro Costa Reis
I E&amp;amp;P Projetos de Desenvolvimento da Produção
I Competências Técnicas em Projetos de DP
I Gerência de Geofísica, Geologia e Engenharia de Reservatórios II
leandro.reis@petrobras.com.nr
Erico Fagundes Anicet Lisboa é engenheiro mecânico, graduado pela Universidade Estadual do Rio de Janeiro (UERJ), em 1996 e Mestre em Engenharia Mecânica pela Coppe/UFRJ, com tese defendida em 2000 sobre escoamento em meios porosos. Ingressou na Petrobras em 2004 e trabalha na área de simulação e gerenciamento de reservatórios do Campo de Albacora Leste desde 2005. Integra projetos de pesquisa nas áreas de análise de incertezas, ajuste de histórico e otimização, participando da elaboração do padrão de quantificação de incerteza envolvendo a problemática do ajuste de histórico. É instrutor de cursos internos na Petrobras sobre metodologias de análise de incertezas e ferramentas de gerenciamento de reservatórios. Participa da equipe de desenvolvimento do simulador de nova geração DRMS, em conjunto com a Computer Modelling Group (CMG) e a Shell.
Leandro Costa Reis é engenheiro de petróleo na Petrobras desde 1983, formado na Universidade Federal do Rio de Janeiro (UFRJ), com mestrado na Unicamp e doutorado na Universidade Paris 6. Trabalhou em gerenciamento e simulação numérica de reservatórios nas áreas de: modelagem de reservatórios carbonáticos (fraturados), caracterização de reservatórios com técnicas geoestatísticas, gerenciamento em tempo real de reservatórios, análise de risco, simulação com linhas de fluxo e ajuste de histórico assistido. É responsável pela supervisão técnica na modelagem de reservatórios carbonáticos.
Deise Massulo Ferreira
I E&amp;amp;P Engenharia de Produção
I Reservas e Reservatórios
I Gerência de Engenharia de Reservatórios
deise@petrobras.com.br
Deise Massulo Ferreira possui graduação em Engenharia Civil pela Universidade Federal do Rio de Janeiro (UFRJ), em 1982 e mestrado em Geoengenharia de Petróleo pela Unicamp, em 1994. Engenheira de petróleo sênior, exerceu atividades relacionadas ao gerenciamento e desenvolvimento de campos de mar da Bacia de Campos, de 1985 a 2006. Desde 2006, atua nas áreas de sísmica 4D, análise de incertezas e suporte técnico da atividade de Engenharia de Reservatórios.
expanded abstract
This is a practical case study to illustrate the global uncertainty assessment for a field that has a long production history. Two commercial tools were tested, in parallel, to perform the analysis (the 2010 software versions were used; small improvements have since been implemented).
A methodology to identify representative models adjusted (within a certain tolerance) to the historical data is proposed. The main purpose is to mitigate uncertainties through a probabilistic history matching, instead of obtaining the best possible match (Becerra, 2007). A secondary objective is to identify limitations, advantages and drawbacks of the two commercial tools most widely used at Petrobras.
Historical data can be used to reduce the range of uncertainty of input parameters, resulting in representative models with better forecast capabilities. The impact of the new parameter distributions on the model responses is evaluated through Monte Carlo simulations based on a proxy model built using experimental design.
The quality of history matching (HM) must be quantified to work with a large number of combinations. The of the difference between real and simulated data is called Objective Function (OF).
In Cougar, confirmation runs are used to improve the Response Surface quality around the OF minimum (best match). A filter is applied to the Monte Carlo simulation to select the best fitted models and to obtain new parameter distributions.
In Cmost, the filter is applied directly to the attempted solutions (flow model simulations, not proxy models) of the HM treated as a deterministic optimization problem.
Finally, to obtain a complete uncertainty analysis for the forecast period, parameters that did not influence the HM period, but had impact on the forecast must be identified and included in the analysis. The range of new forecast production curves will be used to evaluate the project feasibility.
The studied field is located in the Campos Basin, about 80km off the Brazilian coastline. The reservoirs are below a water depth between 300 and 800m. The main sand reservoir has good petrophysical characteristics and also good-quality oil.
There was a significant depletion during the first fourteen years of production due to the lack of water injection. In subsequent years, water injection began, and several well were recompleted to avoid an excessive water production.
For this study, only the first fourteen years of production were considered as observed data. The production of the following years was treated as unknown, and predicted by the flow model.
The considered uncertain parameters were related to aquifer properties, rock compressibility, faults, well productivity, permeability and transmissibility multipliers, water-oil contact and relative permeability curves.
The simulation responses were monthly oil and water production rates at several moments, the final produced volume of oil and water and the average reservoir pressure. Production rates and pressure were used to evaluate the history matching quality, while the volumes established the uncertainty range.
The uncertainty analysis was based on Monte Carlo propagation, the responses of a large number of parameter combinations had to be evaluated. In most cases, it was not feasible to directly test each case with the dynamic flow simulator, because of the high computational cost required.
Proxy models or response surfaces are simplified models that try to emulate the flow model response, based on a limited number of cases (the experimental design). Although less precise, they are much faster to run than the complete model. For the studied situation, it is important the proxy model has good precision near the objective function minimums. The response surface can be modeled by polynomial regression, kriging, artificial neural networks, etc.
Both tools have several types of experimental design available. The chosen technique was an optimal Latin hypercube. This technique guarantees the entire sampling space is investigated with fewer simulations. This design also takes into account the parameters probability distributions, creating more samples in more probable regions.
A Global Sensibility Analysis was performed for the individual history matching quality of the water and oil
expanded abstract
production and average pressure, and also for the global history matching quality. The parameters with high sensibility indices (or interaction with other parameters) were chosen and kept for the following steps.
Initially, a prior uncertainty assessment was made, without considering the historical production data. This step was necessary to evaluate the uncertainty present before matching the production data. These results were later compared with the posterior uncertainty assessment. The prior uncertainty assessment also shows if the historical data is within the expected range of the production curves. The most significant parameters identified in the previous step were combined in a Latin hypercube design.
When evaluating the uncertainties for a field with a production history, it should be confirmed if the considered scenarios respect the known data. Response surfaces for the output responses of interest were obtained, considering time instants about a year apart. These surfaces make it possible to analyze the responses behavior for the whole production period, instead of only a single snapshot at the final time.
Once a reliable response surface was obtained, the probability distribution of the uncertain parameters was redefined from those combinations of parameters that best fit the observed data. Those posterior distributions are obtained from histograms of the Monte Carlo propagation filtered cases of the global HM OF.
The uncertain parameters redefined in the previous step were combined again in a design of experiments based on Latin hypercube sampling, now using the posterior distributions. Multi-time response surfaces were generated for the responses of interest, which were composed of oil and water pressure and flow rates. Scalar responses were also considered (oil and water pressure and cumulative production) for year ends 1998 and 2010.
The same uncertainty analysis workflow made with the prior distributions was performed with the posterior distributions. The main steps were uncertainty analysis over time to view the P10 to P90 percentile envelope of the variables and the Monte Carlo simulation on the scalar responses for 1998 and 2010. Compared with the prior
uncertainty analysis, there was a noticeable narrowing of more than 12 million m3 of oil in the final forecast time (2010) and very small spread between P10 to P90 for the historical period, indicating that all probabilistic models fit the measured production data.
Therefore, final the uncertainty analysis was performed, using posterior distributions, and other parameters and controllable attributes that do not impact the historic setting, but have considerable influence on predictions. The analysis was performed with the same procedure used in the previous uncertainty analysis, design of experiments with a Latin hypercube and generation of response surfaces. The historical data was once again honored, passing near a curve representative of the P50, keeping in close range of P10-P90 in the historical period. However, this band became wider due to remaining uncertainty, which represents the ultimate project risk.
The parallel work on both tools made it possible to compare their relative pros and cons, and to realize that the differences were bigger than a hasty evaluation showed. Although both tools can be used to reach the proposed goal, that is, to obtain an uncertainty analysis, which reflects the historical production data, some precautions should be observed. Cmost can be more efficient for a deterministic (single solution) history matching task, but still has limited resources to handle uncertainties. The Cmost workflow is direct and intuitive, with a user-friendly interface that works seamlessly with other applications from the CMG suite. The configuration of parallel simulations with computer clusters is also straightforward.
Cougar, on the other hand, can have a slow learning curve and a complex configuration setup, which can alienate inexperienced users. However, it more strictly observes the theoretical principles of uncertainty analysis. This tool has resources to improve the quality of RSs and launching additional simulation rounds. The analysis of the responses is also more flexible, with options such as considering responses for several time steps at once.
expanded abstract
The procedure to make an uncertainty analysis conditioned by production data still needs more research and development. The discussed methodology is one of several possible techniques, conditioned by the commercial tools available. The Bayesian approach, more correct from a theoretical point of view, can have a prohibitive computational cost for many real simulation flow problems. Even the discussed approach, though considerably lighter, demands a significant amount of work, both in computational cost and human effort.
The "art" of obtaining a satisfactory uncertainty analysis that considers historical data depends on the capacity to identify critical parameters that impact the production forecast without compromising the quality of the fit. These parameters should also be plausible from a
geological point of view. Therefore, the history matching process should involve not only the reservoir engineer, but also the field geologist and geophysicist.
It is important to keep in mind the objective is to reduce the uncertainties - eliminating them completely is impossible. A single deterministic model, even if it is perfectly adjusted for a long production period, does not guarantee a good predictability.
Even with all the issues presented, conditioning the uncertainty analysis to historical data can bring significant gains to the project predictability, and should be applied whenever possible. To arrive at a consistent and efficient workflow to reduce uncertainties by considering the history matching, the constant exchange of experiences among professionals in the field is necessary.
</field>
	</doc>
</add>