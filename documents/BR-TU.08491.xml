<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.08491</field>
		<field name="filename">13328_Kozakevich_DanielNorberto_D.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">SISTEMAS NAO-LINEARES
DA FÍSICA E DA
ENGENHARIA
Este exemplar corresponde à redação final da tese devidamente corrigida e defendida pelo Sr. DANIEL NORBERTO KOZAKEVICH e aprovada pela Comissão Julgadora.
Campinas, 20 de Junho de 1995
Tese apresentada ao Instituto de Matemática, Estatística e Ciência da Computação, UNICAMP. como requisito parcial para a obtenção do título de DOUTOR em MATEMÁTICA APLICADA.
Pela Banca Examinadora composta pelos Profs. Drs.
prof(a). Dr(a).CLOVIS RAIMUNDO MALISKA
Prof(a). Dría). MARIO CESAR ZAMBALDI
Departamento de Matemática Aplicada
Instituto de Matemática, Estatística e Ciência da Computação
Universidade Estadual de Campinas
Sistemas Não Lineares da Física e da Engenharia
Daniel Norberto Kozakevich1
Julho 1995
Dissertação submetida ao Departamento de Matemática Aplicada Universidade Estadual de Campinas, como requisito parcial para a obtenção do título de Doutor em Matemática Aplicada
© Daniel Norberto Kozakevich, 1995. Todos os direitos reservados.
Dr. José Mario Martínez, DMA-IMECC-UNICAMP (Orientador)
Dr. Clóvis R. Maliska, FEM-UFSC
Dr. José A. Cuminato, DM, USP-S.Carlos
Dr. Murilo fT Thomé, DM, USP-S. Carlos
.Mario C. Zambaldi, DM-CFM-UFSC
1° Suplente: Márcia A. Gomes-Ruggiero, DMA-IMECC-UNICAMP
2D Suplente: Vera L. Rocha Lopes, DMA-IMECC-UNICAMP
3o Suplente: José V. Zago, DMA-IMECC-UNICAMP
4° Suplente: Alvaro De Pierro, DMA-IMECC-UNICAMP
Prefácio
Esta tese contém contribuições teóricas e práticas no campo da resolução de sistemas algébricos não lineares de grande porte. Esse tipo de sistemas aparece com muita frequência em aplicações de engenharia e física, portanto, é nesse tipo de problemas que nos concentramos.
Nosso aporte comprende quatro áreas:
•	A comparação controlada, do ponto de vista computacional, dos métodos de Newton, Newton modificado, Broyden e Column-Updating, com e sem estratégias de globalização, em um conjunto de problemas originados na discretização de equações diferenciais parciais. Procuramos aqui identificar situações problemáticas e fornecer um panorama claro sobre o que é de se esperar de algoritmos mais ou menos clássicos para resolver problemas com variados graus de dificuldade.
•	A análise e resolução exaustiva do “problema da cavidade", para altos números de Reynolds, descartando as estratégias de globalização por otimização (de pobre desempenho neste caso) e reivindicando táticas homotopicas muito simples. O desempenho de alguns métodos quase-Newton, neste caso, é muito bom.
•	A introdução de um método novo do tipo Newton-inexato. com uma variação que permite uma resolução eficiente de problemas de autovalores não lineares. Esses problemas são, por direito próprio, sistemas não lineares mas, ao mesmo tempo, refletem com bastante fidelidade o grau de dificuldade que pode ser encontrada em outros sistemas dependentes de um parâmetro.
•	A resolução de um problema de evolução (petróleo) onde em cada nível temporal deve ser resolvido um sistema não linear. Neste caso, métodos quase-Newton com Jacobiano inicial escolhido como fatoraçao incompleta provaram ser notavelmente eficientes.
Agradecimentos
Eu gostaria de agradecer:
Ao meu Orientador pela paciência e motivação infindáveis.
Aos Professores do Grupo de Otimização pelo espírito de solidariedade e a boa disposição de construir.
A Sandra e Mário pelo convívio e inestimável colaboração na realização deste trabalho.
Aos Colegas do Depto. de Matemática, CFM-UFSC pela postura de investir e pela confiança depositada.
Aos Colegas da Pós-Graduação, Professores e Funcionários do IMECC pelo excelente ambiente de trabalho criado.
As autoridades do IMECC-UNICAMP pelo suporte oferecido.
A FAPESP, CAPES e CNPq pelo apoio financiero.
A Gaby, Ale e Conce pela compreensão e por compartilharem as dificuldades e alegrias passadas.
... e a todos os que acham ter-me ajudado, sinceramente.
Dedico este trabalho à minha família.
Conteúdo
Prefácio	v
Agradecimentos	vi
1	Introdução	1
1.1	Algoritmos para a Resolução de	Sistemas	Não Lineares..................... 1
1.1.1	0 Método de Newton................................................ 2
1.1.2	Métodos Quase-Newton.............................................. 3
1.2	Métodos Newton Inexatos.................................................. 7
1.3	Estratégias de Globalização............................................. 10
1.3.1	Globalização por Otimização...................................... 10
1.3.2	Globalização por Homotopias...................................... 12
Bibliografia	14
2	Métodos tipo Newton para problemas	com valor	de	contorno	19
2.1	Introdução.............................................................. 19
2.2	Globalização por “backtracking”......................................... 21
2.3	Descrição dos problemas................................................. 21
2.4	Aproximação Numérica..................................................   23
2.5	Experiências numéricas.................................................. 23
2.6	Conclusões e trabalhos futuros.......................................... 26
Bibliografia	29
3	Métodos tipo Newton globalizados para a equação biharmonica não linear 31
3.1	Introdução.............................................................. 31
3.2	Formulação Função-Corrente	Vorticidade.................................. 33
3.3	O Problema da Cavidade.................................................. 35
3.4	Aproximação Numérica..................................................   35
3.5	Procedimento de Resolução	........................................ 38
3.6	Análise dos Resultados Numéricos........................................ 39
3.6.1	Métodos Newton e Quase-Newton.................................... 41
Bibliografia	50
4	Determinação de Pontos Singulares com Métodos Newton-In exatos	52
4.1	Introdução................................................................ 52
4.2	Algoritmos globalmente convergentes....................................... 54
4.3	Implementação............................................................. 56
4.3.1	A determinação de pontos singulares................................ 57
4.4	Descrição dos Problemas e Resultados Numéricos............................ 59
4.4.1	Problema 1	-	Estrutura de barras.................................. 59
4.4.2	Problema 2	-	A função de Freudenstein-Roth........................ 60
4.4.3	Problema 3-0 problema de estabilidade em aeronavegaçao............. 61
4.4.4	Problema 4	-	O circuito gatilho................................... 62
4.4.5	Problema 5	-	Um problema de reação química........................ 63
4.4.6	Problema 6	-	A Equação “H” de Chandrasekhar....................... 64
4.4.7	Problema 7	-	Um problema de valor de contorno..................... 65
4.5	Análise dos resultados e conclusões....................................... 67
Bibliografia	68
5	Métodos Quase-Newton e Newton Inexato para fluxos em meios porosos 70
5.1	Introdução................................................................ 70
5.2	Descrição do Problema .................................................... 71
5.2.1	Caracterização do Problema......................................... 78
5.3	Descrição dos métodos..................................................... 78
5.3.1	Newton Inexato com Precondicionadores de Fatorações Incompletas ...	79
5.3.2	Atualizações Secantes em Fatorações Incompletas.................... 79
5.4	Resultados numéricos...................................................... 82
5.4.1	Newton Inexatos Precondicionados................................... 83
5.4.2	Quase-Newton com Jacobianos de	Fatorações Incompletas.............. 83
5.5	Conclusões e Trabalhos Futuros............................................ 87
Bibliografia	90
A Comentários Finais
92
Lista de Tabelas
2.1	Equação de Poisson Não Linear.......................................... 25
2.2	Equação de Bratu....................................................... 26
2.3	Equação de Convecção-Difussao.......................................... 27
3.1	Métodos Newton	e	Quase-Newton, AJ?e = 250 ............................ 42
3.2	Métodos Newton	e	Quase-Newton, A7?e = 500 ............................ 43
3.3	Métodos Newton	e	Quase-Newton com e sem opções de recomeços........... 44
3.4	Método de Newton	Inexato, A2?e = 50................................... 45
4.1	Problema	1 ............................................................ 60
4.2	Problema	2 ............................................................ 61
4.3	Problema	3 ............................................................ 62
4.4	Problema	4 ............................................................ 63
4.5	Problema	5 ............................................................ 64
4.6	Problema	6 ............................................................ 65
4.7	Problema	7 ............................................................ 66
5.1	Newton Inexato com Fatoração Incompleta , Malha: M = 50................ 83
5.2	Quase-Newton	com Fatoração Incompleta, Malha:	M =■ 30................. 84
5.3	Quase-Newton	com Fatoração Incompleta, Malha:	M = 40.................. 85
5.4	Quase-Newton	com Fatoração Incompleta, Malha:	M = 50.................. 85
5.5	ICOL com Fatoração Incompleta , Nível: 1 = 3........................... 86
Lista de Figuras
3.1	Vórtices da Cavidade............................................... 36
3.2	Molécula de 13 pontos para o operador biharmonico discretizado..... 38
3.3	Estrutura da matriz jacobiana ..................................... 40
3.4	Vórtices	para Reynolds= 0........................................   48
3.5	Vórtices	para Reynolds= 1000 ...................................... 48
3.6	Vórtices	para Reynolds^ 5000 ...................................... 49
3.7	Vórtices	para Reynolds = 11000 .................................... 49
4.1	Ponto de retorno................................................... 53
Capítulo 1
Introdução
Neste trabalho analisaremos o desempenho de um conjunto de algoritmos para resolver sistemas não lineares originados em problemas reais. Selecionamos para isso, diversos problemas da Física e da Engenharia e vários algoritmos cujas implementações computacionais se encontram em diferentes estágios de experimentação.
Descreveremos a seguir, em forma sintética, alguns dos métodos para a resolução de sistemas não lineares de equações, que serão usados nos capítulos posteriores.
1.1	Algoritmos para a Resolução de Sistemas Não Li-
neares
Dada F : FF —&gt; í?n, F = (fi,..., /n)r, desejamos achar a solução de
F(,)=0.	(1.1)
Suporemos que F está bem definida e tem derivadas parciais contínuas em um conjunto aberto de FF; denotamos com a matriz das derivadas parciais de F (matriz Jacobiana). Assim
' /{(*) ■		■ ■		■gw ■■	
				.few ■	■
particular de com a finalidade de melhorar as características computacionais do algoritmo usado para resolver (1.1).
Os métodos ordinarios para resolver sistemas não lineares são locais. Um método local é uni procedimento iterativo que converge, se a aproximação inicial está suficientemente perto da solução. Uma caracterização qualitativa do algoritmo é dada pela taxa de convergência que indica a velocidade de aproximação assintótica à solução. Na maioria dos casos o domínio de convergência destes métodos é grande, e por este motivo são assiduamente usados. Porém, quando a aproximação inicial não for suficientemente boa, os métodos locais devem ser modificados para incorporar propriedades de convergência global.
D i sernos que um método para resolver (1.1) é globalmente convergente se, ao menos, um ponto limite da sequência gerada pelo método é a solução ou, no mínimo, um ponto estacionário onde, V||E'(j:)||2 = 0. A maioria das vezes todos os pontos limites sao soluções ou pontos estacionários e frequentemente a sequência converge completamente à solução. Em geral, os métodos globais são modificações de métodos locais que tentam preservar as propriedades de convergência do método local original.
1.1.1	O Método de Newton
O Método de Newton é costumeiramente usado para resolver (1-1). Dada uma estimativa da solução como ponto inicial x°, o método considera a cada iteração a aproximação
F(x) &amp;amp; Lk(x) = F(xk) + J(xk)(x - xk)	(1.2)
e calcula como a solução do sistema linear Lk(x) = 0. Assim, uma iteração do método de Newton pode ser descrita por
J(xk)sk = -F(xk),	(1.3)
xk+1 =xk + sk.	(1.4)
A cada iteração de Newton devemos avaliar o Jacobiano J(xfc) e resolver o sistema linear (1.3). Usando técnicas de diferenciação automática (ver Rali [62] e [63], Griewank [26], etc) é possível calcular F(x) e J(x) de uma forma confiável e com baixo custo computacional.
Se n não for excessivamente grande consegue-se resolver (1.3) usando a fatoração LU com pivotamento parcial ou com a fatoração QR (ver Golub and Van Loan [22]). O custo destes métodos é da ordem de n3 operações em artitmética de ponto flutuante. Vários algoritmos para fatorações esparsas estão compilados em Duff. Erisman and Reid [16].
Gomes-Ruggiero, Martínez e Moretti [2õ] descreveram uma primeira versão do pacote computacional Rouxinol onde estão implementados diversos algoritmos para resolver sistemas não lineares esparsos. Os sistemas lineares são resolvidos com a metodologia de George e Ng [21].
O sistema (1.1) tem uma única solução se e somente se J(xk) é não singular. Um Jacobíano quase singular ou um sistema linear mal condicionado usualmente causam grandes incrementos logo, a grandeza de ||sfc|j deve ser controlada. 0 tamanho do passo é comumente normalizado com
?^min{l,
onde A é um parâmetro dado pelo usuário.
O principal resultado relativo à convergência ao método de Newton está dado no seguinte teorema
Teorema 1 Suponhamos que F ; Í1 C lRn —* FE; íí um conjunto aberto e conexo; F € C1(íl), F^x”) — 0,	não singular, e que existam L,p&gt; 0 tal que para todo x £ Í1
||J(^) -	&amp;lt;£||a; - sT-	(1.5)
Então existe e &gt; 0 tal que se |ja:0 — .t*|] &amp;lt;s, a sequência {;U’} gerada por (1.3)-(1.4) está bem definida e converge a x*, e satisfaz
||.rfc+1-ír’||&amp;lt;c||®fe-r|Sp+1.	(1.6)
(Prova; Ver Ortega e Rheinboldt [61], Dennis e Schnabel [13], etc.).	□
A consecução da convergência quadrática (p = 1) dependerá da satisfação da condição de Holder (1.5), sem a qual, pode ser provada apenas convergência superlinear para
1.1.2	Métodos Quase-Newton
Denominamos Métodos Quase-Newton a aqueles que resolvem (1.1) com uma fórmula do tipo
=	__ BijlF(xk).	(1.7)
Os métodos Quase-Newton caracterizam-se por evitar o cálculo das derivadas e a necessidade de resolver integralmente os sistemas lineares a cada iteração. Em consequência, o custo de cada iteração diminui sendo que há uma leve perda das propriedades de convergência em relação ao método de Newton.
Uma modificação destes métodos é realizada introduzindo recomeços. Isto significa que Bk = J(xk) se k é um múltiplo de um inteiro m ou se não há um decréscimo suficiente de |[2r,(a;fe)||; Bk é obtida a partir de Bk_i nos outros casos.
0 Método de Newton Estacionário é o mais simples dos métodos Quase-Newton, onde Bk = L(z°) para todo k € dN. Neste método as derivadas são avaliadas no ponto inicial sendo necessária somente uma fatoração LU de J(x°). Há uma paulatina piora nos métodos Newton estacionários, já que, exceto quando k = 0 (mod m), Bk não incorpora informação de xk e F(xk). Logo, a semelhança do modelo Lk(x) = F(xk) + Bk(x ~ xk) com F(x) pode diminuir com k. Observamos que por (1-7), nos métodos Quase-Newton, se define como a solução de Lk(x) = 0, que existe e é unica se Bk é não singular. Uma maneira de incorporar informação vinda de F sobre o modelo linear consiste em impor condições interpolatórias.
Lk+i(xk) = F(xk),	(1.8)
W*í+1) = r(ii+1).	(1.9)
Definindo	
yk = F(xk+r) - F(xk)	(1.10)
e subtraindo (1.8) de (1.9) obtemos a Equação Secante	
= p.	(1.11)
Recíprocamente, se Bk+i satisfaz (1.11), Lt+i interpola F em xk e a?44, Secantes à familia dos métodos baseados em (1.7) e (1.11).	. Designamos Métodos
Se n &gt; 2, existem infinitas possibilidades para escolher Bk+i de modo a satisfazer (1.11). Esta versatilidade permite através de uma escolha apropriada, garantir estabilidade numérica. 0 Método de Broyden “bom” (Primeiro Método de Broyden, [4] e o Método de Atualização da Coluna (COLUM) (Martínez [42]) se aproveitam desta possibilidade. Em ambos métodos	
n	o , (yk - Bfc+1 -Bk+	^Tsk	(1.12)
onde	
	(1.13)
para o método de Broyden, e	
zk =	(1.14)
¡(^*1 = liólos	(1.15)
para COLUM onde {e1,... ,en} é a base canónica FU.	
Aplicando a fórmula de Sherman-Morrison a (1.12) (Golub and Van	Loan [22]) obtemos
n-r	. ü*+l -	+	(z^Tp-^yk	*k ■	(1.16)
Observamos que
onde uk = (sk — Bkíyk')/(zk)TBjfiyk, e assim
Bp = (I + ut-'(i‘-1)T)...(/ +.uV)TW,	(1-18)
para k = 1,2,3 ... Se n for grande a fórmula (1.18) é utilizada.
0 Método de Broyden é um caso particular da família dos Métodos de Atualização Secante com Variação Mínima (Dennis e Schnabel [12],[13], Dennis e Walker [14], Martinez [48], [50]), que indue vários algoritmos que são úteis para problemas com estrutura particular (ver Hart e Soul [32], Kelley e Sachs [35]), para problemas separáveis com métodos Quase-Newton Particionados (Griewank e Toint [27], [28], [29], [30], Toint [66]), métodos com Atualização Direta na Fatorização (Dennis and Marwil [10], Johnson e Austria [34], Chadee [6], Martinez [47]), algoritmos do tipo BFGS e DFP para minimizaçao irrestrita (ver Dennis e Schnabel [13]), etc.
Os principais resultados sobre a convergência dos algoritmos Quase-Newton são enunciados a seguir:
Assumimos que como no Teorema 1, F : íl C FF —&gt; Í1 é aberto e convexo, F G C1(Q), F(x*) = 0, J(xx)é não-singular e que a condição de Holder é satisfeita.
Teorema 2 Dado r G (0.1), existem s,8 &gt; 0 tal que se ||a:0 — j?*|| &amp;lt;£ e — J(^*)|| &amp;lt;8 para todo k Ç. JN então a sequência gerada por (1.7) está bem definida, converge a xx, e satisfaz
|[;rfc+1 — nr“|| &amp;lt;r|[a;fc — 2’“||	(1-19)
para todo k € JV.
(Prova: ver por exemplo, Dennis e Walker [14].)	□.
Usando o teorema anterior podemos provar que o Método de Newton Estacionário com recomeços tem convergência local, com taxa linear.
A ferramenta fundamental para provar convergência superlinear para os métodos Quasi-Newton é o teorema seguinte, devido a Dennis e Moré.
Teorema 3 Assumamos que gerada por (1.7) está bem definida e converge parax*. Então as duas seguintes propriedades são equivalentes
(Prova: ver Dennis e Moré [11].)
□
A equação (1.20) é chamada a condição de Dennis-Moré. Usando (1.20), podemos provar que o Método de Newton Estacionário com recomeços periódicos (para o qual limfc Bk = J(,r’’)) tem convergência superlinear. A condição de Dennis-Moré está relacionada com a Equação Secante e permite obter o seguinte resultado (Broyden, Dennis e Moré [5]).
Lema 1 Se a sequência gerada por um Método Secante converge a x* e além disso,
lim	= 0.
(1.22)
então a convergência é superlinear.
□
O Teorema 3 não garante a convergência local de todos os Método Secantes. Em verdade, a hipótese deste teorema requer que todas as Bk devam pertencer a uma vizinhança de J(x”) de radio 6. Entanto devemos observar que, mesmo se a primeira Bq pertence a esta vizinhança existiria a possibilidade de que |[i4 — J(s*)|| &gt; |¡B0 — J(t“)[[, destruindo a convergência. Afortunadamente, para os métodos LCSU (incluindo o método de Broyden) é possível provar que existe V &gt; 0 tal que ||Bfc — J(^")|| &amp;lt;6 para todo k 6 W, se |[Bo — J( :r“)]| &amp;lt;6'.
Teorema 4 Existem &gt; 0 tal que, se [|z° —rr*|| &amp;lt;£ e ]|Bo —&amp;lt;7(nr*)|| &amp;lt;S, a sequência gerada pelo método de Broyden está bem definida, converge para x* e satisfaz (1.21)
(Prova: Ver Broyden, Dennis Moré [5]. Uma extensão para outros métodos LCSU é mostrada em Martínez [48], [50].	□
O método COLUM não pertence à família dos métodos LCSU, logo a convergência local superlinear não pode ser provada usando as técnicas baseadas em Propriedades de Deterioração Limitada. Para COLUM conseguimos esse resultado mediante o seguinte teorema
Teorema 5 Suponhamos que a sequência {a^} seja gerada pelo método COLUM, exceto quando k = Q (modm), Bk ~ J(xk). Então, existe £ &gt; 0 tal que, se ]|a;0—x*|| &amp;lt;e, a sequência converge superlinearmente a x*.
(Prova: ver Martínez [42]).	□
Um resultado similar pode ser obtido para o Método de Atualização de uma Coluna da matriz Inversa (ICOLUM), ver Martínez e Zambaldi [56].
Teorema 6 Suponhamos que n = 2. Seja r e (0,1). Então existem £,S &gt; 0 tal que, se&amp;lt;c e ||£f0-J(O|[ &amp;lt;8, a sequência {xfe} gerada por COLUM está bem definida, converge para x*, e satisfaz (1.21).
(Prova.: ver Martínez [52]).
□
Teorema 7 Suponhamos que a sequência gerada por COLUM esteja bem definida, convirja para t* e satisfaça (1.21). Então
lim
k—HXl
]]zí:+2n — a;*[|
= 0
e
lim |[orfc -	= 0.
k—KXi
(1.23)
(1.24)
(Prova: ver Martínez [52]). A propriedade (1.24) determina uma convergência R-superlinear. □
1.2	Métodos Newton Inexatos
Quando o método de Newton é aplicável à resolução de (1.1), é recoméndavel o uso de algoritmos mais eficientes como CUM ou Broyden com recomeços de Newton. No pacote Rouxinol foi incorporado um procedimento automático, no qual uma iteração de Newton é realizada somente quando há expectativas de que sua eficiência melhore a correspondente da Quase-Newton que vem sendo efetuada.
O uso de uma fatoração esparsa LU para resolver (1.3), pode ser altamente inadequada no caso da matriz Jacobiana ter uma estrutura desfavorável. Um excessivo enchimento durante o processo de fatoração impossibilita o uso de tais técnicas, devido a uma grande demanda de memória computacional e um tempo exagerado de computação a cada iteração. Uma alternativa plausível é a introdução de "Jacobianos Falsos”. Esta estratégia consiste, no recomeço de uma iteração Quase-Newton. em substituir Bk — J(%k) por B^ = J(xk), onde J(xk) é um ’’Jacobiano simplificado” de tal forma que a fatoração LU possa ser desenvolvida. Infelizmente, pode acontecer que |[J(a:fc) — &gt;1(2*) || seja tão grande que o método Quase-Newton perca as propriedades de convergência local.
Em tais circunstâncias o uso de um método Newton-Inexato é altamente recomendável. A inconveniência de se usar um método direto (LU) leva a resolver (1.3) com um Método Iterativo Linear. Usual mente, os métodos iterativos lineares preferidos são aqueles definidos sobre espaços de Krylov (Ver Golub e Van Loan [22], Hestenes e Stiefel [33], Saad e Schultz [64], etc.). Essencialmente, a memória exigida é aproximadamente da mesma ordem que para armazenar o sistema inicial.
Quando resolvemos (1.3) usando um método iterativo linear precisamos providenciar um critério de parada para decidir quando terminar o processo de cálculo (correspondente ao laço interno). Um critério que parece razoável (baseado no valor do resíduo do laço externo) é
+ F(?)||	(1.25)
onde 3^ G (0,1). A condição 9% &amp;lt;1 é necessária para que eventualmente, um incremento sk = 0 possa ser aceito como solução aproximada de (1-3). Por outro lado se 6k k 0, o número de iterações necessárias pelo método iterativo linear para satisfazer (1.25) poderia ser muito grande. Um valor usualmente adotado é Ôk ~ 0-1.
Dembo, Eisenstat e Steihaug [9], introduziram um algoritmo impondo o critério (1.25) e provaram as principais propriedades de convergência local.
Teorema 8 Suponhamos que F(x*) — 0, J(x*) não singular e contínuo em x*, e &amp;amp;k &amp;lt;0max &amp;lt;9 &amp;lt;1. Então existe e &gt; 0 tal que, se ||r° — r*|| &amp;lt;e, a sequência {a;*} obtida satisfazendo (1,25) com ik-j-i = %k + Sfc converge a x* e satisfaz
para todo k &gt; 0, onde ]|i/|| = || J(x*)y ||. Se	= 0 a convergência é superlinear.
( Prova: Ver Dembo, Eisenstat e Steihaug [9])	□
Os métodos definidos sobre espaços de Krylov são costumeiramente implementados usando um precondicionador. (Ver Axelsson [3]). Basicamente, um precondicionador para o sistema linear Az = b é uma matriz H tal que a resolução do sistema HAz = Hb demande menor esforço que o sistema original. Aplicado sobre (1.3) resulta
(1.26)
onde fíf1 (ou no mínimo o produto HfM) seja fácil de calcular sendo Hk J(xk).
Diversos precondicionadores para problemas específicos podem ser encontrados em Spedi-cato [65], em sua grande maioria baseados sobre Fatorizações Incompletas. Uma característica comum aos diferentes esquemas de precondicionamento aplicados ao sistema Az — b, é que a primeira iteração do método iterativo linear é z1 ~ XH~ lò, onde H é o precondicionador. Assim, para (1-3), o primeiro incremento deveria ser da forma — AHF1JF(xfe). Este valor para será aceito se satisfizer (1.25). Entretanto, já que (1.3) não é um sistema linear isolado seria criterioso usar a informação decorrente em iterações futuras. Com efeito, J(xk) ~ principalmente quando k —&gt; oo. Este fato, motiva o uso de Hk, F(xk), F(xk+1), xk+1, xk para construir o precondicionador Hk+i de tal modo que satisfaça a Condição Secante. Assim, é razoável introduzir um algoritmo baseado em (1.25) onde a sequência de precondicionadores Hk = Bk são escolhidos de modo a satisfazer (1.11) para todo k £ IN.
Existem infinitas possibilidades para a escolha B^+i satisfazendo (1.11). Nazareth e Nocedal [59] e Nash [60] sugeriram o uso da fórmula clássica BFGS para precondicionar (1.3) quando se trata de problemas de minimízaçao.
Uma outra opção é definir
Bfc+i = Ck+i + A'+i	(1.27)
onde C\.+1 é um precondicionador clássico e Dk é escolhida de modo a satisfazer (1-11).
Martínez [51] mostrou que o uso de uma fórmula precondicionadora secante possibilita obter resultados de convergência mais fortes que as enunciadas no Teorema 8. Isto é, a obtenção de convergência superlinear sem a imposição 9^ —+ 0. Um Método Newton Inexato Precondicio-nado foi introduzido por Martínez [51] com convergência superlinear sem impor uma precisão tendendo a infinito na solução de (1.3).
Algoritmo 1 Seja 8^ G (0,0) para todo k G JPV, 9 G (0,1) e lim^,»^ — 0. Suponhamos que x° G JFF seja uma aproximação inicial para a solução de (1.1) e que Bq G J??nxn seja um precondicionador inicial não singular. Dado xk G í?n e Bk não singular, os passos para obter xk+1,Bk+i são os seguintes:
Passo 1		
Calcular	4	(1-28)
Passo 2 Se	iij(x‘)4+F(xl)n&amp;lt;	(1-29)
definir	? - V s - SQ.	(1.30)
Senão, obter um incremento sk tal que satisfaça (1.25) usando um método iterativo.
• Passo 3
Fazer xk+l — xk + sk.	9
O teorema seguinte estabelece os principais resultados relacionados ao algoritmo anterior.
Teorema 9 Suponhamos que F ; Q C lRn —»■ -í?n, U um conjunto aberto e convexo; F G C'1(Q), J{x') não singular, F(x“) = 0, e que (1.0) seja satisfeita para algum L &gt; Q,p &gt;
1.	Suponhamos que	e [[jEÇ1]] estejam limitadas e que a condição de Dennis-Moré seja
satisteita. Então existe c &gt; 0 tal que, se -^*11 9 = a sequência {rrfc} gerada pelo Algoritmo f.ê converge superlinearmente a x*. Além disso existe kQ 6 W tal que sk = Sq para todo k &gt; k0.
(Prova: Ver Martínez [51]).
□
O teorema anterior estabelece que se o precondicionador usado satisfizer a condição de Dennis-Moré. a convergência superlinear é obtida sem limA„TO^ = 0. Em verdade, a primeira
Recentemente, Abaffy [1] considerou a possibilidade de usar algoritmos iterativos, ponderando as variações das componentes, sem a necessidade de avaliar o resíduo integralmente e introduzindo um novo critério de parada.
1.3	Estratégias de Globalização
Os métodos locais caracterizam-se por apresentar altas taxas de convergência quando o ponto inicial está suficientemente próximo da solução. Entretanto, podem divergir se esta condição não for satisfeita ou se o sistema nao linear apresentar fortes não linearidades. Com a finalidade de eliminar ou reduzir esta possibilidade, os algoritmos baseados em métodos locais são usualmente modificados incorporando propriedades de convergência global.
1.3.1	Globalização por Otimização
Uma forma de implementar esta estratégia consiste em transformar (1.1) em um problema de Otimização, através de uma função de mérito como = Í||F(r)||2t uma vez que qualquer solução de (1.1) será um mínimo da função f. A opção de usar um método que minimize f para resolver (1.1), em geral, pode não ser satisfatória. Os métodos locais convergem rapidamente para a solução, sendo que a sequência gerada , não é necessariamente monótona. Nestes casos, o método local puro será mais eficiente que a minimização de f. Por outro lado, os métodos de minimização convergem a mínimos locais (não globais) de f, enquanto que o método local converge para a solução de (1.1)- Diferentes soluções tem sido propostas para este problema. ( Ver Gripo, Lampariello e Lucidi [31] ). Descreveremos a estratégia que combina algoritmos locais e métodos de minimização que foi implementada no pacote computacional Rouxinol. Chamamos de iteração ordinária a cada iteração realizada pelo método local e iteração especial a correspondente do algoritmo de minimização de f. Definimos, para todo ¿ E IV,
ak = Argmin {/(rr°),...,/(z*1)}.	(1.31)
As iterações ordinárias e especiais são combinadas mediante uma estratégia tolerante.
Algoritmo 2 Inicializar: k +— 0, FLAG «— 1.
Seja q&gt; Q um inteiro, 7 6 (0,1).
• Passo 1
Se FLAG = 1, obter zk+1 por meio de uma iteração ordinária.
Senão xk+1 será obtido usando uma iteração especial.
• Passo 2
Se
Tomar FLAG 1, k&amp;lt;— k + 1. Voltar ao Passo 1.
Senão, redefinir
xk+i ak+i'
FLAG -l,k&amp;lt;- k + 1.
Voltar ao Passo 1.
O
Se a condição (1.32) for satisfeita um número infinito de vezes, então existirá um sub sequência tal que lim¿„oo||E(2:¿)|| = 0. Se a sequência for limitada será possível achar uma solução de (1.1) que satisfaça uma precisão predeterminada. Contrariamente, se (1.32) não for satisfeita para todo k &gt; Áq, então todas as iterações que começam em ¿o, serão especiais e a convergência da sequência será controlada pelas propriedades de convergência do algoritmo de minimização.
A princípio, qualquer algoritmo de minimização descrito na literatura pode ser usado para definir uma iteração especial.^ Dennis and Schnabel [13], Fletcher [IS], etc.). Em Rouxinol, visando a resolução de problemas de grande porte, foram implementadas estratégias baseadas em Regiões de Confiança combinadas com critérios tipo Newton Inexatos (Friedlander, Gomes-Ruggiero, Martínez and Santos [20]). Esta estratégia está descrita pelo seguinte algoritmo:
Algoritmo 3 Suponhamos que &gt; 0,o G (0,1) sejam dadas independentemente da iteração k. Define-se tM1) = ]|F(xk) + J(xk)(x - zfe)||2 , A &gt; Amin.
• Passo 1
Calcular um minimizador aproximado x de	dentro da caixa ]|.t --	&amp;lt;A tal que
xq é a projeção de xk — 2J{xkjTF(xl:)/Mk na caixa e Mk 2|| J(a’b)||i|| J(^t)||oo.
• Passo 2 Se
||E(J)II2 &amp;lt;||F(xk)¡I2 + a(0(rt) - ^(x))	(1-33)
definir xk+1 — x.
Senão
Escolher Anovo € [0.1||x — x*||, 0.9A). Substituir A by Anwo.
Voltar ao Passo 1.
Minimizar	1
'	s.t. |M1&lt;A J	(L34)
que consiste em minimizar uma quadrática em uma caixa n-dimensional.
Para estes problemas, há uma preferencia em usar algoritmos que combinam métodos em Subespaços de Krylov com estratégias de Gradientes Projetados. Em Rouxinol, a solução aproximada de (1.34) está definida por	e além disso a norma do gradiente
projetado de Vfet^) é menor que 0.1|| J(s:fc):rF(ícfc)||. Também é selecionada Am¡n = 0.001 x (valor típico de ||;r||), como valor inicial de A = Ao = ||z°||, Anovo — O.õjjir — .r*j|, outra escolha é A = 4 x A. As propriedades de convergência do Algoritmo 2 estão dadas em [20]. Cada ponto limite x* da seqüência {rr¿} gerada por este algoritmo satisfaz J(x*)TF(z*) = 0. Logo, z* será a solução de (El) se J(x*) for não singular. Infelizmente, se J(z*) for singular, existirá a possibilidade F(x*)	0. Justamente este é o caso onde qualquer algoritmo de minimização
baseado na globalização de (1.1) esbarrará.
Uma característica interessante das iterações especiais baseadas em. regiões de confiança consiste na facilidade de se adaptar naturalmente a problemas com restrições para resolver (1.1). Métodos desenvolvidos recentemente com uma abordagem Newton Inexato podem ser encontrados en [8] e [17],
1.3.2	Globalização por Homotopias
Uma técnica alternativa para incluir propriedades de globalização, quando não é possível fornecer uma boa aproximação inicial para resolver (1.1) está baseada em métodos homotópicos.
Podemos definir uma homotopia associada para este problema através de uma função H(z,t) : lRn x í? —&gt; í? tal que
^,1) = #U°,0) =	0. J
Se H satisfaz (1.35) é de esperar-se que
r = {(z,t) e K1 x IR | H(x, i) - 0,0 &amp;lt;t &amp;lt;1}
seja uma curva que conecta a aproximação inicial :r° com uma solução z*. As técnicas ho-motópicas consistem em traçar T desde í = 0 a t = 1 de maneira confiável e eficiente. A fixação dos extremos é arbitrária. Propostas precursoras para construir homotopias são encontradas em [36] e [8].
O traçado da curva constitui em alguns problemas um objetivo em si mesmo. O caso onde interessa apenas a solução de íf(;r, 1) — 0 conduz a uma situação especial, com consequências
(1.35)
(1.36)
práticas. Com efeito, a tentativa de abandonar o traçado da curva, quando t está próximo de 1 e passar para um método local, sem cuidar excessivamente das soluções intermediariass, resultará em tornar o processo de resolver 1) = 0 mais eficaz.	.
Alguns resultados clássicos da Geometria Diferencial garantem que o traçado da curva, começando em x° conduz à solução de (1.35) (Milnor [58], Ortega e Rheinboldt [61], Chow, Mallet-Paret e Yorke [7], Watson [11] e [12], etc.).
Homotopias naturais aparecem com frequência; esta designação origina-se pelo fato que o parâmetro t passa a representar um valor característico do próprio problema. Em outras ocasiões, é necessário introduzir homotopias artificiais, aplicáveis em princípio a qualquer problema da forma (1.35). A homotopia de Redução do Resíduo está definida como
= E(z) + (t - l)F(x°).
A homotopia “regularizante”, implementada no pacote computacional HOMPACK (Watson, Billups e Morgan [70]) está definida como
H(x,t)=iF(x} + (l-t'j(x~xa).
Em geral, a construção da curva demanda o uso de um método numérico. Após escolher 77, o procedimento para o traçado da curva se inicia com a parametrização de T . Freqüentemente o próprio parâmetro t pode ser usado. Quando para um determinado t0 temos que H^x,ta) é singular, x não pode ser explicitado em função t em uma vizinhança de t0, o que obriga a decrescer t, com o objeto de progredir em T. Por isso, usualmente o traçado de T é feito usando o comprimento de arco s como parâmetro. Neste caso o procedimento usualmente recomendado para traçar T é do tipo Preditor-Corretor.
Independentemente da escolha da homotopia, do parâmetro e da técnica para o traçado da curva, cada ponto solução de (1.35) será obtido aplicando um método local ao sistema não linear i) = 0, constituindo-se na fase corretora, com aproximação inicial fornecida pela etapa preditora. Se neste sistema consideramos t também como uma variável, teremos rt equações com n + 1 incógnitas. Algoritmos especiais locais para sistemas não lineares subdeterminados foram desenvolvidos por Walker e Watson [67], Martínez [49], etc. Uma interessante discussão sobre métodos homotópicos encontra-se em [19],
Bibliografía
[1]	Abaffy, J. [1992]: Superlinear convergence theorems for Newton-type methods for nonlinear systems of equations, JOTA , 73, pp. 269 - 277.
[2]	Abaffy, J.; Galantai, A. ; Spedicato, E. [1987]: The local convergence of ABS method for nonlinear algebraic system, Numerische Mathematik 51, pp. 429 - 439.
[3]	Axelsson, 0., Kaporin, I. E. [1993]: On computer implementation of Inexact-NewtonConjugate Gradient-type algorithms. Preprint.
[4]	Broyden, C.G. [1965]: A class of methods for solving nonlinear simultaneous equations, Mathematics of Computation 19, pp. 577-593.
[5]	Broyden, C.G.; Dennis Jr., J.E.; Moré, J.J. [1973]; On the local and superlinear convergence of quasi-Newton methods, Journal of the Institute of Mathematics and its Applications 12, pp. 223-245.
[6]	Chadee, F.F. [1985]: Sparse quasi-Newton methods and the continuation problem, T.R. S.O.L. 85-8, Department of Operations Research, Stanford University.
[7]	Chow, S.N.; Mallet-Paret, J.; Yorke, J.A. [1978]: Finding zeros of maps; Homotopy methods that are constructive with probability one, Mathematics of Computation 32, pp. 887-899.
[8]	Davidenko, D.F. [1953]: On the approximate solution of nonlinear equations, Ckrain. Mat. Z. 5, pp. 196 -206.
[9]	Dembo, R.S.; Eisenstat, S.C.; Steihaug, T. [1982]: Inexact Newton methods, SIAM Journal on Numerical Analysis 19, pp. 400-408.
[10]	Dennis Jr.. J.E.; Marwil, E.S. [1982]: Direct secant updates of matrix factorizations, Mathematics of Computation 38, pp. 459-476.
[11]	Dennis Jr., J.E.; Moré, J.J. [1974]: A characterization of superlinear convergence and its application to quasi - Newton methods, Mathematics of Computation 28, pp. 549 -560.
[12]	Dennis Jr.,J.E.; Schnabel,R.B. [1979]: Least change secant updates for quasi-Newton methods, SIAM Review 21, pp. 443-459.
[13]	Dennis Jr.,J.E.; Schnabel,HB. [1983]:Numerical Methods for Unconstrained Optimization and Nonlinear Equations, Prentice-Hall, Englewood Cliffs.
[14]	Dennis Jr., J.E. ; Walker, H.F. [1981]: Convergence theorems for least-change secant update methods, SIAM Journal on Numerical Analysis 18, pp. 949-987.
[15]	Deuflhard, P. [1991]: Global inexact Newton methods for very large scale nonlinear problems Impact of Computing in Science and Engineering 3, pp. 366-393.
[16]	Duff, I.S.; Erisman, A.M.; Reid, J.K. [1989]-.Direct Methods for Sparse Matrices, Oxford Scientific Publications.
[17]	Eisenstat, S.C.; Walker, H.F. [1993]: Globally convergent inexact Newton methods, to appear in SIAM Journal on Optimization.
[18]	Fletcher, R. [1987]: Practical Methods of Optimization (2nd edition), John Wiley and Sons, New York.
[19]	Forster, W. [1993]: Homotopy methods, to appear in Handbook of Global Optimization, Kluwer.
[20]	Friedlander, A.; Gomes-Ruggiero, M.A.: Kozakevich, D. N.; Martinez, J.M.; Santos, S.A. [1993]: A globally convergent method for solving nonlinear systems using a trust - region strategy, Technical Report, Department of Applied Mathematics, University of Campinas.
[21]	George, A.; Ng, E. [1987]: Symbolic factorization for sparse Gaussian elimination with partial pivoting, SIAM Journal on Scientific and Statistical Computing 8, pp. 877-898.
[22]	Golub, G.H.; Van Loan, Ch.F. [1989]: Matrix Computations, The Johns Hopkins University Press, Baltimore and London.
[23]	Gomes-Ruggiero [1990]: Algoritmos para a resolução de Sistemas Não Lineares., Tese de Doutorado FEC - UNICAMP.
[24]	Gomes-Ruggiero, M.A.; Martinez, J.M. [1992]: The Column-Updating Method for solving nonlinear equations in Hilbert space, Mathematical Modelling and Numerical Analysis 26, pp 309-330.
[25]	Gomes-Ruggiero, M.A.; Martinez, J.M.; Moretti, A.C. [1992]: Comparing algorithms for solving sparse nonlinear systems of equations, SIAM Journal on Scientific and Statistical Computing 13, pp. 459 - 483.
[26]	Griewank, A. [1992]: Achieving Logarithmic Growth of Temporal and Spacial Complexity in Reverse Automatic Differentiation, Optimization Methods and Software 1, pp. 35 - 54.
[27]	Griewank, A.; Toint, Ph.L. [1982a]; On the unconstrained optimization of partially separable functions, in Nonlinear Optimization 1981, edited by M.J.D. Powell, Academic
. Press, New York.
[28]	Griewank, A.; Toint, Ph.L. [1982b]: Partitioned variable metric for large structured optimization problems, Numerische Mathematik 39, pp. 119 - 137.
[29]	Griewank, A.; Toint, Ph.L. [1982c]: Local convergence analysis for partitioned quasiNewton updates, Numerische Mathematik 39, pp. 429-448.
[30]	Griewank, A.; Toint, Ph.L. [1984]: Numerical experiments with partially separable optimization problems, in Numerical Analysis Proceedings Dundee 1983, edited by D.F. Griffiths, Lecture Notes in Mathematics vol. 1066, Springer - Verlag, Berlin, pp. 203-220.
[31]	Grippo, L.; Lampariello, F.; Lu ci di, S. [1986]: A nonmonotone line search technique for Newton’s method, SIAM Journal on Numerical Analysis 23, pp. 707 - 716.
[-32] Hart, W.E.; Soul, S.O.W. [1973]: Quasi-Newton methods for discretized nonlinear boundary value problems, J. Inst. Math. Applies. 11, pp. 351 - 359.
[33]	Hestenes, M.R.; Stiefel, E. [1952]: Methods of conjugate gradients for solving linear systems, Journal of Research of the National Bureau of Standards B49, pp. 409 - 436.
[34]	Johnson, G.W.; Austria, N.H. [1983]: A quasi-Newton method employing direct secant updates of matrix factorizations, SIAM Journal on Numerical Analysis 20, pp. 315-325.
[35]	Kelley, C.T.; Sachs, E.W. [1987]: A quasi-Newton method for elliptic boundary value problems, SIAM Journal on Numerical Analysis 24, pp. 516 - 531.
[36]	Lahaye, E. [1934]: Une methode de resolution d’une categorie d’equations transcendantes, Comptes Rendus Acad. Sci. Paris 198, pp. 1840-1842.
[37]	Martinez, J.M. [1979a]: Three new algorithms based on the sequential secant method, BIT 19, pp. 236-243.
[38]	Martinez, J.M. [1979b]: On the order of convergence of Broyden - Gay - Schnabel’s method, Commentationes Mathematicae Universitatis Carolinae 19, pp. 107-118.
[39]	Martinez, J.M. [1979c]: Generalization of the methods of Brent and Brown for solving nonlinear simultaneous equations, SIAM Journal on Numerical Analysis 16, pp. 434 - 448.
[40]	Martinez, J.M. [1980]: Solving nonlinear simultaneous equations with a generalization of Brent’s method, BIT 20, pp. 501 - 510.
[41]	Martinez, J.M. [1983]: A quasi-Newton method with a new updating for the LDU factorization of the approximate Jacobian, Matemdtica Aplicada e ComputacionaT2, pp. 131-142.
[42]	Martinez, J.M. [1984]: A quasi-Newton method with modification of one column per iteration, Computing 33, pp. 353-362.
[43]	Martinez, J.M. [1986a]: The method of Successive Orthogonal Projections for solving nonlinear simultaneous equations, Calcolo 23, pp. 93 - 105.
[44]	Martinez, J.M. [1986b]: Solving systems of nonlinear simultaneous equations by means of an accelerated Successive Orthogonal Projections Method, Computational and Applied. Mathematics 165, pp. 169 - 179.
[45]	Martinez, J.M. [1986c]: Solution of nonlinear systems of equations by an optimal projection method, Computing 37, pp. 59 - 70.
[46]	Martinez, J.M. [1987]: Quasi-Newton Methods with Factorization Scaling for Solving Sparse Nonlinear Systems of Equations, Computing 38, pp. 133-141.
[47]	Martinez, J.M. [1990a]: A family of quasi-Newton methods for nonlinear equations with direct secant updates of matrix factorizations, SIAM Journal on Numerical Analysis 27, pp. 1034-1049.
[48]	Martinez, J.M. [1990b]: Local convergence theory of inexact Newton methods based on structured least change updates, Mathematics of Computation 55, pp. 143-168.
[49]	Martinez, J.M. [1991]: Quasi-Newton Methods for Solving Underdetermined Nonlinear Simultaneous Equations, Journal of Computational and Applied Mathematics 34, pp. 171190.
[50]	Martinez, J.M. [1992a]: On the relation between two local convergence theories of least change secant update methods, Mathematics of Computation 59, pp. 457-481.
[51]	Martinez, -J.M. [1992b]: A Theory of Secant Preconditioners, to appear in Mathematics of Computation.
[52]	Martinez, J.M. [1992c]: On the Convergence of the Column-Updating Methods, Technical Report, Department of Applied Mathematics, University of Campinas.
[53]	Martinez, J.M. [1992d]: Fixed-Point Quasi-Newton Methods, SIAM Journal on Numerical Analysis 29, pp. 1413-1434.
[54]	Martinez, J.M. [1992e]: SOR - Secant Methods, to appear in SIAM Journal on Numerical Analysis.
[55]	Martinez, J.M. [1993]: Algorithms for Solving Nonlinear System of Equations
[56]	Martinez, J.M.; Zambaldi, M.C. [1992]: An inverse Column-Up dating Method for solving Large-Scale Nonlinear Systems of Equations, to appear in Optimization Methods and Software.
[57]	Matthies, H.; Strang, G. [1979]: The solution of nonlinear finite element equations, International Journal of Numerical Methods in Engineering 14, pp. 1613 - 1626.
[58]	Milnor, J.W. [1969]: Topology from the differential viewpoint, The University Press of Virginia, Charlottesville, Virginia.
[59]	Nazareth, L.; Nocedal, J. [1978]: A study of conjugate gradient methods, Report SOL 78-29, Department of Operations Research, Stanford University.
[60]	Nash, S.G. [1985]: Preconditioning of Truncated Newton methods, SIAM Journal on Scientific and Statistical Computing 6, pp, 599 -616.
[61]	Ortega, J.M.; Rheinboldt, W.G. [1970]:hferain&gt;e Solution of Nonlinear Equations in Several Variables, Academic Press, NY.
[62]	Rail, L.B. [1984]: Differentiation in PASCAL - SC: Type Gradient, ACM Transactions on Mathematical Software 10, pp. 161-184.
[63]	Rail, L.B. [1987]: Optimal Implementation of Differentiation Arithmetic, in Computer Arithmetic, Scientific Computation and Programming Languages, U. Kulisch (ed.), Teubner, Stuttgart.
[64]	Saad, Y.; Schultz, M.H. [1986]: GMRES: A generalized minimal residual algorithm for solving nonsymmetric linear systems, SIAM Journal on Numerical Analysis 7, pp. 856869.
[65]	Spedicato, E. [1991] (editor): Computer Algorithms for Solving Linear Algebraic Equations. The State of Art, NATO ASI Series, Series F: Computer and Systems Sciences, Vol. 77, Springer Ver lag, Berlin.
[66]	Toint, Ph.L. [1986]: Numerical solution of large sets of algebraic nonlinear equations, Mathematics of Computation 16, pp. 175 - 189.
[67]	Walker, H.F.; Watson, L.T. [1989]: Least - Change Update Methods for underdetermined systems, Research Report, Department of Mathematics, Utah State University.
[68]	Watson, L.T. [1979]: An algorithm that is globally convergent with probability one for a class of nonlinear two-point boundary value problems, SIAM Journal on Numerical Analysis 16, pp. 394-401.
[69]	Watson, L.T. [1980]: Solving finite difference approximations to nonlinear two-point boundary value problems by a homotopy method,SIAM .Journal on Scientific and Statistical Computing 1, pp. 467-480.
[70]	Watson, L.T.; Billups, S.C.; Morgan, A.P. [1987]: Algorithm 652: HOMPACK: A suite of codes for globally convergent homotopy algorithms, ACM Trans. Math. Software 13, pp. 281-310.
Capítulo 2
Métodos tipo Newton para problemas com valor de contorno
2.1	Introdução
Os sistemas originados pela discretização de problemas de contorno podem ser considerados como uma das aplicações mais importantes dos métodos para resolver sistemas nao lineares esparsos e de grande porte.
As modelagens de diversos problemas da mecânica de fluidos, transferência de calor e massa, etc., daô origem a problemas deste tipo que podem ser representados por operadores da forma
G(u) - V2u + u, ux,	uw) - f(x, y). (z, y) e Í2,
(2.1) U = ¿(x, y), (z, y) 6 dft
sendo C R2, À G IR e H uma função não linear.
Selecionamos para este trabalho as equações de Poisson Não-Linear [10], o Problema de Bratu Modificado [3] e o Problema de Convecção-Difusão Não-Linear [7] que serão aproximadas usando o método das diferenças finitas. Embora a equação de Poisson tenha sido criada artificialmente , podemos considerar esta coleção de equações não lineares como protótipos de problemas reais.
O principal esforço neste trabalho estará concentrado em resolver cada um dos problemas em uma forma padrão identificando valores de À para os quais o problema apresente características especiais.
Para isto, selecionamos vários algoritmos baseados nas idéias quase-Newton, que foram implementados incorporando-lhes uma estratégia de globalização, com o intuito de estabelecer um marco de referência para a resolução de um conjunto de problemas definidos como em (2.1).
A introdução dos termos originados pela discretização de H produzem uma deterioração das
propriedades do sistema gerado pela discretização do Laplaciano, piorando o condicionamento e nos dois últimos casos causando a perda da simetria. Em geral o parâmetro A, que pondera os termos não lineares acentua estas características. Valores de A para os quais o Jacobiano é singular sao denominados autovalores do sistema não linear (2.1).
O conjunto dos sistemas algébricos não lineares originados pela discretização das correspondentes equações , constitue uma coleção de problemas teste para a validação dos Métodos Especializados na Resolução de Sistemas Não-Lineares Esparsos e de Grande Porte (Ortega e Rheinblodt [9], Schwandt [10], Watson [11], [12], [13], Wat son e Scott [14] , Watson e Wang [15], etc. ).
Começaremos inicialmente descrevendo a estratégia de globalização implementada: logo a seguir os problemas que foram objeto de estudo e suas respectivas discretízaçÕes, salientando as características numéricas que consideramos mais relevantes; na Seção 5 apresentaremos os testes numéricos e análise dos resultados e finalmente na última Seção, conclusões e futuros trabalhos.
O conjunto de métodos e algoritmos básicos de resolução que serão utilizados neste trabalho estão descritos no Capítulo 1.
2.2	Globalização por “backtracking”
Como mencionamos na Introdução, os métodos quase-Newton não possuem a propriedade de decrescimento monótono
il^U-+i)|| &amp;lt;||F(^)||	(2.2)
e são localmente convergentes, o que significa que conseguem achar a solução do sistema no caso em que a aproximação inicial seja muito boa. Esta última afirmação, na maioria das vezes pode ser considerada pessimista. Ocorre que devido a boas propriedades da matriz Ja-cobiana., consegue-se convergência em um número finito de iterações e o método passa a exibir propriedades de convergência global.
Habitualmente incorporam-se modificações sobre as iterações locais para satisfazer (2.2) de tal modo que essa imposição aumente a possibilidade de obter convergência global.
Uma das formas de satisfazer (2.2) consiste em introduzir um procedimento denominado estratégia de retrocesso (“backtracking"). Neste caso a iteração básica se transforma em
= st - afcBfclF(xfe),	(2.3)
onde Ofc é obtido da sequência {2_ 1, i = 0,1,...}. A existência de a* satisfazendo (2.2) está garantida se d^ = —B^F^Xk) for uma direção de descida, isto é
[J(.rt)4]W¿)&amp;lt;0.	(2.4)
Esta condição é obviamente satisfeita pela iteração de Newton. Nos métodos quase-Newton a condição (2.4) deve ser previamente conferida antes de efetuar o processo de retrocesso. Um procedimento alternativo que evita a necessidade de calcular o Jacobiano consiste em definir uma outra sequência para at, como {(-1),+12“*, i = 0,1,...} de tal modo a satisfazer (2.2). Esta estratégia, que poderia ser denominada como retrocesso bidirecionado, será usada nas experiências numéricas. O processo descrito é costumeiramente incorporado aos algoritmos definidos pelos métodos básicos por razões de ordem prática. Analisaremos o desempenho dos métodos quase-Newton com e sem a estratégia de globalização para resolver os sistemas mencionados acima. Não pretendemos mostrar qual é o melhor dos métodos para resolver um determinado problema mas sim, detectar situações onde alguns deles apresentam alguma deficiência ou um comportamento particular.
2.3	Descrição dos problemas
Nesta Secção descreveremos os problemas em que o Laplaciano é combinado com outros termos não lineares. Em todos os casos acharemos as soluções aproximadas das equações discretizadas no quadrado unitário íí : {[0,1] x [0,1]. Resulta relativamente fácil encontrar uma solução exata que satisfaça as condições de fronteira, ajustando o termo independente y(.T,y). Para todos os casos escolhemos
ií*(;c,y) =	— i)(l — y)expx4’5
(ver [7]); em consequência ^x^y) = Q. f é avaliada em cada nó da malha de tal forma que a discretização de u*, é uma solução exata das equações discretizadas.
0 fato de ter definido a priori a solução exata, nos permite definir o seguinte critério de
assim o processo iterativo será interrompido na k—ésima iteração, quando o erro relativo em cada componente da solução Uh for menor que 10-4 .
sistemas, estes problemas sao usados extensamente como problemas teste padrões; tanto para mostrar a eficácia dos algoritmos para a resolução dos sistemas lineares subjacentes, como para a construção de precondicionadores, etc. A nossa abordagem visa mostrar o desempenho de um determinado processo para melhorar a convergência de um método ao resolver o sistema não linear.
Os problemas testes são listados a seguir juntamente com suas respectivas aproximações.
PI - Problema de Poisson Não Linear
cuja discretização pode ser escrita como
4 UfJ (ll,'—i;j tq-i-i j -j-	d-
(2.5)
Se A &gt; 0 o problema é fácil; a dificuldade cresce para valores negativos de A.
P2 - Problema de Bratu
sendo discretizado como
4 uí,j — (uí-ij +	+ u»j-i + Ufj+i)
P3 - Problema de Convecção-Difusão
sendo discretizado como
4 ui,j ~	+ ^í+l.j + ui,j-l + “tj+l)
d" ^/2 A Ujj (Ut'+ij U;_i ,■ -|-	ttij-i) h /¿(t;,?/;) — 0
(2.7)
1&amp;lt;	&amp;lt;(i- 1)
Em todos os casos se conserva o mesmo padrão de esparsídade que gera a aproximação do operador Laplaciano. Nos dois últimos problemas os sistemas são não simétricos.
2.4	Aproximação Numérica
As equações diferenciais serão aproximadas usando o método das diferenças finitas com urna discretização padrão de segunda ordem sobre uma malha uniformemente espaçada de tamanho h = onde L é o número de divisões. Denotamos o dominio discretizado por Qj, sendo Xi — ih,yj = jh as coordenadas dos nós de Da- Assim teremos (£ — l)2 nós em ílx e L nós sobre cada lado de Õílh.
Para uma função de malha qualquer u;.j definimos, em cada nó, os seguintes operadores de diferenças que serão utilizados nos diferentes problemas:
Dyitij = (ujj+i — uJ]j_i)/2ã
■^xx^t.j	~~ 2Ut\j “I*
2ufj -|-
= d*
Fixamos em todos os casos, L = 64 obtendo assim jV = 3969 incógnitas.
2.5	Experiências numéricas
Para cada problema foi criada uma sequência de experiências para diferentes valores do parâmetro A. Esta sequência foi gerada por um procedimento totalmente heurístico, procurando achar os valores de A com o intuito de criar casos com o maior grau de dificuldade possível, em
relação à sua resolução. Não levamos em consideração valores para A que tivessem significado físico, nem tivemos qualquer preocupação em obter soluções positivas.
Os métodos utilizados com e sem globalização, para a realização dos testes são: Newton, Newton Modificado, Broyden (Primeiro Método) e Atualização de Coluna (ver Gómes-Ruggiero [1990] [5]).
Os resultados das experiências são apresentados separadamente para cada problema, nas respectivas tabelas. Cada coluna corresponde a um A diferente e cada parênteses contém o número de iterações e/ou, o número de iterações e o número de avaliações de função, para as versões com e sem globalização, respectivamente.
Declaráramos divergência (div) quando o número de iterações realizado pelo método ultrapassa ItMax (número máximo de iterações permitidas) ou a norma do resíduo supera ResMax (valor do resíduo máximo permitido) sendo a experiência interrompida em ambos os casos. Em todos os testes fixamos ResMax = IO20 e usamos a mesma aproximação inicial a;0 = 0.
Devido a fato de que o custo computacional de uma iteração de Newton é, em geral, consideravelmente mais caro que uma iteração quase-Newton, sendo esta relação muito mais drástica quando comparada com a iteração de Newton Modificado, fixamos diferentes valores para ItMax para cada método em particular, com o propósito de colocá-los em uma situação mais equilibrada. A realização de algumas experiências preliminares nos permitiu padronizar uma relação que considera custos equitativos para cada método. Desta forma fixamos, para cada iteração de Newton, 15 de Broyden e Atualização de Coluna e 25 de Newton Modificado. Vale esclarecer que existem pequenas variações destes valores para os distintos problemas e obviamente entre os métodos de Broyden e Atualização de Coluna. Estas experiências também nos possibilitaram estabelecer ItMax^ewton = 10, considerando: um custo razoável em tempo real e a demanda média do número de iterações para conseguir convergência. O custo médio em tempo real de uma iteração de Newton é de aproximadamente 17 segundos.
Por outro lado, os critérios de parada para a convergência forem estabelecidos quando alguma das seguintes condições foram satisfeitas:
k -&amp;lt;| &amp;lt;ícr4,
ou
II FtF) ||„&amp;lt;IO-10.
Os casos em que as iterações foram interrompidas por causa desta última condição estão indicadas com um asterisco o que eventualmente indica que a solução obtida é outra diferente da solução exata. Nestes casos para corroborar esta hipótese, calculamos o erro entre as soluções exata e a calculadaem forma aproximada para a componente situada no meio do quadrado como
Err\ =	— .r*|.
A resposta (stop) significa a impossibilidade de obter um decréscimo no resíduo durante a busca linear; também as iterações são interrompidas.
Analisamos a seguir os resultados obtidos para cada problema.
Método	A	-200	-100	—35	-10	200	1000
Newton	Sem Global.	O 10)	(3)*	(10)#	(3)	(6)	(10)
	Globalizado	(9,14)	(3,3)*	(10,10).	(3.3)	(6,6)	(10,10)
Newton	Sem Global.	(div)	(7)*	(&gt; 250)	(7)	(&gt; 250)	(&gt; 250)
Modif.	Globalizado	(stop)	(7,7).	(&gt; 250)	(7,7)	(17,66)	(28,143)
Broyden	Sem Global.	(35)	(5)*	(15)-	(4)	(14)	(73)
	Globalizado	(stop)	(5,5)*	(15,15)*	(4,4)	(13,29)	(stop)
Atuai*	Sem Global.	(&gt; 150)	(5)*	(14)*	(4)	(23)	(&gt; 150)
Coluna	Globalizado	(stop)	(5,5).	(14,14).	(stop)	(stop)	(stop)
Tabela 2.1: Equação de Poisson Não Linear
Equação de Poisson - Na Tabela (2.1) observamos que para A = — 35 o número de iterações é notoriamente maior que para A = ±100 o que nos faz suspeitar a proximidade de um autovalor. Para À = 200, CUM (Atualização da Coluna) perde a convergência quando é rodado com globalização; o mesmo acontece com Broyden para A = —200 e A = 1000.
Para A = —100 e A = —35 obtivemos convergência com a norma do resíduo; para o primeiro caso constatamos a convergência para uma outra solução; temos Err„wo — 0.71762801070788. Para o outro valor de A obtivemos Err„35 = 6.9234404057972D — 03 muito próximo de 10-4. Para A — —1000 não se obteve convergência em nenhum caso.
Para A = 200 o método de Broyden globalizado mostrou uma pequena margem de vantagem, com um tempo de execução total de 26.38 segundos contra 26.60 segundos sem “backtrackingT
O único método favorecido com a globalização foi Newton Modificado para A = 200 e A = 1000.
Equação de Bratu - Na Tabela (2.2) observamos que para A — —10 obtivemos o que poderia ser chamado de resultado padrão em termos do número de iterações realizadas.
Para A G [—10,1000] a maioria dos métodos teve um desempenho semelhante. Todos os testes rodaram sem fazer uso da globalização uma única vez.
Para A — —100 conseguimos convergência com Newton para uma outra solução; temos
Método	A	-100	-40	-25	-10	100	1000
Newton	Sem Global.	(8).	(5)*	(6)	(3)	(4)	(4)
	Globalizado	(8,18)*	(5t5)*	(6,6)	(3,3)	(4,4)	(4,4)
Newton	Sem Global.	(div)	(47,47).	(66)	(6)	(15)	(43)
Modif.	Globalizado	(stop)	(47,47).	(66,66)	(6,6)	(15,15)	(43)
Broyden	Sem Global.	(&gt; 151)	(9).	(10)	(4)	(6)	(7)
	Globalizado	(dlv)	(9,9)*	(10,10)	(4,4)	(6,6)	(7,7)
At nal.	Sem Global.	(&gt; 151)	(10).	(23)	P)	(7)	(7)
Coluna	Globalizado	(div)	(10,10)-	(div)	(4,4)	(7,7)	(7,7)
Tabela 2.2: Equação de Bratu
Equação de Convecção—Difusão - Na Tabela (2.3) reportamos os resultados para o Problema de Convecção-Difussão. Este se mostra um problema de difícil resolução. Curiosamente ocorre um grande número de casos onde a globalização prejudica a convergência. Para os valores de A = ±100 não conseguimos obter convergência com nenhum método. Este problema apresenta resultados “simétricos” em relação aos valores positivos e negativos de A.
2.6	Conclusões e trabalhos futuros
Neste Capítulo reunimos um conjunto de problemas não lineares origin ados das discretizações de problemas de contorno de segunda ordem. Os sistemas resultantes foram resolvidos com algoritmos baseados nas ideias dos métodos quase-Newton e implementados com globalização.
Em gerai a estratégia de globalização por “backtracking” foi acionada poucas vezes e em vários casos levou à divergência. Podemos concluir que as direções geradas por cada um dos métodos são inadequadas e não permitem obter um decréscimo do resíduo; obviamente, nesta situação, qualquer estratégia de globalização será inútil. Por outro lado, as modificações que introduzem as globalizações na sequência das soluções eventualmente podem ser mal sucedidas.
Método	A	-50	-20	-10	10	20	50
Newton	Sem Global.	(8)	(4))	(3)	(3)	(4)	(7)
	Globalizado	(&gt; io)	(4,4))	(3)	(3,3)	(4,4)	(7,13)
Newton	Sem Global.	(&gt; 250)	(&gt; 250))	(44)	(44)	(&gt; 250)	(&gt; 250)
Modif.	Globalizado	(stop)	(stop)	(44)	(44,44)	(stop)	(stop)
Broyden	Sem Global.	(&gt; 150)	(16)	(8)	(9)	(15)	(&gt; 150)
	Globalizado	(stop)	(stop)	(10.14)	(9,9)	(stop)	(stop)
Atual-	Sem Global.	(&gt; 150)	(16)	(9)	(8)	(15)	(&gt; 150)
Coluna	Globalizado	(stop)	(stop)	(8,8)	(9,9)	(18,36)	(stop)
Tabela 2.3: Equação de Convecção-D ifussào
Em geral, para uma mesma situação a versão com globalização melhorou ligeiramente o custo computacional.
Em particular, a expectativa em termos de dificuldade para resolver um determinado problema não linear como os apresentados deve ser formada em base às mudanças que produzem os termos originados pela função H, nas propriedades estruturais da matriz Jacobiana.
Problemas de difusão não-linear cuja equação arquetípica pode ser escrita como
= Ad(u) + /(«)-
têm recentemente suscitado um particular interesse. A solução está definida em um domínio espaço-temporal da forma fí x [0, T]. Esta equação modela várias situações reais como;
conhecida como “a equação em meios porosos” que por sua vez representa outros casos como: a equação de calor com m = 1, a teoria de gases ionizados a altas temperaturas com m &gt; 1, a teoria de trasferência radiante, a teoria de camada limite, etc. Por outra parte, a equação em meios porosos representa o caso mais simples de uma classe de equações da forma:
du
~ - V.[K.Vd(u)] + V.[v0(u)J + ¿(u) = 0
Aqui, o termo de difusão A^ é acrescido com termos não-lineares convectivos e tipo fonte/sumidouro õ. Equações deste tipo são obtidas pelas modelagens de problemas como: escoamento de águas superficiais, dinâmica populacional, reservatórios de petróleo, etc. 0 problema matemático correspondente consiste em deteminar de que forma a estrutura, do operador influirá no comportamento da solução (ver Peleter e Serrin [8]).
Para a nossa abordagem atual, a seleção apropriada de alguns destes problemas conduziria a definir um outro conjunto de problemas padrão que iriam complementar os escolhidos neste trabalho.
Bibliografia
[1]	Deuflhard, P. [1995]: Newton techniques for highly nonlinear problems. Theory and algorithms, in preparation.
[2]	Deuflhard, P.; Freund, R. and Walter, A. [1990]: Fast secant methods for the iterative solution of large nonsymmetric linear systems, Impact of Computing in Science and Engineering 2, pp. 244-276.
[3]	Brown, P. N., Saad Y.,[1990] Hibrid Krylov Methods for Nonlinear Systems of Equations, SIAM Journal on Scientific and Statistical Computing 11, pp. 450 - 481.
[4]	Golub, G.H.; Van Loan, Ch.F. [1989]: Matrix Computations, The Johns Hopkins University Press, Baltimore and London, ork.
[5]	Gomes-Ruggiero M. A.,[1990]: Métodos Quase-Newton para Sistemas Não Lineares Tese de Doutourado, FEE, UNICAMP.
[6]	Johnson, G.W.; Austria, N.H. [1983]: A quasi-Newton method employing direct secant updates of matrix factorizations, SIAM Journal on Numerical Analysis 20, pp. 315-325.
[7]	Kelley, C.T. [1995]: Iterative methods for linear and nonlinear equations, SIAM Publications, to appear.
[8]	Peleter, L. A., Serrín, J. [1993]: Nonlinear Difussion Equations and Their Equilibrium States, Peleter &amp;amp; Seriin (Eds.)
[9]	Ortega, J.M.; Rheinboldt, W.G. [1970]:/ier&lt;Rwe Solution of Nonlinear Equations in Several Variables, Academic Press, NY.
[10]	Schwandt, H. [1984]; An interval arithmetic approach for the construction of an almost globally convergent method for the solution of the nonlinear Poisson equation on the unit square, SIAM Journal on Scientific and Statistical Computing 5, pp. 427 - 452.
[11]	Watson, L.T. [1979]: An algorithm that is globally convergent with probability one for a class of nonlinear two-point boundary value problems, SIAM Journal on Numerical Analysis 16, pp. 394-401.
bibliografia
30
[12]	Watson, L.T. [1980]: Solving finite difference approximations to nonlinear two-point boundary value problems by a homotopy method, SIAM Journal on Scientific and Statistical Computing 1, pp. 467-480.
[13]	Watson, L.T. [1983]: Engineering applications of the Chow-Yorke algorithm, in Homotopy Methods and Global Convergence (B.C. Eaves and M.J. Todd eds.), Plenum, New York.
[14]	Watson, L.T.; Scott, M.R. [1987]: Solving spline-collocation approximations to nonlinear two-point boundary value problems by a homotopy method, Applied Mathematics and Computation 24, pp, 333-357.
[15]	Watson, L.T.; Wang, C.Y. [1981]: A homotopy method applied to elastics problems, International Journal on Solid Structures 17, pp. 29-37.
Capítulo 3
Métodos tipo Newton globalizados para a equação biharmonica não linear
3.1	Introdução
Neste capítulo analisaremos o desempenho de um conjunto de métodos quase-Newton globalizados e Newton-Inexato, para resolver as equações de Navier-Stokes em uma cavidade quadrada para altos números de Reynolds. 0 fluxo é newtoniano e incompressível em regime estacionário. Formulado em termos da função-corrente define um problema de quarta ordem não linear, com valores de fronteira (Peyret e Taylor [21]).
Uma primeira dificuldade neste problema, que é frequentemente abordado com um enfoque numérico-computacional ( Walker [27], Deuflhard [8], Axelsson e Kaporin [1], etc ) aparece associada ao termo advectivo. Na medida em que o parâmetro que pondera esse termo (o número de Reynolds), é incrementado se produz correspondentemente, um aumento da não linearidade que por sua vez afeta as estruturas dos sistemas lineares subjacentes, o que se traduz em um paulatino crescimento do mau condicionamento desses sistemas e gradual dissimetria. Em nossos testes o número de Reynolds é incrementado até o aparecimento de soluções espúrias (vizinhança de um ponto limite), ( Schreiber e Keller [19]). A possibilidade de continuar construindo a curva requer o uso de técnicas de Continuação mais especializadas ( Schreiber e Keller [24], Rheinblodt [18], etc.).
As discontinuidades nas condições de fronteira requerem o uso de técnicas de discretização mais apuradas. Torna-se difícil determinar a influência destas singularidades sobre a precisão da solução. Neste sentido, tem-se realizados significativos esforços, orientados principalmente na direção de criar esquemas de discretização alternativos ( Crochet, Davies e Walters [7])
As técnicas de discretização e os métodos utilizados não são novos, tomados individualmente, porém a escolha de uma de tais técnicas que aparece como sendo simples, precisa e robusta combinada com o conjunto de algoritmos para a resolução das equações resultantes, pretende
criar um novo marco de procedimento na resolução numérica deste problema. A introdução de diversas técnicas de globalização pretende ampliar qualitativamente a definição deste marco, que será estabelecido através de um estudo comparativo dos métodos, em relação a sua capacidade e eficiência em termos de esforço computacional. Também, este problema se constitui em mais um problema teste para validar os métodos especializados na Resolução de Sistemas Não-Lineares Esparsos e de Grande Porte.
Consideramos conveniente aclarar que nosso principal objetivo consiste em analisar o desempenho de algoritmos e técnicas complementares para uma estrutura que resulta interessante ”per se” e que é originada pela modelagem de um problema real da mecânica dos fluidos, antes que resolver otimamente este problema em particular.
Este Capítulo está organizado como segue: inicialmente descreveremos o problema objeto de estudo e sua discretização, salientando suas características numéricas mais importantes do ponto de vista que nos interessa; logo a seguir são apresentados o testes numéricos, análise dos resultados e as conclusões. 0 conjunto de algoritmos de resolução utilizados são os descritos nos capítulos anteriores, sendo mencionados quando for necessário, alguns dos parâmetros mais relevantes.
v-v = o.
Quando esta condição é introduzida na equação de continuidade obtemos
dp/dt + V • Vp = 0
o que significa que a densidade p permanece constante ao longo da trajetória das partículas do fluido. Se a viscosidade p é constante, a equação de momento se reduz a
p[dV/õt + (V • V)V] + Vp - pV2V = fe	(3.1)
que é denominada a forma nao-conservativa da equações de Navier-Stokes. Neste caso (for* mulação nas variáveis primitivas) as incógnitas são o campo de velocidades V e a pressão p.
Uma outra formulação das equações de Navier-Stokes faz uso do vetor vorticidade
w = V xV
(3-2)
Pela aplicação do operador rotacional na equaçao (3.1), o termo que contém a pressão desaparece , resultando
¿&gt;w/9t + (V • V)w - (u&gt; • V)V - vV2w = 1/pV x fe	(3.3)
onde v = pjp é viscosidade cinemática. Esta equação é usualmente associada com o vetor função-corrente definido através de
V=Vx$
(3.4)
sendo assim automaticamente satisfeita a condição de íncompressibilidade. Aplicando o rotacional a (3.4) e usando (3.2) obtemos
v2tf+ w = o.
(3-5)
V = V x (k^&gt;)
sendo k é o vetor unitário normal ao plano do fluxo e t/) é uma função escalar.Neste caso, a vorticidade u&gt;= u;k e as equações (3.3) e (3.5) se transformam em equações escalares
div/di + fV -Vy - iXV = 1/pV x fe	(3.6)
V2Í + w = 0.
Como para as equações nas variáveis primitivas, a eq. (3.6) é chamada uma forma não-conservativa Como caracterísitica relevante, na formulação função corrente-vorticidade a pressão não aparece explícitamente.
Em ausência de campos externos e para o caso estacionário a eq.(3.6) se transforma em
(V ■	- VjV = 0	(3.7)
V2tf+w = 0.	(3.8)
onde v = p/p é a viscosidade cinemática.
Quando estas equações são apropriadamente adimensionalizadas, é possível substituir v pelo recíproco do número de Reynolds 2?e_1 = v{VL sendo V uma velocidade média e L um comprimento característico do modelo físico.
Eliminando w de (3.7) e (3.8) e tomando para as componentes do campo de velocidades V como (u,v) =(dV/dx, —di^/dy) obtemos uma equação apenas em termos de 0, não linear, de quarta ordem
F(V&gt;) =	+&amp;amp;[V&gt;Í(V3V)I - ^(V2^),]	(3.9)
Podemos reescrever esta ultima equação na forma
F(^) = B(^) + ReG(d’),	(3.10)
sendo Biy) o operador biharmonico linear
= ^XXXX + 2^ xvyy + ^yyyy
e
G'(V) = ^(V2^-^(VM
um termo não linear em ■
3.3	O Problema da Cavidade
Consideramos o problema de resolver o fluxo bidimensional estacionario para um fluido viscoso incompressível. O domínio onde determinaremos a solução em termos da função corrente, é definido como um quadrado de lado com seu lado superior aberto em contato com um fluido viscoso que se desloca com velocidade unitaria V. Para um fluxo totalmente desenvolvido, indicamos a existência de um vórtice principal que ocupa a região central e uma série de vórtices secundarios próximos aos vértices, girando em sentido contrario. Esta configuração é mostrada na Figura (3.1) conjuntamente com as condições de fronteira
Assim, o problema consiste em achar	£ C4 tal que
E(^) = Bfy) + ReGfy) - Oemfl,	(3.11)
onde Q = {(.r. y) : 0&lt;i&lt;l,0&lt;y&lt;l)}e que satisfaça as seguintes condições de contorno
^ = 0,	(x,y) e díl,	
&lt;M0,y) = 0,	0 &amp;lt;y &amp;lt;i,	
tMM) = o,	o &amp;lt;y &amp;lt;1,	(3.12)
	0 &amp;lt;x &amp;lt;1,	
^y(z,i) = 1,	0 &amp;lt;X &amp;lt;1.	
Esta forma de definir as condições na fronteira origina discontinuidades ñas derivadas normais nos vértices superiores no lado aberto do quadrado. Uma tentativa para suavizar essas discontinuidades é proposta em [3], mudando esta última condição para
^(x, 1) — — 16a;2(1 — re)2, 0 &amp;lt;x &amp;lt;1
Como V’y é singular nestes cantos, qualquer discretizaçao espalha esta singularidade aos nós vizinhos de tal forma que o esquema considerado deve ser modificado para levar em conta esta singularidade. Um tratamento rigoroso em tal sentido faz uso localmente de uma expressão analítica da singularidade [18]. Em [14] é apresentado um método considerando também uma forma local para a singularidade, introduzindo-a dentro do esquema global em diferenças. Outros métodos alternativos como refinamento da malha, transformação conforme, séries de potências, etc. são listados em [10] , [6],
3.4	Aproximação Numérica
Obteremos uma solução aproximada usando o método das diferenças finitas. Para isto escolhemos uma discretização padrão de segunda ordem definida sobre uma malha uniformemente
V
Figura 3.1: Vórtices da Cavidade
espaçada de tamanho h — 1/L, onde L é o número de divisões, em amba.s direções .t e y. Denotamos o domínio discretizado por sendo a;,- = ih,yj = jh as coordenadas dos nós de Q/j. Assim teremos (L — l)2 nós em Qa ei nós sobre cada lado de
Para uma função de malha qualquer ipj definimos em cada nó os seguintes operadores de
diferenças	(^ij+i ^ij-i)/2/z ~ (ui-i-ij — 2tz¿j 4* u-i—ij'i/h DyyUi.j = (^íj + l ~ ^Ui,j V Ui,j-l)/h ~ (D^j, 4“ Dyy\Uiyj ^hui3 = ((Dxxxx 4" 2DTTyy 4* ^yyyy)uij)/h4
Gh(uh) = (((£&gt;,- (D^D^u^/h4.
Quando a solução í/j) de (3.11) junto com (3.12) é aproximada nos correspondentes nós por uma função de malha ipfj satisfazendo um esquema em diferenças de acordo ao dado acima, obtemos a seguinte função de resíduo
Fh(&amp;amp;j} =
=
20^,; — SfV’í-l,; + ‘fii+l.j + V’iJ-l +
+2(^i-I,j+l +	+ 0t+lj+l)
+^i-2,i + &amp;amp;+2,j + ^ÍJ-2 + Kj + 2
(3.13) +J?e/4(v’i,j+i -0ÍJ-1)
(V’i—2,j + V’í-lJ-l + V’i-lj + l —	+ 4Vv+lj ~ ^í+lj-l — V’i+l.j+l — ^t+2,j)
-Re/i^i+u ~ V\-i,j)
(yi,j-2 + V’í-l.j-l + ^t+l,j-l —	+ ^íj+l — ^í-lj+l — ^¿+1J+1 ~ 1pij+2),
1&lt;U&amp;lt;(¿-1)
Desde que Fhfyij) — O deve ser satisfeita apenas para os nós de Uj, teremos .V = (L — l)2 equações. Porém, os valores de i£&gt;ij sobre o contorno e exteriores vizinhos à fronteira, estarão incluidos nestas equações.
Os valores de contorno são os análogos a (3.12) dlscretizados
V’ij = 0, (.r,-, y¿) € dí\,
Por outro lado, os valores de V-'íj nos nós exteriores a podem ser determinados aproximando as derivadas normais especificadas na fronteira mediante um esquema de diferenças centradas
^,-1=^,1,1&amp;lt;*&lt;(£- 1)
V’í.íL+lJ^Vi-ÍL-lh I &amp;lt;í &amp;lt;(i - 1)
1 &amp;lt;j &amp;lt;(L - 1)
&amp;lt;j &amp;lt;(£ - 1)
Usando estes valores em (3.13) para eliminar os valores externos a Qa . obtemos N equações para as N incógnitas i/’íj •
Este sistema de equações têm não linearidades quadráticas e é esparso. Cada equação contém 13 incógnitas dispostas em um arranjo molecular em forma de estrela como é mostrada
Figura 3.2: Molécula de 13 pontos para o operador biharmonico discretizado
3.5	Procedimento de Resolução
0 procedimento escolhido consiste na construção de uma “curva” Re) satisfazendo Fhfâ, Re) = 0, para uma sequência crescente de números de Reynolds : Rek+1 = Rek + A Re até a vizinhança de um ponto limite ( ’’singular point” ) com passos fixos ARe.
Desta forma, um conjunto de soluções é gerado a partir de (r/&gt;°, Re = 0) resolvendo o sistema Fh(ú, Re + AJ?e) = 0 para cada passo ARe, utilizando como aproximação inicial a solução de Fhty,Re) = 0.
Procedimentos deste tipo, no qual um parâmetro (neste caso o número de Reynolds), variando num intervalo é incrementado gradativamente e onde as soluções intermediárias são usadas como aproximações iniciais para as próximas iterações, são denominadas Técnicas de Continuação.
Com o intuito de obter melhores aproximações iniciais, uma abordagem clássica para a implementação destas técnicas modifica o procedimento descrito acima (que pode ser considerado como elementar), diferenciando em relação ao parâmetro (número de Reynolds) e originando uma equação diferencial ordinária com valor inicial
—(&amp;amp;) = GMh,Rc},
com 0ft(O) =
Neste caso torna-se necessário parametrizar a curva pelo cumprimento de arco s em lugar do Re e construir um caminho seguindo a curva. Esta abordagem requer a solução de Fh(^($),Re(s)) = 0 mais uma equação não linear para o comprimento de arco s que pode ser aproximada por
R2- !(¿&amp;lt;+ (SRe?
sendo que, para criar o problema com valor inicial, a derivação deve ser feita em relação a s, com valores iniciais definidos por ^(0) = iph e Re(ty — 0-
A linearização de Fh(i/&gt;, Re) = 0, pela aplicação do método de Newton origina uma sequência de problemas lineares,
J^Rejô1' = ~Fh(^,Re)	(3.14)
onde 6” = d,I/+1 — 0" e	é a matriz Jacobiana.
Basicamente, a diferença fundamental na capacidade dos métodos para resolver (3.13) está diretamente ligada com a forma com que resolvem os sistemas lineares (3.14) correspondentes; os quais por sua vez, dependem da estrutura e propriedades do Jacobiano
J(i/P,Re) = dFhW,Re)/d^ = Bk[$] + 7?eÔGA[^j/^.
Os coeficientes da matriz Jacobiana estão constituidos por constantes correspondentes às derivadas de Bh e de uma parte antisimétrica dGh[^]/d^, ponderada pelo número de Reynolds e que depende da ’’suavidade ” da função de malha ç-.
Na Figura (3.5) mostramos uma linha da matriz Jacobiana onde
P -
Q =	+ V’í-l.j-l + V’í-lJ+l — 4^1-1,J +	— V’i-t-lu + l ~ ^»+2j)
R ~ (V’.p+i - V’íj-i)
S — (^»,j-2 + V’Í-IJ-I +	— 4^1,j-1 +4^ij+l - &amp;amp;-1J+1 — 0Í+1J+1 — ^t',j+2)
3.6	Análise dos Resultados Numéricos
A maioria dos testes e respectivos resultados que serão apresentados foram realizados sobre uma malha uniformemente espaçada, com L = 64 divisões em ambas direções x e y, o que origina um problema com N = 3969 equações e incógnitas.
Re* P
• ••
2.- Re * (P + P)	—8-4- * (4P+ S)	2.— Re - (P - R)
• ••
1.- Pí -P	-8*4- Re * (4R - Q)	20.	—8.+ Re * (&lt;J - 4P)	1-4-

2.- Re * (P + P)	-8.- Pe * (4P + S)	2.4- Pe * (P — R)
1-+
Re* P
-
Figura 3.3: Estrutura da matriz jacobiana
Obtivemos várias sequências de soluções para Re g [0,11000], usando o procedimento descrito anteriormente, fixando distintos valores para o passos A Re. O extremo superior do intervalo foi determinado pela proximidade de um ponto limite, indicado por um súbito aumento do número de iterações do algoritmo usado, com o aparecimento de pronunciadas distorções nos gráficos das soluções.
Uma outra série de testes foi realizado com Re Ç [0,500], com diversos passos NRe utilizando as técnicas de globalização como “backtracking” (em forma análoga ao feito no Capítulo 2) e região de confiança (da forma que foi descrito no Capítulo 1).
O esquema de discretização configurado, permite trabalhar com malhas de até aproximadamente 100 x 100 divisões. Este limitante foi obtido de forma heurística, observando a evolução dos gráficos das curvas de nível das soluções e refinando a malha gradualmente.
A escolha do tamanho da malha responde principalmente à possibilidade de realizar comparações dos resultados obtidos para igual dimensão, com os apresentados por vários outros autores (Axelsson [1993] , Deuflhard [1991],Walker [1992], etc).
Por outro lado, os resultados obtidos com testes sob malhas mais refinadas praticamente não mostraram comportamento muito diferentes aos da malha selecionada.
Os algoritmos testados são os descritos na Capítulo 1, contidos nos pacotes computacionais ROUXINOL, NI-GMRES e BOX-QUACAN .
Considerando que os métodos tipo Newton Inexatos tiveram um desempenho desencoraja-dor, os testes com estes métodos tiveram que ser realizados enfraquecendo as exigências para conseguir convergência, com tempos reais de execução razoáveis. Assim, mostraremos um pequeno conjunto de resultados com NI-GMRES, com a única finalidade de mostrar o efeito que produz o uso dos distintos precondicionadores sobre os sistemas lineares.
Apresentaremos uma análise mais exaustiva sobre um conjunto de resultados obtidos com os métodos Quase-Newton implementados no pacote computacional ROUXINOL, que podem
ser considerados como muito bem sucedidos.
Para este último caso, e com o objetivo de realizar comparações entre alguns dos métodos implementados nesse pacote, geramos inicialmente uma sequência de soluções usando o método de Newton, usando um critério de parada sobre o resíduo : || F(ib,Re) ||&amp;lt;1O~10 . Posteriormente, foram gerados os gráficos respectivos, das curvas de nível das soluções, que foram padronizados como representando as “soluções verdadeiras". Alguns destes gráficos para Re = 0,1000, 5000 e 11000, são mostrados no Apêndice.
E conveniente aclarar que as curvas correspondentes a Re = 0 devem ser consideradas como uma solução assintótica sem qualquer significado físico. Numa situação real, para este valor do número de Reynolds deveriamos ter considerado simultaneamente (ar, 1) = 1, 0 &amp;lt;x &amp;lt;1 obtendo-se assim = 0.
A validade destas soluções está sustentada pela comparação, para distintos números de Reynolds, com as apresentadas por Ghia, Ghia e Shin [1982], usando uma malha de 256 x 256 e Benjamín e Denny [1973] para uma malha de 151 x 151, considerando a precisão da nossa aproximação.
Para garantir que as soluções originadas pelos métodos Quase-Newton fossem, no mínimo, “tão boas” como as obtidas com o método de Newton, foi repetido o mesmo processo descrito acima, confrontando os gráficos de cada uma das soluções que compõem a sequência.
A “não-convergência” de qualquer dos métodos foi estabelecida fixando o número máximo de iterações tipo-Newton.
3.6.1	Métodos Newton e Quase-Newton
Nas Tabelas (3.1) e (3.2) são apresentados um conjunto de resultados para Re G [0,11000], com passos A Re = 250 e A Re ~ 500 respectivamente.
Cada linha, que representa um experimento para um determinado número de Reynolds, indica os resultados para cada método através de dois ou três números (quando corresponde): iterações de Newton, iterações Quase-Newton e tempo de execução (escalado). Em tempo real, a execução para um experimento particular, por exemplo para Re — 11000 usando o método de Newton, demandou pouco mais de 10 minutos.
Para ARe = 1000 todos os métodos excederam o número máximo de iterações, e as experiências realizadas com passos menores necessitaram tempos de execução consideravelmente maiores.
Podemos observar que todos os métodos usam somente uma iteração para resolver F(ib, 0) — 0, já. que o sistema é linear.
Em todos os casos, a primeira iteração é uma iteração de Newton. Desta maneira, é forçada a realização de uma fatorização LU completa da matriz Jacobiana.
Pode ser observado a demanda de um esforço um pouco maior para atingir Re = 1500. Ultrapassado este valor, as iterações continuam com uma demanda do tempo de execução uniforme, até o fim do intervalo.
Em termos de custo computacional, todos os métodos Quase-Newton têm um custo apro-
Número de Reynolds	Newton	Newton Modificado	Broyden	CUM
0	( I , 188.60 )	(1,0, 192.61 )	( 1,0, 188.32 )	( 1,0, 189.80 )
250	( 5 , 942.56 )	( 1 , 56 , 368.38)	( 1 , 23,264.70 )	( 1 , 22 , 258.69 )
500	( 5 , 756.39 )	( 1 . 18 , 244.80 )	( 1 , 13 ,230.61 )	( 1,13,230.06 )
750	( 5 , 754.04 )	( 1,14, 232.29 )	(1,8, 214.96 )	(1,8,213.83 )
1000	( 5 , 754.02 )	(1,9, 217.14 )	( 1,6,207.83 )	(1,7, 210.76 )
1250	( 3 , 572.77 )	(1.7, 213.18 )	(1,6, 210.82 )	( 1 , 6,210.44 )
1500	( 3 , 585.68 )	(1.7, 214.27 )	(1,5, 211.31 )	(1,5, 210.68 )
1750	( 3 , 594.76 )	(1,5, 214.00)	(1,5 ,214.57 )	(1,5, 214.14 )
2000	( 3 , 598.95 )	(1,5, 215.51 ) (1.5, 216.90 )	(1,4,212.97 )	(1,4, 212.49)
2250	( 3,602.59 )		(1,5, 216.72 )	(1,5, 216.61 )
2500	( 3 , 607.52 )	(1.5, 219.08 )	(1,5,219.01 )	(1,5, 219.47 )
2750	( 3,608.14 )	(1,5, 219.10 )	(1,5, 218.28)	(1,5, 218.83 )
3000	( 3,613.12 )	(1,5, 219.66 )	(1,5 ,219.74 )	(1,5, 219.83 )
3250	( 3 , 616.41 )	( 1.5, 220.96 )	( 1,5 ,221.08)	(1,5, 221.17 )
3500	( 3 , 615.55 )	(1.4, 218.14 )	(1,4, 218.13)	(1,4, 218.35 )
3750	( 3 , 619.21 )	(1,4, 219.01 )	(1,4, 218.88 )	( 1,5, 222.19 )
4000	( 3,619.82 )	(1.4, 218.86 )	(1,4, 219.20)	(1,4, 218.74 )
4250	( 3,620.91 )	(1,4, 219.88)	(1,4 ,219.86 )	(1,4, 219.96 )
4500	( 3 , 621.30 )	(1.4, 219.64 )	(1,4,219.82 )	( 1,4, 220.03 )
4750	( 3,624.95 )	( 1.4, 220.39 )	( 1,4, 223.28 )	( 1,4, 220.47 )
5000	( 3 , 621.63 )	(1.4, 221.01 )	(1,4, 223.61 )	(1,4, 220.64 )
5250	( 3,625.65 )	( 1.4, 221.22 )	( 1,4, 221.28)	( 1,4, 220.89 )
5500	( 3,627.07 )	(1,4, 221.32 )	( 1,4, 221.57 )	(1,4, 221.15 )
5750	( 3 , 628.12 )	(1,4, 221.77 )	(1,4,222.34 )	( 1 , 4 , 221.90 )
6000	( 3,627.15 )	( 1.4, 221.28 )	( 1,4 ,221.64 )	( 1,4, 220.98 )
6250	( 3 , 628.21 )	( 1.4, 222.28)	( 1 , 4 , 222.50 )	(1,4, 221.65 )
6500	( 3,631.79 )	( 1,4, 222.58 )	( 1,4, 222.61 )	(1,4, 222.69 )
6750	( 3,631.67 )	( 1.4, 222.21 )	(1,4, 223.25 )	( 1,4, 222.57 )
7000	( 3 , 629.86 )	(1,4, 222.26 )	(1,3, 219.63 )	(1,3, 219.23 )
7250	( 3,632.56 )	( 1,4, 222.23 )	( 1 , 3,219.41 )	(1,3,219.19 )
7500	( 3 , 630.92 )	( 1,4, 223.35 )	( 1 ,3 ,220.57 )	( 1,3,220.19 )
7750	( 3,645.42 )	(1.3, 220.05 )	( 1,3,220.21 )	( 1,3, 220.86 )
8000	( 3,642.68 )	( 1.3, 220.33 )	(1,3, 219.93 )	( 1,3,220.46 )
8250	( 3,633.28 )	(1,3, 220.31 )	( 1 , 3 , 221.29 )	(1,3,220.16 ) ( 1,3.220.29)
8500	( 3,638.68 )	(1.3, 220.44 )	(1,3,220.83 )	
8750	( 3,632.14 )	( 1.3, 220.54 )	( 1 ,3,219.56 )	( 1,3, 220.55 )
9000	( 3 , 642.20 )	(I,3, 221.26 )	(1,3, 219.56 )	( 1,3, 220.92 )
9250	( 3 , 644.13 )	( 1,3, 220.89 )	( 1,3,221.24 )	( 1,3,221.05 )
9500	( 3 , 644.02 )	( 1.3, 220.90 )	(1 , 3,221.61 )	(1,3, 220.83 )
9750	( 3 , 636.24 )	( 1.3, 220.82 )	(1,3, 221.19 )	(1,3,221.18 )
10000	( 3 , 637.02 )	( 1.3, 220.87)	(1,3,220.98 )	(1,3,220.73 )
IO25O	( 3,635.66 )	( 1,4, 224.31 )	(1,3,221.59 )	( 1,3,221.42 )
10500	( 3 , 636.71 )	( 1.4, 224.21 )	( 1,4, 224.97 )	( 1 . 4,224.55 )
10750	( 3 , 636.46 )	( 1.4, 224.70 )	( 1 ,4 ,225.12 )	( 1,4,224.85 )
11000	( 3,635.67 )	( 1,4, 224.37 )	(1,4, 224.71 )	(1,4, 224.43 )
Tabela 3.1: Métodos Newton e Quase-Newton, A7?e = 250
Para AJ?e = 500 apenas os métodos de Newton e Broyden conseguem convergência. CUM demandou um pouco mais de 100 iterações para Re = 250. Nesta tabela, também são incluidos resultados com a opção de recomeços com um desempenho um pouco pior, quando comparados com os obtidos sem usar esta opção. A opção de recomeços, no método de Newton Modificado, não foi acionada uma única vez, devido a que a condição de decréscimo suficiente foi sempre satisfeita. Em todos os casos, a demanda do custo computacional foi aproximadamente de 60% que para A Ne = 250.
Número de Rejmolds	NEwton	Broyden	
		Com Recomeços	Sem Recomeços
0	( 1 , 192.89 )	( 1,0, 188.64 )	( 1,0, 188,89 )
500	( 6 , 1150.78)	( 3 , 10 , 597.90 )	( 1 , 79 , 477.47 )
1000	( 5 , 961.07 )	( 2,7,399.75 )	( 1 , 13,231,25 )
1500	( 4 , 782.63 )	(1,8, 221.82 )	( 1,8, 222.85 )
2000	( 3 , 599.87 )	(1,7,222.85 )	( 1,7, 223.33 )
2500	( 3,607.67 )	(1,7,226.00 )	( 1,7, 227.24 )
3000	( 3 , 612.56 )	(1,7,227.10 )	( 1,7, 227.90 )
3500	( 3 , 617.13)	( 1 , 6,225.96 )	( 1,6, 226.38 )
4000	( 3,619.79 )	(1,6, 226.67 )	( 1.6, 228.04 )
4500	( 3 , 623.49 )	(1,6, 227.39 )	( 1,6, 227.S2 )
5000	( 3,623.93 )	( 1,6,227.97 )	(1,6,229.29 )
5500	( 3 , 627.64 )	(1,6, 228.46)	(1,6, 228.93 )
6000	( 3 , 628.09 )	( 1,5,225.97 )	( 1,5, 226.96 )
6500	( 3,629.64 )	(1,5, 226.67 )	( 1,5, 226.55 )
7000	( 3 , 630.71 )	( 1 ,5, 225.97 )	( 1,5, 227.41 )
7500	( 3 , 632.49 )	( 1,5, 227.15 )	( 1,5, 227.94 )
8000	( 3 , 634.03 )	(1,5, 227.57 )	(1,5, 228.02 )
8500	( 3 , 633.93 )	( 1 , 4,224.19 )	( 1,4, 224.61 )
9000	( 3,636.06 )	( 1,4, 224.72 )	(1.4, 225.31 )
9500	( 3 , 635.11 )	( 1,4, 224.78 )	( 1,4, 225.14 )
10000	( 3 , 636.89 )	( 1,5, 227.78 )	( 1,5, 228.21 )
10500	( 3 , 637.49 )	(1,5, 228.83 )	(1,5, 228.62 )
11000	( 3,638.72 )	(1,6, 232.29 )	(1,6, 232.74 )
Tabela 3.2: Métodos Newton e Quase-Newton, AAe — 500
Outros métodos Quase-Newton como: Escalamento na Diagonal e Escalamento na Coluna não conseguiram convergência sequer para Re — 250.
Os métodos Quase-Newton com Jacobiano Truncado, mostraram-se muito sensíveis ã introdução de um Jacobiano inicial “falso” com resultados negativos.
Método		A Re = 250	ARe = 500
Newton		(141,0,7.881)	(73,0,4.164)
Newton Mod.		(45,260,2.797)	(Não converge )
Broyden	Com Rec. Seem Rec.	(46,192,2.795) (45,205,2.753)	(26,129,1.587) (23,204,1.511)
CUM	Com Rec. Sem Rec.	(47,185,2.835) (45,206,2.750)	(Não Converge)
Tabela 3.3: Métodos Newton e Quase-Newton com e sem opções de recomeços
3.6.2	Métodos Newton Inexatos - GMRES Precondicionados.
Os testes realizados com as diferentes opções que podem ser selecionadas usando estes métodos, foram desalentadores quando comparados com o desempenho dos métodos Quase-Newton. Nas condições exigidas para estes últimos, nao se obteve convergência em nenhum caso.
Com o objetivo de avahar a eficiência dos diferentes precondi donadores implementados, os requerimentos sobre distintos parâmetros tiveram que ser relaxados, para obter convergência. Para isso, o tamanho do passo foi reduzido para ARe = 50 e a exigência sobre a diminuição no valor do residuo foi aumentada para || Re) ||&amp;lt;10-5 . Desta forma, conseguimos obter um conjunto de resultados, que permitiu realizar uma análise mínima. A mudança no valor daquele último parâmetro, impede fazer qualquer tipo de comparação com os resultados obtidos com os métodos Quase-Newton, porque a convergência é obtida para soluções aproximadas diferentes.
Em uma das experiências rei ativamente “bem sucedidas”, obtivemos convergência até Re = 9100 usando um precondicionador baseado na Fatoraçao Incompleta, com — 0.1.
Uma tentativa para estimar qualitativamente a eficácia do precondicionador ao longo do intervalo de convergência, foi feita calculando o quociente entre os valores acumulados do número de iterações dos laços interno e externo em cada intervalo Re ~ Re + 1000. Os resultados mostram que a eficácia do precondicionador vai decaindo paulatinamente a cada intervalo. Duas causas inter-relacionadas que contribuem no mesmo sentido, podem explicar este comportamento: a perda de diagonal dominância na matriz Jacobiana e a consequente perda na qualidade do precondicionador, o qual está sendo reconstruído sobre uma matriz cada vez pior condicionada [1]. A irregularidade que se produz no intervalo [1000 — 2000] , coincide com a apontada anteriormente usando os métodos diretos.
Número de Reynolds	Sem Precondicionamento		. . 1 Precond ici onad o	
	ek = o.i	6k = 0.67	=0.1	Sk = 0.67
0	( 12 , 1114 , 1.0 )	( 22 , 1208 , 1.1 )	( 6,461 , 0.42 )	( 15 , 354,0.38 )
50	( 5 , 438 , 0.39 )	( 9,373 , 0.36 )	( 3,230 ,0.21 )	( 8 , 197,0.21 )
100	(6,544 , 0.49 )	( 11 , 594 , 0.56 )	( 3 , 234 , 0.21 )	( 8 , 182,0.20 )
150	( 7 , 648 ,0.58 )	( 12 , 567,0.54 )	( 3,239 ,0.22 )	( 8 , 231 , 0.24 )
200	( 7 , 652 ,0.59 )	( 12,677,0.63 )	(3,245 ,0.22 )	( 8,258,0.26 )
250	( 8,754 , 0.68 )	( 13,682 , 0.64 )	( 3,250,0.23 )	( 8 , 262,0.26 )
300	( 10,955 , 0.86 )	( 15,977,0.90 )	( 3,252 ,0.23 )	( 8 , 262 , 0.26 )
350	( 11 , 1053,0.94 )	( 15,977 , 0.90 J	( 3,255 , 0.23 )	( 8 , 275 ,0.28 )
400	( 12 , 1152 , 1.0 )	( 15 , 988 , 0.91 )	(3,258 , 0.23 )	( 8 , 281 , 0.28 )
450	( 13,1252 , 1.1 )	( 17, 1256 , 1.1 )	( 4,364 ,0.33 )	( 9,385,0.37 )
500	( 16 , 1151 , 1.1 )	( 19 , 1462 , 1.3 )	( 4,361 , 0.32 )	( 8 , 282,0.28 )
550	( 13 , 1250 , 1.1 )	( 22 , 1764 , 1.6 )	( 4 ,366 ,0.33 )	( 9 , 286 ,0.29 )
600	( 20,1951 , 1.7 )	( 20 , 1548 , 1.4 )	( 3,272,0.24 )	( 8 , 281 , 0.28 )
650	( 20 , 1950 , 1.7 )	( 28,2354 , 2.1 )	( 5 , 498 ,0.44 )	( 9 , 426,0.41 )
700	( 21 , 2140 , 1.9 )	( 18 , 1215 ,1.1 )	( 3 , 283 ,0.25 )	( 8,317,0.31 )
750	( 23 , 2249,2.0 )	( 36,3158 , 2.8 )	( 5 , 500,0.45 )	( 10 , 540,0.51 )
800	( 28,2749 , 2.5 )	( 23,1831 , 1.7 )	( 4 , 400,0.36 )	( 9,425,0.41 )
850	( 22 , 2148 , 1.9 )	( 49 , 4441 , 4.0 )	( 4,400,0.36 )	( 11 , 641 , 0.60 )
900	( 41 , 4048,3.6 )	( 24 , 1926 , 1.7 )	( 5 , 500,0.45 )	( 9,441 , 0.42 )
950	( 22 , 2149 , 1.9 )	( 63 , 5836,5.2 )	( 4 , 400,0.36 )	( 9,444 , 0.42 )
1000	( 68 , 6748 , 6.0 )	( 28,2317 , 2.1 )	( 4,400,0.36 )	( 14 , 949,0.87 )
Resultados				
Globais	( 3S5,37095 , 1.0 )	( 471 , 36131 , 0.99 )	( 79,7168,0.19 )	( 192,7719,0.22 )
Tabela 3.4: Método de Newton Inexato, AJ?e = 50
Com a mesma finalidade, uma outra série de testes foi realizado apenas no intervalo Re Ç [0,1000] , usando o mesmo precondidonador, com o objeto de avaliar o efeito de se mudar o parâmetro Os resultados são mostrados na Tabela (3.4). Para cada valor do número de Reynolds indicamos: número de iterações dos laços externo e interno e o tempo de execução (escalado), apenas para dois diferentes valores de 0k, que são os mais representativos sobre um conjunto bem mais numeroso de testes. Podemos apreciar uma pequena vantagem para o menor valor de Ôk. Em tempo real, a execução para percorrer completamente o intervalo, demandou mais de 4 horas.
Sem o uso de qualquer precondicionador não se obteve convergência e os outros precondici-onadores foram menos eficientes,
3.7	Conclusões e trabalhos futuros.
O estudo realizado neste Capítulo representa um esforço para definir um marco de referência na solução das equações de Navier-Stokes em termos da função-corrente, usando diversos Métodos tipo-Newton, para um problema que modela o fluxo em uma cavidade, para altos números de Reynolds.
Um conjunto numeroso de soluções discretas, em termos da função-corrente, foi obtido para números de Reynolds variando entre 0 — 11000. Este conjunto foi convalidado por comparação com as soluções obtidas por outros pesquisadores.
Uma estimativa do desempenho e eficiência destes Métodos, orientada para a avaliação do esforço computacional demandado, objeto principal deste trabalho, foi conseguida a partir da realização de inúmeras experiências, usando distintos pacotes computacionais que implementam aqueles métodos . A fixação dos parâmetros próprios de cada pacote, que eventualmente aprimoraram sua eficiência, foram determinados através de extensos e minuciosos testes; alguns dos quais foram explícitamente mostrados.
Os Métodos Quase-Ne wton se mostraram robustos e os mais eficazes. Não há significativas diferenças entre eles, entretanto exibiram um desempenho marcadamente superior ao Método de Newton.
A seleção de maiores passos, para incrementar o número de Reynolds, tem-se mostrado como a mais indicada em relação a economia do custo computacional global. O aumento do tamanho do passo está associado ao problema de melhorar a aproximação inicial, para a resolução do sistema correspondente a cada número de Reynolds. Isto sugere a introdução de Técnicas de Continuação mais apuradas, implementadas com subrutinas para a determinação automática do tamanho do passo.
Os Métodos tipo-Newton Inexatos com Precondicionamento não são competitivos; a inclusão e comentários acima dos resultados obtidos com este método pretendem apenas mostrar o desempenho de métodos iterativos na resolução de problemas com esta estrutura. Mesmo com uma redução nas exigências estabelecidas como critério para aceitação da solução, requereram, no melhor dos casos, tempos de execução práticamente inaceitáveis.
Os resultados obtidos mediante a formulação definida pela minimizaçao de f(x) —1| F(x) ||j, usando o pacote BOX-QUACAN foram definitivamente desencorajadores; não se obteve convergência sequer para Re = 0.	-
Uma tentativa para avaliar a eficácia do uso dos precondicion adores sobre os sistemas originados na linearização de F(x) = O, tampouco produziram uma melhoria significativa, porém tendo como fato relevante, a consecução de convergência. O pacote utilizado neste caso, NI-GMRES foi testado com Precondicionadores Secantes e com uma Fatoraçao LU Truncada, sendo esta última, a opção melhor sucedida. Uma modificação na configuração do esquema, de discretizaçao do termo nao linear, que atenuasse ou evitasse o paulatino crescimento do mau-condicionamento possibilitaria, em princípio, tornar o método mais competitivo.
Figura 3.4: Vórtices para Reynolds— 0
Figura 3.5: Vórtices para Reynolds= 1000
Figura 3-6: Vórtices para Reynolds— 5000
1.0E-03
-1.05-03
o.oo
2.SE-04
1.05-03
Figura 3.7: Vórtices para Reynolds — 11000
0.00
Bibliografia
[1]	Axelsson., 0., Kaporin, I. E, [1993]: On computer implementation of Inexact-NewtonConjugate Gradient-type algorithms. Preprint.
[2]	Benjamin, A. S., Denny, V. E. [1973]: On the convergence of numerical solutions for 2-D flows in a cavity at hight Re. J. Com put. Phys 12, pp, 348-358.
[3]	Bercovier, M., Pironneau, 0. [1979]: Numerical Math. 33, pp.211-224.
[4]	Brown, P. N., Saad, Y. [1990]: Hybrid Krilov Methods for Nonlinear Systems of Equations. SIAM J.Sci. Statist. Comput. 11, pp. 450-481.
[5]	Collatz, L. [1973]: Numerical Treatment of Differential Equations. Springer-Ver lag. Berlin.
[6]	Crank, J., Furzeland, R. M. [1978]: The numerical solution of elliptic and parabolic partial differential equations with boundary singularities. J. Comput. Physics 26, pp. 285-296.
[7]	Crochet, M. J., Davies, A. R., Walters,K. [1984]: Numerical simulation of non-newtonian flow. Rheology series 1. Elsevier.
[8]	Deuflhard, P. [1991]: Global Inexact Newton Methods for very large scale nonlinear problems. Impact of Comp, in Sc. and Eng. 3, pp. 366-393.
[9]	Eisenstat ,S. C., Walker, H. F. [1994]: Globally convergent inexact Newton methods. To appear in SIAM Journal on Optimization.
[10]	Fox, L., Sankar, R.[1969]: Boundary singularities in linear elliptic differential equations. J. Inst. Math. Applied 5, pp. 340-350.
[11]	Ghia, U., Ghia, K. N., Shin, C.T.[19S2]: High-Re Solutions for Incompressible Flow Using the Navier-Stokes Equations and a Multigrid Method. J. Comput. Phys.48, pp. 387-411.
[12]	Glowinski, R. [1984]: Numerical Methods for Nonlinear Variational Problems 2nd ed. Springer-Verlag. N.Y.
[13]	Greenspan, D. [1969]: Numerical solution of prototype cavity flow problems. Comput. J. 12.
BIBLIOGRAFIA
51
[14]	Holstein, H., Paddon, D.J. [1981]: A singular finite difference treatment of re-entrant corner flow. Part I.Newtonian Fluids.J.non-Newtonian Fluid Meeh. 8, pp. 81-93.
[15]	Kubicek, M., Hlavacek, V. [1975]: Solution of nonlinear boundary-value problems. IX.Chem.Eng.Sci. 30, pp. 1439-1440.
[16]	Matthies, H., Strang, G. [1979]: The solution of nonlinear finite element equations. Int. J. Num, Meth. Eng. 14, pp. 1613-1626.
[17]	Mittelmann, H. D., Roose, D. (Eds.) [1990]: Continuation Techniques and Bifurcation Problems. Int. Series of Num. Math., Vol 92.
[18]	Moffat, H. K. [1964]: Viscous and resistive eddies near a sharp corner, J. Fluid Meeh. 18, pp. 1-18.
[19]	Olson, M. D., Tuan, S. -Y. [1981]: Comput. and Fluids bf 7, pp. 123-135.
[20]	Oden, J.T. [1972]: Finite element of nonlinear continua. New York. McGraw-Hill.
[21]	Peyret, R, Taylor, T. [1985]: Computational methods for fluid flow. Springer Verlag.
[22]	Rheinboldt, W. C. [1986]: Numerical analysis of parametrized nonlinear equations. University of Arkansas Lectures notes in the mathematical sciences, 7
[23]	Richtmeyer, R. D., Morton, K. W. [1967]: Difference methods for initial value problems. Interscience. Publishers. N.Y.
[24]	Schreiber, R., Keller, H. B. [1983]: Driven cavity flows by efficient numerical techniques. J. Comput. Phys. 49, pp, 310-333.
[25]	Schreiber, R., Keller, H. B. [1983]: Spurious Solutions in Driven Cavity Calculations. J. Comput. Phys. 49, pp. 165-172.
[26]	Smith, G.D. [1987]: Numerical solutions of partial differential equations: Finite differences methods. Clarendon.
[27]	Walker, H. F. [1992] : A GMRES-backtracking Newton iterative method. Proceeding of the Copper Conference on Iterative Methods.
Capítulo 4
Determinação de Pontos Singulares com Métodos Newton-Inexatos
4.1	Introdução
Neste Capítulo, utilizaremos o método Ne wton-Inexato para a determinação de pontos singulares situados sobre uma curva homotópica (ver Cap. 1). Estes pontos estão relacionados intimamente com a estabilidade e multiplicidade das soluções.
Consideremos o seguinte problema não linear de autovalor
#(íM) = o,	(4.1)
onde H : JRm+1 -&gt; lRm. y G fflm, t G J?1.
Usualmente y = y(t) é considerada uma solução de (4.1) já que nas aplicações físicas o autovalor t representa um parâmetro de especial interesse (por exemplo a carga sobre uma estrutura, a tensão em um circuito, etc).
Se (j/o,to) é uma solução de (4.1) e a matriz Jacobiana m x m, Hll(y,t') é inversível, é possível garantir a existência de uma única curva solução (y,t) que passe por (^o.to) de tal forma a explicitar y(to) = Po-
Definimos F = {(y.t) G IR™ x lR\H(-y.i) — 0}.
Um ponto singular é um ponto de F onde Hy(y, t) é singular. Quando as linhas de H'(y, t) = são linearmente independentes, isto é, Ht(y,t) $ ’R.[Hy(y,t)] (a imagem de TFjífy,/)), o ponto singular é denominado ponto de retorno. Existe uma única curva solução que passa por esse ponto, porém a dy/dt é infinita e uma pequena variação de t produz um aumento desproporcionadamente grande em ||y[|. Uma situação típica é mostrada na Figura
4.1.
Vários métodos têm sido propostos para a determinação de pontos de retorno. A idéia básica consiste em acrescentar uma o mais equações ao sistema (4.1) tal que a solução do
Figura 4.1: Ponto de retorno
sistema aumentado
í(y,i) = 0	'
a,(y,í)v = o ■
/(»)-! = o ,
(4.2)
seja um ponto de retorno e de modo a garantir uma matriz Jacobiana não-singular para este novo sistema (ver [15], [14], [1]).
Todos estes métodos usam algum tipo de fatoração de matrizes, o que é inconveniente em problemas de grande porte.
O Método de Newton-Inexato será usado para resolver
F(x) — Q,
(4.3)
onde F : lRn —+ lRn é a função que aproxima o sistema aumentado 4.2, cuja formulação é chave do presente trabalho.
Na próxima seção introduziremos algoritmos globalmente convergentes; na Seção 3 mostraremos os novos sistemas aumentados, cujas soluções sao os pontos singulares de (4.1). Na Seção 4 apresentaremos os problemas testes conjuntamente com as experiências numéricas realizadas, utilizando um método de Newton-Inexato globalizado para resolver os sistemas mostrados na Seção 3. A maioria dos problemas foram selecionados da coleção de Melhem e Rheinboldt [14]. As conclusões serão mostradas na Seção 5.
4.2	Algoritmos globalmente convergentes
Introduzimos algoritmos globalmente convergentes para resolver (4.3) cujas direções são geradas pelo método de Newton-Inexato.
Nossa abordagem é similar à de Eisenstat e Walker [3] e de Martínez e Qi [11] porém sendo mais geral, desde que podem ser consideradas estratégias não necessariamente baseadas em buscas lineares.
Consideramos para isso a soma do quadrados de E(x) como a função de mérito
= |lRz)||2,	(4.4)
e um algoritmo que reduz monotonamente f(xk). No que se segue, ||.|| representa a norma Euclideana.
Algoritmo 4 Minimização Monótona
Suponhamos que: a G (0,1), 7 6 (0,1], 71,72 G (0,1), 71 &amp;lt;72 sejam dados independentemente de k. Xq € JRn seja uma aproximação inicial arbitrária e ap = 1.
Dado Xk G JRn, ctk G (0,1], os passos para obter Xk+i,Qk+i são:
Passo 1. Escolher	dk &amp;amp; JR,n.	(4.5)
Passo 2. Se	f(xk 4- akdk) &amp;lt;/(xfc)	(4.6)
calcular	=	xk + akdk. Se (j.6) não for satisfeita, definir .Tfc+i = Xk.	
Passo 3. Se	f(xk+i) &amp;lt;(1 -&amp;lt;nak)fM	(4.7)
definir Qk+i = 1- Senão, escolher		
	&amp;amp;k+i € [71^,72^].	(4.8)
O algoritmo acima é muito geral. Nenhuma condição é exigida sobre as direções dk e até direções nulas dk = 0 podem ser aceitas.
Impondo condições sobre as direções dk é possível provar interessantes resultados relativos à convergência, que terão implicações de ordem prática.
4.2.	Algoritmos globahnente convergentes
5-5
Teorema 10 Convergência Global
Suponhamos que {rc Ç lRn | f(x) &amp;lt;/(^o)} seja limitada. Seja	uma sequência
gerada pelo algoritmo anterior. Suponhamos que exista M &gt; 0 tal que para todo k ~ 0,1, 2,..
hll&lt;^	(4.9)
e
.	(4.10)
Então
(a) Qualquer ponto limite x„ de satisfaz F(x*) = 0.
(bj Se um ponto limite z* e uma solução isolada de (4-3) e	—» 0, então {a\.} converge a
x„
(c) Se um ponto limite x* é uma solução isolada de (4-3) e existe Â &gt; 0 tal que ||cZjt|[ &amp;lt;/3j|JF’(a,^)|| para todo k = 0,1,2,..., então {xk} converge a x*.
Prova: (Vér Kozakevich, Martínez e Santos [9])	□
Essencialmente, o teorema estabelece que se for possível calcular direções de busca dk tais que (4.9) e (4.10) sejam satisfeitas em cada iteração, então garante-se convergência global para a solução do sistema. Se J(xk) é não singular, a direção de Newton djf = —J(xQ~1F(xk) satisfaz (4.10) com 7 — 1. Em geral, se dk satisfaz
||J(x*)at + F(xt)||2 &amp;lt;i||F(x*)||2,	(4.11)
com t € [0,1) temos que
{J(xk)dk,J(xk)dk} ã-2{J(xQdk,F(xk)} &amp;lt;(t - 1)||)||2
Assim,
(•W,F(xt)) &amp;lt;í^l||F(Il)||2,
isto é, a condição (4.10) é satisfeita com 7 = 1 — t. A condição (4,11) é a “versão quadrática” do critério clássico para definir a iteração de Newton-Inexato.
Vemos, em virtude deste teorema, que quando o método de Newton (ou a sua generalização para Newton-Inexato) não converge, usando a globalização dada pelo Algoritmo 4, então a sequência de direções dk geradas é ilimitada. Neste caso, o método criará uma sequência que tende para um ponto onde o Jacobiano é singular. Este ponto não é necessariamente um minimizador local, ou ainda nem um ponto estacionário de
4.3	Implementação
Nesta seção descrevemos a implementação do Algoritmo 4. Basicamente, em cada iteração escolhemos, = akdk como sendo um minimizador aproximado de
+ ;■(&lt;
sobre uma região de confiança apropriada (ver Fletcher [4]) da forma &amp;lt;A. Se 0 não for um minimizador de isto é, J(xk}T F(xk}	0, deverá ser possível obter s*, tal que
o que implica que
(J(xk)dk,F(xk)) &amp;lt;0.
independentemente do valor de cxk &gt; 0. Após avaliarmos sk, são conferidas as desigualdades (4.9) e (4.10). Se alguma delas não for satisfeita, a execução é interrompida. Isto acontece quando o problema não tem solução. A escolha da norma [I.Hoo em lugar da Euclideana responde à necessidade de considerar possíveis limitantes para as variáveis aq.
Algoritmo 5 Minimização em regiões de confiança
Seja&amp;lt;7 e (0,1), 7 e (0,1], G (0,1),	&amp;lt;qs, M &gt; 0, tol 6 (0,1), max € IV dados
independetemente de k e seja x0 6 JRn um ponto inicial arbitrário, Ao = M e a0 = 1.
Dado xk G Ftn tal que J(xk)TF(xk) 0, Aí; &gt; 0 e ak G (0,1), os passos para obter x^, Afc-f-i e ctfc+i são os seguintes:
•	Passo 1.
Calcular sk como uma “solução aproximada” e
Minimizar ^(s) = ||| J(xk)s + 7?(^í.)||2 s.t.	&amp;lt;A*.	(4.12)
A solução aproximada de (j.lê) é obtida aplicando o método descrito em [7] parando quando
))VP^)|| &amp;lt;tol ||XM(0)l|,	(4.13)
(onde Vpúfis) é o gradiente projetado de ip na caixa ]]s||oo &amp;lt;A^) ou quando o número de iterações usado pelo algoritmo [7] ultrapassa max. (Isto garante pelo menos que +	&amp;lt;llíWIJ.
•	Passo 2.
Definir dk = sk/ak. Se (j.10) e (4.9) são satisfeitas, passar para o Passo 3. Senão, parar (o algoritmo falhou, provavelmente pela proximidade de um Jacobiano singular)
•	Passo 3.
Idem que o Passo 2 do Algoritmo 1.
•	Passo 4.
Iãem que o Passo 3 do Algoritmo 1.
•	Passo 5.
Se ctjt+i =■ 1, definir A*+i — M.
Senão, definir Ak+1 = UsfeJlco/2.
Os parâmetros usados na implementação são a ~ 10-5, 7 = 10-4, r^ =	Aí = IO10,
ío/ = max = n.
O código computacional usado para a implementação deste algoritmo é uma adaptação do algoritmo para minimização em caixas realizado por Friedlander. Martínez and Santos [6].
0 algoritmo usado para obter as soluções aproximadas de (4.13) combina iterações conjugadas e “chopped” (componentes cortadas) do gradiente, de tal forma que várias restrições ativas podem ser acrescentadas ou eliminadas em uma iteração.
4.3.1	A determinação de pontos singulares
Dado H :	&gt; Blm, fí = ff(y, i), H G C1(JRm+1), dizemos (conforme a [15]) que (y*,t_)
é um ponto singular de	= 0 se e somente se íf(y.,t*) ~ 0 e se	t.) é singular. Se
o posto de (íf'(j/.,t,)) = m dizemos que (y*,t.) é um ponto de retorno. Pontos singulares são soluções de
K(y,t)=0	'
= 0 *
(4.14)
H2 = 1
para algum v 6 IRm. O sistema (4.14) tem n = 2m + 1 equações e incógnitas.
O algoritmo usado para obter as soluções aproximadas de (4.12) combina iterações com direções conjugadas e ’’chopped” do gradiente, de tal forma que as restrições ativas podem ser acrescentadas ou eliminadas em uma iteração.
A resolução de (4.14) usando um método tipo Newton-Inexato requer o cálculo de derivadas segundas. Entretanto, observamos que
= gm
H(y + hv, t) — H(y — hv, t)
—
(4.15)
Resulta natural então, substituir (4.14) pelo sistema
(4-16)
H(y+hv,t)-H(v~hv,t)
2h
IK-i
f
para h &gt; 0. E de se esperar que as soluções de (4.16) para valores pequenos h, sejam boas aproximações das soluções de (4.14). Uma segunda alternativa consiste em considerar em lugar de (4.14), o sistema
#(y,/) = 0	1
//■j,(t/,í)w - 0	*
(4.17)
rTv = 1
onde r € IRm não está em 7£(7/j,(y, t)), o que garante a existência da solução das duas últimas equações de (4.17). Este sistema foi usado por Moore e Spence [15] e Seydel [21],
Considerando (4.17), e usando a aproximação (4.15), consideramos o sistema

HÇy+hv.t)-H{y~hv.,t} 2h
rTV = 1
(4.18)
A vantagem de (4.18) sobre (4.16) reside em que o termo não-quadrático (||f||2 — l)2 na função de mérito (4.4), for substituido por (rTv — l)2. Entretanto, se por acaso escolhemos r € ^(^(y*,/.)), onde (y„ ,A) é o ponto de retorno que estamos calculando, o sistema (4.17) não terá solução. Se o ângulo entre r e	t.)) for pequeno, o problema de achar v que
satisfaça Hy(y-¡t)v = 0 e rTv = 1 pode ser mal condicionado, conduzindo a resultados pouco confiáveis. Em nossas experiências selecionamos r = vo — (1, • - •, l)T/m2.
Observamos que as matrizes Jacobianas Ji(y,t) e J2(y,t), dos sistemas (4.16) e (4.18) são respectivamente
Ji(z) =
2h
hv,t)+fi3(y~hv,t)
2
(4.19)
0
J
e
=
0
2h
(4.20)
2
0
É conveniente frisar, que na implementação do Algoritmo 3.1 não são efetuadas fatorações de matrizes. Em verdade, apenas precisamos de subrotinas que calculem o produto e	para vetores arbitrários w. Observando (4.19) e (4.20), notamos que podemos
aproveitar a estrutura destas matrizes de forma a facilitar a multiplicação por vetores.
4.4	Descrição dos Problemas e Resultados Numéricos
Para a realização dos testes selecionamos os problemas apresentados em [14] acrescentando-se mais um outro, originado da modelagem de um problema de transferência de energia [2]. Cada problema é descrito sucintamente deixando claro o significado do ponto de retorno, e colocando em relevância alguns dos parâmetros mais importantes, em relação ao problema e ao algoritmo. Com a finalidade de reproduzir os resultados relatados, fomos forçados a introduzir algumas correções em alguns dos dados indicados na referência [14].
Em cada Tabela, apresentada conjuntamente com a descrição do problema, indicamos na primeira coluna o sistema aumentado selecionado: “A” ou 1LB” que correspondem respectivamente às formulações (4.16) e (4.18); na próxima o ponto inicial, acompanhado com um parâmetro característico (como por exemplo, o tamanho do problema). Os resultados dos testes, são mostrados a partir da terceira coluna, na qual colocamos o valor do ponto de retorno C achado em cada caso; a seguir indicamos os valores singulares mínimos e máximos de Hy obtidos na aproximação final; na quinta coluna, a soma dos quadrados de f\yx. ¿*) e finalmente, nas duas últimas colunas, o número de iterações e o número de avaliações da função realizadas pelo algoritmo.
O código computacional para cada problema, foi implementado usando FORTRAN 77, com dupla precisão. Uma adaptação do pacote computacional BOX-QUACAN [6] (para Mini-mização em Caixas com Canalizações) foi usada como subrotina para resolver o problema de minimização. Os testes correspondentes aos problemas 1-6, foram realizados em um PC486, e o 7 em uma SUN SPARC-Station 2.
4.4.1	Problema 1 - Estrutura de barras
Em [16], Oden apresenta um problema, que consiste em determinar os deslocamentos de uma estrutura formada por duas barras construídas com um material isotrópico. A aplicação do método dos elementos finitos nas equações de equilibrio origina o seguinte sistema não linear
F(y,t) = 4(y)y - tp, y e fô2, t e JR1,
(4.21)
para o vetor de deslocamento y, onde
A(y) = í ~ 3fiyi + 2/¿2	y^2~yy2
\ yii/2 - W2 yl-pyr + Z )
VyeIR2
sendo p G JR2 é um vetor de carga dado e p =2.
Os testes foram realizados modificando as relações entre o vetores de carga e o ponto de retorno informados em [14], Em lugar de (0.3,0.91) usamos (1/0.91,0.3). Também, observamos que em relação ao primeiro vetor 2 + corresponde a —e corresponde a
Vetores de Carga;
Qj = (1,0), Q2=(vO,0.3).
Pontos iniciais:
Wo) - [(3,0), -3], P2(yo,io) - [(0,0),5], P3(yo,to) - [(1,1)3], W3o) = [(3,1), -3].
Sistema	(w,io)	tt				It er.	Aval.
A	Qi.Pi	-3.079205	4.86e-06	6.66e-01	9.87e-09	9	10
B		-3.079205	1.23e~O8	6.66e-0I	4.38e-I0	8	9
A		3.079201	5.70e-07	6.66e-01	3.72e-10	8	9
B		3.079209	6.27e-05	6.66e-01	7.23e-09	10	14
A	Qi,	1.933818	3.94e-O6	0.47 e-01	1.37e-10	4	5
B		1-933S36	1.30e-07	0.47e-01	9-97e-14	5	6
A	Qi,Ft	-2-307797	3.06e-05	0.24e-01	7.94e-10	4	5
B		-2.307S31	1.04e-06	0.24e-01	3.73e-10	5	6
Tabela 4.1: Problema 1
4.4.2	Problema 2 - A função de Freudenstein-Roth
O seguinte sistema de equações, originalmente formulado em [5], é usado frequentemente como problema teste, por vários autores.
y-L - yl + 5y% - 2y2 + 34t - 47 = 0 1 yi + y2 + yl - 14^2 + lOi - 39 = 0 J
Para 0 &amp;lt;t &amp;lt;1 obtemos dois pontos singulares.
Pontos Iniciais:
Pi(jMo) = [(1,1), 1], W, ío) - [(50,10), -10]
Sistema	(yo,io)	t.				Iter.	Aval.
A	A	0.5875923	1.56e-06	1.89e+01	5.1 Se-09	14	22
B		0.5875873	5.68e-06	1.89e-J-01	2.87e-ll	20	36
A	A	-0.6863575	6.65 e- 05	7.73	8.05e-09	16	33
B		-0.6863527	3.45e-08	7.73	1.00e-14	24	53
Tabela 4.2: Problema 2
4.4.3	Problema 3-0 problema de estabilidade em aeronavegação
Uma versão simplificada das equações de equilíbrio aerodinâmico em aeronaves, que permitem prever deslocamentos bruscos em resposta a manobras realizadas, envolve cinco equações e oito variáveis ([y, u]T). Três destas, (u = [uj, u2, u3]r) que modelam o elevador, aileron e o deflector respectivamente, funcionam como variáveis de controle. Para o problema de estabilidade de aeronavegação estudado em [13], as equações adimensionalizadas tem a seguinte forma
A [y,u]r +&amp;lt;¿(y,u) = 0, V y g #?5, u&amp;lt;= IR3,
(4.23)
onde
	/ -3.933 0	0.107 -0.987	0126 0	0 -22.95	—9.99 0	0 -28.37	— 45.83 0	-7.64 \ 0
II T	0.002	0	-0.235	0	5.67	0	-0.921	0
	o	1.0	0	-1.0	0	-0.168	0	0
	\ o	0	-1.0	0	-0.196	0	-0.0071	0 /
e
	/ -0.727y2y3	+8.39y3y4	-684.4y4y5 +63.5y4y2
	0.949y4y3	+0.173yiy3
^(y,u)=	-.0.176yiy2	-1.578yly4 +U32y4y2
-J/1SZ5
\ V1V4
Para, realizar os cálculos escolhemos i = ií^, e foram fixados «+ = 7 e «3 = 0. O número de pontos de retorno varia com os valores de 7.
Neste caso foram necessárias duas correções: o elemento A31 = 0.002 na matriz A e na função&amp;lt;$&gt;, o termo ¡t/ij/n por yi«2-
Valores de 7:
7X = —0.05, 72 = —0.008, 73 = 0.00, 74 — 0.05, 75 = 0.10
Pontos iniciais:
A(yo,ío) = [(-3,l,-.l,.5,-.3),.5],
A(yMo) = [(-3,-.2,-.!, .02, .1), .2],
= [(-2-5,-8, .03,-.04), .3],
W, to) = [(-2.5,1.5, .06, -.08, .06), .7].
Sistema	y,Plvo, ío)	t.		a„(Hs)		Iter.	Aval.
A		0.5087968	1.26e-05	2.20e+02	1.56e-10	68	139
B		0.5087889	2.64e-06	2.20e+02	1,04e’09	341	56122
A	~t2íP2	0.2063399	5.17e-05	4.99e+01	9.74e-09	33	52
B		0.2065148	2.076-06	4.99e+01	5.07e-09	49	73
A		0.872326	1.09e-05	5.86e+01	1.08e-10	37	65
B		0.3887898	1.62e-03	4.71+01	8.62e-04	500	950
A	-oPs	0.2929449	4.55e-05	1.84e+02	9.12e-09	22	37
B		0.2929395	7.84e-06	1.84e+02	2.60e-10	61	77
A	75; Ps	9.2277146’02	3.46e+01	7.96e+01	1.02e-01	66	165
B		2.789284e-02	2.26e-02	1.04e+02	1.59e-01	105	214
Tabela 4.3: Problema 3
4.4.4	Problema 4 - O circuito gatilho
A operação de um circuito “gatilho” está descrito em [17]. As equações que descrevem o fluxo de corrente no circuito podem ser escritas na seguinte forma:

(yi “ V3)/10000 + (yi - y2)/39 + (yi - í)/51 = 0
(y¡ - ys)/10 + (y2 - yi)/39 + J(y2) = 0
&amp;lt;(ya - yi)/10000 + (y3 - y4)/25.5 = 0
(y4 - V3)/25.5 + V4/0.62 - í/5 + y4 = 0
(ys - ye)/13 + y5 “ 2/4 + I(ys) = 0
. (ye - y5)/13 + (ye ~ y2)/10 + (y&amp;amp; - U(y3 - yi)/0.201 = 0
Os dois diodos e o amplificador estão modelados por I(x) := 5.6 X 10“8(e25T — 1) , U(x) : = 7.65tcm“1(1962.'c), respectivamente. As quantidades [(yi,... , ys),t] representam voltagens, em particular y6, a voltagem de saída, é de interesse prático, sendo que t é a voltagem de entrada. 0 comportamento elétrico deste circuito gatilho está caracterizado por dois pontos de retorno.
De acordo com [17], fizemos duas alterações: num coeficiente de H e no valor do diodo I(x).
Pontos iniciais:	Pi(yo,to) = [(.05,.5, .05,.05, .15,-13),.5], P2(y0,io) - [(.2,.6,.2,.2,.6,9.5),.3].
	(3/0. ío)	tt	&lt;h(H9)	an(Hv)		Iter.	Aval.
A		0.6020924	1.26e-04	l.OSe.Ol	8.23e-09	98	215
							
B		0.6013642	7.28e-05	1.03e+01	9.74e-09	118	148
A		0.3326203	l.S2e-05	2.08e-f-01	7.58e-09	57	93
	Ps						
B		0.3329312	1.94e-05	2.07e-i-01	8.57e-09	27	43
Tabela 4.4: Problema 4
4.4.5	Problema 5 - Um problema de reação química
A equação integral
(4.25)
com k(s, a) — s — 1, s&gt;a,	= k(&lt;r,s) e onde
g(z) = z exp(
1 + 0(1 - z)h
foi usada por Moore e Spence [15] para testar algoritmos para calcular pontos de retorno. Esta integral representa uma reformulação do problema estudado por Kubicek em [10] que descreve a transferência de calor e massa em uma pastilha de catalizador poroso. A integral (4.25) é
y; - t/i^Wj ¿(á -	~ 1 = 0, i = 0,...,m	(4.26)
j=0
com wi = 1/2, e wj = 1 nos outros casos. Com 7 - 20, /3 — 0.4 e m = 32, são obtidos dois pontos de retorno.
Pontos iniciais:
Pi(yo,to) = [(1, ■ • ■, 1), .2], P2(jfo,i0) ~ [(.5,..., .5), .1].
Sistema	(yotío)	t*				Iter.	Aval.
	Pi	0.1375316	3.28e~D5	1.00	8.30e-09	4	5
A	?2	0.07791575	8.48e-06	1.09	9.50e-ll	6	11
	Pl	0.1375395	2.22e-06	1.00	8.39 e-11	4	5
B	P2	0.07791559	4.60e^06	1.09	5.49e-10	6	14
Tabela 4.5: Problema 5
4.4.6	Problema 6 - A Equação “H” de Chandrasekhar
Em [2], Chandrasekhar apresenta a seguinte equação integral, no contexto de problemas de transporte de energia radiante.
xm=1+&lt;J^ds	(,27)
0 problema consiste em achar r(í) € C[0,1], que satisfaça (4.27)
Aproximamos a integral usando quadratura com nós em	e pesos	resultando
assim no sistema não linear
M x ~ _
com x G Rn.
Quando aumentamos o número de pontos usados para aproximar a integral a matriz Jaco-biana perde esparsidade,
' -lx£V? , diü.
&lt;	T 2 Z_,j=l fi+¡J
L 2 2
Malha: M = 8,16,32.
Ponto inicial;
Sistema	M	t.		^n(^)		Iter.	Aval.
A	S	1.000003	3.42e-06	8.88e-01	3.67e-10	6	9
B		1.000000	1 .S0e-0S	8.88e-01	4.30e-12	7	10
A	16	1.000000	4.48e-7	9.35e-01	4.66e-ll	9	12
B		1.000004	6.43e-05	9.35e-01	3.47e-09	7	12
A	32	1.000000	1,67e-06	9.63e-01	1.29e-09	8	11
B		1.000000	9.12e-08	9.63e-01	2.2Ie-ll	8	13
Tabela 4.6: Problema 6
4.4.7	Problema 7 - Um problema de valor de contorno
Consideremos a aproximação do problema com valor de contorno não linear, ( ver Simson [22])
Au = -í g[u), V(x,y)T € íl,	(4.28)
u9íí = 0
sobre uma malha uniforme de tamanho h = l/l em Í1 = [(0,1) x (0,1)], na qual definimos a discretização de nove pontos para o operador de Laplace como
OgUíj = 6^-[4 (uíj-! + Ui-ij + Ut+i,j + uiJ+i) +
(uí-ij-i + ^í+ij-i + uí-i,j+i + Uí+ij+i) — 20u,j],
i,j = 1,...,M - 1
e para o laplacíano de g(u) uma discretização de cinco pontos
□s^fuíj) =	+í(u,■_!,;) + p(tíí+ij +£f(u;j+i) -4^(uíj)],
ij = 1,...,M - 1.
EgWíj + t[&lt;/(uij) + ^2^	= 6,
Assim obtemos
ij ~	- 1
com as respectivas condições de contorno discretizadas
uíj = 0, i = 0, i — M, 0 &amp;lt;j &amp;lt;M, 0 &amp;lt;i &amp;lt;M, j — 0, j = M
que representa uma aproximação da ordem de h4 para (4.28).
Desta forma, originamos um sistema não-linear de N — (M — l)2 equações com A” incógnitas «ij’, i, j = 1, ■ • •, (1 — 1), além do parâmetro t.
Para p(u) foram escolhidos
a)	g(u) = eu
b)	sW = 1 +
e para o cálculo dos pontos de retorno, tamanhos de malha M = 49,121,225.
Ponto inicial: P(y0, to) = [(1,..., 1), 8]
Sistema	s(u), M	i.				Iter.	Aval.
A	a,49	6.807507	8.35e-07	3.07e+01	1.93e-09	6	7
B		6.807504	9.44e-07	3.07e+01	1.44e-10	8	9
A	a, 121	6.808005	1.25e-06	3.I4e+01	3.39e-10	8	9
B		6.808005	1.44e-06	3.14e-|-01	2.85e-10	8	9
A	a, 225	6.808096	3."3244e-06	3.14e+01	1.03e-09	9	10 1
B		6.808045	1.04e-06	3.16e+01	1.68e-09	7	8
A	b,49	7.980354	5.52e-07	3.07e4-01	2.90e-l 1	15	30
B		7.980359	1.14e-04	3.07e+01	9.15e-09	13	23
A	6,121	7.981427	2.06e-05	3.14e4-01	2.76e-10	23	52
B		7.981423	1.16e-06	3.14e-f-01	1.30e-10	24	54
A	¡&gt;,225	7.981605	1.07e-04	3.16e+01	6.04e-09	44	76
B		7.981612	8.606-05	3.16e+01	5.44e-09	23	24
Tabela 4.7: Problema 7
4.5	Análise dos resultados e conclusões
Procedemos a uma análise dos resultados numéricos.	.
Para calcular os acréscimos em (4.14) e em (4.16) usamos em ambos casos, um incremento h = 10-4. Este valor pode ser convalidado a partir dos valores singulares obtido para Hy na aproximação final. Outros valores foram testados sem modificar substancialmente os resultados. Com exceção do Problema 3, o critério de convergência definido pela soma dos quadrados de f(yk) ~ fíVkAk) para a aproximação final foi fixada em ¡|f(zjb)|| &amp;lt;IO-8.
Para 7 = 0 e usando (4.18), atingiu-se o máximo número de iterações (500). A convergência para 7 = 0.1 foi conseguida, devido a que o critério ||VjP/(ar¿)|¡ &amp;lt;10-5 max{|/(xfc)|, 1}/ max{||xfc| em relação ao gradiente projetado sobre a caixa —10&amp;lt;	&amp;lt;10, i = 1,.. ., õ , — 1 &amp;lt;i &amp;lt;1 foi sa-
tisfeito.
O desempenho observado através dos experimentos, dos sistemas ampliados (4.16) e (4.18), não permite concluir sobre a superioridade de quaisquer deles. Em geral, a eficácia de ambas aproximações depende principalmente do ponto inicial escolhido e também da não linearidade do problema.
No Capítulo 3 tratamos de um problema da dinâmica dos fluidos onde o número de Reynolds aparece naturalmente como o autovalor de (4.1). Schreiber e Keller [19] relatam vários pontos de retorno para diferentes tamanhos de malha. Em nenhum caso o nosso método conseguiu convergência, usando ambas formulações e diferentes pontos iniciais. Neste sentido, outras tentativas foram realizadas para obter soluções em diferente pontos não-singulares, redefinindo a função de mérito como /(x) = ||#(y. t)[|, com resultados também mal sucedidos. O método de Newton-Inexato se mostra inadequado para resolver este problema devido probavelmente à dispersão no espectro de autovalores da matriz Jacobiana Hy(y, t).
Iniciamos este Capítulo apresentando um método tipo Newton-Inexato por Minimização para resolver sistemas não lineares de equações. O método não usa buscas lineares e está implementado usando estratégias de regiões confiança. Na formulação selecionada, o sistema resultante foi resolvido usando o algoritmo de minimização mencionado. Esta nova metodologia de resolução pode ser considerada como uma contribuição para a resolução de problemas não lineares de autovalor.
Diversos tipos de problemas reais foram usados como testes para avaliar a eficiência e precisão deste novo esquema de resolução.
Este método foi testado para calcular pontos singulares de curvas homotópicas, que são soluções de sistemas aumentados aproximados. Salientamos que o ponto chave da nossa formulação, consiste em substituir a equação que estabelece que o espaço nulo do Jacobiano tem um vetor não nulo, por uma equação de diferenças, evitando o cálculo de derivadas.
As experiências realizadas mostram que o método consegue achar as soluções em forma precisa e permitem recomendar um valor para o parâmetro de discretização. 1
Agradecimentos. À Dra. Sandra A. Santos, que acompanhou a implementação e a realização dos testes.
Bibliografia
[1]	Abbott, J. P. [1978]: An efficient algoritm for the determination of certain bifurcation points. J. of Comp, and Appl. Math.4, 19-27.
[2]	Chandrasekhar, S. [I960]: Radiative Transfer. Dover, New York.
[3]	Eisenstat, S. C. , Walker, H. F. [1994]: Globally convergent inexact Newton methods. Para aparecer em SIAM Journal on Optimization.
[4]	Fletcher, R. [1987]: Practical Methods of Optimization (2nd edition), John Wiley and Sons, Chichester, New York, Brisbane, Toronto and Singapore.
[5]	Freudestein, F., Roth, B. [1963]: Numerical solution of systems of nonlinear equations. J. ACM 10, 550-556.
[6]	Friedlander, A., Martinez, J.M., Santos, S.A.[1992]: A new trust region algorithm for bound constrained minimization. Technical Report, Departament of Applied Mathematics, University de Campinas.
[7]	A. Friedlander, J. M. Martinez [1994], On the maximization of a concave quadratic function with box constraints. To appear in SIAM Journal on Optimization,
[8]	Kelley, C. T. [1980]: Solution of the Chandrasekhar Tt- equation by Newton’s Method. Journal of Mathematical Physics 21, pp. 1625-1628.
[9]	Kozakevich, D. N., Martinez, J.M., Santos, S. A. [1994]: Inexact-Newton Methods and the Computation fo Singular Points. Relatório de Pesquisa 14/94. DMA, IMEC'C, Universidade de Campinas, Brasil.
[10]	Kubicek, M., Hlavacek, V. [1975]: Solution of nonlinear boundary-value problems. IX.Chem.Eng.Sci.30,1439-1440.
[11]	Martinez, J. M., Qi, L. [1993]: Inexact Newton methods for solving nonsmooth equations. Relatório de Pesquisa 67/93. DMA, IMECC, Universidade de Campinas, Brasil.
[12]	Matthies, H,, Strang, G. [1979: The solution of nonlinear finite element equations. Int. J. Num. Meth. Eng. 14, pp.1613-1626.
BIBLIOGRAFIA
69
[13]	Mehra, R.K., Kessel, W.C., Caroil, J.V [1977/78/79]: Global estability and control analysis of aircraft at high angles of attack. ONR Report-CR-215-248-1,2,3.
[14]	Melhem, R.G., Rheinboldt, W.C.[1982]: A comparison of methods for determining turning points of nonlinear equations. Computing 29, 221-226.
[15]	Moore, G., Spence, A., [1980]: The calculation of turning points of nonlinear equations. SIAM J. Num. Anal. 17, 567-576.
[16]	Oden, J.T. [1972]: Finite element of nonlinear continua. New York. McGraw-Hill.
[17]	Ponish, G., Schwetlick, H. [1981]: Computing turning points of curves implicity definded by nonlinear equations depending on a parameter. Computing 26, 107-121.
[18]	Rheinboldt, W. C. [1986]: Numerical analysis of parametrized nonlinear equations. (University of Arkansas Lectures notes in the mathematical sciences; v. 7)
[19]	Schreiber, R., Keller, H. B. [1983]: Spurious Solutions in Driven Cavity Calculations. J. Comput. Phys. 49, pp. 165-172.
[20]	Schwetlick, H. [1978]: Numerische Losung	earer Gleichungen Deutscher Verlag der
Wissenschften. Berlin.
[21]	Seydel, R. [1979]: Numerical computation of branch points in ordinary differential equations. Numerische Mathematik 32, pp.51-68.
[22]	Simpson, R. B. [1975]: A method for numerical determination of bifurcation states of nonlinear systems of equations. SIAM J. Num. Anal. 12, pp.439-451.
Capítulo 5
Métodos Quase-Newton e Newton Inexato para fluxos em meios porosos
5.1	Introdução
A construção de modelos que representem adequadamente o escoamento dos fluidos num reservatório permite realizar previsões em relação a sua vida útil, capacidade de produção, etc., o que determina em princípio, a viabilidade da exploração da bacia petrolífera. Também, com a finalidade de otimizar a extração do óleo contido, possibilita o controle do regime de produção, a seleção de técnicas e a implementação de métodos alternativos de recuperação secundária.
A escolha de um modelo apropriado para um reservatório, dependerá básicamente das características estruturais da rocha produtora e das propriedades dos fluidos presentes. Os modelos tipo “black-oil” são usados habitualmente na realização de testes orientados a avaliar as características numéricas de um determinado algoritmo.
Consideraremos métodos numéricos para determinar o fluxo de dois fluidos imiscíveis escoando num meio poroso usando o método das diferenças finitas para aproximar as equações.
A maioria dos simuladores comerciais utilizam um tratamento temporal explícito para as não linearidades. Atualmente existe uma tendência direcionada para o desenvolvimento de simuladores que ofereçam soluções totalmente implícitas, cujas principais vantagens são as de fornecer soluções estáveis sem a necessidade de limitar o tamanho dos passos no tempo. Este esquema origina sistemas acoplados de equações algébricas não lineares a cada passo do tempo. A linearização destas equações gera sistemas lineares de grande porte, esparsos e não simétricos. Assim a eficácia do esquema totalmente implícito será dada principalmente pelas virtudes do método para resolver os sistemas envolvidos.
pálmente qual deles é o mais eficiente para este problema em particular. Nos concentraremos principalmente nos métodos que já têm sua eficiência comprovada na resolução de outros problemas, confrontando métodos diretos e iterativos para os sistemas emergentes. Ambos os métodos têm sido implementados com técnicas complementares baseadas em Fator ações Incompletas que melhoram substancialmente seu desempenho.
Na próxima seção, apresentamos as equações que regem o escoamento num meio poroso e suas correspondentes discretizações espaciais e temporais. As características do problema implementado serão mostradas na Seção 3. Na Seção 4 descreveremos sucintamente o conjunto de métodos para sua resolução. Os resultados numéricos e respectivas análises serão mostrados na Seção 5. Finalmente apresentaremos algumas conclusões e sugestões para futuros trabalhos.
5.2	Descrição do Problema
Os modelos “ black-oil" são considerados como protótipos para este tipo de problemas e vêm sendo usados habitualmente na realização de testes para diversos algoritmos na simulação de reservatórios (ver Aziz [2]).
Fazendo uso das hipóteses padrões que são habitualmente aplicadas sobre este modelo para um fluxo multifásico, resultam as seguintes equações:
Equação de conservação de óleo
V • (AD(Vp0 -	= d ^So/Bo} /dt + Qo	(5.1)
Equação de conservação de água
V	■ (Aw (VPfl - 7wVP)) = d &amp;amp;WSW/BW) /dt + Qw	(5.2)
Equação de conservação de gás
V	• (Aff - 75vr) + RgoXo (Vp0 - 7oV2?)) -
d (&lt;/&gt;Sg/B3 + RsoSo/Bo} /dt + (Q3 + R3OQ0).	(5.3)
Consideraremos para o nosso estudo o escoamento de dois fluidos imiscíveis em um reservatório bidimensional. As equações que regem o fluxo para este caso particular podem ser obtidas a partir das equações de conservação listadas acima, resultando:
d (Xodpo/dx) jdx + d (Xadp0/dy") ¡dy - Õ ^So/Bo) /dt + Qo	(5.4)
d(Xwdpw/dx) /dx + d(Xwdpw/dy) /dy = d (&lt;¡&gt;SW/BW) /dt + Qw,
(5.5)
pí ~
bp
Bf fij
sendo f — w,o ■ p = x,y.
As pressões de ambas as fases estão relacionadas através da pressão capilar
Pc =Po~ Pw,
e a equação de restrição para a saturação como
Sw + So — 1 ■
Discretízação
Aproximaremos numericamente as equações de fluxo sobre uma malha com espaçamento uniforme. A discretização dos termos de fluxo conduz a :
d (x ,ÔPf\ ~ 1 (x Pfi+r, -Pfij , ,	~ Pfij \
dx \ dx J.¿ ~ ¿Xxí \ xpi+1/2 Azí+i/2	Axí_í/2 J ’
3 t\ &amp;amp;Pf} ~ 1	X	~ Pf.A
M	AW+1/a	A^1/2 )’
(5.6)
(5.7)
e a aproximação para o termo de acumulação pode ser escrita como
di\BfJ At \Bf) \Bf)
(5.8)
Utilizando as aproximações (5.6) a (5.8) nas equações (5.4) e (5.5) e multiplicando pelo volume do bloco da malha AVJj = A-T^At/jA-s , temos
[Pzf,-1 /2 (?/í-l ,j “ Pfij ) +	/2 (P/i+1 ,J ~ Pl&lt;,&gt; ) ] 5-
para f - w,o , i - 1,2,..., Nx ,ej = 1,2,...,^.
As transmissibilidades das fases nas direções x e y estão dadas por
^S/j±l/2
v AxjAz
A taxa de produção (injeção) do componente c no bloco z, j em condições padrões é
Q~. = A1U
C&gt;.J
0 superscrito v indica o nível na aproximação temporal: v = v + 1 para um esquema totalmente implícito; v = u para um esquema totalmente explícito.
0 primeiro termo entre colchetes em (5.9) é a taxa do fluxo da fase f no bloco i,j na direção x. Podemos escrever este termo como se segue:
ATxfApj — Tzfi-ii? (pfi-ij ~~ Pfíj) d"-^h+i/2 (pfi+ij	~	(5 10)
Qxfi-i/2 d" Qsfi+i/2
Similarmente, o segundo termo entre colchetes expressa a taxa do fluxo na direção y :
ATyfApf	(p/ij-l	d" -^Íj+1/2	Pfij)
Qyfj-112 d" Qjdj+1/2
(5.11)
Assim, a equação (5.9) representa o balanço de material da fase f no bloco i.j . Isto significa que a taxa volumétrica de fluxo da fase f deve ser igual a taxa de variação de volume acrescida por uma fonte ou sumidouro da fase f no bloco.
Usando a relação de capilaridade e a de saturação, as equações discretizadas para ambas fases podem ser expressas em termos de p0 e Sw como segue
(AT^ApJ^ + (AT^APC\} + (ATywAp^ d- (AT¡/U,APC)Í=
’	(5.12)
(AV^/A^A.^/B^-IQ^,
(AT^ApJ^. + (ATyoApo); j =
'	’	(5.13)
(AU-j/Aí) At [¿(1 - S^/B^ - [Qo]. .
sendo At = [ f+1 - [ ]\
Estas equações em diferenças aplicadas ao longo da malha, podem ser escritas em forma
compacta como
F(x) = [Fw[po, Sw), F0(poy SW)]T ~ T x — C —	- Q,
(5.14)
em que o vetor incógnita x é definido como
—" (^"111 2-12, ■ ■ ■, *£í,j —1; &amp;amp;i,j, 2-í,j+l i ■ i ■¡•Nff) ,
sendo cada elemento de x um subvetor da forma x;j = (po,
A matriz de transmissibilidade T é pentadiagonal por blocos cuja estrutura é dada por:
íí,j+l/2
Ti+l/2,ji
onde cada bloco é 2 x 2, sendo cada uma das submatrizes
^¿±1/2,j -
0
0
0
0
0
0
,j±l/2
T
T y°}±l/2
em que
JZ-F» —	+ Tyw^/2 + 3"zwt+1/2 + TVWÍ+i/i,
^/To — 'PaOt-ij? +	+ Txo¡+1¡2 + TyO}+lj2.
A forma em que a matriz T e o vetor x estão definidos implica que a malha é percorrida primeiro na direção y .
0 vetores A, C e Q representam os termos de acumulação, capilaridade e injeçao/produção cujas componentes são dadas respectivamente por :
(AV^l - Sw)/B0^
Tratamento das transmissibilidades
e similarmente na direção y,
~	UJ í±1/2 (Mj±i/2 ■
Como se pode observar em ambas equações, as transmissibilidades estão compostas pelos seguintes fatores: no primeiro fator aparece o fator geométrico Fg, que depende da geometria da malha e da distribuição da permeabilidade absoluta (a permeabilidade na interfase do bloco será avaliada utilizando a média harmônica), o fator seguinte Fp contém os parâmetros dependentes exclusivamente da pressão, neste caso usamos uma ponderação centrada; o último fator Fs depende apenas da saturação. A permeabilidade relativa krj é intrinsecamente relacionada com problemas convectivos com equações de natureza hiperbólica; o uso de uma ponderação centrada pode conduzir a resultados sem significado físico. Por este motivo é usado um esquema “upstream” com a desvantagem de produzir dispersão numérica na solução.
As não linearidades introduzidas pelas transmissibilidades podem ser divididas em dois grupos: não linearidades fracas causadas pela dependência com a pressão, e não linearidades fortes que são os coeficientes dependentes da saturação como krj e Pc.
Esquema totalmente implícito
Como pode ser observado em (5.14) as equações discretizadas para um fluxo bifásico geram sistemas não lineares de equações em diferenças a cada passo do tempo.
Para alguns problemas que envolvem escoamento multidimensionais. os esquemas explícitos ou parcialmente implícitos para as equações de fluxo discretizadas são inadequados. A estabilidade numérica impõe limitações sérias sobre tais esquemas. Por este motivo, é necessário um tratamento totalmente implícito para a equação (5.14) o que implica em resolver dado o valor inicial
F"+1(.r) = 0
'	(5.15)
(A^/AtjAí
F =
(ATX0Apo) + (ATjjoApo) +
(5.16)
(AVí,j/Aí) A, [&lt;/.( 1 - S^/B^ - [QJ..J .
A matriz Jacobiana do sistema (5.15) e (5.16) tem a mesma estrutura que a matriz T e é composta pelas seguintes submatrizes
dP^,.,
SP-&gt;i,i
dRw. .
Jij —
afiw,.,
5S“í,j
ÔS^i.:
ÔR,

&lt;7i±l/2,j
Ji,j±1/2
	 apo^ij	dSv,i±l/2,j 8R°i,3
S^±1/2J	dSwi±l/2,}
r sr^í.3	
QRO..	dSwi,}±l dROi}
35u,&gt;,J±l


w*
Os elementos destas submatrizes contêm as derivadas dos resíduos em relação as variáveis primárias po e Sw. Usando (5.15) e (5.16) podemos obter os elementos de cada submatriz de Jí,j
^rJ
8Q~ .
9ñu,j.j as“í,j
dR°i,} dpOi^
frKO;,J
sendo
E3/ - ^A-1/2 + r«/í+l/2 + ^V/,-1/2 + ^y/j+1/2-
Os elementos das submatrizes Ji±i/2,j estão dados por:
dR*i,j
9po,±lJ
$Rwt j
"wi±l ,j
3*°.rJ
9P°í±3,j
dTxw
‘±1/2 T 9pO;±IrJ
A^9T^.±l/2 9p°.±l,j
asZ-iij (po,±1'J	+
T^i±i/2Pc,i±1j + ~ãs^~ GVil.j “ pci,j) ’
(	^^^±1/2 /	\
— dXOí±1/2 + 5po.±1' ^í±lT; — P&lt;=i,3j 3
(Pci±1.3 ~	’
T
dR°i,3 _ dTxoití/2 ( 9S™Í±1,3	9S^i±l,j V ‘
Análogamente, para as submatrizes Jij±i/2 temos
’°&gt;±3,Jr P°i.j ) ’
9pt&gt;í,J±l
dRu;i.3
aSu,,-J±1
T	4-	fn _ n _L
XxwJ±J/2 f dPo.j±i xPoijít P°ij} AOT^±l/2 (p	_p \
3p%J±1 V C‘-&gt;±1 C'-D ’
f^2±l¿2. (v	\+T
’	ÕT™3±l/2 ( p	_ p X
S5“’ij±i V C,’J±1 M1
_L 9Ti°2±i/2 9p%J±l
P’ +
cw±l


T

/2
9Rc,i,3	_ 9J~JOJ±1 /2 /	X
ãs^tr - 95»trJ±1	P°’ j ’
A matriz Jacobiana pode ser decomposta como
J = r-T'-A'-Q'
sendo T' a derivada da matriz de transmissibilidade, Tc' a derivada da matriz capilaridade-transmissilidade, A' a derivada do termo de acumulação eQ' a derivada do termo de injeção/prodv Somente as matrizes T' e T/ introduzem elementos fora da diagonal da matriz Jacobiana devido a que os termos de transmissibilidades dependem das variáveis do bloco i,j e dos nós vizinhos.
5.2.1	Caracterização do Problema
0 problema sobre o qual serão realizados os testes é caracterizado pelos seguintes conjuntos de hipóteses e condições:
•	Formulação do modelo ”black-oil” para simular o fluxo imiscível de óleo e água em reservatórios horizontais.
•	Sistema bidimensional em coordenadas cartesianas.
•	Admite-se compressibilidade de fluido e rocha. Viscosidade não é dependente da pressão. Meio isotrópico.
•	Reservatório heterogêneo com distribuições conhecidas de permeabilidade e porosidade.
•	Vazão nula na fronteira, Vp(t) • n = 0 em T.
•	Curvas de permeabilidade relativa para as rochas presentes no reservatório cuja dependência com Sw é dada através de dados empíricos, krp vs. Sw] a expressão que interpola os dados (obtida via regressão quadrática) é dada por krp = (ipS^1?.
•	Processo de injeção de água em reservatórios (para um esquema de um quarto de “five spot”).
•	Discretizaçao temporal totalmente implícita.
5.3	Descrição dos métodos
Nesta seção comentaremos a incorporação de uma mesma técnica complementar em dois tipos de métodos com concepções diferentes, que foram descritos no primeiro Capítulo. A introdução desta técnica (ver Zambaldi [17]) modifica drasticamente seu desempenho computacional.
A desvantagem na escolha do esquema totalmente implícito está na necessidade de resolver, um sistema não-linear a cada passo do tempo. As matrizes envolvidas caracterizam-se por ser de grande porte, esparsas e não-simétricas. Neste contexto, o ponto crucial do ponto de vista numérico, na aplicabilidade de um determinado método sobre um simulador, reside principalmente na eficiência da resolução dos sistemas.
Embora os métodos diretos sejam robustos e precisos , o tempo de processamento e a demanda de armazenagem são consideravelmente maiores que para os métodos iterativos. Uma família de métodos desta classe, denominados tipo Gradientes Conjugados reúnem as características desejadas desde que incluam o uso de precondicionado res.
5.3.1	Newton Inexato com Precondicionadores de Fatorações Incompletas
Um precondicionador adequado, para um sistema linear Ax — b, eni que a matriz A tem uma estrutura esparsa arbitrária, pode ser construido usando uma fatoração incompleta. Esta técnica consiste em achar uma fatoração aproximada de M =LU, em que L e U são obtidas por uma fatoração incompleta da matriz A, calculada por eliminação Gaussiana, eliminando os coeficientes que ocasionariam um enchimento na estrutura original de A. Os fatores £ e U que são matrizes triangulares inferiores e superiores devem reter o mesmo padrão de esparsi-dade de A. Uma melhor aproximação para a fatoração implicará em uma aceitação na perda desse padrão. Designamos a ILU(l) como sendo uma fatoração incompleta com um nível de preenchimento definido por l.
Na abordagem de Lantangen [10] o nível de preenchimento se estabelece mediante uma matriz de índices P = [i,j] associada diretamente ao parâmetro /, que representa o padrão de esparsidade da fatoração LU . Se P — {(i,j)/A¿j	0}, onde representa todos os elementos
não nulos de A. conduz a uma matriz LU onde todos os elementos adicionais originados pela decomposição são rejeitados; não admitir qualquer preenchimento será indicado por i = 0. Lantangen define a matriz no nível l utilizando o padrão de esparsidade do nível imediato inferior.
Assim, ILU(l) é definida em termos de ILU(l — 1) da seguinte forma; seja a matriz Pi_i a matriz cujos coeficientes são os indices (í,j) correspondentes ao padrão de esparsidade no nível (Z — 1). Consideremos a seguir o preenchimento causado ao efetuar o produto L x U. estará dada pelo conjunto de índices de P¡-i adicionando-se aqueles correspondentes aos novos coeficientes originados por efetuar o produto LU.
Para resolver E’(.r) = 0, o método Newton Inexato gera uma sequência	j = 1,2,...
pela aplicação de um método iterativo ao sistema linear
J(xk)s = -F(zk),
de tal forma de obter um	“suficientemente bom”, cuja qualidade é determinada com um
critério prefixado (ver Capítulo 1). Neste trabalho utilizamos uma implementação do método Newton Inexato com o Método GMRES para resolver os sistemas lineares, usando precondicionadores baseados em Fatorações Incompletas.
5.3.2	Atualizações Secantes em Fatorações Incompletas
As diferentes estratégias concebidas para definir as fatorações incompletas encontradas na literatura como foi descrito acima, tem como objetivo a construção de precondicionadores para diminuir o trabalho computacional na resolução dos sistemas lineares.
Fórmulas secantes
Os métodos quase Newton que obedecem a equação secante, diferenciam-se entre si pelas condições adicionais impostas sobre as matrizes Bk, como preservar alguma estrutura da matriz Jacobiana ou satisfazer algum princípio de variação mínima.
Neste estudo consideraremos quatro fórmulas secantes para gerar as matrizes de iteração dos algoritmos correspondentes aos métodos Quase-Newton usando Fatorações Incompletas. As fórmulas que apresentamos correspondem aos respectivos métodos secantes: Broyden-1 (Primeiro Método de Broyden); Broyden-2 (Segundo Método de Broyden); Atualização de uma Coluna( COLUMN) e Atualização de uma Coluna da Inversa (ICOL).
Consideraremos a seguintes fórmulas para
Em todos os casos yk é definido como:
yk = F(xH1) - F(xk)
• Fórmula de Broyden-1
Bk+i — Bk +
(yk - BM
T
(Ver Broyden [6])
• Fórmula de Broyden-2
Bjt+x - Bk 1 +
VkVk
(Ver Broyden [6])
• Fórmula de Atualização na Coluna (Column)
Bjt+i — Bk +
(yk - Bksk) ejk
sendo | ejksk |=[| IU
9
(Ver Martínez [11])
• Fórmula de Atualização na Coluna da Matriz Inversa (ICol)
Bk+i - Bk1 +
(sfc - B/yfc) ejk eIkyk
sendo | ejkyk ]=|| yk ¡¡^
(Ver Martínez e Zambaldi [12])
As fórmulas B-l e Column satisfazem
^fc+i = (J + u^k) (l +	- (j + uozo) Bo 1
em que os vetores uk,zk são:
e
Uk =
(sk-B^yk)
^yk
Zk = sk
{Sk-Bk'yk) ^yk
?k = ejk
para cada fórmula, respectivamente.
Para calcular o produto Bkrw para qualquer vetor arbitrário w 6 Rn necessitamos armazenar 2kn posições para Broyden-1 e apenas kn para Column.
Similarmente, para B-2 e para Icol temos
Bk+1 — UkZk + 1ik_-ízl_1 + ... + UqZq
em que os vetores uk, zk são:
zk — •Sh
e
WJt =
(sfe - Bk ^yk) ^B^yk

B-l e B-2 são fórmulas LCSU, enquanto que Column e Icol não satisfazem o princípio de variação mínima.
Já que a demanda de armazenamento de memória para os algoritmos baseados nestas fórmulas cresce com k , devem ser implementados com recomeços.
Habitualmente Bo = J(.t0), e os recomeços são produzidos utilizando algum critério sobre a taxa de diminuição do resíduo restituindo a matriz Bk = J(xk) ou, a cada q iterações da forma Bq = J(zk); isto é, quando k for múltiplo de um inteiro q a fórmula de atualização não é usada.
xk+1 = xk- B^ F(xk),
Bkq=J (#*)*
(5.17)
(5.18)
sendo
Bo— J (#o)
em que
J(xo) + B
isto é. J(x0) vem de uma fatoração incompleta (ILU) de J(aro), com recomeços a cada q iterações.
Uma outra estratégia mais elementar para conseguir uma matriz com um menor padrão de esparsidade que a matriz Jacobiana, consiste em definir uma matriz aproximada J obtida pela projeção de J(xk) sobre um subespaço S &amp;amp; IRF*n. 0 subespaço S pode ser escolhido dentre aqueles gerados por matrizes de banda. Esta aproximação surge naturalmente na discretização de problemas com valor de fronteira. Os resultados obtidos com diversas aproximações deste tipo foram totalmente desencorajadores.
5.4	Resultados numéricos
Um extenso conjunto de testes foram realizados utilizando diversos algoritmos com os métodos de Newton, Quase-Newton (implementados em Rouxinol) e Newton Inexatos com Precondici-onadores Secantes e FatoraçÔes Incompletas (implementados em NIPrec).
Apresentaremos apenas os resultados obtidos utilizando os métodos descritos na seção anterior por apresentar melhor desempenho, sobre um problema cujos parâmetros físicos e geométricos estão listados no fim deste capítulo.
A convergência é aceita quando a condição
&amp;lt;IO”10
5.4.1	Newton Inexatos Precondicionados
Mostramos o primeiro conjunto de resultados na Tabela 5.4.1 para diferentes níveis de preenchimento e distintos valores de (vários outros valores de Ô'K também foram testados).
Em cada parêntese informamos: (Iterações Newton Inexato Acumuladas, Iterações GMRES Acumuladas, Tempo de Execução Acumulado (CPU) [Seg])
Em termos de custo computacional ILU(4) - Ú;. = 0.1 mostrou ser o mais eficiente, com tempo de execução: 0.90e+07 enquanto que ILU(5) - Ôk = 0.01 demandou um menor número de iterações. Este fato pode ser explicado como se segue: com &amp;amp;k — 0.1 temos mais iterações de GMRES porém em espaços de menor dimensão e, em consequência, com menor custo computacional.
IEU(l)	= o.i	ek = 0.01
1 = 2	( 264,20216 , .5O9e+13 )	( 214 , 18607 , ,497e+13 )
1 = 3	( 217 , 3693 , ,152e+09 )	( 159,3964 , .181e+10 )
1 = 4	( 203 , 2298 , .S00e-f-07 )	( 161 , 2248 , ,142e+O8 )
1 ~ 5	( 207 , 2034 , .520e+08 )	( 162 , 2001 , .659e+08 )
Tabela 5.1: Newton Inexato com Fatoraçao Incompleta . Malha: M = 50
5.4.2	Quase-Newton com Jacobianos de Fatorações Incompletas
Apresentamos uma sequência de tabelas para problemas de tamanhos crescentes, em que o número de resultados apresentados serão gradualmente reduzidos, levando em consideração o desempenho computacional observado. Escolhemos várias malhas e realizamos diversas experiências com varios níveis de preenchimento l selecionando valores diferentes para os recomeços q. Os métodos usados foram:
•	A : Método de Broyden-1 (Primeiro Método de Broyden)
•	B : Método de Broyden-2 (Segundo Método de Broyden)
•	C : Método de Atualização de uma Coluna
•	D : Método de Atualização de uma Coluna da Inversa
	9	1 = 2	1 = 3	1=4	í = õ
A	10 25	&gt;	250 &gt;	250	&gt; 250 2766, 129, .844e-|-01	&gt; 250 1672, 78, .168e+O2	2844, 289, .348e+03 1607, 73, ,956e-j-02
•n.	50 100	&gt;	250 &gt;	250	2087, 58, ,514e+01 &gt; 250	1824, 51, .137e+02 &gt; 250	1663, 47, .819e+02 &gt; 250
B	10 25	&gt; 250 3839, 169, .318e+02	&gt; 250 1564, 82, -535e+01	&gt; 250 1186, 57, ,135e+02	&gt; 250 1123, 56, -656e+02
	50 100	1723, 46, ,998e+00 1596, 30, ,724e+00	1294, 36, ,308e+01 1346, 31, .297E+01	1089, 32, .866e+01 1151,31, .869E+01	1021,32, ,489e+02 1070, 31, .535e+02
	10 25	&gt;	250 &gt;	250	&gt; 250 3575, 161, .107e-|-02	&gt; 250 1727, 79, ,175e+02	&gt; 250 1444, 67, .803e+02
u	50 100	&gt;	250 &gt;	250	2258, 57, .442e+01 2486, 37, ,315e-f-01	1773, 49, ,132e+02 2089, 37, .943e+01	1593, 46, ,680e+02 2004, 37, ,672e4-O2
n	10 25	&gt;	250 &gt;	250	&gt; 250 1777, 86, .561e+01	&gt; 250 1306, 61, .137e+02	2391, 238 .253e+O3 11751 57j .777e-j-02
u	50 100	2049, 55, ,994e+00 1757, 30, .676e+00	1445, 36, .327e+01 1457, 31, ,285e+01	1181, 35, .879e-i-01 1206, 31, .873ê+01	1080, 33, ,484e4-02 1129, 31, ,562e+02
Tabela 5.2: Quase-Newton com Fator ação Incompleta, Malha: M — 30
Com l — 0 e l = 1 obtivemos convergência somente para esta malha, sendo l = 1 o nível que apresentou o melhor resultado.
Os recomeços pioram o tempo de execução e em alguns casos inibem a convergência; para q = 10 na maioria dos testes ultrapassou ItMaxQN- Idealmente, o valor de q (parâmetro que fixa o número de iterações para acionar os recomeços) deveria ser maximizado, porém há uma limitação na capacidade de memória para os vetores que armazenam as atualizações secantes. Este fato que se repetirá para as outras malhas, corrobora que a melhor aproximação ao Jacobiano corresponde aquela que conserva um pouco mais o histórico que vem sendo realizado pelos métodos secantes atualizando a fatoração incompleta. Contrariamente quando recomeçamos com a ILU do Jacobiano no ponto atual, este Jacobiano Incompleto está mais longe do Jacobiano verdadeiro que com as atualizações ILU + QN.
Observamos que há um comportamento regular considerando a eficiência do método em relação ao nível de preenchimento com o tamanho da malha. Obviamente convém trabalhar,
	9	1 = 2	1 = 3	1 = 4	1 = 5
A	50	&gt; 250	3742, 90, ,609e+03	2484, 64, .268e+03	2471, 62, ,947e+04
	100	&gt; 250	&gt; 250	&gt; 250	&gt; 250
B	50	2768, 68, 141.e+03	1670, 46, ,345e4-03	1289, 34, .146e+04	1193, 33, .715e+04
	100	2091, 30,.615e+02	1632, 31, .254e+03	1342, 31, ,133e+04	1240, 31, .624e+04
C	50	&gt; 250	&gt; 250	2445, 67, -270e4-04	2304, 60, ,914e4-04
	100	&gt; 250	&gt; 250	3104, 47, .176e+04	3096, 48, .724e+04
D	50	3116, 75, ,138e+03	1984, 46, .333e4-03	1447, 44, .176e+04	1311, 37, .587e+04
	100	2410, 32, .667e4-02	1781,31, .243e+03	1460, 31, .I31e+04	1331, 31, .584e+04
Tabela 5.3: Quase-Newton com Fatoração Incompleta, Malha: M = 40
	1 = 2	1 = 3	1 = 4	1 - 5
A	&gt; 250	&gt; 250	&gt; 250	&gt; 250
B	2555, 30, .280E+04	1921,31, .858E+04	1541,31, .3444-05	1431,31, .294E4-06
C	&gt; 250	&gt; 250	&gt; 250	3556, 52, .405E4-06
D	3462, 45, .349E+04	2140, 31, .814c+04	1682, 31, .329e-f-05	1544, 31, .337e+06
Tabela 5.4: Quase-Newton com Fatoração Incompleta, Malha: M = 50
Em geral, o número de iterações totais diminui e o tempo de execução (CPU) aumenta com o incremento de l. Isto é devido a que por um lado o aumento de preenchimento da fatoração proporciona uma melhor aproximação ao Jacobiano sendo que por outro lado é aumentado o custo das iterações individuais pela perda de esparsidade.
Etapa	Passo de Tempo [Dias]	Iterações Q-N	Tempo de Execução [Segundos]	Erro no Balanço de Agua	Erro no Balanço de Oleo
1	0.01	130	0.522E+02	O.OOOE+OO	O.OOOE+OO
2	0.19	47	0.673E+02	0.279E-09	0.919E-08
3	1.64	49	0.823E+02	0.106E-08	0.684E-07
4	1.99	49	0.974E+02	0.267E-08	0.189E-06
5	3.11	49	0.112E+03	0.393E-08	0.283E-06
6	5.55	52	0.128E4-03	0.815E-08	0.601 E-06
7	7.67	52	0.143E+03	0.167E-07	0.124E-05
8	10.2	54	0.159E+03	0.312E-07	0.228E-05
9	14.4	54	0.174E+03	0.405E-07	0.298E-05
10	19.0	55	0.189E+03	0.530E-07	0.378E-05
11	25.1	63	0.204E+03	0.796E-07	0.536E-05
12	31.7	64	0.219E4-03	0.126E-06	0.771 E-0ã
13	40.7	77	0.234E+03	0.165E-06	0.961E-05
14	50.0	92	0.250E+03	0.225E-06	0.120E-04
15	50.0	87	0.265E+03	0.261E-06	0.126E-04
16	50.0	82	0.279E+03	0.293E-06	0.139E-04
17	50.0	80	0.294E+03	0.350E-06	0.150E-04
18	50.0	81	0.309E+03	0.4I5E-06	0.160E-04
19	50.0	71	0.324E+03	0.465E- 06	0.182E-04
20	50.0	70	0.340E+03	0.543E-06	0.205E-04
21	50.0	77	0.355E+03	0.586E-06	0.220E-04
22	50.0	70	0.370E+03	0.655E-06	0.229E-04
23	50.0	66	0.385E+03	0.756E-06	0.240E-04
24	50.0	73	0.400E+03	0.818E-06	0.249E-04
25	50.0	71	0.414E+03	0.924E-06	0.262E-04
26	50.0	68	0.429E+03	0.101E-05	0.290E-04
27	50.0	76	0.445E+03	0.114E-05	0.326E-04
28	50.0	67	0.460E+03	0.134E-05	0.364E-04
29	50.0	76	0.474E+03	0.143E-05	0.393E-04
30	50.0	69	0.489E+03	0.161E-05	0.414E-04
31	50.0	69	0.489E4-03	0.165E-05	0.424E-04
Tabela 5.5: ICOL com Fatoração Incompleta , Nível: l — 3
5.5,	Conclusões e Trabalhos Futuros
87
5.5	Conclusões e Trabalhos Futuros
Neste trabalho, através de um vasto número de testes dentre os quais foram extraídos os mais relevantes, mostramos que existe uma clara superioridade computacional dos métodos quase-newtonianos combinados com FatoraçÕes Incompletas sobre métodos iterativos precon-dicionados que usam esta mesma técnica. Este resultado constitui uma contribuição para a resolução deste tipo de problemas.
Os resultados obtidos com métodos quase-newtonianos com Bo =	como implemen-
tados em Rouxinol mostraram-se pouco eficientes em relação aos outros.
Os métodos Newton Inexato com precondicionadores construidos sobre FatoraçÕes Incompletas tiveram um melhor desempenho que quando usados com Precondicionadores Secantes, porém foram menos eficientes que os Quase-Newton com Bo=LU com recomeços, em que LU é obtida a partir de uma Fatoração Incompleta do Jacobiano.
Entre estes últimos Broyden-2 e ICOL mostraram ser os mais eficientes, convergiram em todos os casos e Broyden-2 apresentou uma leve vantagem sobre ICOL. Em condições de convergência nenhum dos métodos mostrou uma notória superioridade em relação aos outros.
Para problemas de evolução, onde um sistema não linear e/ou vários sistemas lineares subjacentes são resolvidos a cada passo do tempo, algoritmos que usam uma fatoraçào simbólica para as matrizes de iteração aumentam significativamente sua eficácia.
As características do problema proporcionam um vasto e diverso conjunto de possibilidades a serem pesquisadas. Com propósito similar ao do presente trabalho têm-se desenvolvido técnicas como: Decomposição de Domínios, Formulações com Implicitude Variável, etc., que eventualmente poderiam combinar-se com os métodos aqui apresentados.
Por outro lado, o modelo selecionado neste trabalho oferece a possibilidade de modificar a dependência funcional da transmissiblidade com a saturação, permitindo implementar problemas com diferente tipo de não linearidades e analisar sua resposta dos distintos métodos em cada caso. Outras possíveis escolhas, diferentes da selecionada no presente trabalho podem ser:
: \ J. ____________ ________________Sw ____________________
iii)
Independentemente da relação de dependência funcional, em geral as funções de resíduos contêm não linearidades que podem ser encontradas nos diferentes termos que as compõem,
como foi devidamente exposto.
Os diversos métodos de solução existentes, conforme a abordagem proposta por Rodríguez [15], estão caracterizados por ter uma correspondência direta com um determinado nível de implicitude que podem ser identificados e correlacionados através de uma seleção apropriada dos diferentes termos que compõem a matriz Jacobiana. Respectivamente, existe uma relação explícita entre esse níveis de implicitude e o grau de não linearidade das equações. Esta mesma abordagem poderia ser aplicada como critério para escolher um Jacobiano Simplificado selecionando um nível de implicitude menor ao TI para construir uma matriz que determinaria uma maior esparsidade. Alternativamente sobre esta matriz “falsa” efetivar-se-iam as Atualizações Secantes o que eventualmente serviria para aumentar o padrão de esparsidade na Fatoração LU Incompleta e assim conseguir alguma economia computacional adicional,
Existem diversos problemas na Engenharia de Simulação de Reservatórios, onde o número de incógnitas é significativamente maior. Consequentemente, a necessidade de diminuir os custos computacionais passa a ser um item de importância crucial. Exemplos de problemas deste tipo são: escoamentos multifásicos com multi componentes, refinamento de malhas em sub domínios específicos, etc.
5.5.	Conclusões e Trabalhos Futuros
89
Parâmetros físicos e geométricos do reservatório
Dimensões laterais lc [ft]	300.0
Altura [ft]	10.0
[Dias]	0.01
ATmaz [Dias]	50.0
Tempo de evolução [Dias]	1000.0
Pressão capilar Pc	0.
Viscosidade da água /zo e do óleo	[cp]	1.0
Porosidade&amp;lt;/&gt;	0.10
Permeabilidade absoluta K [mD]	12.5
Compressibilidade relativa da água cTW e do óleo cTÚ [psCl]	1 x 10"6
Fator de formação volumétrico da água Bw e do óleo Bo [psi]	1.0
Vazão de injeção de água [bb/d] Qí	20.
Vazão de produção de água e óleo Qp [bb/d]	20.
Pressão inicial p0[psi]	3000.
Saturação inicial Sw	.25
Bibliografia
[1]	Aziz, K., Settari, A, [1979]: Petroleum Simulation. London, Applied Science Pub.
[2]	Aziz, K. [1993]: Notes for Petroleum Reservoir Simulation. Stanford University.
[3]	Behie, A, Forsyth, P. A. [1984]: Incomplete Factorization Methods for Fully Implicit Simulation of Enchanced Oil Recovery. SIAM J. Sci. Stat. Comput., [5], pp. 543’561.
[4]	Behie, A, Vinsome, P. K. W [1982]: Block Iterative Methods for Fully Implicit Reservoir Simulation .Soc. Pet. Eng. J., [22],pp. 659-668.
[5]	Bonet, L. [1990]: Simulação Numérica de Reservatórios utilizando um Método de Implici-tude Auto-adaptável. Tese de Mestrado. FEM. UNICAMP.
[6]	Broyden, C.G. [1965]: A class of methods for solving nonlinear simultaneous equations, Mathematics of Computation 19, pp. 577-593.
[7]	Collatz, L. [1973]: Numerical Treatment of Differential Equations. Springer-Verlag. Berlin.
[8]	Ewing, R.E. [1983]: Editor. The Mathematics of Resevoir Simulation. SIAM. Philadelphia.
[9]	Langtangen. H. P. [1989]: Conjugate Gradient Methods and ILU Preconditioning of Non-Symetric Matrix with Arbitrary Sparsity Pateras.Mt. J. Num. Meth. Fluids, [9], pp. 213233.
[10]	Langtangen, H. P. [1990]: Implicit Finite Element Methods for Two-phase Flow in Oil Reservoirs. Int. J. Num. Meth. Fluids, [10], pp. 651-681.
[11]	Martínez, J.M. [1994]: Quase-Newton Methods witht Derivatives. Por aparecer em Calcolo.
[12]	Martínez, J.M.; Zambaldi, M.C. [1992]: An inverse Column-Updating Method for solving Large-Scale Nonlinear Systems of Equations, to appear in Optimization Methods and Software.
[13]	Peaceman, D.W. [1977]: Fundamentals of numerical reservoir simulation. Amsterdam.
[14]	Pimentel Gomes, H. [1990]: Modelo compositional de reservatórios com Formulação Totalmente Implicita. Tese de mestrado. FEM. UNICAMP.
BIBLIOGRAFIA
91
[15]	Rodríguez, F. [1988]: Un enfoque unificado de métodos de simulación numérica de yacimientos”. Workshop das aplicações da ciências na engenharia de reservatórios. Rio de Janeiro.
[16]	Smith, G. D. [1987]: Numerical solutions of partial differential equations: Finite differences methods. Clarendon.
[17]	Zambaldi, M. C. [1995]: Métodos Quase-Newton com Fatorações Incompletas. Relatório Técnico. DMA-CFM. UFSC.
Apêndice A
Comentários Finais
Neste trabalho analisamos o desempenho de um conjunto de algoritmos para resolver sistemas não lineares originados em problemas reais. Selecionamos para isso, diversos problemas da Física e da Engenharia e vários algoritmos cujas implementações computacionais se encontram em diferentes estágios de experimentação.
Os problemas foram escolhidos com diferentes critérios; por um lado objetivamos originar casos com diferentes dificuldades numéricas mais ou menos generalizadas em relação às não-linearidades e estruturas, por outro lado consideramos a assididuidade com que estes problemas aparecem na literatura como “problemas testes” para estimar a eficiência dos métodos. Esta última consideração nos levou a tratar com esses problemas e seus respectivos esquemas de aproximação de maneira a reproduzi-los com a maior fidelidade, antes de nos preocupar exessivamente em melhorar sua formulação numérica. Com a finalidade de estabelecer formas padrões de resolução demos um tratamento numérico unificado o que eventualmente implicou na necessidade de “ignorar” em algunas situações, particularidades físicas e numéricas próprias do problema.
Os algoritmos especializados na resolução de sistemas não lineares de grande porte, cujas implementações preexistentes foram adequadas para serem aplicadas aos sistemas, são baseados nas ideias dos métodos de Newton, Quase-Newton e Newton Inexatos.
Em cada uma das respectivas implementações existe um conjunto de parâmetros que devem ser definidos pelo usuário. Em todos os casos a realização de experiências preliminares permitiu fixar valores para alguns desses parâmetros, sendo que os considerados mais relevantes foram deixados expressamente como variáveis constituindo-se em incógnitas adicionais a serem determinadas ao longo das experiências. Devemos esclarecer que a determinação desses valores de forma a otimizar o desempenho dos pacotes computacionais foi uma preocupação secundária: assim mesmo consideramos que a sua determinação constitui uma contribuição para o melhoramento desses pacotes.
Majoritariamente os sistemas foram gerados pela aproximação de problemas de contorno
Considerando a existência de “problemas padrões*’ que representam formas simplificadas das criadas pelas modelagens dos problemas reais selecionamos as equações de Poisson Não-Linear, o Problema de Bratu Modificado e o Problema de Convecção-Difusão Não-Linear, estabelecendo um marco de referência ao identificar valores do parâmetro para os quais a resolução das equações apresentam especiais dificuldades. Neste caso a nossa preocupação esteve dirigida a detectar situações problemáticas sem nos interessar exessivamente com a eficácia dos algoritmos utilizados.
Mediante o uso de técnicas elementares de continuação, as equações de Navier-Stokes foram resolvidas numa cavidade quadrada para altos números de Reynolds. 0 fluxo é newtonia.no e in-compressível em regime estacionário. A formulação das equações em termos da função-corrente define um problema de quarta ordem não-linear, com valores de fronteira. Outras técnicas de globalização foram introduzidas para resolver este problema, cujos resultados complementam os obtidos com operadores de segunda ordem.
Os métodos de globalização por otimização tiveram um desempenho pouco eficiente tanto em relação a obtenção de convergência quanto em relação ao tempo de execução.
Um novo método para a determinação de pontos singulares situados sobre uma curva ho-motópicafoi testado sobre uma coleção de diversos problemas. Estes pontos estão relacionados intimamente com a estabilidade e multiplicidade das soluções. As soluções são obtidas através de sistemas aproximados aumentados. 0 ponto chave da formulação consiste em substituir a equação que estabelece que o espaço nulo do Jacobiano tem um vetor não nulo por uma equação em diferenças, evitando o cálculo de derivadas.
Algoritmos com atualizações Secantes sobre Fatorizações Incompletas e Newton Inexatos Precondicionados são comparados em termos de eficiência computacional para resolver as equações que regem o escoamento bifásico bidimensional num meio poroso. Os sistemas foram gerados pela discretizaçao das equações originadas por um modelo tipo “black-oil” com uma formulação totalmente implícita.
Para os tamanhos dos problemas definidos os métodos diretos mostraram ser robustos e precisos apresentando vantagens em relação aos métodos iterativos. O número de incógnitas em cada caso foi determinado a partir das experiências realizadas por outros pesquisadores ou por uma limitação na capacidade do computador utilizado.
A eficiência dos métodos teve uma dependência mais marcante em relação às propriedades estruturais das matrizes Jacobianas do que com o tipo ou “grau” da não-linearidade das funções de resíduos.
0 Método de Newton teve o melhor desempenho na consecução de convergência sendo que neste caso os métodos quase-newtoni anos foram mais eficientes. Em termos gerais o Método de Newton Modificado se mostrou como uma excelente opção e deveria ser testado sempre por quem esteja interessado em obter economia no custo computacional.
Métodos Quase-Newton combinados com Fatorações Incompletas mostraram ser muito eficientes. Isto é, métodos diretos funcionam melhor que os iterativos enquanto exista capacidade de memória computacional.</field>
	</doc>
</add>