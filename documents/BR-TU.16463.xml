<?xml version="1.0" encoding="utf-8"?>
<add>
	<doc>
		<field name="docid">BR-TU.16463</field>
		<field name="filename">230_Paiva_RogerioFerreirade_M.pdf</field>
		<field name="filetype">PDF</field>
		<field name="text">UNIVERSIDADE ESTADUAL DE CAMPINAS
FACULDADE DE ENGENHARIA MECÂNICA
DEPARTAMENTO DE ENGENHARIA DE PETRÓLEO
Dissertação apresentada ao Departamento de Engenharia de
Petróleo da Universidade Estadual de Campinas , como requisito parcial para obtenção do grau de Mestre em Engenharia de Petróleo .
ESTUDO DA TÉCNICA TOMOGRÁFICA PARA
ANÁLISES EM GEOLOGIA E ENGENHARIA DE
PETRÓLEO

-fese


z


'W /


Por
G S I
de Paiva
Rogério Ferreira
/ /
Orientador : Prof. Dr. Antônio Celso Fonseca dé Arruda
DEZEMBRO , 1990
UN rCÀ M P
effiLiOTECA CEAiTRAL
UNIVERSIDADE ESTADUAL DE CAMPINAS
FACULDADE DE ENGENHARIA MECÂNICA DEPARTAMENTO DE ENGENHARIA DE PETRÓLEO
A dissertação "ESTUDO DA TÉCNICA TOMOGRÁFICA PARA ANÁLISES EM GEOLOGIA E ENGENHARIA DE PETRÓLEO" elaborada por Rogério Ferreira de Paiva e aprovada por todos os membros da Banca Examinadora foi aceita pela Sub-Comissão de Pós-Graduação em Engenharia de Petróleo como requisito parcial a obtenção do Título de Mestre em Engenharia de Petróleo.
Campinas, 12 de dezembro de 1990
Banca Examinadora:
Sílvio Crestaria, Dr.
Agradecimentos
Aos colegas, professores e funcionários do DEP e do Cepetro pelo ambiente de companheirismo proporcionado.
Ao prof. Antônio Celso pela orientação deste trabalho e pelo constante incentivo.
Aos engenheiros Farid e Sérgio Coelho do SEAREV-CENPES pelo suporte de material e cooperação.
Ao Fernando, ao Luiz e a Maria do Carmo Campozana pela solidariedade.
Ao Dr. Aldemir e ao Hospital Heliópolis pela cessão das instalações e equipamentos.
Aos pesquisadores Sílvio Crestana, Carlos Voz e André Torre Neto pela inestimável ajuda e à EMBRAPA pela cessão das instalações e equipamentos do NPDL4.
Ao amigo Luís Teimo pelo incentivo.
À Elizabeth, pelo carinho e compreensão.
Aos meus pais, Orestes e Gerdna, pelo carinho e apoio.
Aos meus irmãos Ricardo, Raphael, Rodrigo, Rachel e Re-jane.
RESUMO
tomografia computadorizada é, modernamente, um dos métodos mais poderosos para aplicações em ensaios não-destrutivos. O presente trabalho apresenta as análises de testemunhos convencionais passíveis da utilização desta técnica e faz, a respeito de diversas variações desta técnica (ultrasom, RMN, raios-x, PET, etc), uma breve explanação sobre seus princípios físicos e adequação às análises desejadas.
gão desenvolvidos os conceitos básicos da tomografia computadorizada de raios-x e apresentados os elementos componentes e a evolução dos equipamentos e, ainda, justificado seu uso na análise de materiais particulares à geologia e engenharia de petróleo,
pinalmente, é avaliado experimental mente o potencial, para estas análises de equipamentos médicos e de um mini-tomógrafo para aplicações multidisciplinares.
ABSTRACT
“fhe computerized tomography (CT) is one of the most powerful techniques for non-destructive applications. This work introduces the conventional core-analysis procedures that can be improved by tomographic techniques and the physical principles and proprieties of several types of CT (NMR, x-rays, PET, etc.).
The basic concepts involved in computerized tomography of X-rays (CTX), the scanner’s evolution and components are shown and the procedures and potencialities for petroleum reservoir materials analyses are described.
p inally, the potencial of medical equipaments and of a mini-tomograph for multi-subject applications is evaluated.
INDICE
Pág,
LLSTA	DE FIGURAS	vii
LISTA	DE TABELAS	x
NOMENCLATURA	xi
CAPÍTULO
1.	Introdução___________________________________________________1
2.	Revisão Bibliográfica da Análise de Testemunhos Convencional_4
Determinação da saturação de fluidos
Medição de porosidade
Compressibilidade
Permeabilidade Relativa
Citologia e Heterogeneidades
Escoamento Multifásico
3.	Revisão Bibliográfica das Técnicas de Tomografia Computadorizada _9
Ultrasom
Emissão Radioativa
RMN
Raios-x
4.	Conceitos Básicos da Tomografia Computadorizada de Raíos-X__________23
Considerações Gerais
Aquisição de Dados
Reconstrução da Imagem
Qualidade de Imagem
CAPÍTULO	pág.
5.	Aplicação da CTX em Análise de Testemunhos________________________36
Determinação de Saturações de Fluidos e Visualização de Escoamento Multifásico
Porosidade
Compressibilidade e Compactação Permeabilidade Relativa
Litologia e Heterogeneidades do Testemunho
6.	Evolução da Tomografia Computadorizada de Raios-X_________________43
Primeira Geração
Segunda Geração
Terceira Geração
Quarta Geração
7.	Elementos Básicos de um Tomógrafo ________________________________51
Transdutores
Sistema de Processamento de Dados
8.	Análises Experimentais	___________________________________69
Equipamentos Médicos
Mim-tomógrafo Multidisciplinar
9.	Conclusões_______________________________________________________ 87
lô. Sugestões para	Trabalhos Futuros_______________________________ 88
BIBLIOGRAFIA	90
LISTA DE FIGURAS
Figura	pág.
3.1	-	Lei de Snell para a refração ____________________________________________14
3.2	-	As técnicas de tomografía por emissão ___________________________________15
3.3	-	Princípios da ressonância magnética nuclear _____________________________17
3.4	-	Tempo de relaxação spin-spin (T2)	 18
3.5	-	Tempo de relaxação spin-spin e spin-rede ________________________________18
3.6	-	Mecanismos de Atenuação de Raios-X	21
4.1	-	Princípios da TCX _______________________________________________________23
4.2	-	Recursos de Imagem : janela e nível _____________________________________24
4.3	-	Diferença	entre a TCX e	a	radiografia	convencional __________25
4.4	-	A	atenuação dos raios-x em	material	homogêneo _______________________26
4.5	-	A	técnica	de retroprojeção	____________________________________27
4.6	-	A	técnica	de retroprojeção	filtrada ____________________________________28
4.7	-	O parâmetro FWHM ________________________________________________________30
4.8	-	O parâmetro MTF _________________________________________________________31
4.9	-	A influência da colimação na matriz de reconstrução _____________________32
5.1	-	Medições para cálculo de saturação_______________________________________37
5.2	-	Gráfico de porosidade ___________________________________________________40
6.1	-	A	tomografía convencional de raios-x ___________________________________43
6.2	-	A	primeira	geração de tomógrafos _______________________________________45
6.3	-	A	segunda	geração de tomógrafos _______________________________________46
6.4	-	A	terceira	e quarta gerações de tomógrafos _____________________________47
Figura	pág
6.5	- Refinamento da matriz de reconstrução no tomógrafo de quarta
geração	____________________________________________________________ 49
7.1	-	O tubo de raios-x ______________________________________________________ 52
7.2	-	Mecanismos de geração dos raios-x _______________________________________53
7.3	-	Bremsstrahlung - espectro energético ____________________________________54
7.4	-	Espectro energético típico de um tubo de raios-x ________________________55
7.5	-	Detector Cintilante _____________________________________________________57
7.6	-	Configuração convencional do detector cintilante	_____________________59
7.7	-	Configuração da câmara de ionização para taxa	de exposição ______________60
7.8	-	Configuração da câmara de ionização para exposição acumulada ____________61
7.9	-	Sistema de Processamento de Dados _______________________________________64
7.10	- Sistema	de Aquisição de Dados ________________________________________65
8.1	-	Tomograma de um Conglomerado_____________________________________________66
8.2	-	Foto da Seção Tomografada do Conglomerado________________________________71
8.3	-	Tomograma de um Arenito Homogêneo________________________________________72
8.4	-	"Scout-View" do Cilindro Padrão Mineralógico -	Vista	Superior _____74
8.5	-	"Scout-View" do Cilindro Padrão Mineralógico -	Vista	de Perfil _____74
8.6	-	Calcarenito Limpo - Seção Transversal 1__________________________________76
8.7	-	Calcarenito Saturado com Solução Kl 1 N -	Seção	Transversal 1 __76
8.8	-	Calcarenito Saturado com Óleo Seção Transversal 1 _______________________76
8.9	-	Calcarenito Limpo - Seção Transversal 2 _________________________________77
8.10	-	Calcarenito	Saturado	com	Solução	Kl 1	N - Seção	Transversal	2	77
8.1.1	-	Calcarenito	Saturado	com	Óleo -	Seção	Transversal	2________________77
8.12	- Calcarenito Limpo - Seção Transversal 3 ________________________________78
8.13	-	Calcarenito	Saturado	com	Solução	Kl 1	N - Seção	Transversal	3	78
8.14	-	Calcarenito	Saturado	com	Óleo -	Seção	Transversal	3 _______________78
Figura	pág.
8.15	- Arenito Saturado com Solução Kl 1 N - Seção Transversal 1________________79
8.16	-	Arenito	Saturado	com	Óleo -	Seção Transversal 1 ____________________79
8.17	-	Arenito	Saturado	com	Solução	Kl 1 N - Seção Transversal	2______80
8.18	-	Arenito	Saturado	com	Óleo -	Seção Transversal 2_____________________80
8.19	-	Arenito	Saturado	com	Solução	Kl 1 N - Seção Longitudinal_____________81
8.20	•	Arenito	Saturado	com	Óleo -	Seção Longitudinal______________________81
8.21	-	Tomograma	dos Experimentos Alar	e Alo_____________________________85
8.22	-	Imagem de	Porosidade da Amostra	Al________________________________85
8.23	-	Tomograma	dos Experimentos A2ar	e A2a_____________________________86
8.24	-	Imagem de	Porosidade da Amostra	A2_________________________________86
LISTA DE TABELAS
Tabela	pág.
8.1	- Diferenciação de Minerais e Rochas pela Tomografia de Raios-x ________75
8.2	- Resultados do Ensaio de Compactação___________________________________82
NOMENCLATURA
Alfabeto Romano
Ai	- amplitude da onda no meio i
ADC	- conversor analógico-digital
b	- constante
CPU	- unidade de processamento central ("Central Processing Unit")
CT#	- valor do coeficiente de atenuação normalizado na escala tomográfica
E	- energia (KeV ou KV)
ECT	- tomografia computadorizada por emissão ("Emission Computerized Tomography)
f	- frequência do ultrasom (MHz)
FWHM.	- "Full Width Half Maximum"
I	- intensidade de fluxo de fótons
lo	- intensidade inicial de fluxo de fótons
K	- constante do tomógrafo (usualmente 1000)
KVp L	-	energia máxima (de pico) em KV -	distância (cm)
M	- momento magnético
MCI	- integrador multicanal
MTF	- "Modulation Transfer Function”
M.UX	- gerenciador multicanal
PET - tomografia computadorizada por emissão de pósitrons ("Positron Emission Tomography")
RF	-	rádio-frequência
RMN	-	ressonância magnética	nuclear
ROI - região de interesse da análise ("Region of Interest")
Si	-	saturação do fluido i	na amostra
SPECT	-	tomografia computadorizada por	emissão de raios y ("Single Photon
Emission Computerized Tomography")
TC	-	tomografia	computadorizada
TCX	-	tomografia	computadorizada de raios-x
T1	-	tempo de	relaxação spin-rede
T2	-	tempo de	relaxação spin-spin
v	-	velocidade	de propagação
x	-	distância (cm)
Z	-	número atômico
Z	-	impedância acústica
Zi	-	impedância acústica do meio i
Alfabeto Grego
a	-	atenuação	ao ultrasom (	dftfaífexm )
$	-	porosidade
//	-	coeficiente	de	atenuação	aos	raios-x
pi	-	coeficiente	de	atenuação	aos	raios-x do meio i
p	-	densidade
Subscritos
o	-	óleo
w	-	água
g	-	gás
r	-	rocha
p	-	propriedade medida pontualmeníe na seção ( de caráter matricial)
ip	- propriedade medida pontualmente na seção saturada com fluido i
Superscritos
1,2
- nível energético da fonte de raios-x
CAPÍTULO 1
” Introdução
Na petrofísica e engenharia de reservatórios, a dificuldade de estudos em sistemas com meios porosos opacos (rochas), gerou a busca por métodos não-convencionais, onde fosse possível a visualização não verificada nos métodos tradicionais.
As técnicas que usam processamento de imagem possuem uma grande versatilidade de aplicações. A tomografía computadorizada de raios-x particularmente, devido ao grande desenvolvimento em sua área de origem, mostrou-se uma solução viável para a análise de testemunhos. Dessa maneira, ela vem logrando uma posição de grande destaque na engenharia de petróleo, que a tem adaptado nos últimos anos para seu uso.
A tomografía computadorizada é um método não destrutivo de exploração de objetos, baseado na interação de alguma forma de energia com a matéria, permitindo uma visualização de caráter tridimensional.
As características mais atrativas desta técnica, portanto, são :
a)	visualização do interior de corpos opacos à maioria dos métodos convencionais ;
b)	caráter tridimensional da visualização obtida ;
c)	alta resolução espacial.
2
Nos EUA e Europa, encontram-se tomógrafos com bastante frequência nas empresas e instituições de pesquisa da área petrolífera , já existindo na literatura varios artigos comprovando sua versatilidade de aplicação.
Normalmente, utilizam-se tomógrafos recondicionados de uso médico de segunda ou terceira geração, mas já existe equipamento específico para análise de testemunhos.
Os equipamentos de uso médico têm, no entanto, inconvenientes: implicam, por exemplo, na necessidade de blindagem de toda uma sala , têm dimensões muito grandes e satisfazem a critérios e limites não críticos ou diferentes à nova aplicação (por exemplo, dosagem de radiação e nível de voltagem ). Eles podem comprometer a qualidade dos resultados e, inclusive, restringir a utilização da técnica. Assim, a escolha do equipamento deve ser bastante criteriosa.
Obviamente, há ainda a necessidade de implementações no “software”.
O equipamento de uso específico é, por outro lado, muito caro devido à recente oferta e ao pequeno mercado comparado ao de uso médico. Por esse mesmo motivo, a oferta desses equipamentos recondicionados é mínima ou ainda não existe.
No Brasil, o uso do tomógrafo de raios-x na engenharia de petróleo, vem despertando grande interesse que pode ser ilustrado na Petrobrás pelo envio de uma missão aos EUA, além da constituição de um grupo de trabalho, ambos com a finalidade de se levantar informações sobre os equipamentos e a importância desta técnica quando aplicada à geologia e engenharia de petróleo. No entanto, dificuldades como oferta do equipamento, manutenção e peças de reposição que inexistem no país, aliado à impossibilidade estrutural das empresas estrangeiras de prestarem estes serviços aqui (CENPES, 1988), impôs a busca de novas alternativas.
A adaptação de um tomógrafo médico para uso da engenharia de petróleo pode, através do aproveitamento da infra-estrutura fornecida a área médica, solucionar os problemas citados e proporcionar resultados quase que imediatos sem,
3
contudo, gerar necessariamente um conhecimento mais profundo do equipamento, o que, de outro forma, permitiria uma exploração mais eficiente de suas potencialidades.
Outra alternativa, qual seja a construção de um tomógrafo tecnologicamente adequado para aplicação em engenharia de petróleo, difícilmente será viável cronologicamente, devido à multidisciplinaridade e complexidades envolvidas, se não for executada por uma equipe com experiência comprovada e com objetivos específicamente orientados para a engenharia de petróleo e geologia. Cite-se, como exemplo, o equipamento fabricado pela Bio-Imaging que, mesmo sendo projetado para a engenharia em geral, apresenta dificuldades na aplicação em engenharia de petróleo ( a troca das amostras é lenta e complicada e a rotação das mesmas, inerente ao equipamento, é indesejada em ensaios com influência gravitacional; CENPES, 1988).
Neste contexto, o objetivo da presente dissertação de mestrado é levantar o estado da arte da análise de testemunhos após o advento da técnica tomográfica. Ao nível experimental, objetiva-se avaliar o potencial da adaptação dos equipamentos médicos citado na literatura internacional de petróleo, além de outros equipamentos com projetos diferenciados .
CAPÍTULO 2
» Revisão Bibliográfica da Análise de Testemunhos Convencional
Vários experimentos dentro da análise de testemunhos que usam técnicas convencionais de uso corrente e, muitas vezes, já normalizadas, são passíveis da utilização da técnica tomográfica.
A dificuldade, principalmente de tempo dispendido, de se trabalhar com testemunhos de diâmetro inteiro ( "full diameter whole core") fez com que a maioria dos ensaios convencionais fossem feitos com "plugs" de 1 polegada de diâmetro, comprometendo muito a representabilidade da amostra em relação à formação.
A tomografia computadorizada trouxe uma maneira fácil e rápida de se trabalhar com testemunhos de diâmetro inteiro, recuperando assim a repre-sentaíividade da amostra e, consequentemente, a confiabilidade dos ensaios.
Neste capítulo, com o objetivo de se comparar posteriormente a "performance" desta nova técnica, levantou-se os princípios usados nas técnicas convencionais, bem como suas limitações e potenciais.
Entre estes experimentos, destacam-se (API, 1960; Amyx,1960):
2.1	Determinação da saturação de fluidos
Métodos : retorta ou destilação à vácuo e destilação-extração.
5
O primeiro método consiste na vaporização e condensação da água livre e do óleo da amostra. A principal desvantagem desse método é a exigencia de curva de calibração de agua, para determinar a temperatura máxima em que ainda não ocorra a desidratação dos minerais, e/ou da curva de correção do óleo, para consideração das perdas devido aos vapores e óleo coque i ficado remanescentes na amostra, além das perdas em forma de óleo craqueado. Essas curvas devem ser construidas para cada sistema óleo-formação, sendo que, na curva de calibração de água, existe ainda a dificuldade de se determinar a temperatura ótima em casos de amostras contendo argila.
Para se evitar a contaminação da amostra, sua densidade natural é determinada usando-se urna amostra adjacente.
O segundo método (destilação-extração) consiste na vaporização e condensação da água e extração do óleo. O volume de óleo é determinado pelo peso da amostra inicial menos o peso da amostra final seca. Esta medição indireta pode constituir-se em uma fonte de erro se no processo de secagem houver vaporização de água de hidratação dos minerais ou se restar óleo na amostra.
Para se determinar as saturações de água e óleo é necessário ainda se obter a porosidade, o volume total da amostra (para todos os métodos) e a densidade do óleo.
2.2	Medição de porosidade
Faz-se através do cálculo do volume total e poroso da amostra. Os métodos utilizados usam em sua maioria deslocamento com fluidos ou a Lei de Boyle (expansão de gases).
O deslocamento com fluidos tem normalmente desvantagens de contaminação da amostra, necessidade de calibração devido a diferenças na temperatura ambiente, além de erros decorrentes de amostras friáveis e yugulares que, respectivamente,
Cap. 2
Revisão Bibliográfica da Análise de Testemunhos Convencional
6
contaminam o fluido (aumentam seu volume) ou que são penetradas por ele (diminuem seu volume). Estas últimas têm normalmente que ser encapadas o que dificulta às vezes seu uso posterior para outros ensaios.
Bolhas de ar não removidas também causam erros consideráveis.
Os métodos que utilizam a Lei de Boyle têm necessidade de calibração cuidadosa e de correção para variações na temperatura e pressão ambientes. A porosidade calculada pode ser maior que a real se os gases são adsorvidos na superfície da amostra.
No caso de se medir a porosidade total, a densidade dos grãos deve ser determinada em uma amostra adjacente (pulveriza-se a amostra) o que, de certa forma, compromete o resultado.
23	Compressibilidade
No laboratório, a medida da compressibilidade da rocha é feita usando-se equipamento que mede o volume expulso da amostra devido ao aumento de pressão.
2.4	Permeabilidade Relativa
* Medição Direta - tem como princípio a drenagem ou embebição da amostra com razões de vazão água-óleo determinadas. Para cada uma destas razões, atingido o regime permanente , medem-se as saturações da amostra, por exemplo, através de balanço volumétrico dos fluidos injetados e produzidos ou da resistividade entre eletrodos colocados estrategicamente na seção de teste da amostra.
Com esses dados (saturação e razão de vazões), constrói-se a curva de permeabilidade relativa.
7
*	Método de Deslocamento - injeta-se gás em amostra saturada com óleo. Através de um balanço volumétrico da injeção de gás e produção de óleo, determina-se a curva de permeabilidade relativa.
2.5	Litologia e Heterogeneidades
São convencionalmente usados dois métodos.
*	Análise Macroscópica : é realizado serrando-se o testemunho na direção de mergulho. Se houver fraturas pode-se fazer uma análise 3-D antes de serrar o testemunho.
Na face serrada se analisa a textura e estrutura sedimentar da rocha.
Textura : granulometria, forma do grão (esfericidade e angularidade, seleção, cimentação e composição mineralógica).
Estrutura Sedimentar : superfície de acomodamento, mergulho, tipos de estratificação, plano paralelo, gradações verticais (normal ou inversa).
*	Análise Microscópica : de acordo com os tipos litológicos e dependendo do nível de detalhe desejado são tiradas amostras de lâminas delgadas para análise microscópica.
Através das lâminas delgadas (que podem incluir fraturas apenas se estiverem fechadas), pode-se fazer a identificação mineralógica dos componentes da rocha no microscópio petrográfico. No caso das argilas essa identificação geralmente é feita usando-se o microscópio eletrônico de varredura e/ou análise difratométrica de raios-x.
Assim, esses métodos possuem as desvantagens da inutilização da amostra e da determinação mineralógica que dificilmente será quantitativa.
8
2.6	Escoamento Multifásico
Várias técnicas, baseadas na determinação das saturações da amostra, foram desenvolvidas para se analisar escoamento multifásico em meios porosos opacos (rochas). Dentre elas, estão (Hove et aL, 1987); atenuação de raios-x (Laird &amp;amp; Putnam, 1951; Morgan et al.t 1950 ), absorção de microondas (Parsons, 1975), condutividade elétrica, ressonância magnética nuclear e injeção de traçadores radioativos.
Estas técnicas têm, no entanto, um sério fator limitante, pois não são capazes de fornecer a distribuição pontual das saturações , isto é, perde-se uma dimensão física da distribuição de saturações.
Este problema limitou muito o uso dessas técnicas, pois obrigava a aceitação de hipóteses, em sua maioria de homogeneidade da amostra, nem sempre válidas em casos reais. Mais grave ainda : impossibilitava a própria ratificação dessas hipóteses, ou seja, não se tinha ao menos como escolher amostras em que as hipóteses assumidas fossem satisfeitas.
CAPITULO 3
» Revisão Bibliográfica das Técnicas de Tomografía Computadorizada
As análises citadas no capítulo anterior e outras, como análise de fraturas e invasão de filtrado, medem uma grandeza ou visualizam um fenômeno interior à amostra de maneira indireta, quase sempre volumétrica ou gravimetricamente.
É nessa maneira indireta e nas tentativas de corrigir suas distorções que essas técnicas enfrentam dificuldades quase sempre operacionais.
Estas dificuldades não justificam, no entanto, o uso da tomografia computadorizada (TC), visto que elas podem ser ajustadas a níveis aceitáveis com o aprimoramento da técnica.
Ora, o que essas técnicas convencionais não contemplam, e aí justifica-se o uso da TC, é a determinação local das propriedades em cada ponto da amostra, ou seja: determina-se uma “função” que relaciona cada ponto com sua propriedade.
Obviamente, para análises de rotina, a determinação da “média” da propriedade na amostra é quase sempre suficiente.
10
A capacidade de medição direta possibilita, ainda, o uso da mesma massa de dados para a determinação de várias propriedades (por exemplo: porosidade, compressibilidade e saturação) durante um ensaio cujo objetivo direto não seja este. A TC tem grande utilidade na medição de parâmetros e validação de simulações, pois não é necessário se fazer interrupções severas nos ensaios, que são muitas vezes dinâmicos, para se determinar grandezas mensuráveis pela tomo-grafia. .
A visualização de fenômenos imperceptíveis aos métodos convencionais, associada a facilidades como as referidas, é que tornam o escoamento em meios porosos o uso nobre da TC.
O surgimento da técnica de TC, por um lado, e de processamento de imagem por outro, implicaram na extensão, quase que óbvia, de técnicas já utilizadas anteriormente para visualização de escoamento multifásico, mas que não tinham caráter tridimensional. São elas: atenuação de raios-x, absorção de microondas, ultrasom, e traçadores radiotivos.
As técnicas de TC têm características comuns sempre presentes. São elas (Bates, 1983):
a)	Operador: é a pessoa responsável pelo ensaio. Fazendo a interface com o sistema e direcionando os ensaios, ele tenta obter o melhor e mais claro resultado para os objetivos desejados.
b)	Corpo: é o objeto cujo interior se quer estudar.
c)	Emanações: é o tipo de energia usada para interagir com o interior do objeto.
d)	Transdutor: é cada fonte e cada detector da emanação.
e)	Sistema: é o conjunto das emanações, do equipamento e sua configuração (esquema de aquisição de dados, “software”, etc) no tomógrafo.
f)	propriedade: é uma propriedade física qualquer cuja distribuição espacial se deseja reconstruir com a ajuda de determinado sistema.
11
g)	“voxel” e “pixel”: são, respectivamente, a menor unidade de volume e área de uma seção do corpo que pode ser individualizada pelo sistema,
h)	imagem ideal: é a reconstrução perfeita da distribuição da propriedade. Ocorre quando os valores de atenuação dos “pixels” ou “voxels” não sofrem influência do elemento vizinho.
As principais técnicas de TC são denominadas segundo as emanações que utilizam. A seguir, descreve-se sucintamente cada uma delas (Sprawls, 1987; Hendee, 1983).
3.1	Ultrasom
Esta onda mecânica pode ser usada como emanação, pois pode ser focalizada em feixes estreitos e penetrantes. Nesta técnica os transdutores são cristais pieze-létricos: quando sujeitos à um pulso elétrico geram vibrações mecânicas de alta frequência (1-15 MHz). De maneira inversa, se vibrações mecânicas atingem o cristal, este emitirá um pulso elétrico. Assim, os transdutores podem agir como receptores e/ou emissores.
A frequência do ultrasom será a de vibração natural do cristal que é característica do mesmo (frequência de ressonância).
A velocidade de propagação da onda através da matéria será dependente da densidade e propriedades elásticas de cada material:
v - Z / p	(3.1)
onde:
v é a velocidade de propagação
Z é a impedância acústica (relativo às propriedades elásticas do material)
P é a densidade do meio
12
A amplitude da vibração é determinada pela forma do pulso elétrico na saída do gerador de pulsos. É, portanto determinada pelo operador. Caracteriza a energía da vibração porém, normalmente, apenas a relação entre as amplitudes das vibrações detectada e gerada é que interessa.
Convencionalmente:
Amplitude Relativa (dB) = 20 log [(A2/A1)]	(3.2)
onde:
Ai amplitude da onda emitida A2 amplitude da onda detectada
A interação do ultrasom com a matéria tem três efeitos principais: atenuação, reflexão e refração.
Atenuação: ao propagar através de um meio homogêneo, o ultrasom é atenuado proporcionalmente à sua frequência, às propriedades elásticas do meio e ao caminho percorrido.
Atenuação (dB) =	a * f * x	(3.3)
onde:	a é 0 coef. de atenuação ( em dB/cmMHz )	
	f é a frequência do ultrasom (MHz)	
	x é 0 caminho percorrido (cm)	
Reflexão: este efeito ocorre na interface de dois materiais com impedâncias acústicas diferentes e implica na redução da amplitude de vibração refletida. A perda por reflexão será tanto maior quanto maior for a diferença de impedância acústica entre os dois materiais (Z2 - Zt). Assim:
13
Perda por Reflexão (dB) - 20 log [(Z2-Z1)/(Z2+Zi)]	(3.4)
Refração: a parte da energia do pulso incidente que não foi refletida é retratada e segue para o material seguinte onde poderá sofrer novamente os três efeitos. Também ocorre perda na amplitude.
A TC ultra-som pode medir as ondas refratadas (TC por transmissão) ou as ondas refletidas (TC por reflexão). Em ambos os casos medem-se as amplitudes e tempo de trânsito da onda. Dessa forma, tenta-se recompor o a e a velocidade do som para cada “ponto” do objeto.
Embora na técnica convencional de imagem por ultrasom, o efeito gerador da imagem seja a reflexão, na técnica tomográfica preferiu-se a atenuação. Isto se deve ao fato de que a reflexão gera artefatos de difícil eliminação para a tomografia. Eles surgem devido à características extremadas de reflexão (alta ou baixa) que “criam” objetos posteriores que são nada mais que sombras (escuras ou brilhantes ) do primeiro material. A reverberação (reflexão sucessiva entre duas substâncias localizadas no eixo do feixe do ultrasom) também gera artefatos complexos.
Devido a tais artefatos, a tomografia por transmissão é a mais utilizada. Sua configuração e princípios são semelhantes ao da tomografia por reflexão, porém são necessários transdutores diferentes para a emissão e recepção. Além disso, a imagem de materiais adjacentes em que a velocidade do som é diferente gera distorções derivadas do desvio do feixe (Lei de Snell, vide Fig. 3,1).
Essas dificuldades ainda não foram sanadas e, mesmo na área médica, a TC de ultra-som tem uso bem restrito, apesar de seu grande potencial para medição de velocidade de fluidos (efeito Doppler) e da riqueza de seus dados (com a mesma massa de dados pode-se gerar imagens relativas ao coeficiente de atenuação ou à velocidade do som no material; Hendee, 1983).
14
O tratamento matemático necessário para se decodificar a propagação do ultrasom é introduzido por Greenleaf (1983).
Fig. 3.1 - Lei de Snell para a refração
3.2	Emissão Radioativa (Knoll, 1983)
Ao contrário da maioria das técnicas de TC que medem a capacidade de absorção da matéria, a TC por emissão revela a distribuição de traçadores radioativos injetados no corpo. Na TC por transmissão, também podem ser usados traçadores que, nesse caso, serão fortes absorvedores e suas dosagens muito maiores que as de traçadores radioativos.
Nas técnicas de TC por emissão (ECT), a emissão é interior ao corpo, o que dificulta a determinação da direção do raio (parâmetro fundamental para a reconstrução da imagem). A solução deste problema divide a ECT em duas técnicas: PET ("Positrón Emíssion Tomography”) e SPECT ("Single Photon Emission Computerized Tomography").
A PET usa radioisótopos que decaem emitindo pósitrons. Estes interagem à curta distância com um elétron do corpo e ocorre uma anulação de massa. A perda de massa desse processo é compensada pela emissão de dois fótons com energia de 511 KeV, ao mesmo tempo e em sentidos opostos.
15
Colocando-se dois sensores de posição em lados opostos do objeto, pode-se definir a direção do raio (Fig. 3.2).
Na técnica de SPECT, qualquer radioisótopo que emita raios y pode ser usado. Nesta categoria encontram-se isótopos do Tc-99m, 1-125, 1-131, etc. A vida média desses isótopos é muito maior que a dos emissores de pósitrons que está entre 2 e 20 minutos. Assim, a PET é, muitas vezes, inviabilizada economicamente pela necessidade da aquisição de um ciclotrón.
Na SPECT, diferentemente da PET, os raios y são emitidos como fótons individuais. Dessa forma, usam-se colimadores de maneira a poder determinar a direção do raio (Fig. 3.2).
D	PET	
e t		
e c t		
0		
r		
1	corpo	
5 e t e c t o r
2
SPECT
c o r P 0
colimadores
D e t e c t o r
Fig. 3.2 - As técnicas de tomografia por emissão.
Pela própria natureza dessa colimação (alta), somente fótons emitidos em determinada direção podem ser detectados. Com isso, a detecção ineficiente é inerente à SPECT.
As emanações de raios y e sua detecção são muito semelhantes às dos raios-x, no entanto em níveis de energias extremas (baixo ou alto), outros mecanismos de atenuação podem se tornar importantes.
A atenuação dos raios y pela matéria que envolve o traçador é indesejada e são feitas correções e aproximações para minimizar seus efeitos na reconstrução da imagem.
16
Enquanto na TC por transmissão o objetivo é mapear a capacidade de atenuação de uma seção do corpo, ou seja, uma característica presente em todo o corpo, na ECT está-se interessado em mapear a distribuição do traçador injetado. Isto obviamente limita bastante o uso da SPECT na análise em testemunhos, onde se quer muitas vezes verificar heterogeneidades de rochas.
33 RMN
Núcleos atômicos com número ímpar de prótons ou nêutrons exibem um momento magnético e, dessa forma, podem interagir com um campo magnético externo. Dentre esses, são de especial interesse para a engenharia de petróleo os íons do hidrogênio (devido à intensidade de seu momento e abundância na maioria dos fluidos), do sódio (presente muitas vezes na água em forma de sal), do manganês e do flúor (devido à facilidade de usá-los como dopantes na fase óleo).
As substâncias que possuem esses núcleos os têm distribuídos de forma randômica, de modo que a resultante do momento magnético é nula (Fig. 3.3a).
Quando um campo magnético externo é aplicado, os núcleos desses íons tendem a se alinhar paralelamente a este campo gerando um momento resultante não nulo (Mo na Fíg. 3.3b), cuja intensidade é proporcional à magnetização ou ’alinhamento’ conseguido.
Aplicando um segundo campo magnético, desta vez pulsante em rádio-frequência, pode-se perturbar este alinhamento (Fig. 3.3c). O novo momento resultante gira em torno do eixo do campo externo (movimento de precessão) em uma frequência proporcional à razão giromagnética (característica do núcleo ) e à intensidade do campo externo (Fig. 3.3d).
Iniciado o movimento de precessão, um pequeno sinal elétrico pode ser detectado colocando-se uma bobina em torno do corpo. A amplitude deste sinal
17
diminui com o tempo segundo um fator constante chamado “tempo de relaxação spin-spin” (T2) (Fig. 3.4).
Fíg. 3.3 - Princípios da ressonância magnética nuclear.
A aplicação do campo de RF com frequência igual à de ressonância do núcleo que se quer visualizar, causa o movimento de precessão: o momento resultante tem três componentes (Mx, My, Mz) e a distribuição dos momentos Mx e My dos núcleos concentra-se preferencialmente em uma região do cone de rotação.
A relaxação spin-spin (T2) tende a anular esses momentos, seja distribuindo-os aleatoriamente no cone de rotação (resultante zero) ou mesmo zerando-os (Fig. 3.5a).
18
bobina de detecção
Fig. 3.4 - Tempo de relaxação spin-spin (T2).
Outra relaxação ocorre concomitantemente, porém de mais longa duração, Seu fator de tempo é conhecido como “tempo de relaxação spin-rede” (TI) e, contrariamente a T2, depende da interação dos núcleos com o meio e tende a recuperar o valor original de Mz (Mo) (Fig. 3.5b).
A decodifícação do sinal detectado fornece os três parâmetros da técnica de RMN: Mo, Ti, T2. A imagem pode ser construída usando-se qualquer um desses parâmetros ou uma combinação deles. A escolha dependerá muitas vezes do objetivo, podendo-se dispor inclusive de três imagens que darão informações com-
plementares.
Fig. 3.5 - Tempo de relaxação spin-spin e spin-rede.
19
Para se conseguir imagens nas frequências de ressonância de núcleos com menor momento magnético que o hidrogênio (flúor, sódio, manganês), o campo deve ser várias vezes aumentado. Consegue-se isto usando-se magnetos supercondutores, cuja operação e manutenção são muito especializadas, além do alto custo de aquisição.
Enquanto a TCX mede propriedades de rochas e fluídos, a TC RMN o faz apenas para fluidos (chamados fluidos móveis) e para suas interações com as superficies de poros e fraturas que os contém, já que para sólidos a detecção é dificultada devido aos curtos tempos de relaxação e à presença de substancias paramagnéticas.
Devido a esses fatores e ao caráter complementar da TC de raíos-X e RMN, elas são muitas vezes usadas em conjunto (Vinegar, 1986), tendo a TCX vantagens, em caso de uso isolado, de custos e interação com a totalidade da amostra, além da resposta linear que lhe dá um caráter quantitativo.
Urna breve comparação entre as duas técnicas e introdução ao equacionamento matemático da TC RMN é dado em Hinshaw e Lent (1983). Gil e Geraldes (1987) dão uma visão bem detalhada dos aspectos físicos da RMN e, em seus últimos capítulos introduz a técnica de imagem por TC.
3.4	Raios-x
É tipicamente uma TC por transmissão. Contrariamente à ECT, a emanação é gerada externamente ao corpo, sob o comando do operador que, dessa forma, pode controlar sua direção.
Os raios-x interagem com a matéria de maneira inversamente proporcional ao seu conteúdo energético e através de dois mecanismos principais: espalhamento Compton e absorção fotoelétrica (Fig. 3.6). No primeiro, a dependência em relação ao nível energético é menos acentuada. Ambos atuam com os elétrons da matéria,
20
mas diferem-se basicamente devido à diferença entre o nível energético da radiação e da ligação desses elétrons com os respectivos átomos. Esta diferença é sempre positiva, porém é grande para o espalhamento Compton e bem menor para a absorção fotoelétrica. Um alto conteúdo energético dos raios-x pode, no entanto, causar a penetração total sem que ocorra qualquer interação.
Absorção fotoelétrica: ocorre em duas etapas. Na primeira, o fóton de raios-x transfere totalmente sua energia a um elétron de uma das camadas atômicas (tipicamente K ou L) que é, então ejetado. Na segunda etapa, o elétron deposita sua energia cinética nas imediações. Esta energia cinética é exatamente a diferença entre a energia do raios-x e a energia de ligação do elétron. A ’vaga’ criada na camada atômica é rapidamente preenchida por um elétron menos energético. Neste processo, quase sempre há emissão de um fóton de raios-x com energia característica (radiação fluorescente).
Espalhamento Compton: semelhante ao anterior, porém a energia do fóton é absorvida parcialmente e tanto a ejeção do elétron e o rechaçamento do fóton ocorrem em direções distintas à do fóton original. Este efeito faz com que o local da interação seja uma nova fonte de raios-x, contrariamente ao princípio da TC por transmissão que é o controle da direção da emanação pelo sistema (o algoritmo de reconstrução usa essa premissa). Pode-se, com alguns artifícios que serão comentados posteriormente, reduzir este ’efeito colateral’ desse mecanismo de interação.
Outros tipos de interações envolvendo fótons ocorrem, porém em níveis de energia não usuais de operação do tomógrafo. A interação do elétron ejetado com outros elétrons das imediações, devido à pequena distância em que ocorre, não é importante na tomografia de corpos não vivos.
Assim como na TC de RMN e de Ultra-som, a presença de mais de um mecanismo permite que se façam medições favorecendo ora um, ora outro. Isto
21
possibilita, na TCX, a geração de dois tipos de imagens: uma delas função preponderante da densidade e outra do número atômico (Z) do material.
raios-x
eletron
forte
ABSORÇÃO F0TMLETR1CA
4 .........®	-...*
; ligação
ESPHHffllENTO CONPTON
fr«ca
Fig. 3.6 - Mecanismos de Atenuação de Raios-X
A relação entre a propriedade de absorção de raios-x e outras propriedades físicas (densidade e Z) é dada pela equação (Wellington &amp;amp; Vinegar, 1987b):
- p (a + b* Z1S/E’V )
(3.5)
sendo :
a - coef. de Klein-Nishina (dependente da energia) -24
b - constante = 9,8	. 10
p - densidade
E - energia (KeV)
Z - número atômico
O primeiro termo da equação é devido ao espalhamento Compton e o segundo, à absorção fotoelétrica.
22
A possibilidade de se explorar toda a amostra (a atenuação ocorre tanto em rocha, quanto em fluidos) e a riqueza de seus dados, aliados ao desenvolvimento alcançado na área médica e baixo custo relativo à outras técnicas (por exemplo, RMN e PET), tomaram a TCX a técnica tomográfica mais utilizada na engenharia de petróleo.
Vale lembrar que a maioria dessas técnicas usadas em TC foram inicialmente desenvolvidas para uso médico. Dentre elas, duas técnicas têm grande potencial na engenharia de petróleo: a de raios-x e de ressonância magnética nuclear (RMN), esta última de uso bem recente.
Devido ao uso mais abrangente e ao alto custo dos equipamentos de RMN, a TCX vem se impondo como a técnica tomográfica mais usada em análise de testemunhos.
CAPÍTULO 4
» Conceitos Básicos da Tomografia Computadorizada de Raios-X
4	J Considerações Gerais
A tomografia computadorizada é um método de exploração não destrutivo que gera a imagem de uma seção (geralmente transversal) de um corpo. Esta seção é mapeada matricialmente, originando no corpo e na imagem, os “voxels” e “pixels”, respectivamente. A matriz gerada é chamada matriz de reconstrução.
O princípio da TCX é a medida da atenuação (coeficiente de atenuação linear) dos raios-x que atravessam o corpo segundo uma lei física conhecida.
Em uma mesma posição axial, o movimento da fonte de raios-x e detector(es) fornece os valores de atenuação acumulada segundo as diversas direções exploradas na seção (Fig. 4.1).
Fig, 4.1 - Princípios da TCX
24
Usando-se um algoritmo de reconstrução, obtém-se o coeficiente de atenuação de cada “voxel” partindo-se de todos os dados de atenuação acumulada medidos. Pode-se, então, gerar uma imagem definida pelo contraste dos coeficientes de atenuação.
A repetição deste processo em diversas posições axiais gera imagens das seções ao longo de todo o eixo.
Determinados os valores de atenuação de cada “pixel”, eles podem ser normalizados numa escala (usualmente na escala Hounsfield, que usa como padrão o coeficiente de atenuação da água). Na medicina, como o objetivo é o diagnóstico, esta escala de números é transformada em uma escala de cores ou tonalidades de cinza (do preto ao branco), gerando uma imagem.
Dentro da escala de cores, a janela (extensão da faixa de números da escala Hounsfield que vai ser usada) e o nível da escala (número central da janela) podem ser escolhidos ou mudados de acordo com a conveniência. Pode-se com isso, entre outras coisas, visualizar ou omitir preferencialmente uma determinada estrutura com faixa de densidade característica (Fig. 4.2).

E
S
C
A
L
A
O o /o
2
—323.»
E
S
c
A
L
A
Fig. 4.2 - Recursos de Imagem: janela e nível
Assim, a TCX é tecnicamente bem mais complexa que a radiografia convencional. Possue, porém uma grande vantagem: enquanto a radiografia mede a atenuação total dos raios através do corpo, a tomografia mede a atenuação em
25
cada “voxel”. Dessa forma, na radiografía, duas direções podem ter a mesma atenuação total, porém com valores completamente diferentes ao longo desta (o que não será distinguido, vide Fig. 4.3).
I = Io	&amp;amp;
= Io e ’0*75 L
1= Io e *0,75 L
Fig. 4.3 - Diferença entre a TCX e a radiografia convencional.
Assim, a TC desfaz a somatória das medidas, dá o valor médio para cada “voxel” e ganha, dessa forma, uma dimensão de exploração.
Esta característica é inerente a tomografia computadorizada, seja ela de raios-x, ultra-som, ressonância magnética nuclear ou outra qualquer.
Em relação à tomografia convencional, a TC possue vantagens provenientes dos recursos do processamento de imagem (por exemplo, subtração de imagens), que permitem clareza e objetividade na visualização e melhor aproveitamento da potência do tubo de raios-x.
26
42	Aquisição de Dados
Sendo o grande fator limitante da velocidade do experimento na TCX, a aquisição de dados foi o item mais modificado na evolução do tomógrafo de raios-x.
Devido a essa importância, ele será visto em detalhe no capítulo 6.
4.3	Reconstrução da Imagem
A atenuação de raios-x pela matéria, obedece à lei exponencial (Fig. 4.4):
1“ Io exp (-« L)
(4.1)
sendo:
I o fluxo de fótons incidente
Io o fluxo de fótons emergente u o coeficiente de atenuação
L o comprimento de atenuação
Fig. 4.4 - A atenuação dos raios-x em material homogêneo.
27
Ora, se os detectores medem a atenuação acumulada em cada direção e, deseja-se a atenuação de cada “voxel”, então será necessário explorar tantas direções quanto for o número desses elementos. Em outras palavras: para que se tenha uma solução única do sistema matemático (um único coeficiente de atenuação para cada “voxel”), é necessário explorar um número mínimo de direções igual ao de ‘'vexeis'’. O número de direções exploradas por cada perfil é igual ao número de detectores ativos por pulso da fonte.
O número de “voxels” escolhido por unidade de volume reflete a resolução espacial desejada e, com certas restrições técnicas, a resolução espacial obtida.
O processo de reconstrução envolve a solução simultânea de muitas equações, por isso se faz necessário o uso de computadores rápidos e métodos práticos de reconstrução matemática de imagem.
São disponíveis métodos iterativos e analíticos para a reconstrução matemática. Destaca-se, porém, devido à sua praticidade, o método chamado de retroprojeção. Basicamente, este método consiste em se assumir um valor uniforme (a média) através de todo o percurso do raio. O valor do coeficiente de atenuação (u) de cada “voxel” recebe uma contribuição de cada raio que o atravessa, contribuição essa que depende do ângulo de incidência do raio na matriz de “voxels” (Fig. 4.5).
				
				
•r.r.r.r.rj'	■v &gt;b .a -* .r iB . E.l.l.l1,*’.iL,| ■iricr r r.r r.r.r.B	.T.r.irr ■.r.rx.r.r.: r.r.BMíJr.r	trrrrri \tMhr4r.r.r.| rr.F.r.r.r.B1	LFjr-r^rjT^ TiJtIJJ
				
				
				

Fig. 4.5 - A técnica de retroprojeção
28
Esta técnica tem a vantagem do processamento de dados de um perfil concomitante com a aquisição de dados de outra. Dessa maneira, ao término do processo de aquisição de dados, a reconstrução final é rapidamente obtida.
O fato de se assumir atenuação uniforme por todo o percurso do raio, cria um efeito estrela na imagem obtida. Como se trata de um processo numérico, quanto maior o número de perfis, mais a imagem se aproximará da realidade, pois menor será este efeito que, no entanto, nunca deixará de existir (Fig. 4.6).
Para se eliminar esse efeito com um número finito e razoável de perfis, aplica-se ao processo de retroprojeção o artifício da filtração (retroprojeção filtrada).
Consta, basicamente, em uma compensação negativa em região de queda brusca de atenuação e em uma compensação positiva em região de aumento brusco de atenuação (Fig. 4.6).
RETROPROJEÇÃO
RETROPROJEÇÃO FILTRADA
Fig. 4.6 - A técnica de retroprojeção filtrada
A escolha da função filtro deve contemplar as necessidade de cada objetivo, pois dependerá dela o resultado final. Sendo, porém um artifício matemático (não gera nenhum dado físico novo), sempre se aplicará às expensas da resolução espacial ou da resolução da densidade.
29
A filtragem pode, por exemplo, suavizar contornos, porém com prejuízo da resolução espacial. A disponibilidade de filtros adequados pode ser muito útil na análise de testemunhos. A função filtro depende de parâmetros como a geometria da fonte de raios-x e dos detectores, o que a torna bastante complexa.
4.4	Qualidade de Imagem
A escala Hounsfleld é uma normalização dos coeficientes de atenuação em
relação à água:
[Unidades Hounsfield - HU]
(4.2)
K é normalmente 1000 e deve atender no mínimo à resolução de densidade do tomógrafo de modo a gerar, para duas substâncias discerníveis pelo tomógrafo, uma diferença mínima de uma unidade.
A qualidade da imagem gerada é quantificada pelas resoluções espacial e de densidade.
4.4.1 Resolução Espacial: é a capacidade com que a imagem define os contornos do objeto. Na sua quantificação, usa-se normalmente o desvio da curva de resposta da imagem em relação ao real.
A imersão de um fio longitudinalmente em um meio homogêneo (plástico ou água) gera uma imagem transversal que, ao invés de mudanças bruscas na tonalidade ou cor, apresenta certa suavidade . A quantificação dessa suavidade é feita com o parâmetro chamado “Full Width Half Máximum” (FWHM): o perfil do ponto será uma curva tipo sino, como indicado na Fig. 4.7. A largura da
3Ô
curva à meio altura do pico é a medida do FWHM. Obviamente, quanto menor o FWHM para um mesmo diâmetro de fío, maior será a resolução espacial.
RESPOSTA
IDEAL
MEDIDA
Fig. 4.7 - O parâmetro FWHM
Deriva desta medida da resolução espacial, outra mais popular que usa a imagem, desta vez longitudinal, de vários fios imersos também em meio homogêneo. A menor aproximação entre os fios (vistos como linhas na imagem) que ainda permite seu discernimento, dará o número máximo de Unhas por centímetro ,
A maneira mais difundida entre os cientistas é, no entanto, a “Modulation Transfer Function ” (MTF) que consegue quantificar o discernimento das linhas. Este discernimento é totalmente subjetivo, no método anterior. É, na prática, a razão entre a diferença relativa entre o pico e o vale do perfil na imagem e no objeto real. A curva da MTF é conseguida com a imagem de vários fios dispostos em espaçamento diferenciado (Fig. 4.8).
A resolução espacial depende de muitos parâmetros, em sua maioria físicos e alguns matemáticos como o filtro utilizado (balanceamento entre as resoluções espacial e de densidade) e a dimensão da matriz de reconstrução escolhida.
31
Fig. 4.8 - O parâmetro MTF
( CONTRASTE REI, LINHA-NEIO ) baje|# (CONTRASTE SKI. LINHA-MEIO ) real
CONTRASTE RELATIVO = A - B LINHA41EIO	A
CONTRASTE RELATIVO
LINHA41EIO
AJ
São exemplos de parâmetros físicos: abertura do orificio dos detectores (colimador), número de perfis, dimensão da região focal do tubo de raios-x e contraste de densidade entre as substâncias que compõem o objeto.
- Abertura do colimador dos detectores: as dimensões do “pixel” são, preliminarmente, determinadas pela largura do raio que atinge os detectores. Quanto menor essa abertura, menor o “pixel” e maior a resolução espacial (Fig. 4.9). No entanto, será menor ou o aproveitamento da potência do tubo ou o custo de fabricação dos componentes (este último cresce exponencialmente), já que se se quiser diminuir a perda no aproveitamento da potência do tubo, se terá de empacotar um maior número de detectores no mesmo espaço.
Estruturas, dentro do objeto analisado, com dimensões menores que o “pixel” terão sua visualização dificultada, pois não o ocuparão por inteiro.
A colimação do detector gera “pixels” tipicamente de dimensões desde um pouco menor que 1 mm até 1,5 mm. Nem todas as gerações de tomógrafos
32
podem, no entanto, reduzir drasticamente as dimensões do “pixel” por este método devido à variação da posição relativa entre a fonte e cada detector (Cap. 6).
CGliaação	cal mação
Fig. 4.9 - A influência da colimação na matriz de reconstrução.
A superposição parcial de direções exploradas no objeto pode gerar, matematicamente, um maior número de direções mais estreitas, aumentando a resolução espacial sem a necessidade da diminuição da abertura do colimador. É muito útil, por esse motivo, principalmente em tomógrafos de quarta geração.
-	Número de Perfis: o número de “pixels” da matriz de reconstrução é determinado pelo número de direções exploradas. Este número pode ser aumentado se o mesmo ocorrer com o número de perfis.
-	Dimensão da matriz de reconstrução: devido à possibilidade da não coincidência entre a estrutura a ser analisada com o “pixel”, o tamanho deste deve ser de 2 a 3 vezes menor que a resolução espacial desejada.
Uma resolução espacial maior implica em uma maior matriz de reconstrução ou em uma menor área física de reconstrução ("Región Of Interest", ROI). Usa-se, neste último caso, o artifício conhecido como “zoom”. Se, contudo, a massa de dados disponível não for suficiente para toda a matriz de reconstrução, geram-se “pixels” com valores idênticos ou relacionados aos adjacentes para suprir os ’buracos’. A definição dos contornos na imagem ficam prejudicados e nenhum aumento de resolução é obtido neste caso.
33
4.4.2 Resolução de Densidade: o procedimento usual para sua medida é a imagem de um meio homogêneo. Calcula-se o desvio padrão estatístico dos CT#. A medida que se apresenta normalmente como resolução espacial é o percentual da escala usada que esse desvio representa. Esta diferença entre valores da escala que deveriam ser idênticos é chamado de ruído.
O ruído é devido em grande parte à baixa intensidade do fluxo de raíos-x que atingem o detector, ao espalhamento Compton, ao erro de propagação computacional, à ação da função filtro e à pequena largura do “voxel” ou seção analisada. Outros fatores importantes são a estabilidade da fonte e do sistema eletrônico de detecção.
O ruído relativo é proporcional ao inverso da raiz quadrada do sinal entregue ao detector. Assim, a presença de materiais muito densos e uma grande área de reconstrução do objeto em relação à energia da fonte diminuem a qualidade do sinal obtido.
Num aparelho de espectro contínuo, a radiação recebida não pode ser diferenciada (se refratada ou refletida pelo espalhamento Compton). Assim, em equipamentos com mais de um detector (2--, 3â ou 4,( gerações), um fóton, ao sofrer espalhamento Compton, pode sensibilizar um detector que não aquele que está na direção do fóton original. Obviamente, quanto maior a abertura do colimador maior será o ruído devido ao espalhamento Compton (tomógrafos de quarta geração, Cap. 6).
O erro de manipulação numérica é devido à propagação quando se soma ou se subtrai números com um erro (resolução finita) já implícito. Ocorre quando se manipula dados superpostos para definição de direções mais refinadas.
4.43 - Artefatos: são imperfeições na imagem. São de vários tipos, dependendo do padrão que fazem surgir na imagem (faixas paralelas, faixas radiais, etc).
As causas mais comuns dos artefatos são:
34
-	mâ calibração de detectores: gera artefatos em forma de anel (tomógrafos de 3â geração) ou de faixas paralelas (23 geração) ou, ainda, anéis. Um alinhamento imperfeito do tubo de raios-x com os detectores pode causar um turvamento da imagem.
Para se evitar estes artefatos, deve-se verificar periodicamente a calibração e alinhamento dos detectores.
-	presença de regiões de alta atenuação e regiões de baixa atenuação: força o detector a trabalhar fora de sua faixa de resposta linear. Gera faixas radiais e pode ser minimizado usando-se detectores com uma maior faixa de trabalho linear.
-	presença no mesmo "voxel" de estruturas com acentuada diferença de atenuação: chamado erro do volume parcial, não gera um padrão na imagem, mas é enganoso quando se quer interpretá-la.
-	espectro contínuo da radiação: gera o chamado endurecimento do feixe, devido a absorção preferencial de fótons menos energéticos. Dessa forma, ao atravessar a matéria, o feixe fica proporcionalmente mais rico em fótons de alta energia aumentando sua penetrabilidade e gerando, mesmo em materiais homogêneos, uma atenuação linear maior no começo do trajeto do feixe de radiação.
Aparece na imagem como faixas escuras. Pode ser minimizado filtrando-se a radiação no tubo de raios-x, de forma reduzir os fótons de baixa energia.
Outros artefatos podem surgir devido a problemas de estabilidade da fonte de raios-x e do sistema de detecção.
Podem também ocorrer imperfeições devido a fatores geométricos do sistema fonte-detectores: o caráter divergente dos raios-x, impõe uma maior quantidade de fótons na altura do centro do "voxel" e menor nas extremidades. A minimização desse problema deve ser feita gerando-se um feixe com raios paralelos, através de colimação ou forma da região focal do anodo.
35
4.5	Manipulação de Imagem :
Recursos de manipulação de imagem permitiram uma grande versatilidade de aplicações à TCX. Recursos já citados como janela e nível da escala, permitem que a alta sensibilidade do aparelho seja acessível ao olho humano. Pode-se também reconstruir imagens de seções longitudinais à partir de várias seções transversais e consequentemente, imagens tridimensionais.
Esta exposição foi baseada em Miraldi e Wiesen (1988).
CAPÍTULO 5
» Aplicação da TCX em Análise de Testemunhos
A TCX pode substituir as técnicas descritas no capítulo 2, quase sempre com vantagens técnicas e operacionais. No entanto, apenas algumas análises como estudo de escoamento multifásico, justificam suficientemente a aquisição de um tomógrafo, pois as técnicas convencionais satisfazem a maioria das necessidades rotineiras da análise de testemunho.
Entretanto, essas análises mais simples devem ser feitas usando-se o tomógrafo se outras, mais complexas, forem também necessárias. Ganha-se quase sempre, com esse procedimento, tempo e acurácia e, muitas vezes, aproveita-se a mesma massa de dados de outra análise.
5.1	Determinação de Saturações de Fluidos e Visualização de Escoamento Multifásico
Na determinação das saturações, em sistemas bifásicos, cada “voxel” terá seu coeficiente de atenuação. Tem-se então as seguintes equações para cada “pixel” (Wellington &amp;amp; Vinegar, 1987b):
37
jüp = « op Sop + /íwp Swp = /íop Sop + /íwp (1-Sop)
onde
(52)
/ir + 0p [(1-Sop) /i w + Sop /i o ]	(53)
/i op = (1- 0 p) /i r +	0 p fio	(5.4)
iíwp ~ (1- $ p) /ir +&amp;lt;p p /i w	(5.5)
DETERMINAÇÃO DA SATURAÇÃO DE ÓLEO
Fig. 5.1 - Medições para Cálculo de Saturação
38
Esse sistema necessita de três medições experimentais (Fig. 5.1): a primeira para se determinar os coeficientes de atenuação de cada ponto da amostra saturada com um dos fluidos (por exemplo água, pwp), a segunda com o sistema bifásico desejado (up) e a terceira para a amostra saturada com o segundo fluido (óleo, /top). Para a determinação das saturações em instantes intermediários, será necessário apenas a medição em cada um desses instantes.
Apenas com a medição de pop e /twp, já é possível se conhecer as porosidades locais da seção (vide seção 5.2).
Sistemas trifásicos exigem, no entanto, mais uma equação (linearmente independente). Fazendo-se duas medições onde predomine, respectivamente e em pelo menos uma das fases, o espalhamento Compton (medição à alta energia) e a absorção fotoelétrica (medição à baixa energia), consegue-se a outra equação. Isto ocorre porque está-se medindo, na realidade, duas atenuações (mecanismos) diferentes, portanto as equações serão linearmente independentes e o sistema terá solução única.
No caso de medição a baixa energia, pode-se evitar o aumento global da atenuação (que diminui o sinal), dopando-se pelo menos uma fase (Wellingíon &amp;amp; Vinegar, 1987b). Com isso, pode-se usar uma energia maior (maior penetratibilidade) e conseguir coeficiente de atenuação com caráter fotoelétrico acentuado.
A modificação da energia dos raios-x é facilmente conseguida pois se usa como fonte um tubo de raios-x (Cap. 7).
As equações são (os índices 1 e 2 diferenciam a energia da fonte ):
y K i c a y p
BÍBLIOTECA CENTRAL
39
So + Sw + Sg = 1	(5.6)
= «1&lt;?p So + «'wp Sa&gt; + u]gp Sg	(5.7)
/¿S3 = /í^p So + /z^p Sw + /zrgp Sg	(5.8)
Obviamente, a grande vantagem prática está no fato das medições poderem ser feitas seguidamente uma da outra, aproveitando-se o mesmo ensaio.
Dessa maneira, obtidos os coeficientes de atenuação de cada “pixel” (/z!p e /z p para escoamento trifásico e /&lt;p para escoamento bifásico), é possível encontrar as saturações locais de cada fase.
É através das saturações locais que o escoamento é acompanhado. Viabiliza-se assim, uma grande quantidade de análises principalmente em simulação e recuperação secundária e terciária, tais como : segregação gravitacional, escoamento miscível e imiscível, fenômeno de “fingering”, influência de forças capilares e viscosas no escoamento, efeitos de fronteira, etc (Wang et al., 1984; Withjack, 1988; Wellington &amp;amp; Vinegar, 1987a).
5.2	Porosidade
A porosidade pode ser calculada em sistemas monofásicos em duas medições com fluidos diferentes (Withjack, 1988; Wang &amp;amp; Ayral, 1984).
Assim, todos os “voxels” estarão preenchidos com um fluido e/ou matriz rochosa. As equações serão as seguintes (o índice p refere-se à cada “pixel” da matriz de reconstrução e os índices 1 e 2 referem-se ao fluido utilizado ere f referem-se à matriz rochosa e aos fluidos, respectivamente):
40
/ip=(l-0p) /ir +&amp;lt;pp fli	(5.10)
Como nâo se alterou a energia da fonte, fir deverá ser invariável e, assim:
0p -

Fig. 5.2 - Gráfico de Porosidade
53 Compressibilidade e Compactação
Conforme Wellington e Vinegar (1987a), a determinação de parâmetros mecânicos é bem rápida e fácil . O coeficiente de atenuação depende da densidade, número atômico e energia da fonte, segundo a equação (cap. 3) :
41
P = p ( a + b Z3’8 / E 3’2)	(3,5)
No estudo de mecânica das rochas, apenas a densidade varia, podendo-se determiná-la e, com ela, diversos parâmetros, entre eles a compressibilidade.
A grande vantagem em relação aos métodos convencionais é a visualização da variação local dessas propriedades em amostras heterogêneas,
5.4	Permeabilidade Relativa
Apesar de demandar um tempo semelhante ao do método convencional, a TCX elimina nesta análise a necessidade do balanço volumétrico ou gravimétrico para determinação das saturações.
5.5	Litologia e Heterogeneidades do Testemunho
A TCX tem uso privilegiado em amostras heterogêneas. Pode, por exemplo, distinguir as porosidades da matriz rochosa e das fraturas, verificar a anisotropia da permeabilidade, determinar, em ensaios não destrutivos, a direção preferencial das fraturas que macroscopicamente pode não ser clara.
Pode-se ainda determinar a largura, espaçamento, tortuosidade e interconexões das fraturas (Bergosh, 1985; Honarpour, 1986) e quantificar invasão de filtrado, etc.
A versatilidade da técnica permite ainda, o uso da TCX para análise de materiais e produtos usados, por exemplo, na área de produção ("riser" sintético).
Pode, por exemplo, descrever em ensaios não-destrutivos falhas milimétricas (antes, durante e após a ação de esforços mecânicos) e estruturas cristalinas de maneira quantitativa e contínua e sem grandes restrições, ao contrário de outros
42
métodos ( por exemplo, acústicos e de injeção de resinas coloridas ). Essas análises são comuns tanto para rochas (fraturas), quanto para materiais diversos não metálicos (fadiga).
Somem-se a essas análises, outras como análise mineralógica quantitativa (inclusive de minerais que preenchem as fraturas) e de invasão de filtrado (Wellington &amp;amp; Vinegar 1987a; Hunt et al, 1987).
CAPÍTULO 6
» Evolução da Tomografia Computadorizada de Raios-X
Não obstante as conquistas obtidas com o advento de técnicas como radiografia e ultrasonografia, a visualização de seções interiores a corpos opacos sem a interferência de regiões adjacentes só foi conseguida com a tomografia.
Neste capítulo, a evolução desta técnica é resumida com enfoque único para a tomografia de raios-x (Brooks &amp;amp; Di Chiro, 1976; Miraldi &amp;amp; Wiesen, 1988 e Sprawls, 1987).
Fig. 6.1 - A tomografia convencional de raios-x.
44
A técnica de anulação da interferência das regiões adjacentes na imagem final, divide historicamente essa evolução em duas fases, quais sejam: tomografia convencional ou do plano focal e a tomografia de reconstrução.
A tomografia convencional de raios-x foi criada há mais de 50 anos e está há muito em desuso. Consiste em se mover a fonte e o filme fotográfico (detector), posicionados opostamente em relação ao corpo, de maneira a se manter em foco (posição de projeção no filme constante) apenas o plano ou seção da qual se quer a imagem (Fig. 6.1).
Dessa maneira, as contribuições das outras seções são superpostas obtendo-se um caráter para a imagem final que supervaloriza a seção desejada sob um fundo mais ou menos homogêneo correspondente à essa superposição não coincidente das outras seções.
A tomografia por reconstrução mudou a posição da fonte e detector em relação à seção de interesse que passou a ser coplanar (Fig. 4.1). Com isso, eliminou-se o ’’fundo” ou interferência das outras seções na imagem, pois os raios detectados não passam mais através das regiões indesejadas.
A acumulação da atenuação de raios-x deixa, então, de ser um ruído a ser eliminado para ser um dado somatório cujos fatores precisam ser obtidos. Isto aumentou muito a quantidade útil de informação obtida numa única detecção diminuindo a necessidade de potência e/ou a dose de radiação absorvida pelo corpo em estudo. Por outro lado, a detecção não podia ser feita simplesmente com um filme fotográfico, mas, ao contrário, deveria ser registrada sob a forma de sinais que pudessem ser quantificados e manipulados matematicamente de maneira a se desfazer sua somatória e, assim, reconstruir pontualmente a imagem.
Para se reconstruir a imagem de uma seção através de dados de acumulação de curvas (integrais de linhas retas, neste caso) dessa seção, é necessário um número de curvas mínimo igual ao número de elementos da matriz de reconstrução
45
e uma grande capacidade de armazenamento e de velocidade de processamento de dados.
A capacidade de armazenamento e rapidez de manipulação foram conseguidas com recursos da informática. O método de reconstrução partindo-se de integrais de linha surgiu na radioastronomía solar e na microscopía eletrônica de biomoléculas complexas na segunda metade da década de 50.
Vários métodos de reconstrução originais foram tentados na CTX, mas somente em 1972 (tomógrafo da EMI Ltd.) produziu-se o impacto necessário (Hounsfield, 1973). A seguir, cada uma das gerações de tomógrafos é analisada. Cita-se os detectores comumente usados em cada uma delas, apenas para efeito de análise posterior (Cap. 7).
6.1	Primeira Geração
PRIMEIRA TRANSLAÇÃO
Fig. 6.2 - A primeira geração de tomógrafos.
H-esiraa TRANSLAÇÃO
Esta geração tem uma aquisição de dados muito lenta: um único par fonte-detector (para cada seção) faz uma translação e depois rotaciona. Este processo é repetido até que seja produzida informação suficiente (Fig. 6.2). No equipamento de Hounsfield (Miraldi &amp;amp; Wiesen, 1988), para uma matriz típica de 160x180, este
46
processo dispende em torno de cinco minutos, A colimação é alta e se mede linearmente: 2x13 mm (profundidade x espessura da seção).
A dificuldade de se manter o paciente imobilizado durante este tempo, levou ao desenvolvimento do tomógrafo de segunda geração com uma aquisição de dados mais rápida, diminuindo assim, os artefatos criados pelo movimento inevitável, muitas vezes involuntário, do corpo. Mesmo para a engenharia de petróleo o tempo gasto na aquisição de dados pode comprometer ensaios de escoamentos.
6.2	Segunda Geração
A fonte deixa de ser altamente colimada (colimação angular de 3-10 graus) para produzir um feixe de raios-x em leque de forma a sensibilizar ao mesmo tempo um número maior de detectores. Assim, como os feixes que atingem os detectores não são paralelos, a translação divide o número de rotações necessárias por um número idêntico ao de detectores: na realidade cada detector terá medido um perfil ao final de cada translação (Fig. 6.3). A aquisição de dados dura cerca de 20 segundos.
Como o tempo de aquisição ainda era impeditivo para várias aplicações médicas, a evolução continuou...
Fig. 6.3 - A segunda geração de tomógrafos.
47
63	Terceira Geração
Visando, desta vez, eliminar as translações, alargou-se o feixe em leque da fonte de maneira a cobrir uma maior parte da seção (Fig. 6.4). Foi necessário, então, o uso de centenas de detectores arranjados concentradamente de forma a diminuir os vãos entre eles, aumentando o aproveitamento da potência da fonte (crítico no uso médico).
TERCEIRA GERAÇÃO
QUARTA GERAÇÃO
Fig, 6.4 - A terceira e quarta gerações de tomógrafos.
Os detectores são dispostos em forma de arco e devem ser mais estáveis, pois a possibilidade de recalibração durante o experimento é mínima, ficando os detectores quase sempre à ’sombra’ do corpo. São usados, normalmente, detectores de câmara de ionização de gás xenônio ou cristal cintilante de iodeto de césio ou tungstato de cádmio. Ambos, câmara e cristal, podem ser agrupados em espaço mínimo, porém o último é mais eficiente.
48
6.4	Quarta Geração
Dispondo os detectores fixos em toda a circunferência de medição, esta geração é considerada apenas uma evolução cronológica (Fig. 6.4), Devido à posição detector-foíite variável (apenas a fonte rotaciona), a colimação possível é muito pequena e, por isso, o nível de ruído aumenta (espalhamento Compton).
Como citado no capítulo 4, essa geração usa, para obter alta resolução espacial, a medição de raios superpostos parcialmente que, através de processamento analítico, gera direções mais refinadas, a despeito da infiltração de erros de manipulação numérica. A seguir, explica-se este procedimento em detalhe.
Todas as gerações anteriores à quarta não variam a posição de cada detector em relação à fonte. Isto significa que o ângulo de incidêndia do raio no detector, nestas gerações, será sempre o mesmo. Assim, os detectores podem ser altamente colimados de forma a manter o nível de ruído devido ao espalhamento Compton bem baixo.
Para a quarta geração, uma alta colimação dos detectores permitiria a sensibilização dos detectores apenas quando eles estivessem em posição diametralmente oposta. Obviamente, isto reduziria o número de direções exploradas a nível insuficiente. Para contornar este problema, aumentou-se a abertura dos detectores (dimínui-se a colimação) e, através da variação instantânea do sinal num mesmo detector durante a rotação da fonte, pode-se diferenciar mais refinadamente as direções contíguas de exploração (Fig, 6,5). Quanto mais refinada a mudança de posição da fonte entre as medições, mais refinadas serão as direções. Entretanto, o aumento da resolução espacial deverá ser contrabalanceado pelo nível de ruído que crescerá.
Vantagens como a recalibração dos detectores compensam parcialmente o problema anterior e outros como custo do alto número de detectores (de 600 a 1200), porém não garantem de maneira alguma a superioridade ou melhor desempenho sobre a terceira geração.
49
Posição da Fronteira do raio eu tempos diferentes (medição superposta parcialmeiite)
T2
f
Fig. 6.5- Refinamento da matriz de reconstrução no tomógrafo de quarta
geração.
Os detectores são geralmente cristais de óxido de germânio-bismuto ou tungstato de cádmio.
Várias inovações voltadas principalmente para o aumento da velocidade de aquisição foram feitas. Hoje são disponíveis equipamentos com várias fontes, detectores bidimensionais (e não unidimensionais), etc. Entretanto, fogem ao escopo desta explanação, visto que, em engenharia de petróleo, são usados, com bons resultados, mesmo os tomógrafos de segunda geração.
Nestes tomógrafos, é normalmente adaptada uma mesa posícionadora de alta precisão, manual ou automática. Existem fabricantes dessas mesas nos EUA (Western Technology Marketing), porém o controle automático via ’'software" pode ser de instalação problemática inclusive com problemas de "hardware" (CENPES, 1988).
Os tomógrafos de 3- geração têm nesse aspecto a vantagem de uma mesa posícionadora de alta precisão com posicionamento automático via "software", já inerentes ao sistema ( tomógrafo GE 8800 da General Electric, por exemplo).
50
Este aspecto indica muito o uso desse tomógrafo, pois a precisão de posicionamento da mesa é um fator crítico nas aplicações de engenharia, ainda que se possa contra-argumentar com a maior complexidade deste equipamento em relação à geração anterior.
CAPITULO 7
» Elementos Básicos de um Tomógrafo
Um tomógrafo consta basicamente de transdutores, com sua estrutura e dispositivo de posicionamento, e de um sistema de processamento de dados.
7d Transdutores
Geram e repassam as informações ao sistema de processamento de dados.
7.1.1 Tubos de Raios-x : a geração de fótons, que era feita por elementos radioativos (raios y), passou a ser feita através de tubos de raios-x. O tubo de raios-x converte energia elétrica em radiação e calor, este último indesejável.
O tubo é composto por um cátodo de pequena área e um anodo de grande área (para dissipação do calor).
A transferência de elétrons entre esses eletrodos através do vácuo é facilitada não só pela alta diferença de potencial existente entre eles, mas também pelo aquecimento imposto ao cátodo (emissão termiônica, Fig. 7.1) .
Os elétrons assim emitidos são acelerados eletrostaticamente através do vácuo e atingem o anodo segundo um feixe estreito e bem definido (de acordo com a forma e dimensão do cátodo). Quanto menor a região focal (local alvo do feixe no anodo), tanto mais a emissão da radiação parecerá proveniente de uma fonte pontual, o que aumentará a capacidade de se produzir imagens de maior
52
resolução espacial. Entretanto, será maior a necessidade de dissipação do calor gerado no anodo. Este problema é solucionado parcialmente usando-se um grande ánodo circular que rotaciona de maneira a mudar constantemente o material exposto à região focal.
CATODO
ELÉTRONS DE ALTA ENERGIA (-100 KV)
* ENERGIA 4 , I ENERGIA
I POTENCIAL . I CINÉTICA
Fig. 7.1 - O tubo de raíos-x.
Devido à sua baixa taxa de evaporação e dilatação térmica, o tungsténio (ou uma liga sua com rênio) é o material usado na superfície do anodo e será com ele que os elétrons irão interagir. O interior deve ser de um material com boa capacidade calorífica e razoavelmente leve: usa-se, normalmente, molíbdênio ou grafite.
53
O encapsulamento desses componentes tem como função absorver a radiação que não aquela que segue a direção desejada (esta passa através de uma janela, sofrendo uma atenuação mínima) e ainda isolar o tubo eletricamente e proporcionar o vácuo.
Ao atingirem o anodo, a energia cinética dos elétrons é transformada em calor e radiação, através de dois mecanismos: Bremsstrahlung e radiação característica (Fíg- 7.2).
Fig, 7.2 - Mecanismos de geração dos raios-x.
Bremsstrahlung: esse mecanismo é responsável pelo maior número dos fótons gerados (acima de 75%). É uma interação entre os núcleos do material do ánodo e os elétrons incidentes e, dessa forma, a energia do fóton gerado dependerá diretamente da energia do elétron incidente e inversamente da distância do local onde a geração ocorre ao núcleo.
54
Assim, com o aumento do comprimento das circunferências equipotenciais ao se afastar do núcleo, aumentar-se-á o número de elétrons que nelas interagem O espectro de energia dos fótons gerados será, então, contínuo e decrescente com o número de fótons (Fig. 7.3).
NÚMERO RELATIVO DE FÓTONS
eií Irons (68 KeV)
ENERGIA DOS FÓTONS 70
(KeV)
Fig. 7.3 - Bremsstrahlung - espectro energético.
O potencial máximo (chamado KVp e dado em KV) dos fótons gerados será sempre igual ou inferior à diferença de potencial à qual estão submetidos os eletrodos.
Radiação Característica: envolvendo o elétron incidente e outro do átomo do anodo, este mecanismo ocorre quando a energia do primeiro é maior que a de ligação do outro com o respectivo átomo. Com a colisão, a ligação se rompe e o elétron é ejetado deixando uma vaga que é, então, preenchida por um elétron de outro orbital menos energético. Essa transferência é que gera o fóton cuja energia será dada pela diferença entre os níveis energéticos dos respectivos orbitais. Portanto, a energia do fóton gerado dependerá exclusivamente do material usado
55
como anodo e do potencial aplicado ao tubo (que definirá os orbitais do elemento do anodo que poderão ter seus elétrons deslocados). Assim, seu espectro energético terá valores discretos.
O ajuste do espectro da radiação e sua intensidade podem ser controlados com a voltagem e corrente no circuito. Ambos são disponíveis ao operador.
Um exemplo de espectro resultante dos dois mecanismos é mostrado na Fig.
7.4,
NÜMERO DE FÓTONS
Fig. 7.4 - Espectro energético típico de um tubo de raios-x.
O caratér contínuo do espectro é acentuado se a diferença de potencial não for constante no tempo. Isto quase sempre ocorre devido à retificação da energia elétrica de alta voltagem.
O espectro contínuo da radiação favorece a absorção fotoelétrica preferencial dos fótons menos energéticos no material analisado e, por isso, com a penetração no material, a radiação emergente tende a ter uma menor intensidade, porém um maior nível energético (endurecimento do feixe), aumentando sua penetração. Este fato desvia o comportamento exponencial da atenuação (vide 4.3), pois o coeficiente
56
de atenuação depende da energia do fóton, devido à competição entre os dois mecanismos de atenuação. O endurecimento do feixe origina artefatos (item 4.4.3) e pode ter seus efeitos minimizados através de pré-filtração ou correções no "software".
Apesar das aplicações em engenharia de petróleo não possuírem limites de dosagem no material a ser analisado, o tempo de exposição contínua é limitado pela capacidade de dissipação térmica do anodo.
Para que um aumento de temperatura não liquefaça pontos na superfície do anodo, parâmetros como o ângulo, velocidade de rotação e material interno do anodo, além da frequência e forma da onda elétrica após a retificação e da capacidade de dissipação de calor do encapsulamento são regulados de maneira a garantir uma radiação de boa performance com um tempo de exposição contínua maximizado.
Curvas de aquecimento e resfriamento do anodo são normalmente fornecidos pelo fabricante.
Em engenharia de petróleo, as energias utilizadas são muito parecidas com as mais elevadas disponíveis nos tomógrafos médicos. Esses valores vão tipicamente de 100 a 150 KVp. Assim, podem ser usados quase sempre os mesmos tubos.
7.1.2	Detectores : a detecção é importante tanto na aquisição de dados quanto na dosagem de radiação que as pessoas e o meio ambiente presentes durante o ensaio recebem. Entretanto, será dada ênfase para a aquisição de dados, visto que somente aí a aplicação em engenharia de petróleo diferencia-se do uso médico.
Os detectores podem ser de cristal cintilante, de ionização e, promissoramente, detectores de estado sólido.
57
Os dispositivos anexos aos detectores e citados nesta subseção, são substituídos nos tomógrafos por outros com as mesmas funções, porém com potencial multicanal (vide seção 7,2).
Detector Cintilante :
Consiste basicamente de um cristal cintilante (converte a radiação recebida em luz), um tubo fotomultíplicador (converte luz em sinal elétrico) e um amplificador (Fig. 7.5).
Fig. 7.5 - Detector Cintilante.
Cristal: possui a função de absorver e transformar a energia radioativa em luz. Várias substâncias podem ser usadas, mas a mais comum é o iodeto de sódio (tomógrafos de primeira e segunda geração). Não obstante a eficiência da detecção, algumas desvantagens do iodeto de sódio (por exemplo, a resposta não-linear para diferentes intensidades) provocaram o uso de outros cristais como fluoreto de cálcio e germanato de bismuto (este último muito popular nos tomógrafos, porém seu sinal luminoso emergente é bem menos intenso que o do Nal).
O cristal pode ser dopado (por exemplo, com tálio) para se tornar mais eficiente. A eficiência de determinado cristal em capturar fótons de uma fonte
58
radioativa e produzir pulsos luminosos é dada principalmente pela espessura do cristal e pela energia da emanação.
Tubo fotomultiplícador : os pulsos luminosos produzidos no cristal são aí convertidos em pulsos elétricos. Os componentes do tubo fotomultiplícador são contidos em um cilindro de vidro. No contato com o cristal, existe uma camada de um material (fotocatodo), onde ocorrem interações fotoelétricas, gerando emissão de elétrons. Neste ponto, a emissão de elétrons é muito pequena para ser medida e deve ser amplificada.
O posicionamento sucessivo de pares de eletrodos (dinodos) com potencial crescente (gerado externamente), acelera os elétrons que, ao se chocarem com o próximo eletrodo, deslocam, às expensas de parte de sua energia cinética, varios outros elétrons. Esta amplificação é, no último eletrodo, cerca de um milhão de vezes o número de elétrons gerado no cátodo.
A amplitude do pulso elétrico gerado é função do brilho da cintilação, ou seja, da energia da radiação detectada no cristal e das voltagens aplicadas no tubo fotomultiplícador. O ajuste dessas voltagens pode ser usado como um controle de ganho para calibrar o detector em relação ao nível da radiação detectada.
Amplificador: aínda que um milhão de vezes amplificado, o sinal elétrico ainda é pequeno para ser medido. Como uma amplificação excessiva no tubo fotomultiplícador tende a aumentar o nível de ruído, usa-se, então, um amplificador eletrônico que deverá ser linear para manter a relação amplitude de pulso/nível energético da radiação. O ajustamento da amplificação também pode calibrar a resposta de maneira semelhante ao controle de ganho (Fig. 7.6).
Recentemente, emprega-se cristais de iodeto de césio dopado com tálio, acoplados com fotodiodos de silício (cuja sensibilidade é exatamente no comprimento de onda da luz emitida pelo Csl). A grande vantagem desses detectores de estado sólido é que eles podem ser fabricados em qualquer forma e dimensão e, portanto, podem ser concentrados com pequenos vãos entre eles.
FÓTON
Fig. 7.6 - Configuração convencional do detector cintilante.
59
Câmaras de Ionização:
Consistem em dois eletrodos cuja função é coletar os íons formados no volume de gás (xenónio) localizado entre eles.
Como dito no capítulo 4, em ambos os mecanismos de interação dos raios-x com a matéria (espalhamento Compton e absorção fotoelé trica), elétrons são ejetados dos respectivos átomos causando ionização. Dessa maneira, a quantificação da ionização em determinado volume de gás da câmara de ionização mede um parâmetro (chamado de exposição) proporcional à intensidade e ao nível energético da radiação que o atinge.
Pode-se, com diferentes configurações de um galvanómetro acoplado à câmara, medir a taxa ou o acúmulo da exposição durante um determinado período de tempo.
Taxa de exposição : nessa configuração, os eletrodos agem como um capacitor carregado sempre com a mesma carga.
Na ausência de ionização, o isolamento proporcionado pelo gás impede a passagem de corrente entre os eletrodos. A ionização na câmara gera elétrons e íons que, por estarem carregados eletricamente, são arrastados para um ou outro eletrodo, tornando o gás um meio condutor. Nos eletrodos, as cargas dos elétrons e íons são anuladas, tendendo a diminuir a carga presente. A reposição dessa
60
carga gera a corrente no circuito elétrico que pode ser, então, medida e seu valor será proporcional à exposição.
Devidamente calibrado, o medidor de corrente poderá fornecer suas medidas em unidades correntes de exposição, como roentgens/min ou 1.000 roentgens/hora (Fig. 7.7).
Fig. 7.7 - Configuração da câmara de ionização para taxa de exposição.
Exposição acumulada: essa configuração é representada na Fig. 7.8 e consiste de três etapas:
-	carga: antes da exposição à radiação, os eletrodos são carregados eletricamente como um capacitor até a saturação. A carga presente ao final desse processo será dependente da forma e área dos eletrodos, além da distância entre eles e das características dielétricas do gás da câmara.
Desconecta-se a bateria dos eletrodos. As cargas permanecerão inalteradas já que não há meio condutor ligando os eletrodos.
-	exposição: os raios-x ionizam o gás que se torna condutor. Os íons e elétrons do gás ao encontrarem os respectivos eletrodos para onde são arrastados, diminuem a carga presente nos mesmos.
-	medição: a diferença de potencial entre os eletrodos ao final da exposição será inversamente proporcional à carga anulada, ou seja, à exposição. Calibrado
61
CARGA
EXPOSIÇÃO
MEDIÇÃO
Fig, 7.8 - Configuração da câmara de ionização para exposição acumulada.
adequadamente, poderá fornecer diretamente valores em roentgens ou 1.000 roent-gens. .
Na prática, medidas de exposição acumulada são feitas em pequenos intervalos de tempo para se prevenir a descarga dos eletrodos devido a outros fatores como umidade do material da carcaça da câmara. Para corrigir os efeitos de ionização dos elétrons ejetados na interação com o material do eletrodo, calibra-se a câmara com outra padrão onde os eletrodos não são expostos à radiação.
62
Vários fatores de correção são usados para corrigir as diversas condições de exposição.
A parede frontal da câmara de ionização é dimensionada de acordo com o nível de energia a ser medido: elas desempenham um papel importante ao absorverem uma parte significante da radiação que as atravessam. Essa interação gera elétrons energéticos que entrarão no volume de gás e também produzirão ionização. Assim, uma parede frontal espessa é muito importante quando o nível energético for alto pois, de outra forma, a radiação penetraria totalmente a câmara sem ser medida. Por outro lado, à baixa energia, a parede frontal deve ser fina o suficiente para não reduzir a ionização e, consequentemente, a eficiência da resposta da câmara.
Outro fator importante é o nível de voltagem aplicado nos eletrodos, pois o elétron ejetado de um átomo (que passa a ser um ion) pode se recombinar com este ou outro íon: se isto ocorrer, este par elétron-íon deixará de atingir os respectivos eletrodos e não serão, portanto, medidos. Essa recombinação é evitada pelo potencial de atração dos eletrodos, ou seja, pela voltagem de carga desses eletrodos.
A voltagem de carga necessária é dependente da forma e tamanho dos eletrodos, além da taxa de ionização que se produzirá. Quando nenhuma recombinação ocorre, diz-se que a câmara está saturada. Para taxas de ionização muito altas, muitas vezes a saturação não é atingida e se faz necessário o uso de fator de correção.
Para aumentar a eficiência de detecção, o gás xenônio é pressurizado (8-10 atm) com a eficiência passando para cerca de 60%.
Devido ao custo bem menor em relação aos detectores cintilantes e ao grande número de detectores necessários aos tomógrafos de 3- geração, as câmaras de ionização são neles preferencialmente utilizadas. O posicionamento relativo fonte-detector variável impede a utilização das câmaras nos tomógrafos de 4a
63
geração, pois as câmaras devem ter uma configuração longa e estreita com o eixo longitudinal apontado para a fonte de radiação (a alta colímação è inerente às câmaras de ionização).
7.2	Sistema de Processamento de Dados
É composto pelo sistema de aquisição de dados, unidade de processamento central ("CPU"), memória, dispositivos de entrada-saída e periféricos (Fig. 7.9).
7.2.1 Sistema de Aquisição de Dados : faz a interface dos transdutores com a "CPU". O sistema converte o sinal elétrico dos transdutores para um sinal digital e o transmite para a CPU. É uma das partes mais caras e sofisticadas do tomógrafo e qualquer disfunção sua trará consequências graves na imagem reconstruída.
Uma configuração comum para esse sistema é exemplificada na Fig. 7.10. Como o comportamento da atenuação é exponencial, a variação da magnitude entre os dados pode atingir um fator de 10. Para uma medição precisa dos valores, eles devem ser amplificados e ter sua variação de magnitude reduzida. Isto é feito com amplificadores logarítmicos que devem ser periodicamente calibrados para se manter constante suas características com o tempo e variação das condições ambientais.
Após a amplificação, o sinal é integrado durante certo tempo (durante o pulso do tubo de raios-x) em integradores multicanal. Nesses integradores, o sinal é conservado até que possa ser recebido na etapa seguinte, quando, então, libera o circuito para nova integração.
A próxima etapa é feita nos conversores analógico-digital, onde os sinais elétricos, usualmente de voltagem, são recebidos por um gerenciador multicanal (MUX) e convertidos em um código numérico.
64
Fig. 7.9 - Sistema de Processamento de Dados.
7.2.2 Unidade de Processamento Central:	é responsável pela manipulação
aritmética dos dados e corresponde exatamente ao que se conhece por "CPU" nos computadores.
A adaptação da tomografia à engenharia implica em pós-processamento dos dados onde parâmetros do ensaio serão obtidos ( por exemplo, saturações de fluidos, reconstruções de seções angulares às medidas e imagens tridimensionais). Esse pós-processamento é quase sempre feito por um computador de maior porte, separadamente do computador dedicado do sistema.
Idealmente, a ligação entre esses computadores deve ser direta, porém é comum a transferência de dados através de "floppy-díscs" ou fitas (processo lento).
A utilização de outro computador torna possível a otimização do uso do equipamento, pois o desimpede para novo ensaio.
65
o » K E Ü T P E O C
T
1 O
R
O E E S
1	MCI	
J	MUX	
G	»
R	E
U	T
P	E
O	C
T
2	O
R
I&gt;	E
E	S
MUX
MUX
MUX
MUX
G D R E U T P E
O C
T
3 O
R
D E
E S
MCI + MUX
Z]	MCI		
	MUX		
	MCI		M
	4*		U
	MUX		
			X
	MCI +		
	MUX		
- MUX ~ DIGITAL

MEMÓRIA

CPU
ADC = MUX = MCI =
CONVERSOR ANALÓGICO-DIGITAL GERENCIADOR MULTICANAL INTEGRADOR MULTICANAL
Fig. 7.10 - Sistema de Aquisição de Dados.
66
723 Memória:	os dados não usados pela "CPU" em determinado momento
são armazenados em algum tipo de memória. A grande diferença entre os vários tipos de memória é o tempo de acesso e o custo por "bit" armazenado.
Memórias magnéticas (por exemplo, "floppy-disks" ou fitas magnéticas) tem um custo mais baixo e são não-voláteis (não se perde as informações ao se desligar o sistema), porém o tempo de acesso é alto (da ordem de IO'1 segundos).
Memórias de semicondutores podem ter um custo maior, porém sempre associado a um tempo de acesso bem menor (da ordem de 10'6 segundos para semicondutores de óxido-metálico com acesso randômíco de memória, MOS-RAM). São, quase sempre, voláteis.
Devido ao longo tempo de acesso das memórias magnéticas e à volatilidade das memórias de semicondutores, elas são usadas conjuntamente: a primeira para armazenamento duradouro e a segunda para processamento imediato.
7.2.4	Dispositivos de entrada-saída: fazem a comunicação com o exterior. Recuperam ou armazenam imagens em disco e mostram imagens em vídeos ou impressoras.
A transferência desses dados pode ser feita através da CPU ("programmed I/O") ou através de canais de dados.
7.2.5	Periféricos:	usados para estocar e mostrar os dados gerados pelo
sistema, incluem impressoras, discos, cassetes, terminais de vídeo e console de operações.
Os terminais de vídeo e impressoras bicolores permitem ao operador uma visualização máxima de 64 tons. Esses periféricos são disponíveis em alguns equipamentos em multicor. São particularmente interessantes em engenharia de petróleo,
67
onde se pode associar, por exemplo, gás à cor vermelha, óleo ao azul e verde à fase aquosa.
Os periféricos interativos desempenham a importante função de dar certo controle do sistema ao operador. Entre eles estão: teclado, "joysticks", "mouse", caneta óptica e mesa digitalizadora.
O armazenamento de imagem é feito normalmente em filmes ou discos. Para os últimos, valem os comentarios feitos para a memória magnética, já que se tratam dos mesmos dispositivos. Os filmes possuem, sobre os discos, a vantagem de não ocuparem o sistema de processamento para nova visualização da imagem, liberando-o, assim, para uso. Perdem, no entanto, o caráter quantitativo, fundamental à engenharia.
7.2.6	Linguagens:	apesar da "CPU" trabalhar em linguagem de máquina que
manipula os dados mais eficientemente, quase sempre estão presentes interpretadores ou compiladores de linguagens de alto nível (Fortran, Cobol, PL/1, C, etc).
Muitas das alterações recentes e provavelmente futuras, se devem ao desenvolvimento do "software" e não do "hardware" como, por exemplo, avaliação estatística de dados, manipulação de imagem, além da redução do tempo de reconstrução.
7.2.7	"Software":	o processamento inicial pode ser feito com o "software"
fornecido junto com o tomógrafo, enquanto o pós-processamento deve ser feito com "software" específico para aplicações em engenharia de petróleo e/ou geologia que pode ser desenvolvido no país ou comprado.
Entre as características que deve ter, destacam-se a flexibilização do controle de dosagem e da energia do tubo e filtros adequados aos materiais comuns à nova área de aplicação.
68
Esta exposição foi baseada principalmente em Hendee (1983) e Sprawls (1987).
CAPÍTULO 8
» Análises Experimentais
Foram usados equipamentos médicos e um minitomógrafo multidisciplinar.
Faz-se necessário, quase sempre, localizar com exatidão uma seção já to-mografada. Isto é devido, quase sempre, às operações com imagens, mas pode ser solucionado com um bom dispositivo de posicionamento acoplado à mesa (a luz usada no tomógrafo médico é muito imprecisa) ou outro independente como uma guia estereostática.
8.1	Equipamentos Médicos
Com o objetivo de se avaliar o potencial dos equipamentos médicos para a análise de rochas, que são materiais mais densos do que aqueles para os quais foram projetados, foram feitos ensaios com tomógrafos médicos, quais sejam:
8.1.1 Avaliação Morfológica:	para esta experiência foi usado um tomógrafo
da CGR, modelo CR 10.000, com	o seguinte ajuste de parâmetros:
tensão do tubo	130 KVp
corrente do tubo	100 mA
filtro	F3 (para tecido ósseo)
matriz de reconstrução	512x512
tempo de exposição	6,8 segundos
	69
70
espessura da seção
diâmetro da área de reconstrução
janela
nível da janela
1 mm
131 mm
3000 HU
1600 HU
Foi utilizado um testemunho “full-diameter” (diâmetro = 0.10 m) de um
conglomerado.
Fig. 8.1 - Tomograma de um Conglomerado
A comparação do tomograma (Fig. 8.1) com a foto da seção do testemunho (após a tomografia o testemunho foi serrado na seção de corte, fig. 8.2), mostra, nos lados esquerdo e direito, seixos de composição semelhantes e entre eles vários fragmentos de rocha.
71
Fig. 8.2 - Foto da Seção Tomografada do Conglomerado
Apesar dos artefatos presentes (endurecimento do feixe) devido a materiais de alta densidade presentes, o tomograma apresentou uma descrição bastante razoável da seção em estudo. Deve-se, prioritariamente, analisar a possibilidade de minimização desses artefatos, usando-se, por exemplo, outra função filtro.
Conseguir uma função filtro é, por outro lado, uma tarefa bastante complexa e envolve vários parâmetros como geometria do tubo de raios-x e dos detectores (Miraldi &amp;amp; Wiesen, 1988).
8.1.2	Análise qualitativa da distribuição de porosidade:	feito apenas com
uma tomografia (vide item 5.2), este experimento pode, apenas grosseiramente, ser
72
chamado por este nome, sendo, na realidade, uma análise da distribuição da densidade.
Devido à razoável homogeneidade da amostra (arenito), no entanto, pode-se considerar este tomograma como uma distribuição aproximada da porosidade.
O equipamento e os parâmetros de ajuste são os mesmos do experimento anterior, com exceção dos seguintes:
janela	1600 HU
nível da janela	1622 HU
Fig. 8.3 - Tomograma de um Arenito Homogêneo
A observação do tomograma (fig. 8.3), mostra alguns pontos de alta densidade, duas regiões maiores (uma ao centro e outra no quadrante superior esquerdo) com densidades altas predominantes, intercaladas com densidades baixas. A região
73
restante mostra, ao contrário, uma predominância de baixa densidade com intercalações de alta.
Essas regiões devem apresentar, portanto, um comportamento crescente de porosidade.
8.13 Análise mineralógica:	para este experimento foram usados os
equipamentos CR 10.000 e Elscint 2002.
Foi construída uma amostra em um cilindro de acrílico de 7,2 cm de diâmetro interno e 16 cm de altura, preenchido com água e areia e, em 5 seções, foram colocados alguns minérios e rochas com a disposição mostrada na figura 8.4. Os minérios e as densidades na escala Hounsfield estão na tabela 8.1. Em uma sexta seção foram colocados dois tubos contendo solução de Kl 1 N e óleo UNIPAR (densidade 0,7759 g/cm3 @ 23°C.
A Fig. 8.5 e 8.6 mostram "Scout-Views " (vista perpendicular às seções de corte) do cilindro e as posições das seções de corte.
Os valores da tabela 8.1 apresentam clara relação com os obtidos por Honarpour, 1985, e ilustram, juntamente com o ensaio do item 8.1.1, as análises descritas no item 5.5 (análise de litologia e heterogeneidades) As divergências entre os valores, seja entre os dois experimentos, seja com o de Honarpour, devem ser creditadas à orientação do feixe de raios-x em relação ao eixo cristalográfico do sólido, a contaminações por elementos de alto número atômico ou ainda a porosidades não corrigidas das amostras. Note-se, por exemplo, aos valores diferentes obtidos em um mesmo equipamento (CR 10.000) para a mesma amostra em duas orientações diferentes em relação ao feixe de raios-x (granito 2438 e 2608 HU e feldspato, 1931 e 1962 HU) ou mesmo para um minério em amostras diferentes (feldspato, 2005 HU e 1931/1962 HU).
74
Fig. 8.4 - "Scout-View" do Cilindro Padrão
Mineralógico - Vista de Perfil
Fig. 8.5 - "Scout-View" do Cilindro Padráo Mineralógico - Vista Superior
75
Amostra / densi-dade (HU)	experimental		Honarpour et al. (1985)
	CR 10.000	Elscint 2002	
calcita	2611	2420	2443
feldspato	2005, 1961, 1932	2640	
quartzito	1996	2650	-
talco	2113	2760	-
citrino	1871	2550	•
fluorita	2999	-	3156
granito	2438, 2608	2760	
quartzo verde	1913, 1920	2550	-
ônix	2432	2606	
quartzo	1886, 1889	2600	1800
dolomita	2601	2340	2296
sodalita	1540	2180	-
grafita	2993	-	1546
calcita laranja	2776	-	-
ardósia	1929	2900	-
óleo UNIPAR	-253	-	
solução Kl 1 N	2030	-	-
Tabela 8.1 - Diferenciação de Rochas e Minérios pela Tomografia de Raios-x
8.1.4	Análise do potencial de determinação quantitativa da distribuição de porosidade e saturação de fluidos em sistemas bifásicos:	este experimento foi
feito com o equipamento Elscint 2002.
Foram usados dois testemunhos "whole-core" de 0,10 m de diâmetro (um calcarenito e um arenito com grãos médios). Eles foram tomografados em três situações diferentes: saturados com ar, solução 1 N de iodeto de potássio (calcarenito saturado a 95,4 % e arenito saturado a 97,8 %) e com óleo UNIPAR (densidade 0,7559 g/cm3 @ 23°C). As seções foram marcadas com ranhuras circulares e, para a comparação das tomografias da mesma seção, foi feita uma ranhura longitudinal que identificará a rotação entre os tomogramas.
76
Fig. 8.6 - Calcarenito
Limpo - Seção
Transversal 1
Janela = 1812 HU
Nível = 1812 HU
Fig. 8.7 - Calcarenito
Saturado com Solução
Kl 1 N - Seção Transver-
sal 1
Janela = 3405 HU
Nível = 2156 HU
Fig. 8.8 - Calcarenito Saturado com Óleo - Seção Transversal 1
Janela = 3408 HU
77
Fig. 8.11 - Calcarenito Saturado com Óleo - Seção Transversal 2
Janela = 4096 HU
Fig. 8.9 - Calcarenito Limpo - Seção
Transversal 2
Janela = 1812 HU
Nível = 1812 HU
Fig. 8.10 - Calcarenito Saturado com Solução Kl 1 N - Seção Transversal 2 Janela = 3405 HU
Nível = 2156 HU
.¿Ai	v	jjcL A
78
Fig. 8.12 - Calcarenito
Limpo - Seção
Transversal 3
Janela = 1812 HU
Nível = 1812 HU
Fig. 8.13 - Calcarenito
Saturado com Solução
Kl 1 N - Seção Trans-
versal 3
Janela = 3405 HU
Nível = 2156 HU
Fig. 8.14 - Calcarenito Saturado com Óleo - Seção Transversal 3
Janela = 3400 HU
79
As diferenças entre os tomogramas da
mesma seção (figuras 8.7 a 8.21) são
prioritariamente devidas ao fluido presente.
Devido à grande atenuação causada
pelo iodeto ñas
imagens do calcarenito em que está presente,
pode-se visualizá-lo
são devidas ao aprisio-
em branco. As partes escuras na periferia do testemunho namento de ar (deficiência na saturação).
Fig. 8.15 - Arenito
Saturado com Solução
Kl 1 N - Seção Trans-
versal 1
Janela = 3026 HU
Nível = 2279 HU
Nível = HU
Fig. 8.16 - Arenito Saturado com Óleo - Seção Transversal 1
Janela = 3026 HU
Nível = 2278 HU
CILINDRO 3-CORTE £
80
Fig. 8.17 - Arenito
Saturado com Solução Kl 1 N - Seção Transversal 2
Janela = 3026 HU
Nível = 2279 HU
/
Fig. 8.18 - Arenito Saturado com Óleo - Seção Transversal 2
Janela = 3026 HU
Nível = 2278 HU
Nas imagens do calcarenito saturado com ar e com óleo, devido ao menor coeficiente de atenuação linear desses fluidos em relação à rocha, visualiza-se preferencialmente a estrutura interna da amostra. As diferenças entre os dois tomogramas são devidas à diferenças de atenuação dos fluidos.
Mostra-se, com isso a viabilidade de se fazer análises de porosidade, de saturação e, consequentemente, de ensaios de escoamento bifásico (itens 5.1, 5.2, 5.4). O uso de dopantes para a fase óleo (por exemplo, chumbo tetra-etila),
81
tornaria mais evidente as diferenças entre os tomogramas (Wellington &amp;amp; Vinegar,
1987b).
Fig. 8.19 - Arenito
Saturado com Solução Kl 1 N - Seção Longitudinal Janela = 3026 HU
Nível = 2279 HU
7
Fig. 8.20 - Arenito Saturado com óleo - Seção Longitudinal
Janela = 3031 HU
Nível = 2278 HU
Os tomogramas do arenito mostram um escurecimento nas imagens com óleo presente, confirmando seu menor coeficiente de atenuação linear em relação à solução de iodeto de potássio.
82
A diferenciação de textura das seções transversais (Fig. 8.16 a 8.19), explica-se claramente ao se observar a seção longitudinal (Fig. 8.20 e 8.21).
É gritante uma maior homogeneidade na saturação do arenito em relação ao calcarenito . A explicação deste fato parece ser a homogeneidade da distribuição da permeabilidade em todo o arenito.
8.1.5 Análise de compactação : foi usado o equipamento da CGR. O procedimento foi a obtenção, através de compactação de areia fina (mesh tyler maior que 16), de corpos com densidades (compactações) distintas (vide Tabela 8.2). Estes corpos foram então tomografados no mesmo nível e janela.
Para se encontrar a relação entre as duas densidades (Hounsfield e mássica), seria necessário um número bem maior de pontos. Esta análise não está, entretanto, entre os objetivos deste trabalho.
A areia foi escolhida por ser semelhante à rochas reservatórios comuns (arenitos).
Amostra \ densidade	exp. CTX (HU)	exp. convencional (g/cm )
1	973	1,47
2	985	1,57
Tabela 8.2 - Resultados do Ensaio de Compactação
8.2	Mini-tomógrafo Multidisciplinar
a
Para essas análises foi usado um minitomógrafo de 1 geração (Cruvinel &amp;amp; Mascarenhas, 1987) construído para fins de análises de solo (Crestana et al, 1985, 1986, 1988). Este equipamento encontra-se no NPDIA - Núcleo de Pesquisa e
83
Desenvolvimento de Instrumentação Agropecuária da EMBRAPA em São Carlos -SP.
Devido as características desse modelo, foi usado, ao contrário dos outros experimentos, amostras com dimensões de “plug” (&amp;lt;/&gt; = 1" ). Essas amostras foram construídas com esferas de vidro coladas.
A colimação usada para a fonte foi de 1 mm. Todas as imagens foram geradas com passo linear de lmm (translação total de 40 mm) e passo angular de 2,5° (rotação total 180°), gerando uma matriz de dados 72x40.
8.2.1 Análise de porosidade: foram usados duas amostras com porosidades de 39,8 % (amostra Al) e 35,0 % (amostra A2).
Foram feitos tomogramas com as amostras saturadas com ar (experimento Alar e A2ar), água (A2a) e óleo marítimo (Alo). Em todos os casos, a fonte de radiação é o Am241 (60 KeV).
Os experimentos foram feitos com um tempo de contagem de fótons de 5 segundo para cada perfil adquirido.
As matrizes já reconstruídas (matriz imagem) foram subtraídas, vide item 5.2, de maneira a fornecer uma matriz com valores proporcionais à da porosidade. A matrizes de dados apresentam a contagem de fótons no período de 5 segundos de aquisição. Como a emissão de fótons é um processo estatístico, o ruído da imagem será tanto menor e os números da contagem tanto maiores, quanto maior for o tempo de contagem. Devido a não unicidade da matriz de dados para uma mesma amostra (depende da distância entre a fonte e o detector, atividade da fonte e tempo de contagem), essas matrizes não são apresentadas. As outras matrizes não foram apresentadas por motivo de concisão e por não guardarem uma relação direta, mas sim proporcional, com grandezas físicas, como o coeficiente de atenuação linear, densidade (matriz imagem) ou porosidade (matriz subtração).
I
84
Assim, são apresentados imagens em que as cores guardam uma proporção com a densidade (Fig. 8.22 e 8.24) e a porosidade (Fig. 8.23 e 8.25), não estando disponível, no entanto, essa conversão.
As imagens foram obtidas com o "software" IDRISI.
85
Fig. 8.21 - Tomograma dos Experimentos Alar e Alo
Fig. 8.22 - Imagem de Porosidade da Amostra Al
86
DENSIDADE
Fig. 8.23 - Tomograma dos Experimentos A2ar e A2a
Fig. 8.24 - Imagem de Porosidade da Amostra A2
» Conclusões
O presente trabalho permite concluir que :
•	A tomografia computadorizada de raios-x é uma técnica de valor inestimável provendo uma maneira rápida e prática para se conseguir resultados qualitativos (com potencial quantitativo) em análises de testemunhos proporcionando, devido à inerente capacidade de medição de propriedades "pontuais", uma visualização de diversos fenômenos interiores à amostra.
•	Ficam comprovadamente viáveis as análises em testemunhos, usando-se tomógrafo médico, nos seguintes ensaios: medição de saturação em sistemas bifásicos, medição de compactação, definição de heterogeneidades, morfologia de inclusões e caracterização mineralógica.
•	A quantificação dessas análises depende da disponibilidade das imagens digitalizadas e de um mecanismo eficiente e preciso de posicionamento da amostra no tomógrafo.
•	A comprovação da possibilidade de se utilizar um tomógrafo de uso médico viabiliza análises de testemunhos com caráter tecnológico avançado associadas a um baixo custo (locação do equipamento ou compra de um equipamento recondicionado) comparativamente ao da aquisição de um equipamento novo.
» Recomendações e Sugestões para Trabalhos Futuros
Não obstante as dificuldades de se conseguir a instalação de um laboratório de tomografia computadorizada para a engenharia de petróleo no país, acredita-se que os resultados seriam sem dúvida recompensadores como atestam ainda vários outros centros de pesquisa no mundo inteiro.
A possibilidade de co-utilização dos equipamentos pela engenharia e pela medicina pode trazer benefícios para ambas as partes, mas dificilmente poderá ocorrer sem uma melhor compatíbilização do tomógrafo com os outros equipamentos envolvidos.
Esta alternativa pode solucionar alguns problemas como a sub-utilização do equipamento e o alto investimento inicial envolvido e ainda daria à engenharia a chance de utilizar um equipamento de tecnologia recente (3â ou 43 geração).
Como opção a este caminho, pode-se adquirir um tomógrafo médico recondicionado de 2â geração que talvez seja o mais indicado para se equipar um laboratório menor, exclusivo da engenharia de petróleo, devido ao seu custo, ao razoável tempo de aquisição de dados e relativa simplicidade.
Entre os estudos que deverão ser feitos, destacam-se:
♦ Interfaceamento com sistemas poderosos de pós-processamento e armazenamento de imagens. O provimento de uma interface comunicação rápida e eficiente com outros sistemas que efetuariam o pós-processamento necessário, daria ao sistema de aquisição de dados uma opção de aprovei-
89
lamento muito mais racional e um potencial muito maior para o sistema como um todo. Pode-se então, com ’’hardware” e "software” prover o sistema com recursos de processamento de imagem avançados como, por exemplo, visualização 3-D, utilização de cores para identificação de minerais e/ou fluidos e animação para validação de simulações.
•	Com o laboratório instalado, poder-se-á, então, realizar as análises citadas nesse trabalho (capítulos 2 e 5) de maneira quantitativa e mais crítica com a utilização de recursos novos como "core-holders” transparentes à radiação e posicionamento mais preciso da amostra.
•	O conhecimento dos algoritmos matemáticos de reconstrução e, principalmente, de filtragem também devem cumprir um papel relevante em pesquisas futuras, pois ao serem adaptados ao conjunto de materiais correntes na engenharia de petróleo, devem produzir efeitos imediatos na redução e/ou eliminação de artefatos como os da Fig. 8.1 e 8.12.
•	Para ambas as etapas (adaptação do sistema e análises) seria de grande proveito o intercâmbio com centros de pesquisas que já tenham excelência na área e, se possível, que possuam equipamentos semelhantes. Alguns desses centros são: Instituto Francês de Petróleo (tomógrafo médico adaptado), Universidade de Stanford e Universidade do Texas (tomógrafo para engenharia).
A opção por um equipamento que não o de uso médico pode aproximar a pesquisa na área de petróleo com outros ramos como : ciência dos solos, engenharia civil, bioengenharia, etc. Na área de ciência dos solos, por exemplo, já existe, no Brasil, um núcleo de pesquisa (EMBRAPA/NPDIA- São Carlos, SP) com capacitação na área que inclusive permitiu a construção do equipamento usado na análise do item 8.2.1.
Bibliografia
American Petroleum Institute: “Recommend Practice for Core-Analysis Procedure”, RP-40, API, 1960.
Amyx, J.W., D. M. Jr., Bass &amp;amp; Whiting, R. L. : “Petroleum Reservoir Engineering
-	Physical Properties”, McGraw-Hill Book Co. Inc., (N.Y. 1960), 52, 184-188,
Bates, R.H.T.; Garden, Kathryn L.; Peters, Terence M.: “Overview of Computerized Tomography with Emphasis on Future Developments”, Proc. IEEE (1983) 7.1, 356-72..
Bergosh, J.L., Marks, T.R. &amp;amp; Mitkus, A.F.: “New Core Analysis Techniques for Naturally Fractured Reservoirs”, artigo SPE 13653 apresentado no “SPE 1985
-	California Regional Meeting” em Bakersfield, 27 a 29 de março.
Brooks, R.A. &amp;amp; DiChiro, G.: “Principles of Computer Assisted Tomography”, Physics in Medicine &amp;amp; Biology", 21, n° 5, 690-732, setembro de 1976.
CENPES : Pornografia Computadorizada Aplicada à Geologia e Engenharia de Petróleo”, Relatório Final do GT-CENPES 07/88.
Crestana, S.: "A Tomografia Computadorizada como um novo Método para Estudos da Física da Água no Solo", Tese de Doutorado do IFQSC-USP, 1985.
Cruvinel, P. E. &amp;amp; Oliveira, S.M.: “Minitomógrafo de raio-x e raio-gama Computadorizado para Análises Multidisciplinares”, Tese de Doutorado do Departamento de Automação Industrial, FEE-UNICAMP, 1987.
Fonseca, L. &amp;amp; Tozzi, C., “O uso da cor no processamento digital de imagem”, Tese de Mestrado do Departamento de Automação Industrial, FEE-UNICAMP, 1990.
91
Greenleaf, James F.: “Computerized Tomography with Ultrasound”, Proc. IEEE, 71 330-37, 1983.
Hendee, William R.: “The Physical Principles of Computed Tomography”, Little, Brown and Company, Boston/Toronto, 1983.
Hinshaw, W.S. &amp;amp; Lent, A.H.: “An Introduction to NMR Imaging: From the Bloch Equation to the Imaging Equation”, Proc. IEEE (1983) 71 338-50.
Honarpour, M.M., McGee, K.R., Crocker, M.E., Maerefat, N.L., Sharma, B.: “Detailed Core Description of a Dolomite Sample From the Upper Madison Limestone Group”, artigo SPE 15174 apresentado no “SPE 1986 - Rocky Mountain Regional Meeting” em Billings, M.T., 19 a 21 de maio, 1986.
Honarpour, M. M.; Cromwell, V.; Halton, D.; Satchwell, R.: “Reservoir Rock Descriptions using Computed Tomography”, artigo SPE 14272, apresentado no "60th Annual Technical Conference and Exhibition of the Society of Petroleum Engineers", Las Vegas, NV, 22 a 25 de setembro de 1985.
Hove, A.O., Ringen, J.K. &amp;amp; Read, P.A.: “Visualiztion of Laboratory Corefloods with the Aid of Computerized Tomography of X-Rays”, SPE Reservoir Engineering, maio, 1987.
Hunt, Patricia K. , Engler, Philip &amp;amp; Bajsarowics, C.: “Computed tomography as a Core Analysis Tool: Applications and Artifact Reduction Techniques”, artigo SPE 16952 apresentado no “SPE 1987 - 62nd Annual Conference and Exhibition ” em Dallas, Texas, 27 a 30 de setembro.
Laird. A.D.K. &amp;amp; Putnam, J.A.: “Three Component Saturation in Porous Media by X-Ray Techniques”, Trans., AIME (1959) 216, 216-20 .
Miraldi, Floro &amp;amp; Wiesen, Ernest J., “Imaging Principles in Computed Tomography.”. In John R. Haaga &amp;amp; Ralph J. Alfidi (ed.).: “Computed Tomography of the Whole Body”, The C.V. Mosby Company, 1988.
Morgan, F.; McDowell, J.M. &amp;amp; Dotty, E.C.: “Improvements in the X-Ray Saturation Technique of Study ng Fluid Flow”, Trans., AIME, .189., 183-94, 1950.
92
Parsons, R.W.: “Microwave Attenuation - A New Tool for Monitoring Saturations in Laboratory Floodings Experiments”, SPEJ, 302-10, agosto, 1975.
Sprawls, Perry, Jr.: “Physical Principles of Medical Imaging”, Aspen Publishers, Inc.; Rockville, Maryland, 1987.
Vinegar, H.J.: “X-Ray CT and NMR Imaging of Rocks”, J.Pet. Tech. , 257-259, março, 1986.
Wang, Simon Y., Ayral, Seyda, Castellana, F.S. &amp;amp; Gryte, Carl C.: “Reconstruction of Oil Saturation Distribution Histories During Immiscible Liquid-Liquid Displacement by Computer-Assisted Tomography”, AIChE Journal M 642-47, julho, 1984.
Wellington, Scott L. &amp;amp; Vinegar, Harold J.: “X-Ray Computerized Tomography”, J. Pet. Tech., 885-898, agosto, 1987a.
Wellington, Scott L. &amp;amp; Vinegar, Harold J.: “Tomographic Imaging of Three-Phase Flow Experiments”, Rev. Sci. Instrum,, 96-107, janeiro, 1987b.
Withjack, E.M.: “Computed Tomography for Rock-Property Determination and Fluid-Flow Visualization”, SPE Formation Evaluation, 696-703, dezembro, 1988.</field>
	</doc>
</add>